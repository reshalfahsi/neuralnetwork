{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cfa4e8da8674385b6099adb6ed01c4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6794aaf98ffa42e48561a9bb697c4d5f",
              "IPY_MODEL_25978f1233ca48a7997228c08efa3490",
              "IPY_MODEL_79690c6507fc49df9623694e309a8d3a"
            ],
            "layout": "IPY_MODEL_3cb0ef9960b247a487588fe44f47a170"
          }
        },
        "6794aaf98ffa42e48561a9bb697c4d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3016aed40443434ebb6f774303f1e87e",
            "placeholder": "​",
            "style": "IPY_MODEL_4f374a5a8fbf4c999c666caf5ccbf4ab",
            "value": "100%"
          }
        },
        "25978f1233ca48a7997228c08efa3490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3467f7b5576b4613b48984d96b4c0951",
            "max": 4170669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1de2eeabb384653aa14158200a9a4e0",
            "value": 4170669
          }
        },
        "79690c6507fc49df9623694e309a8d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70d3d8b018d240acbcc29888dbcbcd45",
            "placeholder": "​",
            "style": "IPY_MODEL_3e88c12564e242edb8e810f3e9cffd14",
            "value": " 4170669/4170669 [00:41&lt;00:00, 432308.07it/s]"
          }
        },
        "3cb0ef9960b247a487588fe44f47a170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3016aed40443434ebb6f774303f1e87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f374a5a8fbf4c999c666caf5ccbf4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3467f7b5576b4613b48984d96b4c0951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1de2eeabb384653aa14158200a9a4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70d3d8b018d240acbcc29888dbcbcd45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e88c12564e242edb8e810f3e9cffd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reshalfahsi/neuralnetwork/blob/main/notebook/NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Package**"
      ],
      "metadata": {
        "id": "UZ6VNZ_J8985"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjSHb5zz80lj"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/reshalfahsi/neuralnetwork\n",
        "%cd neuralnetwork\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameters**"
      ],
      "metadata": {
        "id": "X48H-uAIA5zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 16\n",
        "lr = 1e-4"
      ],
      "metadata": {
        "id": "_bppSEPgA5EV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Preparation**\n",
        "\n",
        "This tutorial will use a toy dataset from [MedMNIST](https://medmnist.com/). We use PneumoniaMNIST, which contains 2D X-ray image-label pairs for distinguishing between Pneumonia-infected and healthy lungs. The pneumonia-infected lung is denoted by the label `1` whilst the healthy lung is labeled as `0`."
      ],
      "metadata": {
        "id": "lUMo0jOu-2Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neuralnetwork.ds.medmnist import PneumoniaMNIST\n",
        "from neuralnetwork import ds\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "train_dataset = PneumoniaMNIST(split='train', download=True)\n",
        "test_dataset = PneumoniaMNIST(split='test', download=True)\n",
        "\n",
        "print(\"Train Dataset:\", len(train_dataset))\n",
        "print(\"Test Dataset\", len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "8cfa4e8da8674385b6099adb6ed01c4b",
            "6794aaf98ffa42e48561a9bb697c4d5f",
            "25978f1233ca48a7997228c08efa3490",
            "79690c6507fc49df9623694e309a8d3a",
            "3cb0ef9960b247a487588fe44f47a170",
            "3016aed40443434ebb6f774303f1e87e",
            "4f374a5a8fbf4c999c666caf5ccbf4ab",
            "3467f7b5576b4613b48984d96b4c0951",
            "c1de2eeabb384653aa14158200a9a4e0",
            "70d3d8b018d240acbcc29888dbcbcd45",
            "3e88c12564e242edb8e810f3e9cffd14"
          ]
        },
        "id": "tiUOUneg--hw",
        "outputId": "44e345a0-9005-4176-c2ed-3599e563dd9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1 to /root/.medmnist/pneumoniamnist.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4170669 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8cfa4e8da8674385b6099adb6ed01c4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n",
            "Train Dataset: 4708\n",
            "Test Dataset 624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.montage(length=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "1iQt-dlo_077",
        "outputId": "45c29800-db9e-4a8e-fca9-2dd80108cb68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=560x560 at 0x7FA5ED440F50>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Neural Network**\n",
        "\n",
        "The artificial neural network is a bio-inspired machine learning method that models neuronal signal propagation by matrix multiplication. Here we have two kinds of neuronal signal propagation: forward propagation and backward propagation. In forward propagation, the neuron actively conveys information from the \"receptor\" (or input) to the \"central nervous system\" (or output). Backward propagation or backpropagation, in short, is utilized in the training or learning process. In the learning process, the neural network transmits error gradients from the \"central nervous system\" to the \"receptor\". For further knowledge about the learning process, read more: [Calculus on Computational Graphs: Backpropagation](https://colah.github.io/posts/2015-08-Backprop/) and [Backpropagation for a Linear Layer\n",
        "](https://web.eecs.umich.edu/~justincj/teaching/eecs442/notes/linear-backprop.html)."
      ],
      "metadata": {
        "id": "FSEI2KQ993k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import neuralnetwork.nn as nn\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NeuralNetwork, self).__init__(**kwargs)\n",
        "        self.linear0 = nn.Linear(784, 200, **kwargs)\n",
        "        self.linear1 = nn.Linear(200, 200, **kwargs)\n",
        "        self.linear2 = nn.Linear(200, 1, **kwargs)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.out0 = self.linear0(x)\n",
        "        self.out1 = self.sigmoid(self.out0)\n",
        "        self.out2 = self.linear1(self.out1)\n",
        "        self.out3 = self.sigmoid(self.out2)\n",
        "        self.out4 = self.linear2(self.out3)\n",
        "        self.out5 = self.sigmoid(self.out4)\n",
        "\n",
        "        return self.out5\n",
        "    \n",
        "    def backward(self, lr, criterion):\n",
        "                                                               # Computational Graph\n",
        "                                                               #\n",
        "        self.dx0 = criterion.grad()                            # loss_grad(pred, y)\n",
        "                                                               #        |\n",
        "        self.dx1 = self.sigmoid.grad(self.out4)                # sigmoid_grad(pred)\n",
        "                                                               #        |\n",
        "                                                               #        +\n",
        "                                                               #       / \\\n",
        "                                                               #      |   |\n",
        "                                                               #  b_grad  *\n",
        "                                                               #         / \\\n",
        "                                                               #        |   |\n",
        "        self.dx2 = self.linear2.grad(self.dx1* self.dx0)       #   A_grad   x_grad\n",
        "                                                               #          .\n",
        "        self.dx3 = self.sigmoid.grad(self.out2)                #          .\n",
        "        self.dx4 = self.linear1.grad(self.dx3 * self.dx2)      #          .\n",
        "\n",
        "        self.dx5 = self.sigmoid.grad(self.out0)\n",
        "        self.dx6 = self.linear0.grad(self.dx5 * self.dx4)\n",
        "\n",
        "        self.linear0.update(lr)\n",
        "        self.linear1.update(lr)\n",
        "        self.linear2.update(lr)"
      ],
      "metadata": {
        "id": "0VOnz0yN93uN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "yfMDdyfU_wnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, X, Y):\n",
        "    pred = model(X)\n",
        "    pred = pred > 0.5\n",
        "    acc = np.sum(pred == Y)\n",
        "    acc = acc / Y.shape[0]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "_4HIPhzvAuOd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = ds.get_loader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = ds.get_loader(dataset=test_dataset, batch_size=1)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "zsnJzsLK_wsL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    loss = list()\n",
        "    acc = list()\n",
        "    for idx, pack in enumerate(train_loader):\n",
        "        x, y = pack\n",
        "        bs = x.shape[0]\n",
        "        L = x.shape[1] * x.shape[2]\n",
        "        x = x.reshape(bs, L) / 255.0\n",
        "        pred = model(x)\n",
        "        loss.append(criterion(pred, y))\n",
        "        model.backward(lr, criterion)\n",
        "        acc.append(accuracy(model, x, y))\n",
        "        print(\n",
        "            \"{}/{} - The training loss at {}th epoch : {}  Training Accuracy:{}\".format(\n",
        "                idx * BATCH_SIZE,\n",
        "                len(train_dataset),\n",
        "                epoch,\n",
        "                np.array(loss).mean(),\n",
        "                np.array(acc).mean(),\n",
        "            ),\n",
        "        )\n",
        "        if idx > int(len(train_dataset) / BATCH_SIZE):\n",
        "            break\n",
        "\n",
        "    if np.array(acc).mean() > 0.9:\n",
        "        break\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "print(\"Training finished in {} epochs\".format(epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-47tVltQAzL6",
        "outputId": "289377d9-7d64-4dbf-9d2a-db2a780b79d6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "784/4708 - The training loss at 13th epoch : 0.09465742630504774  Training Accuracy:0.865\n",
            "800/4708 - The training loss at 13th epoch : 0.09605233373861452  Training Accuracy:0.8639705882352942\n",
            "816/4708 - The training loss at 13th epoch : 0.09607548145248895  Training Accuracy:0.8653846153846154\n",
            "832/4708 - The training loss at 13th epoch : 0.09677517103412456  Training Accuracy:0.8643867924528302\n",
            "848/4708 - The training loss at 13th epoch : 0.09634390916015674  Training Accuracy:0.8634259259259259\n",
            "864/4708 - The training loss at 13th epoch : 0.09627401465066089  Training Accuracy:0.8636363636363636\n",
            "880/4708 - The training loss at 13th epoch : 0.09582411805334123  Training Accuracy:0.8649553571428571\n",
            "896/4708 - The training loss at 13th epoch : 0.09552779241762925  Training Accuracy:0.8640350877192983\n",
            "912/4708 - The training loss at 13th epoch : 0.09715207786021243  Training Accuracy:0.8620689655172413\n",
            "928/4708 - The training loss at 13th epoch : 0.09616674495567448  Training Accuracy:0.8633474576271186\n",
            "944/4708 - The training loss at 13th epoch : 0.09822165029768885  Training Accuracy:0.8604166666666667\n",
            "960/4708 - The training loss at 13th epoch : 0.0977441933323681  Training Accuracy:0.8616803278688525\n",
            "976/4708 - The training loss at 13th epoch : 0.09788547872891755  Training Accuracy:0.8618951612903226\n",
            "992/4708 - The training loss at 13th epoch : 0.09916347759522787  Training Accuracy:0.8601190476190477\n",
            "1008/4708 - The training loss at 13th epoch : 0.09839721086264701  Training Accuracy:0.8603515625\n",
            "1024/4708 - The training loss at 13th epoch : 0.09762046302175248  Training Accuracy:0.8615384615384616\n",
            "1040/4708 - The training loss at 13th epoch : 0.0970056021616073  Training Accuracy:0.8626893939393939\n",
            "1056/4708 - The training loss at 13th epoch : 0.09860729922925933  Training Accuracy:0.8600746268656716\n",
            "1072/4708 - The training loss at 13th epoch : 0.09794402729397883  Training Accuracy:0.8602941176470589\n",
            "1088/4708 - The training loss at 13th epoch : 0.09915655567906662  Training Accuracy:0.8586956521739131\n",
            "1104/4708 - The training loss at 13th epoch : 0.09947715817300762  Training Accuracy:0.8571428571428571\n",
            "1120/4708 - The training loss at 13th epoch : 0.10010723354034184  Training Accuracy:0.8556338028169014\n",
            "1136/4708 - The training loss at 13th epoch : 0.09954298112969716  Training Accuracy:0.8567708333333334\n",
            "1152/4708 - The training loss at 13th epoch : 0.0991735238852191  Training Accuracy:0.8570205479452054\n",
            "1168/4708 - The training loss at 13th epoch : 0.09887850903316128  Training Accuracy:0.8581081081081081\n",
            "1184/4708 - The training loss at 13th epoch : 0.09788776589812367  Training Accuracy:0.86\n",
            "1200/4708 - The training loss at 13th epoch : 0.09676811479823617  Training Accuracy:0.8618421052631579\n",
            "1216/4708 - The training loss at 13th epoch : 0.09601260757199623  Training Accuracy:0.8628246753246753\n",
            "1232/4708 - The training loss at 13th epoch : 0.09543682162022722  Training Accuracy:0.8645833333333334\n",
            "1248/4708 - The training loss at 13th epoch : 0.09555645364093981  Training Accuracy:0.8647151898734177\n",
            "1264/4708 - The training loss at 13th epoch : 0.0961321493388791  Training Accuracy:0.8640625\n",
            "1280/4708 - The training loss at 13th epoch : 0.09603038061969568  Training Accuracy:0.8641975308641975\n",
            "1296/4708 - The training loss at 13th epoch : 0.09785323520035853  Training Accuracy:0.8620426829268293\n",
            "1312/4708 - The training loss at 13th epoch : 0.09830098133481135  Training Accuracy:0.8614457831325302\n",
            "1328/4708 - The training loss at 13th epoch : 0.09765014630624497  Training Accuracy:0.8630952380952381\n",
            "1344/4708 - The training loss at 13th epoch : 0.09766281526864783  Training Accuracy:0.8632352941176471\n",
            "1360/4708 - The training loss at 13th epoch : 0.09739981189788664  Training Accuracy:0.8626453488372093\n",
            "1376/4708 - The training loss at 13th epoch : 0.09661042148736101  Training Accuracy:0.8635057471264368\n",
            "1392/4708 - The training loss at 13th epoch : 0.09749979153411249  Training Accuracy:0.8629261363636364\n",
            "1408/4708 - The training loss at 13th epoch : 0.0969326574190871  Training Accuracy:0.8637640449438202\n",
            "1424/4708 - The training loss at 13th epoch : 0.09664862652299158  Training Accuracy:0.8645833333333334\n",
            "1440/4708 - The training loss at 13th epoch : 0.09630541361805901  Training Accuracy:0.8646978021978022\n",
            "1456/4708 - The training loss at 13th epoch : 0.09697429838887327  Training Accuracy:0.8641304347826086\n",
            "1472/4708 - The training loss at 13th epoch : 0.09698466545273528  Training Accuracy:0.864247311827957\n",
            "1488/4708 - The training loss at 13th epoch : 0.09644137887434101  Training Accuracy:0.8650265957446809\n",
            "1504/4708 - The training loss at 13th epoch : 0.09615542512783054  Training Accuracy:0.8657894736842106\n",
            "1520/4708 - The training loss at 13th epoch : 0.09606275965937923  Training Accuracy:0.8658854166666666\n",
            "1536/4708 - The training loss at 13th epoch : 0.09538151845998954  Training Accuracy:0.8666237113402062\n",
            "1552/4708 - The training loss at 13th epoch : 0.09522905509961152  Training Accuracy:0.8673469387755102\n",
            "1568/4708 - The training loss at 13th epoch : 0.09545474908599248  Training Accuracy:0.8667929292929293\n",
            "1584/4708 - The training loss at 13th epoch : 0.09527226905753264  Training Accuracy:0.8675\n",
            "1600/4708 - The training loss at 13th epoch : 0.09450670637218098  Training Accuracy:0.8688118811881188\n",
            "1616/4708 - The training loss at 13th epoch : 0.09406342983520002  Training Accuracy:0.8694852941176471\n",
            "1632/4708 - The training loss at 13th epoch : 0.09361259458448594  Training Accuracy:0.8701456310679612\n",
            "1648/4708 - The training loss at 13th epoch : 0.09462277923137577  Training Accuracy:0.8689903846153846\n",
            "1664/4708 - The training loss at 13th epoch : 0.09486997114943925  Training Accuracy:0.8690476190476191\n",
            "1680/4708 - The training loss at 13th epoch : 0.09487876491962516  Training Accuracy:0.8691037735849056\n",
            "1696/4708 - The training loss at 13th epoch : 0.09460849031933577  Training Accuracy:0.8697429906542056\n",
            "1712/4708 - The training loss at 13th epoch : 0.09401685447549385  Training Accuracy:0.8703703703703703\n",
            "1728/4708 - The training loss at 13th epoch : 0.09441256843755588  Training Accuracy:0.8698394495412844\n",
            "1744/4708 - The training loss at 13th epoch : 0.09418781121136076  Training Accuracy:0.8704545454545455\n",
            "1760/4708 - The training loss at 13th epoch : 0.09346107491400234  Training Accuracy:0.8716216216216216\n",
            "1776/4708 - The training loss at 13th epoch : 0.0931956106576075  Training Accuracy:0.8716517857142857\n",
            "1792/4708 - The training loss at 13th epoch : 0.09303491801071191  Training Accuracy:0.8716814159292036\n",
            "1808/4708 - The training loss at 13th epoch : 0.09296999900316576  Training Accuracy:0.8722587719298246\n",
            "1824/4708 - The training loss at 13th epoch : 0.09229085525875466  Training Accuracy:0.8733695652173913\n",
            "1840/4708 - The training loss at 13th epoch : 0.0928348522792154  Training Accuracy:0.8717672413793104\n",
            "1856/4708 - The training loss at 13th epoch : 0.09241347803436832  Training Accuracy:0.8723290598290598\n",
            "1872/4708 - The training loss at 13th epoch : 0.0923988411485615  Training Accuracy:0.8728813559322034\n",
            "1888/4708 - The training loss at 13th epoch : 0.09237548321034729  Training Accuracy:0.8734243697478992\n",
            "1904/4708 - The training loss at 13th epoch : 0.09337510044031251  Training Accuracy:0.8723958333333334\n",
            "1920/4708 - The training loss at 13th epoch : 0.09339671165397918  Training Accuracy:0.871900826446281\n",
            "1936/4708 - The training loss at 13th epoch : 0.09379588905652099  Training Accuracy:0.8714139344262295\n",
            "1952/4708 - The training loss at 13th epoch : 0.0943112241964542  Training Accuracy:0.8709349593495935\n",
            "1968/4708 - The training loss at 13th epoch : 0.09411945058240477  Training Accuracy:0.8709677419354839\n",
            "1984/4708 - The training loss at 13th epoch : 0.09428714004581035  Training Accuracy:0.871\n",
            "2000/4708 - The training loss at 13th epoch : 0.09398844701910208  Training Accuracy:0.8715277777777778\n",
            "2016/4708 - The training loss at 13th epoch : 0.09471874447750644  Training Accuracy:0.8705708661417323\n",
            "2032/4708 - The training loss at 13th epoch : 0.0956505392981329  Training Accuracy:0.86865234375\n",
            "2048/4708 - The training loss at 13th epoch : 0.09504767241251462  Training Accuracy:0.8696705426356589\n",
            "2064/4708 - The training loss at 13th epoch : 0.09498627760374932  Training Accuracy:0.8697115384615385\n",
            "2080/4708 - The training loss at 13th epoch : 0.09449425483785226  Training Accuracy:0.8702290076335878\n",
            "2096/4708 - The training loss at 13th epoch : 0.09601512426987059  Training Accuracy:0.8683712121212122\n",
            "2112/4708 - The training loss at 13th epoch : 0.09658826436096866  Training Accuracy:0.8674812030075187\n",
            "2128/4708 - The training loss at 13th epoch : 0.09600986330429327  Training Accuracy:0.8684701492537313\n",
            "2144/4708 - The training loss at 13th epoch : 0.09554314410600495  Training Accuracy:0.8694444444444445\n",
            "2160/4708 - The training loss at 13th epoch : 0.09574256655568401  Training Accuracy:0.8690257352941176\n",
            "2176/4708 - The training loss at 13th epoch : 0.09580744417689194  Training Accuracy:0.8690693430656934\n",
            "2192/4708 - The training loss at 13th epoch : 0.09562782260130837  Training Accuracy:0.8695652173913043\n",
            "2208/4708 - The training loss at 13th epoch : 0.09544386580158717  Training Accuracy:0.8696043165467626\n",
            "2224/4708 - The training loss at 13th epoch : 0.09569762165252955  Training Accuracy:0.8696428571428572\n",
            "2240/4708 - The training loss at 13th epoch : 0.09555634382827341  Training Accuracy:0.8701241134751773\n",
            "2256/4708 - The training loss at 13th epoch : 0.09528864770803584  Training Accuracy:0.8705985915492958\n",
            "2272/4708 - The training loss at 13th epoch : 0.09559788427475854  Training Accuracy:0.8701923076923077\n",
            "2288/4708 - The training loss at 13th epoch : 0.09560354848097675  Training Accuracy:0.8702256944444444\n",
            "2304/4708 - The training loss at 13th epoch : 0.09612112389742113  Training Accuracy:0.8693965517241379\n",
            "2320/4708 - The training loss at 13th epoch : 0.097494119054484  Training Accuracy:0.8672945205479452\n",
            "2336/4708 - The training loss at 13th epoch : 0.09786657328461601  Training Accuracy:0.8669217687074829\n",
            "2352/4708 - The training loss at 13th epoch : 0.09817838480546168  Training Accuracy:0.8665540540540541\n",
            "2368/4708 - The training loss at 13th epoch : 0.09790249171779444  Training Accuracy:0.8666107382550335\n",
            "2384/4708 - The training loss at 13th epoch : 0.09769407345486877  Training Accuracy:0.8670833333333333\n",
            "2400/4708 - The training loss at 13th epoch : 0.09747043362161492  Training Accuracy:0.8675496688741722\n",
            "2416/4708 - The training loss at 13th epoch : 0.0979704900510305  Training Accuracy:0.8667763157894737\n",
            "2432/4708 - The training loss at 13th epoch : 0.09912822597780153  Training Accuracy:0.8656045751633987\n",
            "2448/4708 - The training loss at 13th epoch : 0.09876513869827983  Training Accuracy:0.8660714285714286\n",
            "2464/4708 - The training loss at 13th epoch : 0.09876739284244124  Training Accuracy:0.8661290322580645\n",
            "2480/4708 - The training loss at 13th epoch : 0.09846092805568822  Training Accuracy:0.8665865384615384\n",
            "2496/4708 - The training loss at 13th epoch : 0.09846944787201115  Training Accuracy:0.866640127388535\n",
            "2512/4708 - The training loss at 13th epoch : 0.09823170562765404  Training Accuracy:0.8670886075949367\n",
            "2528/4708 - The training loss at 13th epoch : 0.09870228080892243  Training Accuracy:0.8667452830188679\n",
            "2544/4708 - The training loss at 13th epoch : 0.0987497917346616  Training Accuracy:0.866796875\n",
            "2560/4708 - The training loss at 13th epoch : 0.09844200315264756  Training Accuracy:0.8672360248447205\n",
            "2576/4708 - The training loss at 13th epoch : 0.09828047384577397  Training Accuracy:0.8676697530864198\n",
            "2592/4708 - The training loss at 13th epoch : 0.09843216610172784  Training Accuracy:0.8677147239263804\n",
            "2608/4708 - The training loss at 13th epoch : 0.0981656578865485  Training Accuracy:0.868140243902439\n",
            "2624/4708 - The training loss at 13th epoch : 0.09827679824421306  Training Accuracy:0.8678030303030303\n",
            "2640/4708 - The training loss at 13th epoch : 0.09854641819757855  Training Accuracy:0.8674698795180723\n",
            "2656/4708 - The training loss at 13th epoch : 0.0982524142659094  Training Accuracy:0.8678892215568862\n",
            "2672/4708 - The training loss at 13th epoch : 0.09817614822701144  Training Accuracy:0.8683035714285714\n",
            "2688/4708 - The training loss at 13th epoch : 0.09765060737257163  Training Accuracy:0.8690828402366864\n",
            "2704/4708 - The training loss at 13th epoch : 0.09769828579091641  Training Accuracy:0.8691176470588236\n",
            "2720/4708 - The training loss at 13th epoch : 0.09803968287754442  Training Accuracy:0.8680555555555556\n",
            "2736/4708 - The training loss at 13th epoch : 0.09770535127662179  Training Accuracy:0.8688226744186046\n",
            "2752/4708 - The training loss at 13th epoch : 0.09779312296665725  Training Accuracy:0.8684971098265896\n",
            "2768/4708 - The training loss at 13th epoch : 0.0977404815376569  Training Accuracy:0.8685344827586207\n",
            "2784/4708 - The training loss at 13th epoch : 0.09838875889915333  Training Accuracy:0.8678571428571429\n",
            "2800/4708 - The training loss at 13th epoch : 0.09877926524008068  Training Accuracy:0.8671875\n",
            "2816/4708 - The training loss at 13th epoch : 0.09848771401899241  Training Accuracy:0.8675847457627118\n",
            "2832/4708 - The training loss at 13th epoch : 0.0981878233722808  Training Accuracy:0.8679775280898876\n",
            "2848/4708 - The training loss at 13th epoch : 0.09802002319634795  Training Accuracy:0.8680167597765364\n",
            "2864/4708 - The training loss at 13th epoch : 0.09818875502509054  Training Accuracy:0.8677083333333333\n",
            "2880/4708 - The training loss at 13th epoch : 0.09771324798099894  Training Accuracy:0.868439226519337\n",
            "2896/4708 - The training loss at 13th epoch : 0.09797273785428247  Training Accuracy:0.8681318681318682\n",
            "2912/4708 - The training loss at 13th epoch : 0.09762741729880464  Training Accuracy:0.8685109289617486\n",
            "2928/4708 - The training loss at 13th epoch : 0.09748127087493033  Training Accuracy:0.868546195652174\n",
            "2944/4708 - The training loss at 13th epoch : 0.09729446272197019  Training Accuracy:0.8685810810810811\n",
            "2960/4708 - The training loss at 13th epoch : 0.0972899534717862  Training Accuracy:0.8686155913978495\n",
            "2976/4708 - The training loss at 13th epoch : 0.09717146019327529  Training Accuracy:0.8689839572192514\n",
            "2992/4708 - The training loss at 13th epoch : 0.09729353686514668  Training Accuracy:0.8686835106382979\n",
            "3008/4708 - The training loss at 13th epoch : 0.09713956463729201  Training Accuracy:0.8690476190476191\n",
            "3024/4708 - The training loss at 13th epoch : 0.09685957968501248  Training Accuracy:0.8690789473684211\n",
            "3040/4708 - The training loss at 13th epoch : 0.09654308024153918  Training Accuracy:0.8697643979057592\n",
            "3056/4708 - The training loss at 13th epoch : 0.0964790058262484  Training Accuracy:0.8701171875\n",
            "3072/4708 - The training loss at 13th epoch : 0.0964504420206198  Training Accuracy:0.8701424870466321\n",
            "3088/4708 - The training loss at 13th epoch : 0.09638552689406506  Training Accuracy:0.8704896907216495\n",
            "3104/4708 - The training loss at 13th epoch : 0.09610372686915694  Training Accuracy:0.8708333333333333\n",
            "3120/4708 - The training loss at 13th epoch : 0.09605495956724346  Training Accuracy:0.8708545918367347\n",
            "3136/4708 - The training loss at 13th epoch : 0.09573204537724034  Training Accuracy:0.871510152284264\n",
            "3152/4708 - The training loss at 13th epoch : 0.09612936980982696  Training Accuracy:0.8705808080808081\n",
            "3168/4708 - The training loss at 13th epoch : 0.09632128666445008  Training Accuracy:0.8706030150753769\n",
            "3184/4708 - The training loss at 13th epoch : 0.09672689510610918  Training Accuracy:0.87\n",
            "3200/4708 - The training loss at 13th epoch : 0.09686296593311527  Training Accuracy:0.8697139303482587\n",
            "3216/4708 - The training loss at 13th epoch : 0.09698822711301532  Training Accuracy:0.869740099009901\n",
            "3232/4708 - The training loss at 13th epoch : 0.09689060644977496  Training Accuracy:0.8697660098522167\n",
            "3248/4708 - The training loss at 13th epoch : 0.09686567508286442  Training Accuracy:0.8697916666666666\n",
            "3264/4708 - The training loss at 13th epoch : 0.09722149158513715  Training Accuracy:0.8692073170731708\n",
            "3280/4708 - The training loss at 13th epoch : 0.09768834461933303  Training Accuracy:0.868628640776699\n",
            "3296/4708 - The training loss at 13th epoch : 0.09747074710416444  Training Accuracy:0.8689613526570048\n",
            "3312/4708 - The training loss at 13th epoch : 0.09738868032627275  Training Accuracy:0.8689903846153846\n",
            "3328/4708 - The training loss at 13th epoch : 0.09713940084195324  Training Accuracy:0.8693181818181818\n",
            "3344/4708 - The training loss at 13th epoch : 0.09736068437573366  Training Accuracy:0.8690476190476191\n",
            "3360/4708 - The training loss at 13th epoch : 0.09700406107722223  Training Accuracy:0.869372037914692\n",
            "3376/4708 - The training loss at 13th epoch : 0.09705840459891066  Training Accuracy:0.8693985849056604\n",
            "3392/4708 - The training loss at 13th epoch : 0.09713268775901032  Training Accuracy:0.869424882629108\n",
            "3408/4708 - The training loss at 13th epoch : 0.09692986268151266  Training Accuracy:0.8694509345794392\n",
            "3424/4708 - The training loss at 13th epoch : 0.09735328157560577  Training Accuracy:0.8686046511627907\n",
            "3440/4708 - The training loss at 13th epoch : 0.09760841387977147  Training Accuracy:0.8680555555555556\n",
            "3456/4708 - The training loss at 13th epoch : 0.09783684793791415  Training Accuracy:0.8677995391705069\n",
            "3472/4708 - The training loss at 13th epoch : 0.09766214135797609  Training Accuracy:0.8681192660550459\n",
            "3488/4708 - The training loss at 13th epoch : 0.09766477245929536  Training Accuracy:0.8681506849315068\n",
            "3504/4708 - The training loss at 13th epoch : 0.09774616689691028  Training Accuracy:0.8678977272727273\n",
            "3520/4708 - The training loss at 13th epoch : 0.09774601301600196  Training Accuracy:0.8679298642533937\n",
            "3536/4708 - The training loss at 13th epoch : 0.09773435006023717  Training Accuracy:0.8676801801801802\n",
            "3552/4708 - The training loss at 13th epoch : 0.09770304431610526  Training Accuracy:0.8677130044843049\n",
            "3568/4708 - The training loss at 13th epoch : 0.0976108482601379  Training Accuracy:0.8677455357142857\n",
            "3584/4708 - The training loss at 13th epoch : 0.09764898467529323  Training Accuracy:0.8675\n",
            "3600/4708 - The training loss at 13th epoch : 0.09748621499974308  Training Accuracy:0.8675331858407079\n",
            "3616/4708 - The training loss at 13th epoch : 0.09732832591034596  Training Accuracy:0.8675660792951542\n",
            "3632/4708 - The training loss at 13th epoch : 0.09774368162070997  Training Accuracy:0.8667763157894737\n",
            "3648/4708 - The training loss at 13th epoch : 0.09744021156341702  Training Accuracy:0.86735807860262\n",
            "3664/4708 - The training loss at 13th epoch : 0.09736403715399462  Training Accuracy:0.8671195652173913\n",
            "3680/4708 - The training loss at 13th epoch : 0.09740829171851456  Training Accuracy:0.8668831168831169\n",
            "3696/4708 - The training loss at 13th epoch : 0.09720818731986751  Training Accuracy:0.8674568965517241\n",
            "3712/4708 - The training loss at 13th epoch : 0.09703802176319917  Training Accuracy:0.8677575107296137\n",
            "3728/4708 - The training loss at 13th epoch : 0.09679101569217864  Training Accuracy:0.8680555555555556\n",
            "3744/4708 - The training loss at 13th epoch : 0.09743350383363607  Training Accuracy:0.8670212765957447\n",
            "3760/4708 - The training loss at 13th epoch : 0.09734631315519039  Training Accuracy:0.8670550847457628\n",
            "3776/4708 - The training loss at 13th epoch : 0.09743594749803808  Training Accuracy:0.8670886075949367\n",
            "3792/4708 - The training loss at 13th epoch : 0.09747460057109805  Training Accuracy:0.8671218487394958\n",
            "3808/4708 - The training loss at 13th epoch : 0.09743637475127893  Training Accuracy:0.8674163179916318\n",
            "3824/4708 - The training loss at 13th epoch : 0.09733563980404986  Training Accuracy:0.8674479166666667\n",
            "3840/4708 - The training loss at 13th epoch : 0.09720983426104017  Training Accuracy:0.8677385892116183\n",
            "3856/4708 - The training loss at 13th epoch : 0.09716237647925591  Training Accuracy:0.8677685950413223\n",
            "3872/4708 - The training loss at 13th epoch : 0.09699809857768617  Training Accuracy:0.8680555555555556\n",
            "3888/4708 - The training loss at 13th epoch : 0.0967385622885649  Training Accuracy:0.8683401639344263\n",
            "3904/4708 - The training loss at 13th epoch : 0.09662592391550974  Training Accuracy:0.8683673469387755\n",
            "3920/4708 - The training loss at 13th epoch : 0.09632668179624745  Training Accuracy:0.8689024390243902\n",
            "3936/4708 - The training loss at 13th epoch : 0.09616247905360129  Training Accuracy:0.8691801619433198\n",
            "3952/4708 - The training loss at 13th epoch : 0.0962942515491441  Training Accuracy:0.8689516129032258\n",
            "3968/4708 - The training loss at 13th epoch : 0.0965848886896869  Training Accuracy:0.8687248995983936\n",
            "3984/4708 - The training loss at 13th epoch : 0.09671201859646854  Training Accuracy:0.8685\n",
            "4000/4708 - The training loss at 13th epoch : 0.0964467554128691  Training Accuracy:0.8690239043824701\n",
            "4016/4708 - The training loss at 13th epoch : 0.0967277110280251  Training Accuracy:0.8687996031746031\n",
            "4032/4708 - The training loss at 13th epoch : 0.09662435476726781  Training Accuracy:0.8685770750988142\n",
            "4048/4708 - The training loss at 13th epoch : 0.09660395289191216  Training Accuracy:0.8686023622047244\n",
            "4064/4708 - The training loss at 13th epoch : 0.09657074227628251  Training Accuracy:0.8688725490196079\n",
            "4080/4708 - The training loss at 13th epoch : 0.09635884397018973  Training Accuracy:0.869140625\n",
            "4096/4708 - The training loss at 13th epoch : 0.0966406542683947  Training Accuracy:0.868920233463035\n",
            "4112/4708 - The training loss at 13th epoch : 0.09638038464691354  Training Accuracy:0.8691860465116279\n",
            "4128/4708 - The training loss at 13th epoch : 0.09613006450132372  Training Accuracy:0.869449806949807\n",
            "4144/4708 - The training loss at 13th epoch : 0.09617934460705352  Training Accuracy:0.8692307692307693\n",
            "4160/4708 - The training loss at 13th epoch : 0.09627053617691936  Training Accuracy:0.8690134099616859\n",
            "4176/4708 - The training loss at 13th epoch : 0.09648031202432963  Training Accuracy:0.8687977099236641\n",
            "4192/4708 - The training loss at 13th epoch : 0.09636127065754783  Training Accuracy:0.8690589353612167\n",
            "4208/4708 - The training loss at 13th epoch : 0.09605224609800009  Training Accuracy:0.8695549242424242\n",
            "4224/4708 - The training loss at 13th epoch : 0.0960600066768582  Training Accuracy:0.8693396226415094\n",
            "4240/4708 - The training loss at 13th epoch : 0.0959160758087165  Training Accuracy:0.8695958646616542\n",
            "4256/4708 - The training loss at 13th epoch : 0.09598435368585732  Training Accuracy:0.8693820224719101\n",
            "4272/4708 - The training loss at 13th epoch : 0.09603452064419746  Training Accuracy:0.8691697761194029\n",
            "4288/4708 - The training loss at 13th epoch : 0.09593528755263396  Training Accuracy:0.8694237918215614\n",
            "4304/4708 - The training loss at 13th epoch : 0.09567498288791212  Training Accuracy:0.8696759259259259\n",
            "4320/4708 - The training loss at 13th epoch : 0.09591277961071776  Training Accuracy:0.8692343173431735\n",
            "4336/4708 - The training loss at 13th epoch : 0.09566071815293288  Training Accuracy:0.8697150735294118\n",
            "4352/4708 - The training loss at 13th epoch : 0.09590182169411833  Training Accuracy:0.8692765567765568\n",
            "4368/4708 - The training loss at 13th epoch : 0.0957043546477751  Training Accuracy:0.8695255474452555\n",
            "4384/4708 - The training loss at 13th epoch : 0.09587522791480765  Training Accuracy:0.8690909090909091\n",
            "4400/4708 - The training loss at 13th epoch : 0.09631231762334487  Training Accuracy:0.8684329710144928\n",
            "4416/4708 - The training loss at 13th epoch : 0.09666980381618534  Training Accuracy:0.8677797833935018\n",
            "4432/4708 - The training loss at 13th epoch : 0.09641613430081929  Training Accuracy:0.8682553956834532\n",
            "4448/4708 - The training loss at 13th epoch : 0.09623594269147422  Training Accuracy:0.8685035842293907\n",
            "4464/4708 - The training loss at 13th epoch : 0.09607860417774357  Training Accuracy:0.86875\n",
            "4480/4708 - The training loss at 13th epoch : 0.09651859414165072  Training Accuracy:0.8681049822064056\n",
            "4496/4708 - The training loss at 13th epoch : 0.09674627737871203  Training Accuracy:0.867686170212766\n",
            "4512/4708 - The training loss at 13th epoch : 0.09656288930743376  Training Accuracy:0.8679328621908127\n",
            "4528/4708 - The training loss at 13th epoch : 0.09641982915234519  Training Accuracy:0.8679577464788732\n",
            "4544/4708 - The training loss at 13th epoch : 0.09625177592364674  Training Accuracy:0.8682017543859649\n",
            "4560/4708 - The training loss at 13th epoch : 0.09663757541067661  Training Accuracy:0.8677884615384616\n",
            "4576/4708 - The training loss at 13th epoch : 0.09651361971650448  Training Accuracy:0.8678135888501742\n",
            "4592/4708 - The training loss at 13th epoch : 0.0965941977565657  Training Accuracy:0.8676215277777778\n",
            "4608/4708 - The training loss at 13th epoch : 0.0964751098235262  Training Accuracy:0.8678633217993079\n",
            "4624/4708 - The training loss at 13th epoch : 0.09662290787753974  Training Accuracy:0.8676724137931034\n",
            "4640/4708 - The training loss at 13th epoch : 0.09642363766324141  Training Accuracy:0.8679123711340206\n",
            "4656/4708 - The training loss at 13th epoch : 0.09642742919307475  Training Accuracy:0.8679366438356164\n",
            "4672/4708 - The training loss at 13th epoch : 0.09669675820887737  Training Accuracy:0.8677474402730375\n",
            "4688/4708 - The training loss at 13th epoch : 0.0964341973322055  Training Accuracy:0.8681972789115646\n",
            "4704/4708 - The training loss at 13th epoch : 0.09665683528270796  Training Accuracy:0.8677966101694915\n",
            "4720/4708 - The training loss at 13th epoch : 0.09646542347039555  Training Accuracy:0.8680320945945946\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 14th epoch : 0.07749982260328622  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 14th epoch : 0.081604913929787  Training Accuracy:0.875\n",
            "32/4708 - The training loss at 14th epoch : 0.06852877215038021  Training Accuracy:0.875\n",
            "48/4708 - The training loss at 14th epoch : 0.08586884006041237  Training Accuracy:0.859375\n",
            "64/4708 - The training loss at 14th epoch : 0.11013100253402833  Training Accuracy:0.8375\n",
            "80/4708 - The training loss at 14th epoch : 0.09690372992373447  Training Accuracy:0.8541666666666666\n",
            "96/4708 - The training loss at 14th epoch : 0.0923591630394425  Training Accuracy:0.8571428571428571\n",
            "112/4708 - The training loss at 14th epoch : 0.09457900214170041  Training Accuracy:0.859375\n",
            "128/4708 - The training loss at 14th epoch : 0.08944750782451327  Training Accuracy:0.8680555555555556\n",
            "144/4708 - The training loss at 14th epoch : 0.09177991269943993  Training Accuracy:0.8625\n",
            "160/4708 - The training loss at 14th epoch : 0.08495537313187283  Training Accuracy:0.875\n",
            "176/4708 - The training loss at 14th epoch : 0.08768479689129229  Training Accuracy:0.8645833333333334\n",
            "192/4708 - The training loss at 14th epoch : 0.08847024530490154  Training Accuracy:0.8653846153846154\n",
            "208/4708 - The training loss at 14th epoch : 0.08358663889551997  Training Accuracy:0.875\n",
            "224/4708 - The training loss at 14th epoch : 0.08784897253996131  Training Accuracy:0.8666666666666667\n",
            "240/4708 - The training loss at 14th epoch : 0.09017056977274326  Training Accuracy:0.8671875\n",
            "256/4708 - The training loss at 14th epoch : 0.08962588759593965  Training Accuracy:0.8676470588235294\n",
            "272/4708 - The training loss at 14th epoch : 0.09046618659738373  Training Accuracy:0.8611111111111112\n",
            "288/4708 - The training loss at 14th epoch : 0.09333692060909438  Training Accuracy:0.8552631578947368\n",
            "304/4708 - The training loss at 14th epoch : 0.09311948071857488  Training Accuracy:0.85625\n",
            "320/4708 - The training loss at 14th epoch : 0.09002862289474726  Training Accuracy:0.8630952380952381\n",
            "336/4708 - The training loss at 14th epoch : 0.09162605825958581  Training Accuracy:0.8607954545454546\n",
            "352/4708 - The training loss at 14th epoch : 0.08949536532585241  Training Accuracy:0.8641304347826086\n",
            "368/4708 - The training loss at 14th epoch : 0.0878574375204747  Training Accuracy:0.8671875\n",
            "384/4708 - The training loss at 14th epoch : 0.08752947384938083  Training Accuracy:0.8675\n",
            "400/4708 - The training loss at 14th epoch : 0.08526159008476578  Training Accuracy:0.8725961538461539\n",
            "416/4708 - The training loss at 14th epoch : 0.08867030237431645  Training Accuracy:0.8657407407407407\n",
            "432/4708 - The training loss at 14th epoch : 0.08809645944220458  Training Accuracy:0.8683035714285714\n",
            "448/4708 - The training loss at 14th epoch : 0.08807595739834541  Training Accuracy:0.8685344827586207\n",
            "464/4708 - The training loss at 14th epoch : 0.08831705439159811  Training Accuracy:0.86875\n",
            "480/4708 - The training loss at 14th epoch : 0.08880627198012246  Training Accuracy:0.8689516129032258\n",
            "496/4708 - The training loss at 14th epoch : 0.08957904530558862  Training Accuracy:0.8671875\n",
            "512/4708 - The training loss at 14th epoch : 0.0876626685460253  Training Accuracy:0.8712121212121212\n",
            "528/4708 - The training loss at 14th epoch : 0.08848056246613285  Training Accuracy:0.8713235294117647\n",
            "544/4708 - The training loss at 14th epoch : 0.08745804917943387  Training Accuracy:0.8732142857142857\n",
            "560/4708 - The training loss at 14th epoch : 0.08769890350699898  Training Accuracy:0.8732638888888888\n",
            "576/4708 - The training loss at 14th epoch : 0.0866416329739216  Training Accuracy:0.875\n",
            "592/4708 - The training loss at 14th epoch : 0.09108114319115448  Training Accuracy:0.8700657894736842\n",
            "608/4708 - The training loss at 14th epoch : 0.0935466550412606  Training Accuracy:0.8669871794871795\n",
            "624/4708 - The training loss at 14th epoch : 0.09213121145591249  Training Accuracy:0.86875\n",
            "640/4708 - The training loss at 14th epoch : 0.0924082565861119  Training Accuracy:0.8689024390243902\n",
            "656/4708 - The training loss at 14th epoch : 0.09131361438532125  Training Accuracy:0.8720238095238095\n",
            "672/4708 - The training loss at 14th epoch : 0.09215917722915042  Training Accuracy:0.872093023255814\n",
            "688/4708 - The training loss at 14th epoch : 0.09264270368105612  Training Accuracy:0.8707386363636364\n",
            "704/4708 - The training loss at 14th epoch : 0.09216161968396884  Training Accuracy:0.8722222222222222\n",
            "720/4708 - The training loss at 14th epoch : 0.09203001211812425  Training Accuracy:0.8722826086956522\n",
            "736/4708 - The training loss at 14th epoch : 0.09123202752725888  Training Accuracy:0.8723404255319149\n",
            "752/4708 - The training loss at 14th epoch : 0.09238513818549943  Training Accuracy:0.8697916666666666\n",
            "768/4708 - The training loss at 14th epoch : 0.09119833261071904  Training Accuracy:0.8724489795918368\n",
            "784/4708 - The training loss at 14th epoch : 0.08943880752430951  Training Accuracy:0.875\n",
            "800/4708 - The training loss at 14th epoch : 0.09015926962540986  Training Accuracy:0.8737745098039216\n",
            "816/4708 - The training loss at 14th epoch : 0.08882335003142719  Training Accuracy:0.8762019230769231\n",
            "832/4708 - The training loss at 14th epoch : 0.08918368004356664  Training Accuracy:0.875\n",
            "848/4708 - The training loss at 14th epoch : 0.08912723595468774  Training Accuracy:0.8761574074074074\n",
            "864/4708 - The training loss at 14th epoch : 0.08832995520808783  Training Accuracy:0.8772727272727273\n",
            "880/4708 - The training loss at 14th epoch : 0.08946434254716731  Training Accuracy:0.8761160714285714\n",
            "896/4708 - The training loss at 14th epoch : 0.09062469794438005  Training Accuracy:0.875\n",
            "912/4708 - The training loss at 14th epoch : 0.09016504871732511  Training Accuracy:0.875\n",
            "928/4708 - The training loss at 14th epoch : 0.08935270992292395  Training Accuracy:0.8760593220338984\n",
            "944/4708 - The training loss at 14th epoch : 0.08814532494606228  Training Accuracy:0.878125\n",
            "960/4708 - The training loss at 14th epoch : 0.08929377075510368  Training Accuracy:0.8760245901639344\n",
            "976/4708 - The training loss at 14th epoch : 0.09004088659869759  Training Accuracy:0.875\n",
            "992/4708 - The training loss at 14th epoch : 0.08914384328737868  Training Accuracy:0.876984126984127\n",
            "1008/4708 - The training loss at 14th epoch : 0.0879153773071773  Training Accuracy:0.87890625\n",
            "1024/4708 - The training loss at 14th epoch : 0.08675662366858172  Training Accuracy:0.8807692307692307\n",
            "1040/4708 - The training loss at 14th epoch : 0.08798267552461664  Training Accuracy:0.8787878787878788\n",
            "1056/4708 - The training loss at 14th epoch : 0.08825279795716479  Training Accuracy:0.8777985074626866\n",
            "1072/4708 - The training loss at 14th epoch : 0.08803024541701615  Training Accuracy:0.8777573529411765\n",
            "1088/4708 - The training loss at 14th epoch : 0.08754486730938581  Training Accuracy:0.8777173913043478\n",
            "1104/4708 - The training loss at 14th epoch : 0.0870955700017729  Training Accuracy:0.8785714285714286\n",
            "1120/4708 - The training loss at 14th epoch : 0.08661953809966448  Training Accuracy:0.8785211267605634\n",
            "1136/4708 - The training loss at 14th epoch : 0.08819377797509305  Training Accuracy:0.8767361111111112\n",
            "1152/4708 - The training loss at 14th epoch : 0.088651456933872  Training Accuracy:0.8758561643835616\n",
            "1168/4708 - The training loss at 14th epoch : 0.08924004862032309  Training Accuracy:0.875\n",
            "1184/4708 - The training loss at 14th epoch : 0.08896855394520349  Training Accuracy:0.8758333333333334\n",
            "1200/4708 - The training loss at 14th epoch : 0.08881302887665227  Training Accuracy:0.8766447368421053\n",
            "1216/4708 - The training loss at 14th epoch : 0.08959390872636146  Training Accuracy:0.875\n",
            "1232/4708 - The training loss at 14th epoch : 0.09013553112209315  Training Accuracy:0.874198717948718\n",
            "1248/4708 - The training loss at 14th epoch : 0.0895624163533801  Training Accuracy:0.875\n",
            "1264/4708 - The training loss at 14th epoch : 0.08991209846383982  Training Accuracy:0.875\n",
            "1280/4708 - The training loss at 14th epoch : 0.08928237865047732  Training Accuracy:0.8757716049382716\n",
            "1296/4708 - The training loss at 14th epoch : 0.08954264520651203  Training Accuracy:0.8757621951219512\n",
            "1312/4708 - The training loss at 14th epoch : 0.08978208603944605  Training Accuracy:0.875\n",
            "1328/4708 - The training loss at 14th epoch : 0.08919305768257918  Training Accuracy:0.8757440476190477\n",
            "1344/4708 - The training loss at 14th epoch : 0.08956347261509218  Training Accuracy:0.875\n",
            "1360/4708 - The training loss at 14th epoch : 0.09075341042077407  Training Accuracy:0.8728197674418605\n",
            "1376/4708 - The training loss at 14th epoch : 0.09023378919567328  Training Accuracy:0.8735632183908046\n",
            "1392/4708 - The training loss at 14th epoch : 0.09079301182802633  Training Accuracy:0.8735795454545454\n",
            "1408/4708 - The training loss at 14th epoch : 0.09078401981889941  Training Accuracy:0.8728932584269663\n",
            "1424/4708 - The training loss at 14th epoch : 0.09051734488690916  Training Accuracy:0.8736111111111111\n",
            "1440/4708 - The training loss at 14th epoch : 0.09010433146833305  Training Accuracy:0.8736263736263736\n",
            "1456/4708 - The training loss at 14th epoch : 0.08956088227902316  Training Accuracy:0.875\n",
            "1472/4708 - The training loss at 14th epoch : 0.08875277308198959  Training Accuracy:0.8763440860215054\n",
            "1488/4708 - The training loss at 14th epoch : 0.08887674095072698  Training Accuracy:0.8756648936170213\n",
            "1504/4708 - The training loss at 14th epoch : 0.0887209596509964  Training Accuracy:0.8756578947368421\n",
            "1520/4708 - The training loss at 14th epoch : 0.08994372249308769  Training Accuracy:0.8736979166666666\n",
            "1536/4708 - The training loss at 14th epoch : 0.08982647926365381  Training Accuracy:0.8737113402061856\n",
            "1552/4708 - The training loss at 14th epoch : 0.08941376853558958  Training Accuracy:0.8743622448979592\n",
            "1568/4708 - The training loss at 14th epoch : 0.0893883308777793  Training Accuracy:0.8743686868686869\n",
            "1584/4708 - The training loss at 14th epoch : 0.08916924909185205  Training Accuracy:0.874375\n",
            "1600/4708 - The training loss at 14th epoch : 0.09064730291270198  Training Accuracy:0.8725247524752475\n",
            "1616/4708 - The training loss at 14th epoch : 0.09083363235676807  Training Accuracy:0.8719362745098039\n",
            "1632/4708 - The training loss at 14th epoch : 0.09061734435294312  Training Accuracy:0.8725728155339806\n",
            "1648/4708 - The training loss at 14th epoch : 0.09003676784051719  Training Accuracy:0.8737980769230769\n",
            "1664/4708 - The training loss at 14th epoch : 0.08940123639182165  Training Accuracy:0.875\n",
            "1680/4708 - The training loss at 14th epoch : 0.08934777881246167  Training Accuracy:0.875\n",
            "1696/4708 - The training loss at 14th epoch : 0.08875057461885964  Training Accuracy:0.8755841121495327\n",
            "1712/4708 - The training loss at 14th epoch : 0.08840248158495694  Training Accuracy:0.8755787037037037\n",
            "1728/4708 - The training loss at 14th epoch : 0.08916932373522321  Training Accuracy:0.8744266055045872\n",
            "1744/4708 - The training loss at 14th epoch : 0.08904024151117239  Training Accuracy:0.875\n",
            "1760/4708 - The training loss at 14th epoch : 0.08919593879863583  Training Accuracy:0.875\n",
            "1776/4708 - The training loss at 14th epoch : 0.08881673347378427  Training Accuracy:0.8755580357142857\n",
            "1792/4708 - The training loss at 14th epoch : 0.08839837739917582  Training Accuracy:0.8761061946902655\n",
            "1808/4708 - The training loss at 14th epoch : 0.08776518626707691  Training Accuracy:0.8771929824561403\n",
            "1824/4708 - The training loss at 14th epoch : 0.08742439391776995  Training Accuracy:0.8771739130434782\n",
            "1840/4708 - The training loss at 14th epoch : 0.08745296766526289  Training Accuracy:0.8776939655172413\n",
            "1856/4708 - The training loss at 14th epoch : 0.0875687082184663  Training Accuracy:0.8776709401709402\n",
            "1872/4708 - The training loss at 14th epoch : 0.08749681155690635  Training Accuracy:0.8776483050847458\n",
            "1888/4708 - The training loss at 14th epoch : 0.08800009032425436  Training Accuracy:0.8771008403361344\n",
            "1904/4708 - The training loss at 14th epoch : 0.08814053989650716  Training Accuracy:0.8770833333333333\n",
            "1920/4708 - The training loss at 14th epoch : 0.08836216485986126  Training Accuracy:0.8770661157024794\n",
            "1936/4708 - The training loss at 14th epoch : 0.08822276356641308  Training Accuracy:0.8775614754098361\n",
            "1952/4708 - The training loss at 14th epoch : 0.08849377131564938  Training Accuracy:0.8770325203252033\n",
            "1968/4708 - The training loss at 14th epoch : 0.0883489132946767  Training Accuracy:0.8775201612903226\n",
            "1984/4708 - The training loss at 14th epoch : 0.08804147614247336  Training Accuracy:0.878\n",
            "2000/4708 - The training loss at 14th epoch : 0.0881156357279132  Training Accuracy:0.8779761904761905\n",
            "2016/4708 - The training loss at 14th epoch : 0.08819335368594991  Training Accuracy:0.8784448818897638\n",
            "2032/4708 - The training loss at 14th epoch : 0.08854909066696273  Training Accuracy:0.87841796875\n",
            "2048/4708 - The training loss at 14th epoch : 0.08815216976541992  Training Accuracy:0.8793604651162791\n",
            "2064/4708 - The training loss at 14th epoch : 0.08851950289287602  Training Accuracy:0.8793269230769231\n",
            "2080/4708 - The training loss at 14th epoch : 0.08873141045710235  Training Accuracy:0.8783396946564885\n",
            "2096/4708 - The training loss at 14th epoch : 0.08870944676615299  Training Accuracy:0.8778409090909091\n",
            "2112/4708 - The training loss at 14th epoch : 0.08839856599607453  Training Accuracy:0.8782894736842105\n",
            "2128/4708 - The training loss at 14th epoch : 0.08777779569060436  Training Accuracy:0.8791977611940298\n",
            "2144/4708 - The training loss at 14th epoch : 0.0878235881941834  Training Accuracy:0.8796296296296297\n",
            "2160/4708 - The training loss at 14th epoch : 0.0872505500457299  Training Accuracy:0.8805147058823529\n",
            "2176/4708 - The training loss at 14th epoch : 0.08745762068505851  Training Accuracy:0.8804744525547445\n",
            "2192/4708 - The training loss at 14th epoch : 0.08778726443458816  Training Accuracy:0.8804347826086957\n",
            "2208/4708 - The training loss at 14th epoch : 0.08786128422533664  Training Accuracy:0.8803956834532374\n",
            "2224/4708 - The training loss at 14th epoch : 0.0882761734261992  Training Accuracy:0.8803571428571428\n",
            "2240/4708 - The training loss at 14th epoch : 0.08925542986700362  Training Accuracy:0.8789893617021277\n",
            "2256/4708 - The training loss at 14th epoch : 0.08913683908644983  Training Accuracy:0.8789612676056338\n",
            "2272/4708 - The training loss at 14th epoch : 0.08943606287853348  Training Accuracy:0.8780594405594405\n",
            "2288/4708 - The training loss at 14th epoch : 0.08965676035629638  Training Accuracy:0.8780381944444444\n",
            "2304/4708 - The training loss at 14th epoch : 0.08993647633196937  Training Accuracy:0.8771551724137931\n",
            "2320/4708 - The training loss at 14th epoch : 0.08991037936853445  Training Accuracy:0.8771404109589042\n",
            "2336/4708 - The training loss at 14th epoch : 0.08947962600274587  Training Accuracy:0.8779761904761905\n",
            "2352/4708 - The training loss at 14th epoch : 0.08944402017907609  Training Accuracy:0.877956081081081\n",
            "2368/4708 - The training loss at 14th epoch : 0.0893259493592292  Training Accuracy:0.87751677852349\n",
            "2384/4708 - The training loss at 14th epoch : 0.08907941434331124  Training Accuracy:0.8779166666666667\n",
            "2400/4708 - The training loss at 14th epoch : 0.08905060022547487  Training Accuracy:0.8778973509933775\n",
            "2416/4708 - The training loss at 14th epoch : 0.08853867220651598  Training Accuracy:0.8787006578947368\n",
            "2432/4708 - The training loss at 14th epoch : 0.08905279626497983  Training Accuracy:0.8782679738562091\n",
            "2448/4708 - The training loss at 14th epoch : 0.0888504110331545  Training Accuracy:0.8786525974025974\n",
            "2464/4708 - The training loss at 14th epoch : 0.08903488596650282  Training Accuracy:0.8782258064516129\n",
            "2480/4708 - The training loss at 14th epoch : 0.08917199697648341  Training Accuracy:0.8778044871794872\n",
            "2496/4708 - The training loss at 14th epoch : 0.08961024285875867  Training Accuracy:0.8769904458598726\n",
            "2512/4708 - The training loss at 14th epoch : 0.08995686443986593  Training Accuracy:0.8765822784810127\n",
            "2528/4708 - The training loss at 14th epoch : 0.08963043297201291  Training Accuracy:0.8769654088050315\n",
            "2544/4708 - The training loss at 14th epoch : 0.08978994501487708  Training Accuracy:0.876953125\n",
            "2560/4708 - The training loss at 14th epoch : 0.09005063158606064  Training Accuracy:0.8769409937888198\n",
            "2576/4708 - The training loss at 14th epoch : 0.09002698533917262  Training Accuracy:0.876929012345679\n",
            "2592/4708 - The training loss at 14th epoch : 0.09042356489780473  Training Accuracy:0.8765337423312883\n",
            "2608/4708 - The training loss at 14th epoch : 0.09089807517876729  Training Accuracy:0.8761432926829268\n",
            "2624/4708 - The training loss at 14th epoch : 0.0906548248477521  Training Accuracy:0.8765151515151515\n",
            "2640/4708 - The training loss at 14th epoch : 0.09078797541830537  Training Accuracy:0.8761295180722891\n",
            "2656/4708 - The training loss at 14th epoch : 0.0906125500724502  Training Accuracy:0.8764970059880239\n",
            "2672/4708 - The training loss at 14th epoch : 0.09030963731021793  Training Accuracy:0.8768601190476191\n",
            "2688/4708 - The training loss at 14th epoch : 0.09061336970128811  Training Accuracy:0.8764792899408284\n",
            "2704/4708 - The training loss at 14th epoch : 0.09012918938000947  Training Accuracy:0.8772058823529412\n",
            "2720/4708 - The training loss at 14th epoch : 0.09000061169062776  Training Accuracy:0.8775584795321637\n",
            "2736/4708 - The training loss at 14th epoch : 0.09007234527691181  Training Accuracy:0.8771802325581395\n",
            "2752/4708 - The training loss at 14th epoch : 0.08985342870961248  Training Accuracy:0.8771676300578035\n",
            "2768/4708 - The training loss at 14th epoch : 0.09005778408916658  Training Accuracy:0.8767959770114943\n",
            "2784/4708 - The training loss at 14th epoch : 0.0897297820133662  Training Accuracy:0.8771428571428571\n",
            "2800/4708 - The training loss at 14th epoch : 0.08953962683467366  Training Accuracy:0.8774857954545454\n",
            "2816/4708 - The training loss at 14th epoch : 0.08948518210215316  Training Accuracy:0.8774717514124294\n",
            "2832/4708 - The training loss at 14th epoch : 0.0896015590887915  Training Accuracy:0.8774578651685393\n",
            "2848/4708 - The training loss at 14th epoch : 0.08926104211818432  Training Accuracy:0.8781424581005587\n",
            "2864/4708 - The training loss at 14th epoch : 0.08944111168093555  Training Accuracy:0.878125\n",
            "2880/4708 - The training loss at 14th epoch : 0.08924489615363132  Training Accuracy:0.8784530386740331\n",
            "2896/4708 - The training loss at 14th epoch : 0.08891113788814396  Training Accuracy:0.8787774725274725\n",
            "2912/4708 - The training loss at 14th epoch : 0.08940164040106933  Training Accuracy:0.8777322404371585\n",
            "2928/4708 - The training loss at 14th epoch : 0.08959256599166164  Training Accuracy:0.8777173913043478\n",
            "2944/4708 - The training loss at 14th epoch : 0.08925584217756533  Training Accuracy:0.8783783783783784\n",
            "2960/4708 - The training loss at 14th epoch : 0.0892681093467442  Training Accuracy:0.8783602150537635\n",
            "2976/4708 - The training loss at 14th epoch : 0.08889214172879194  Training Accuracy:0.8790106951871658\n",
            "2992/4708 - The training loss at 14th epoch : 0.08897024792626772  Training Accuracy:0.8789893617021277\n",
            "3008/4708 - The training loss at 14th epoch : 0.08892028722338277  Training Accuracy:0.8792989417989417\n",
            "3024/4708 - The training loss at 14th epoch : 0.08851970333845642  Training Accuracy:0.8799342105263158\n",
            "3040/4708 - The training loss at 14th epoch : 0.08828746863083818  Training Accuracy:0.8802356020942408\n",
            "3056/4708 - The training loss at 14th epoch : 0.08841289557661491  Training Accuracy:0.8798828125\n",
            "3072/4708 - The training loss at 14th epoch : 0.08811513761363723  Training Accuracy:0.8801813471502591\n",
            "3088/4708 - The training loss at 14th epoch : 0.08839424304772095  Training Accuracy:0.8801546391752577\n",
            "3104/4708 - The training loss at 14th epoch : 0.08901864578576468  Training Accuracy:0.8791666666666667\n",
            "3120/4708 - The training loss at 14th epoch : 0.08904378524093927  Training Accuracy:0.8794642857142857\n",
            "3136/4708 - The training loss at 14th epoch : 0.08929611346361532  Training Accuracy:0.8788071065989848\n",
            "3152/4708 - The training loss at 14th epoch : 0.08927177053280966  Training Accuracy:0.8791035353535354\n",
            "3168/4708 - The training loss at 14th epoch : 0.08947932986625703  Training Accuracy:0.8787688442211056\n",
            "3184/4708 - The training loss at 14th epoch : 0.08976191022608986  Training Accuracy:0.878125\n",
            "3200/4708 - The training loss at 14th epoch : 0.08975893481825095  Training Accuracy:0.8781094527363185\n",
            "3216/4708 - The training loss at 14th epoch : 0.08955563996609665  Training Accuracy:0.8784034653465347\n",
            "3232/4708 - The training loss at 14th epoch : 0.09011699178185668  Training Accuracy:0.8774630541871922\n",
            "3248/4708 - The training loss at 14th epoch : 0.08982782226150349  Training Accuracy:0.8777573529411765\n",
            "3264/4708 - The training loss at 14th epoch : 0.0901202537480534  Training Accuracy:0.8777439024390243\n",
            "3280/4708 - The training loss at 14th epoch : 0.08978824469204306  Training Accuracy:0.8783373786407767\n",
            "3296/4708 - The training loss at 14th epoch : 0.08940606913306053  Training Accuracy:0.8789251207729468\n",
            "3312/4708 - The training loss at 14th epoch : 0.08902589560224691  Training Accuracy:0.8795072115384616\n",
            "3328/4708 - The training loss at 14th epoch : 0.0890597559055988  Training Accuracy:0.8794856459330144\n",
            "3344/4708 - The training loss at 14th epoch : 0.08914508763183121  Training Accuracy:0.8794642857142857\n",
            "3360/4708 - The training loss at 14th epoch : 0.0892175995906524  Training Accuracy:0.8794431279620853\n",
            "3376/4708 - The training loss at 14th epoch : 0.08884632073080202  Training Accuracy:0.8800117924528302\n",
            "3392/4708 - The training loss at 14th epoch : 0.08892517106997866  Training Accuracy:0.8799882629107981\n",
            "3408/4708 - The training loss at 14th epoch : 0.088746665888119  Training Accuracy:0.8802570093457944\n",
            "3424/4708 - The training loss at 14th epoch : 0.08890635379700197  Training Accuracy:0.8799418604651162\n",
            "3440/4708 - The training loss at 14th epoch : 0.08877131916981791  Training Accuracy:0.8802083333333334\n",
            "3456/4708 - The training loss at 14th epoch : 0.08890989347416049  Training Accuracy:0.8798963133640553\n",
            "3472/4708 - The training loss at 14th epoch : 0.08908724048279064  Training Accuracy:0.8795871559633027\n",
            "3488/4708 - The training loss at 14th epoch : 0.08886691490638576  Training Accuracy:0.879851598173516\n",
            "3504/4708 - The training loss at 14th epoch : 0.08867464138183527  Training Accuracy:0.8801136363636364\n",
            "3520/4708 - The training loss at 14th epoch : 0.08876632517046547  Training Accuracy:0.8800904977375565\n",
            "3536/4708 - The training loss at 14th epoch : 0.08922195837131733  Training Accuracy:0.879222972972973\n",
            "3552/4708 - The training loss at 14th epoch : 0.0894083802949173  Training Accuracy:0.8792040358744395\n",
            "3568/4708 - The training loss at 14th epoch : 0.08997954646744473  Training Accuracy:0.8786272321428571\n",
            "3584/4708 - The training loss at 14th epoch : 0.09036725569623544  Training Accuracy:0.8783333333333333\n",
            "3600/4708 - The training loss at 14th epoch : 0.09042413371932531  Training Accuracy:0.8783185840707964\n",
            "3616/4708 - The training loss at 14th epoch : 0.09078665639278  Training Accuracy:0.8777533039647577\n",
            "3632/4708 - The training loss at 14th epoch : 0.09064102725020913  Training Accuracy:0.878015350877193\n",
            "3648/4708 - The training loss at 14th epoch : 0.09078179664392341  Training Accuracy:0.8780021834061136\n",
            "3664/4708 - The training loss at 14th epoch : 0.09105012568683102  Training Accuracy:0.877445652173913\n",
            "3680/4708 - The training loss at 14th epoch : 0.09107837278970957  Training Accuracy:0.877435064935065\n",
            "3696/4708 - The training loss at 14th epoch : 0.09096208055609914  Training Accuracy:0.8776939655172413\n",
            "3712/4708 - The training loss at 14th epoch : 0.09076723849531405  Training Accuracy:0.8779506437768241\n",
            "3728/4708 - The training loss at 14th epoch : 0.09061935660727119  Training Accuracy:0.8779380341880342\n",
            "3744/4708 - The training loss at 14th epoch : 0.09066033274944604  Training Accuracy:0.8779255319148936\n",
            "3760/4708 - The training loss at 14th epoch : 0.0906148177692476  Training Accuracy:0.8779131355932204\n",
            "3776/4708 - The training loss at 14th epoch : 0.0904970792725402  Training Accuracy:0.8781645569620253\n",
            "3792/4708 - The training loss at 14th epoch : 0.09039974094380106  Training Accuracy:0.8784138655462185\n",
            "3808/4708 - The training loss at 14th epoch : 0.09035095062940307  Training Accuracy:0.8783995815899581\n",
            "3824/4708 - The training loss at 14th epoch : 0.09085542320805287  Training Accuracy:0.8776041666666666\n",
            "3840/4708 - The training loss at 14th epoch : 0.09081164829863575  Training Accuracy:0.8778526970954357\n",
            "3856/4708 - The training loss at 14th epoch : 0.09078795948091514  Training Accuracy:0.8778409090909091\n",
            "3872/4708 - The training loss at 14th epoch : 0.09097526868621321  Training Accuracy:0.8775720164609053\n",
            "3888/4708 - The training loss at 14th epoch : 0.09151346109614371  Training Accuracy:0.8770491803278688\n",
            "3904/4708 - The training loss at 14th epoch : 0.0918703549741391  Training Accuracy:0.8762755102040817\n",
            "3920/4708 - The training loss at 14th epoch : 0.09160602808591682  Training Accuracy:0.8767784552845529\n",
            "3936/4708 - The training loss at 14th epoch : 0.09173300351815351  Training Accuracy:0.8765182186234818\n",
            "3952/4708 - The training loss at 14th epoch : 0.0914548575595585  Training Accuracy:0.8770161290322581\n",
            "3968/4708 - The training loss at 14th epoch : 0.09137933468353535  Training Accuracy:0.8772590361445783\n",
            "3984/4708 - The training loss at 14th epoch : 0.09138242205114068  Training Accuracy:0.877\n",
            "4000/4708 - The training loss at 14th epoch : 0.09142888403587955  Training Accuracy:0.87699203187251\n",
            "4016/4708 - The training loss at 14th epoch : 0.09126655249119944  Training Accuracy:0.8772321428571429\n",
            "4032/4708 - The training loss at 14th epoch : 0.090919380180626  Training Accuracy:0.8777173913043478\n",
            "4048/4708 - The training loss at 14th epoch : 0.09066741093433604  Training Accuracy:0.8781988188976378\n",
            "4064/4708 - The training loss at 14th epoch : 0.09114333938236584  Training Accuracy:0.8774509803921569\n",
            "4080/4708 - The training loss at 14th epoch : 0.09123167673070191  Training Accuracy:0.877197265625\n",
            "4096/4708 - The training loss at 14th epoch : 0.0910605789823996  Training Accuracy:0.877431906614786\n",
            "4112/4708 - The training loss at 14th epoch : 0.09086603073412347  Training Accuracy:0.8776647286821705\n",
            "4128/4708 - The training loss at 14th epoch : 0.09120479630098213  Training Accuracy:0.8771718146718147\n",
            "4144/4708 - The training loss at 14th epoch : 0.09122637415433144  Training Accuracy:0.8771634615384616\n",
            "4160/4708 - The training loss at 14th epoch : 0.091131486705952  Training Accuracy:0.8773946360153256\n",
            "4176/4708 - The training loss at 14th epoch : 0.0912703674569689  Training Accuracy:0.8771469465648855\n",
            "4192/4708 - The training loss at 14th epoch : 0.09147913941529086  Training Accuracy:0.877138783269962\n",
            "4208/4708 - The training loss at 14th epoch : 0.09123420603929211  Training Accuracy:0.8776041666666666\n",
            "4224/4708 - The training loss at 14th epoch : 0.0914947991937452  Training Accuracy:0.8768867924528302\n",
            "4240/4708 - The training loss at 14th epoch : 0.09147903184650268  Training Accuracy:0.8766447368421053\n",
            "4256/4708 - The training loss at 14th epoch : 0.09153947605653912  Training Accuracy:0.8766385767790262\n",
            "4272/4708 - The training loss at 14th epoch : 0.09166395448119223  Training Accuracy:0.8763992537313433\n",
            "4288/4708 - The training loss at 14th epoch : 0.09170873236799972  Training Accuracy:0.8763940520446096\n",
            "4304/4708 - The training loss at 14th epoch : 0.09186535396061728  Training Accuracy:0.8761574074074074\n",
            "4320/4708 - The training loss at 14th epoch : 0.09184258907761654  Training Accuracy:0.8759225092250923\n",
            "4336/4708 - The training loss at 14th epoch : 0.09197497771938354  Training Accuracy:0.8756893382352942\n",
            "4352/4708 - The training loss at 14th epoch : 0.09184957148992566  Training Accuracy:0.8759157509157509\n",
            "4368/4708 - The training loss at 14th epoch : 0.09189131206077723  Training Accuracy:0.8759124087591241\n",
            "4384/4708 - The training loss at 14th epoch : 0.09158805113411721  Training Accuracy:0.8763636363636363\n",
            "4400/4708 - The training loss at 14th epoch : 0.09152007571429997  Training Accuracy:0.8765851449275363\n",
            "4416/4708 - The training loss at 14th epoch : 0.09155083248523549  Training Accuracy:0.8763537906137184\n",
            "4432/4708 - The training loss at 14th epoch : 0.09147425148372597  Training Accuracy:0.8763489208633094\n",
            "4448/4708 - The training loss at 14th epoch : 0.09148902736410265  Training Accuracy:0.8763440860215054\n",
            "4464/4708 - The training loss at 14th epoch : 0.0912454521077265  Training Accuracy:0.8765625\n",
            "4480/4708 - The training loss at 14th epoch : 0.09105070974231326  Training Accuracy:0.876779359430605\n",
            "4496/4708 - The training loss at 14th epoch : 0.09089441425991143  Training Accuracy:0.8769946808510638\n",
            "4512/4708 - The training loss at 14th epoch : 0.09064226629027855  Training Accuracy:0.8774293286219081\n",
            "4528/4708 - The training loss at 14th epoch : 0.09074390619726234  Training Accuracy:0.8774207746478874\n",
            "4544/4708 - The training loss at 14th epoch : 0.09081119982876487  Training Accuracy:0.8771929824561403\n",
            "4560/4708 - The training loss at 14th epoch : 0.09080153523357135  Training Accuracy:0.8771853146853147\n",
            "4576/4708 - The training loss at 14th epoch : 0.09089902746233652  Training Accuracy:0.8769599303135889\n",
            "4592/4708 - The training loss at 14th epoch : 0.09065934685837024  Training Accuracy:0.8773871527777778\n",
            "4608/4708 - The training loss at 14th epoch : 0.09061415738641526  Training Accuracy:0.8775951557093425\n",
            "4624/4708 - The training loss at 14th epoch : 0.09057730683797673  Training Accuracy:0.877801724137931\n",
            "4640/4708 - The training loss at 14th epoch : 0.09056395087089847  Training Accuracy:0.8775773195876289\n",
            "4656/4708 - The training loss at 14th epoch : 0.09066228596954536  Training Accuracy:0.8773544520547946\n",
            "4672/4708 - The training loss at 14th epoch : 0.09074362604694149  Training Accuracy:0.876919795221843\n",
            "4688/4708 - The training loss at 14th epoch : 0.09067056528300332  Training Accuracy:0.8769132653061225\n",
            "4704/4708 - The training loss at 14th epoch : 0.09061419967446803  Training Accuracy:0.8769067796610169\n",
            "4720/4708 - The training loss at 14th epoch : 0.09052840567753438  Training Accuracy:0.8771114864864865\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 15th epoch : 0.10865005249806828  Training Accuracy:0.8125\n",
            "16/4708 - The training loss at 15th epoch : 0.08573884571551599  Training Accuracy:0.875\n",
            "32/4708 - The training loss at 15th epoch : 0.07247342777478094  Training Accuracy:0.8958333333333334\n",
            "48/4708 - The training loss at 15th epoch : 0.08786107915442704  Training Accuracy:0.890625\n",
            "64/4708 - The training loss at 15th epoch : 0.08486852727030478  Training Accuracy:0.9\n",
            "80/4708 - The training loss at 15th epoch : 0.08124059853336714  Training Accuracy:0.90625\n",
            "96/4708 - The training loss at 15th epoch : 0.09479824341641303  Training Accuracy:0.8839285714285714\n",
            "112/4708 - The training loss at 15th epoch : 0.08917941039330793  Training Accuracy:0.890625\n",
            "128/4708 - The training loss at 15th epoch : 0.08534569351435399  Training Accuracy:0.8958333333333334\n",
            "144/4708 - The training loss at 15th epoch : 0.07944965541649064  Training Accuracy:0.9\n",
            "160/4708 - The training loss at 15th epoch : 0.07785124819462626  Training Accuracy:0.9034090909090909\n",
            "176/4708 - The training loss at 15th epoch : 0.08638372057688036  Training Accuracy:0.890625\n",
            "192/4708 - The training loss at 15th epoch : 0.09294247070841713  Training Accuracy:0.8798076923076923\n",
            "208/4708 - The training loss at 15th epoch : 0.09409924990492098  Training Accuracy:0.8705357142857143\n",
            "224/4708 - The training loss at 15th epoch : 0.0915066281854843  Training Accuracy:0.8708333333333333\n",
            "240/4708 - The training loss at 15th epoch : 0.09506405324100739  Training Accuracy:0.859375\n",
            "256/4708 - The training loss at 15th epoch : 0.09745303180359588  Training Accuracy:0.8566176470588235\n",
            "272/4708 - The training loss at 15th epoch : 0.09515581281574048  Training Accuracy:0.8611111111111112\n",
            "288/4708 - The training loss at 15th epoch : 0.09293424372867999  Training Accuracy:0.8618421052631579\n",
            "304/4708 - The training loss at 15th epoch : 0.0928779944180473  Training Accuracy:0.8625\n",
            "320/4708 - The training loss at 15th epoch : 0.09357462604859094  Training Accuracy:0.8630952380952381\n",
            "336/4708 - The training loss at 15th epoch : 0.08977187889126502  Training Accuracy:0.8693181818181818\n",
            "352/4708 - The training loss at 15th epoch : 0.08754131710922182  Training Accuracy:0.8722826086956522\n",
            "368/4708 - The training loss at 15th epoch : 0.0869536314149224  Training Accuracy:0.8723958333333334\n",
            "384/4708 - The training loss at 15th epoch : 0.08361248955386197  Training Accuracy:0.8775\n",
            "400/4708 - The training loss at 15th epoch : 0.08735232339210222  Training Accuracy:0.8725961538461539\n",
            "416/4708 - The training loss at 15th epoch : 0.08637203241350679  Training Accuracy:0.875\n",
            "432/4708 - The training loss at 15th epoch : 0.08784727275532513  Training Accuracy:0.875\n",
            "448/4708 - The training loss at 15th epoch : 0.08677422981211771  Training Accuracy:0.8771551724137931\n",
            "464/4708 - The training loss at 15th epoch : 0.08584477987641012  Training Accuracy:0.8791666666666667\n",
            "480/4708 - The training loss at 15th epoch : 0.08629200295735345  Training Accuracy:0.8790322580645161\n",
            "496/4708 - The training loss at 15th epoch : 0.08486979892938523  Training Accuracy:0.880859375\n",
            "512/4708 - The training loss at 15th epoch : 0.08589776324621518  Training Accuracy:0.8806818181818182\n",
            "528/4708 - The training loss at 15th epoch : 0.0867659685445506  Training Accuracy:0.8805147058823529\n",
            "544/4708 - The training loss at 15th epoch : 0.08692103323961413  Training Accuracy:0.8821428571428571\n",
            "560/4708 - The training loss at 15th epoch : 0.08829133263331838  Training Accuracy:0.8784722222222222\n",
            "576/4708 - The training loss at 15th epoch : 0.08959224355338666  Training Accuracy:0.8766891891891891\n",
            "592/4708 - The training loss at 15th epoch : 0.08773329712659675  Training Accuracy:0.8799342105263158\n",
            "608/4708 - The training loss at 15th epoch : 0.08922660794403994  Training Accuracy:0.8782051282051282\n",
            "624/4708 - The training loss at 15th epoch : 0.091201884721931  Training Accuracy:0.875\n",
            "640/4708 - The training loss at 15th epoch : 0.0901203236538718  Training Accuracy:0.8765243902439024\n",
            "656/4708 - The training loss at 15th epoch : 0.08887459221333187  Training Accuracy:0.8779761904761905\n",
            "672/4708 - The training loss at 15th epoch : 0.09068037278678483  Training Accuracy:0.875\n",
            "688/4708 - The training loss at 15th epoch : 0.08944805339265295  Training Accuracy:0.8764204545454546\n",
            "704/4708 - The training loss at 15th epoch : 0.0896070571098503  Training Accuracy:0.8763888888888889\n",
            "720/4708 - The training loss at 15th epoch : 0.09071641203295992  Training Accuracy:0.873641304347826\n",
            "736/4708 - The training loss at 15th epoch : 0.09156938184369273  Training Accuracy:0.8723404255319149\n",
            "752/4708 - The training loss at 15th epoch : 0.09220735311146404  Training Accuracy:0.8723958333333334\n",
            "768/4708 - The training loss at 15th epoch : 0.09216234045556312  Training Accuracy:0.8724489795918368\n",
            "784/4708 - The training loss at 15th epoch : 0.09234804341274933  Training Accuracy:0.87125\n",
            "800/4708 - The training loss at 15th epoch : 0.09304089495335383  Training Accuracy:0.8688725490196079\n",
            "816/4708 - The training loss at 15th epoch : 0.09263193355835964  Training Accuracy:0.8689903846153846\n",
            "832/4708 - The training loss at 15th epoch : 0.09244474091089379  Training Accuracy:0.8691037735849056\n",
            "848/4708 - The training loss at 15th epoch : 0.0938152234001743  Training Accuracy:0.8657407407407407\n",
            "864/4708 - The training loss at 15th epoch : 0.09371788889922046  Training Accuracy:0.865909090909091\n",
            "880/4708 - The training loss at 15th epoch : 0.09456397701264783  Training Accuracy:0.8660714285714286\n",
            "896/4708 - The training loss at 15th epoch : 0.09549533223389108  Training Accuracy:0.8640350877192983\n",
            "912/4708 - The training loss at 15th epoch : 0.09444449021543737  Training Accuracy:0.8663793103448276\n",
            "928/4708 - The training loss at 15th epoch : 0.09614680615158544  Training Accuracy:0.864406779661017\n",
            "944/4708 - The training loss at 15th epoch : 0.09592862068327722  Training Accuracy:0.865625\n",
            "960/4708 - The training loss at 15th epoch : 0.09564250846556213  Training Accuracy:0.8668032786885246\n",
            "976/4708 - The training loss at 15th epoch : 0.09502249648222272  Training Accuracy:0.8669354838709677\n",
            "992/4708 - The training loss at 15th epoch : 0.09488124678542907  Training Accuracy:0.8670634920634921\n",
            "1008/4708 - The training loss at 15th epoch : 0.094911038435843  Training Accuracy:0.8671875\n",
            "1024/4708 - The training loss at 15th epoch : 0.09433956879053544  Training Accuracy:0.8682692307692308\n",
            "1040/4708 - The training loss at 15th epoch : 0.09411091783403121  Training Accuracy:0.8683712121212122\n",
            "1056/4708 - The training loss at 15th epoch : 0.09579848075486433  Training Accuracy:0.8656716417910447\n",
            "1072/4708 - The training loss at 15th epoch : 0.09515126842166195  Training Accuracy:0.8667279411764706\n",
            "1088/4708 - The training loss at 15th epoch : 0.09429614698210652  Training Accuracy:0.8686594202898551\n",
            "1104/4708 - The training loss at 15th epoch : 0.0933583685477826  Training Accuracy:0.8705357142857143\n",
            "1120/4708 - The training loss at 15th epoch : 0.09335664737948106  Training Accuracy:0.8705985915492958\n",
            "1136/4708 - The training loss at 15th epoch : 0.09351264262796653  Training Accuracy:0.8706597222222222\n",
            "1152/4708 - The training loss at 15th epoch : 0.09344696421703964  Training Accuracy:0.8698630136986302\n",
            "1168/4708 - The training loss at 15th epoch : 0.09285567831208567  Training Accuracy:0.870777027027027\n",
            "1184/4708 - The training loss at 15th epoch : 0.09193684490050749  Training Accuracy:0.8716666666666667\n",
            "1200/4708 - The training loss at 15th epoch : 0.09182735999505136  Training Accuracy:0.8717105263157895\n",
            "1216/4708 - The training loss at 15th epoch : 0.09083597663611614  Training Accuracy:0.8733766233766234\n",
            "1232/4708 - The training loss at 15th epoch : 0.09173158782558631  Training Accuracy:0.8717948717948718\n",
            "1248/4708 - The training loss at 15th epoch : 0.0908050010705167  Training Accuracy:0.8734177215189873\n",
            "1264/4708 - The training loss at 15th epoch : 0.09177385701290995  Training Accuracy:0.87109375\n",
            "1280/4708 - The training loss at 15th epoch : 0.09250437236490917  Training Accuracy:0.8703703703703703\n",
            "1296/4708 - The training loss at 15th epoch : 0.09166870463491622  Training Accuracy:0.8719512195121951\n",
            "1312/4708 - The training loss at 15th epoch : 0.09088266110224538  Training Accuracy:0.8727409638554217\n",
            "1328/4708 - The training loss at 15th epoch : 0.09116968434075667  Training Accuracy:0.8720238095238095\n",
            "1344/4708 - The training loss at 15th epoch : 0.09150816321883445  Training Accuracy:0.8713235294117647\n",
            "1360/4708 - The training loss at 15th epoch : 0.09211582104555628  Training Accuracy:0.8706395348837209\n",
            "1376/4708 - The training loss at 15th epoch : 0.0917332863704911  Training Accuracy:0.8714080459770115\n",
            "1392/4708 - The training loss at 15th epoch : 0.09184585586497697  Training Accuracy:0.8707386363636364\n",
            "1408/4708 - The training loss at 15th epoch : 0.09180786611337638  Training Accuracy:0.8707865168539326\n",
            "1424/4708 - The training loss at 15th epoch : 0.09252894095259548  Training Accuracy:0.8701388888888889\n",
            "1440/4708 - The training loss at 15th epoch : 0.09372140653214647  Training Accuracy:0.867445054945055\n",
            "1456/4708 - The training loss at 15th epoch : 0.09361165378845791  Training Accuracy:0.8688858695652174\n",
            "1472/4708 - The training loss at 15th epoch : 0.09377210601245699  Training Accuracy:0.8689516129032258\n",
            "1488/4708 - The training loss at 15th epoch : 0.09351153175691707  Training Accuracy:0.8690159574468085\n",
            "1504/4708 - The training loss at 15th epoch : 0.09421140946494853  Training Accuracy:0.868421052631579\n",
            "1520/4708 - The training loss at 15th epoch : 0.09353773137420833  Training Accuracy:0.869140625\n",
            "1536/4708 - The training loss at 15th epoch : 0.09339190238309072  Training Accuracy:0.8685567010309279\n",
            "1552/4708 - The training loss at 15th epoch : 0.09407139462555635  Training Accuracy:0.8679846938775511\n",
            "1568/4708 - The training loss at 15th epoch : 0.09358526386373085  Training Accuracy:0.8686868686868687\n",
            "1584/4708 - The training loss at 15th epoch : 0.09384714175084229  Training Accuracy:0.86875\n",
            "1600/4708 - The training loss at 15th epoch : 0.09462054496763675  Training Accuracy:0.8675742574257426\n",
            "1616/4708 - The training loss at 15th epoch : 0.09426381526448399  Training Accuracy:0.8682598039215687\n",
            "1632/4708 - The training loss at 15th epoch : 0.0938463363405947  Training Accuracy:0.8689320388349514\n",
            "1648/4708 - The training loss at 15th epoch : 0.09385089011205497  Training Accuracy:0.8695913461538461\n",
            "1664/4708 - The training loss at 15th epoch : 0.09426437163389725  Training Accuracy:0.8690476190476191\n",
            "1680/4708 - The training loss at 15th epoch : 0.09405715294826208  Training Accuracy:0.8685141509433962\n",
            "1696/4708 - The training loss at 15th epoch : 0.09344017853109268  Training Accuracy:0.8697429906542056\n",
            "1712/4708 - The training loss at 15th epoch : 0.09305977317843472  Training Accuracy:0.8703703703703703\n",
            "1728/4708 - The training loss at 15th epoch : 0.09287631762598222  Training Accuracy:0.8709862385321101\n",
            "1744/4708 - The training loss at 15th epoch : 0.09221846098173202  Training Accuracy:0.8715909090909091\n",
            "1760/4708 - The training loss at 15th epoch : 0.0928824656273573  Training Accuracy:0.8710585585585585\n",
            "1776/4708 - The training loss at 15th epoch : 0.09284728152956327  Training Accuracy:0.87109375\n",
            "1792/4708 - The training loss at 15th epoch : 0.09283334405120319  Training Accuracy:0.8711283185840708\n",
            "1808/4708 - The training loss at 15th epoch : 0.09222923824022118  Training Accuracy:0.8722587719298246\n",
            "1824/4708 - The training loss at 15th epoch : 0.09227396265256338  Training Accuracy:0.8722826086956522\n",
            "1840/4708 - The training loss at 15th epoch : 0.09232860464870782  Training Accuracy:0.8728448275862069\n",
            "1856/4708 - The training loss at 15th epoch : 0.09212458573360705  Training Accuracy:0.8733974358974359\n",
            "1872/4708 - The training loss at 15th epoch : 0.09292625065579165  Training Accuracy:0.871822033898305\n",
            "1888/4708 - The training loss at 15th epoch : 0.0932829026151278  Training Accuracy:0.8707983193277311\n",
            "1904/4708 - The training loss at 15th epoch : 0.09308051355219145  Training Accuracy:0.8708333333333333\n",
            "1920/4708 - The training loss at 15th epoch : 0.09380013821367204  Training Accuracy:0.8698347107438017\n",
            "1936/4708 - The training loss at 15th epoch : 0.09336509764004561  Training Accuracy:0.8703893442622951\n",
            "1952/4708 - The training loss at 15th epoch : 0.09348527187048765  Training Accuracy:0.8699186991869918\n",
            "1968/4708 - The training loss at 15th epoch : 0.09283008787099618  Training Accuracy:0.8709677419354839\n",
            "1984/4708 - The training loss at 15th epoch : 0.09254587292819676  Training Accuracy:0.871\n",
            "2000/4708 - The training loss at 15th epoch : 0.09268337116724738  Training Accuracy:0.871031746031746\n",
            "2016/4708 - The training loss at 15th epoch : 0.09206225605099815  Training Accuracy:0.8720472440944882\n",
            "2032/4708 - The training loss at 15th epoch : 0.09167633194141113  Training Accuracy:0.87255859375\n",
            "2048/4708 - The training loss at 15th epoch : 0.0915431120946991  Training Accuracy:0.872577519379845\n",
            "2064/4708 - The training loss at 15th epoch : 0.0913830678617458  Training Accuracy:0.8725961538461539\n",
            "2080/4708 - The training loss at 15th epoch : 0.09139961427276753  Training Accuracy:0.8726145038167938\n",
            "2096/4708 - The training loss at 15th epoch : 0.09150446502803118  Training Accuracy:0.8726325757575758\n",
            "2112/4708 - The training loss at 15th epoch : 0.09186190746809932  Training Accuracy:0.8721804511278195\n",
            "2128/4708 - The training loss at 15th epoch : 0.09174985158311692  Training Accuracy:0.8726679104477612\n",
            "2144/4708 - The training loss at 15th epoch : 0.09145609063745404  Training Accuracy:0.8731481481481481\n",
            "2160/4708 - The training loss at 15th epoch : 0.09174200375980275  Training Accuracy:0.8727022058823529\n",
            "2176/4708 - The training loss at 15th epoch : 0.09159000237048939  Training Accuracy:0.8727189781021898\n",
            "2192/4708 - The training loss at 15th epoch : 0.09103808583366382  Training Accuracy:0.873641304347826\n",
            "2208/4708 - The training loss at 15th epoch : 0.09092012199839276  Training Accuracy:0.8736510791366906\n",
            "2224/4708 - The training loss at 15th epoch : 0.09156849068956152  Training Accuracy:0.8732142857142857\n",
            "2240/4708 - The training loss at 15th epoch : 0.09194676207502839  Training Accuracy:0.8727836879432624\n",
            "2256/4708 - The training loss at 15th epoch : 0.09177928383919363  Training Accuracy:0.8732394366197183\n",
            "2272/4708 - The training loss at 15th epoch : 0.09157842125615341  Training Accuracy:0.8732517482517482\n",
            "2288/4708 - The training loss at 15th epoch : 0.09226585411434565  Training Accuracy:0.8723958333333334\n",
            "2304/4708 - The training loss at 15th epoch : 0.09237785492191476  Training Accuracy:0.8724137931034482\n",
            "2320/4708 - The training loss at 15th epoch : 0.09248238926745186  Training Accuracy:0.8715753424657534\n",
            "2336/4708 - The training loss at 15th epoch : 0.09271781477699186  Training Accuracy:0.8715986394557823\n",
            "2352/4708 - The training loss at 15th epoch : 0.09256617709535876  Training Accuracy:0.8711993243243243\n",
            "2368/4708 - The training loss at 15th epoch : 0.09272317026448489  Training Accuracy:0.8708053691275168\n",
            "2384/4708 - The training loss at 15th epoch : 0.09281403696149954  Training Accuracy:0.8704166666666666\n",
            "2400/4708 - The training loss at 15th epoch : 0.09268283787566874  Training Accuracy:0.8708609271523179\n",
            "2416/4708 - The training loss at 15th epoch : 0.09307723828329617  Training Accuracy:0.8700657894736842\n",
            "2432/4708 - The training loss at 15th epoch : 0.0930927923026602  Training Accuracy:0.8700980392156863\n",
            "2448/4708 - The training loss at 15th epoch : 0.09379049139635863  Training Accuracy:0.8693181818181818\n",
            "2464/4708 - The training loss at 15th epoch : 0.09358818719486815  Training Accuracy:0.8693548387096774\n",
            "2480/4708 - The training loss at 15th epoch : 0.09349822712517554  Training Accuracy:0.8697916666666666\n",
            "2496/4708 - The training loss at 15th epoch : 0.09394775945361898  Training Accuracy:0.8694267515923567\n",
            "2512/4708 - The training loss at 15th epoch : 0.09385502626627054  Training Accuracy:0.8694620253164557\n",
            "2528/4708 - The training loss at 15th epoch : 0.09387250259499637  Training Accuracy:0.8694968553459119\n",
            "2544/4708 - The training loss at 15th epoch : 0.09423431917414739  Training Accuracy:0.869140625\n",
            "2560/4708 - The training loss at 15th epoch : 0.09396079952752506  Training Accuracy:0.8695652173913043\n",
            "2576/4708 - The training loss at 15th epoch : 0.09392185293969112  Training Accuracy:0.8695987654320988\n",
            "2592/4708 - The training loss at 15th epoch : 0.093671720481348  Training Accuracy:0.8696319018404908\n",
            "2608/4708 - The training loss at 15th epoch : 0.09366325948721047  Training Accuracy:0.8696646341463414\n",
            "2624/4708 - The training loss at 15th epoch : 0.09351395551731212  Training Accuracy:0.8700757575757576\n",
            "2640/4708 - The training loss at 15th epoch : 0.09332609393621641  Training Accuracy:0.8704819277108434\n",
            "2656/4708 - The training loss at 15th epoch : 0.09316268679232677  Training Accuracy:0.8708832335329342\n",
            "2672/4708 - The training loss at 15th epoch : 0.09272270282685892  Training Accuracy:0.8716517857142857\n",
            "2688/4708 - The training loss at 15th epoch : 0.09268729683140345  Training Accuracy:0.8720414201183432\n",
            "2704/4708 - The training loss at 15th epoch : 0.09280296435789481  Training Accuracy:0.8720588235294118\n",
            "2720/4708 - The training loss at 15th epoch : 0.09281091043493839  Training Accuracy:0.8717105263157895\n",
            "2736/4708 - The training loss at 15th epoch : 0.09288242067376262  Training Accuracy:0.8717296511627907\n",
            "2752/4708 - The training loss at 15th epoch : 0.09313594861028784  Training Accuracy:0.8717485549132948\n",
            "2768/4708 - The training loss at 15th epoch : 0.09271397187058647  Training Accuracy:0.8724856321839081\n",
            "2784/4708 - The training loss at 15th epoch : 0.09297789673465932  Training Accuracy:0.8721428571428571\n",
            "2800/4708 - The training loss at 15th epoch : 0.09261738153659932  Training Accuracy:0.8725142045454546\n",
            "2816/4708 - The training loss at 15th epoch : 0.09280967751258323  Training Accuracy:0.8721751412429378\n",
            "2832/4708 - The training loss at 15th epoch : 0.09303342108069464  Training Accuracy:0.8718398876404494\n",
            "2848/4708 - The training loss at 15th epoch : 0.09282290967282032  Training Accuracy:0.8722067039106145\n",
            "2864/4708 - The training loss at 15th epoch : 0.0926936271043882  Training Accuracy:0.8725694444444444\n",
            "2880/4708 - The training loss at 15th epoch : 0.09234389407754112  Training Accuracy:0.8732734806629834\n",
            "2896/4708 - The training loss at 15th epoch : 0.09193099792443073  Training Accuracy:0.8739697802197802\n",
            "2912/4708 - The training loss at 15th epoch : 0.09181135193566828  Training Accuracy:0.8739754098360656\n",
            "2928/4708 - The training loss at 15th epoch : 0.09190859886731387  Training Accuracy:0.8733016304347826\n",
            "2944/4708 - The training loss at 15th epoch : 0.09220047471143714  Training Accuracy:0.8729729729729729\n",
            "2960/4708 - The training loss at 15th epoch : 0.09276183339970073  Training Accuracy:0.8716397849462365\n",
            "2976/4708 - The training loss at 15th epoch : 0.09262807598731047  Training Accuracy:0.8719919786096256\n",
            "2992/4708 - The training loss at 15th epoch : 0.09230702943571915  Training Accuracy:0.8726728723404256\n",
            "3008/4708 - The training loss at 15th epoch : 0.09243686778993437  Training Accuracy:0.8723544973544973\n",
            "3024/4708 - The training loss at 15th epoch : 0.09215091344354351  Training Accuracy:0.8730263157894737\n",
            "3040/4708 - The training loss at 15th epoch : 0.09218524444244014  Training Accuracy:0.8730366492146597\n",
            "3056/4708 - The training loss at 15th epoch : 0.09180812402069759  Training Accuracy:0.8736979166666666\n",
            "3072/4708 - The training loss at 15th epoch : 0.09192678639258757  Training Accuracy:0.8737046632124352\n",
            "3088/4708 - The training loss at 15th epoch : 0.09169359281295841  Training Accuracy:0.8743556701030928\n",
            "3104/4708 - The training loss at 15th epoch : 0.09198226012064106  Training Accuracy:0.8737179487179487\n",
            "3120/4708 - The training loss at 15th epoch : 0.09192976550162514  Training Accuracy:0.8737244897959183\n",
            "3136/4708 - The training loss at 15th epoch : 0.09179275976298688  Training Accuracy:0.8740482233502538\n",
            "3152/4708 - The training loss at 15th epoch : 0.09150132733412249  Training Accuracy:0.8743686868686869\n",
            "3168/4708 - The training loss at 15th epoch : 0.09138728862453567  Training Accuracy:0.8743718592964824\n",
            "3184/4708 - The training loss at 15th epoch : 0.0916139044115414  Training Accuracy:0.8740625\n",
            "3200/4708 - The training loss at 15th epoch : 0.09164792216655701  Training Accuracy:0.8740671641791045\n",
            "3216/4708 - The training loss at 15th epoch : 0.0914773586142052  Training Accuracy:0.8743811881188119\n",
            "3232/4708 - The training loss at 15th epoch : 0.0912077733672445  Training Accuracy:0.874692118226601\n",
            "3248/4708 - The training loss at 15th epoch : 0.0914502950116887  Training Accuracy:0.8746936274509803\n",
            "3264/4708 - The training loss at 15th epoch : 0.09119488950084018  Training Accuracy:0.875\n",
            "3280/4708 - The training loss at 15th epoch : 0.09137763235638124  Training Accuracy:0.8746966019417476\n",
            "3296/4708 - The training loss at 15th epoch : 0.09124372775081499  Training Accuracy:0.875\n",
            "3312/4708 - The training loss at 15th epoch : 0.09186225015921498  Training Accuracy:0.8740985576923077\n",
            "3328/4708 - The training loss at 15th epoch : 0.091908206754483  Training Accuracy:0.8744019138755981\n",
            "3344/4708 - The training loss at 15th epoch : 0.09191209652455115  Training Accuracy:0.8744047619047619\n",
            "3360/4708 - The training loss at 15th epoch : 0.09163202666517949  Training Accuracy:0.8747037914691943\n",
            "3376/4708 - The training loss at 15th epoch : 0.09166723268497205  Training Accuracy:0.8744103773584906\n",
            "3392/4708 - The training loss at 15th epoch : 0.09216044441894487  Training Accuracy:0.8735328638497653\n",
            "3408/4708 - The training loss at 15th epoch : 0.09244236957333259  Training Accuracy:0.8732476635514018\n",
            "3424/4708 - The training loss at 15th epoch : 0.09210651311049488  Training Accuracy:0.8738372093023256\n",
            "3440/4708 - The training loss at 15th epoch : 0.09197096972738492  Training Accuracy:0.8738425925925926\n",
            "3456/4708 - The training loss at 15th epoch : 0.0923640837012553  Training Accuracy:0.8735599078341014\n",
            "3472/4708 - The training loss at 15th epoch : 0.09204676865298375  Training Accuracy:0.8741399082568807\n",
            "3488/4708 - The training loss at 15th epoch : 0.0919518493387505  Training Accuracy:0.8741438356164384\n",
            "3504/4708 - The training loss at 15th epoch : 0.09224655431268601  Training Accuracy:0.8738636363636364\n",
            "3520/4708 - The training loss at 15th epoch : 0.09223918508277182  Training Accuracy:0.8741515837104072\n",
            "3536/4708 - The training loss at 15th epoch : 0.09213281947524872  Training Accuracy:0.8744369369369369\n",
            "3552/4708 - The training loss at 15th epoch : 0.09220613536239194  Training Accuracy:0.874439461883408\n",
            "3568/4708 - The training loss at 15th epoch : 0.09213208081578725  Training Accuracy:0.8747209821428571\n",
            "3584/4708 - The training loss at 15th epoch : 0.09212341785643624  Training Accuracy:0.8747222222222222\n",
            "3600/4708 - The training loss at 15th epoch : 0.09252796343457939  Training Accuracy:0.8741703539823009\n",
            "3616/4708 - The training loss at 15th epoch : 0.0923960492672225  Training Accuracy:0.8744493392070485\n",
            "3632/4708 - The training loss at 15th epoch : 0.09247347864246447  Training Accuracy:0.8741776315789473\n",
            "3648/4708 - The training loss at 15th epoch : 0.09227522235219782  Training Accuracy:0.8744541484716157\n",
            "3664/4708 - The training loss at 15th epoch : 0.0923519462524869  Training Accuracy:0.8741847826086957\n",
            "3680/4708 - The training loss at 15th epoch : 0.09206535045505405  Training Accuracy:0.8747294372294372\n",
            "3696/4708 - The training loss at 15th epoch : 0.09202398091833754  Training Accuracy:0.8747306034482759\n",
            "3712/4708 - The training loss at 15th epoch : 0.09170000741331662  Training Accuracy:0.8752682403433476\n",
            "3728/4708 - The training loss at 15th epoch : 0.09174857812997295  Training Accuracy:0.875267094017094\n",
            "3744/4708 - The training loss at 15th epoch : 0.09181189920439896  Training Accuracy:0.8752659574468085\n",
            "3760/4708 - The training loss at 15th epoch : 0.09204094307217081  Training Accuracy:0.8747351694915254\n",
            "3776/4708 - The training loss at 15th epoch : 0.09212672281723076  Training Accuracy:0.8744725738396625\n",
            "3792/4708 - The training loss at 15th epoch : 0.09213331028060648  Training Accuracy:0.8744747899159664\n",
            "3808/4708 - The training loss at 15th epoch : 0.09203467238525495  Training Accuracy:0.8747384937238494\n",
            "3824/4708 - The training loss at 15th epoch : 0.09251365763339753  Training Accuracy:0.8739583333333333\n",
            "3840/4708 - The training loss at 15th epoch : 0.09236306541523737  Training Accuracy:0.8742219917012448\n",
            "3856/4708 - The training loss at 15th epoch : 0.09242444594923477  Training Accuracy:0.8739669421487604\n",
            "3872/4708 - The training loss at 15th epoch : 0.09217593617400155  Training Accuracy:0.8742283950617284\n",
            "3888/4708 - The training loss at 15th epoch : 0.09211154895278074  Training Accuracy:0.8744877049180327\n",
            "3904/4708 - The training loss at 15th epoch : 0.09175107354804309  Training Accuracy:0.875\n",
            "3920/4708 - The training loss at 15th epoch : 0.09203697607817081  Training Accuracy:0.8747459349593496\n",
            "3936/4708 - The training loss at 15th epoch : 0.09173805913420986  Training Accuracy:0.875253036437247\n",
            "3952/4708 - The training loss at 15th epoch : 0.09169123625175805  Training Accuracy:0.8752520161290323\n",
            "3968/4708 - The training loss at 15th epoch : 0.09177565526119474  Training Accuracy:0.875\n",
            "3984/4708 - The training loss at 15th epoch : 0.0916036878425366  Training Accuracy:0.87525\n",
            "4000/4708 - The training loss at 15th epoch : 0.09177960022360568  Training Accuracy:0.8752490039840638\n",
            "4016/4708 - The training loss at 15th epoch : 0.09155702508780998  Training Accuracy:0.8754960317460317\n",
            "4032/4708 - The training loss at 15th epoch : 0.09163321054993527  Training Accuracy:0.8752470355731226\n",
            "4048/4708 - The training loss at 15th epoch : 0.09196850642881076  Training Accuracy:0.874753937007874\n",
            "4064/4708 - The training loss at 15th epoch : 0.09171052363065146  Training Accuracy:0.875\n",
            "4080/4708 - The training loss at 15th epoch : 0.09176126713110175  Training Accuracy:0.875\n",
            "4096/4708 - The training loss at 15th epoch : 0.09159560247424889  Training Accuracy:0.8752431906614786\n",
            "4112/4708 - The training loss at 15th epoch : 0.09157668204034478  Training Accuracy:0.875\n",
            "4128/4708 - The training loss at 15th epoch : 0.09176708854787903  Training Accuracy:0.8745173745173745\n",
            "4144/4708 - The training loss at 15th epoch : 0.09170181043999485  Training Accuracy:0.8745192307692308\n",
            "4160/4708 - The training loss at 15th epoch : 0.09153481229676458  Training Accuracy:0.8747605363984674\n",
            "4176/4708 - The training loss at 15th epoch : 0.09173719361757288  Training Accuracy:0.8745229007633588\n",
            "4192/4708 - The training loss at 15th epoch : 0.09186245852582126  Training Accuracy:0.874287072243346\n",
            "4208/4708 - The training loss at 15th epoch : 0.09224252905858889  Training Accuracy:0.8738162878787878\n",
            "4224/4708 - The training loss at 15th epoch : 0.09216607459076955  Training Accuracy:0.8738207547169812\n",
            "4240/4708 - The training loss at 15th epoch : 0.09198147245429239  Training Accuracy:0.8740601503759399\n",
            "4256/4708 - The training loss at 15th epoch : 0.09197271938658004  Training Accuracy:0.8740636704119851\n",
            "4272/4708 - The training loss at 15th epoch : 0.09188387345889291  Training Accuracy:0.8743003731343284\n",
            "4288/4708 - The training loss at 15th epoch : 0.09201298660214585  Training Accuracy:0.8740706319702602\n",
            "4304/4708 - The training loss at 15th epoch : 0.09232172273386963  Training Accuracy:0.8736111111111111\n",
            "4320/4708 - The training loss at 15th epoch : 0.09225058293408651  Training Accuracy:0.8738468634686347\n",
            "4336/4708 - The training loss at 15th epoch : 0.0924138662290232  Training Accuracy:0.8736213235294118\n",
            "4352/4708 - The training loss at 15th epoch : 0.09229739564637572  Training Accuracy:0.8738553113553114\n",
            "4368/4708 - The training loss at 15th epoch : 0.09258908536427682  Training Accuracy:0.8734032846715328\n",
            "4384/4708 - The training loss at 15th epoch : 0.09229828792358769  Training Accuracy:0.8738636363636364\n",
            "4400/4708 - The training loss at 15th epoch : 0.09206978341774558  Training Accuracy:0.8740942028985508\n",
            "4416/4708 - The training loss at 15th epoch : 0.09196353175137814  Training Accuracy:0.8743231046931408\n",
            "4432/4708 - The training loss at 15th epoch : 0.09215830855145264  Training Accuracy:0.8741007194244604\n",
            "4448/4708 - The training loss at 15th epoch : 0.09192135351677824  Training Accuracy:0.8745519713261649\n",
            "4464/4708 - The training loss at 15th epoch : 0.09184854436920169  Training Accuracy:0.8745535714285714\n",
            "4480/4708 - The training loss at 15th epoch : 0.09157103170145797  Training Accuracy:0.875\n",
            "4496/4708 - The training loss at 15th epoch : 0.09126287233737806  Training Accuracy:0.8754432624113475\n",
            "4512/4708 - The training loss at 15th epoch : 0.09127590708928686  Training Accuracy:0.8752208480565371\n",
            "4528/4708 - The training loss at 15th epoch : 0.09125594245533657  Training Accuracy:0.8752200704225352\n",
            "4544/4708 - The training loss at 15th epoch : 0.09153520438673149  Training Accuracy:0.8747807017543859\n",
            "4560/4708 - The training loss at 15th epoch : 0.09149384169182795  Training Accuracy:0.8747814685314685\n",
            "4576/4708 - The training loss at 15th epoch : 0.0912019147070463  Training Accuracy:0.8752177700348432\n",
            "4592/4708 - The training loss at 15th epoch : 0.09094721133109686  Training Accuracy:0.8756510416666666\n",
            "4608/4708 - The training loss at 15th epoch : 0.09090753284008897  Training Accuracy:0.8758650519031141\n",
            "4624/4708 - The training loss at 15th epoch : 0.09087273742271183  Training Accuracy:0.875646551724138\n",
            "4640/4708 - The training loss at 15th epoch : 0.0906062332188492  Training Accuracy:0.876073883161512\n",
            "4656/4708 - The training loss at 15th epoch : 0.09109348887564336  Training Accuracy:0.8754280821917808\n",
            "4672/4708 - The training loss at 15th epoch : 0.0910701246472091  Training Accuracy:0.8756399317406144\n",
            "4688/4708 - The training loss at 15th epoch : 0.09083606583168799  Training Accuracy:0.876062925170068\n",
            "4704/4708 - The training loss at 15th epoch : 0.09094233765509163  Training Accuracy:0.8758474576271187\n",
            "4720/4708 - The training loss at 15th epoch : 0.09099497897232862  Training Accuracy:0.8758445945945946\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 16th epoch : 0.058510970206423776  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 16th epoch : 0.15450458808117265  Training Accuracy:0.75\n",
            "32/4708 - The training loss at 16th epoch : 0.1517180377631249  Training Accuracy:0.7916666666666666\n",
            "48/4708 - The training loss at 16th epoch : 0.11916109711358558  Training Accuracy:0.84375\n",
            "64/4708 - The training loss at 16th epoch : 0.11300527469013955  Training Accuracy:0.85\n",
            "80/4708 - The training loss at 16th epoch : 0.1279744845467339  Training Accuracy:0.8333333333333334\n",
            "96/4708 - The training loss at 16th epoch : 0.12885760244141756  Training Accuracy:0.8214285714285714\n",
            "112/4708 - The training loss at 16th epoch : 0.13256450349411253  Training Accuracy:0.8203125\n",
            "128/4708 - The training loss at 16th epoch : 0.13116823254794419  Training Accuracy:0.8263888888888888\n",
            "144/4708 - The training loss at 16th epoch : 0.12209916390842572  Training Accuracy:0.8375\n",
            "160/4708 - The training loss at 16th epoch : 0.11662445869281908  Training Accuracy:0.8465909090909091\n",
            "176/4708 - The training loss at 16th epoch : 0.10835002582305969  Training Accuracy:0.859375\n",
            "192/4708 - The training loss at 16th epoch : 0.10826458632074722  Training Accuracy:0.8557692307692307\n",
            "208/4708 - The training loss at 16th epoch : 0.10606499649918508  Training Accuracy:0.8616071428571429\n",
            "224/4708 - The training loss at 16th epoch : 0.10459884850044958  Training Accuracy:0.8625\n",
            "240/4708 - The training loss at 16th epoch : 0.10200431603193175  Training Accuracy:0.8671875\n",
            "256/4708 - The training loss at 16th epoch : 0.09928629504822946  Training Accuracy:0.8713235294117647\n",
            "272/4708 - The training loss at 16th epoch : 0.09415265127879587  Training Accuracy:0.8784722222222222\n",
            "288/4708 - The training loss at 16th epoch : 0.10016602248034745  Training Accuracy:0.8717105263157895\n",
            "304/4708 - The training loss at 16th epoch : 0.10262260661940197  Training Accuracy:0.86875\n",
            "320/4708 - The training loss at 16th epoch : 0.1018429128689739  Training Accuracy:0.8720238095238095\n",
            "336/4708 - The training loss at 16th epoch : 0.0982786083659185  Training Accuracy:0.875\n",
            "352/4708 - The training loss at 16th epoch : 0.10031562231534438  Training Accuracy:0.8722826086956522\n",
            "368/4708 - The training loss at 16th epoch : 0.09789582482939907  Training Accuracy:0.875\n",
            "384/4708 - The training loss at 16th epoch : 0.0951421620317515  Training Accuracy:0.8775\n",
            "400/4708 - The training loss at 16th epoch : 0.09284125004673055  Training Accuracy:0.8822115384615384\n",
            "416/4708 - The training loss at 16th epoch : 0.0948568191858148  Training Accuracy:0.8773148148148148\n",
            "432/4708 - The training loss at 16th epoch : 0.09623731500600652  Training Accuracy:0.8727678571428571\n",
            "448/4708 - The training loss at 16th epoch : 0.09487057587106452  Training Accuracy:0.875\n",
            "464/4708 - The training loss at 16th epoch : 0.09554260319460404  Training Accuracy:0.8729166666666667\n",
            "480/4708 - The training loss at 16th epoch : 0.09468858784667623  Training Accuracy:0.875\n",
            "496/4708 - The training loss at 16th epoch : 0.09518108475795328  Training Accuracy:0.87109375\n",
            "512/4708 - The training loss at 16th epoch : 0.09419403710546771  Training Accuracy:0.8712121212121212\n",
            "528/4708 - The training loss at 16th epoch : 0.09238018451391834  Training Accuracy:0.8731617647058824\n",
            "544/4708 - The training loss at 16th epoch : 0.09515734461554803  Training Accuracy:0.8696428571428572\n",
            "560/4708 - The training loss at 16th epoch : 0.09662779868540006  Training Accuracy:0.8663194444444444\n",
            "576/4708 - The training loss at 16th epoch : 0.09695517245571274  Training Accuracy:0.8648648648648649\n",
            "592/4708 - The training loss at 16th epoch : 0.09691419754355808  Training Accuracy:0.8651315789473685\n",
            "608/4708 - The training loss at 16th epoch : 0.09613745239037678  Training Accuracy:0.8669871794871795\n",
            "624/4708 - The training loss at 16th epoch : 0.09520835347620121  Training Accuracy:0.8671875\n",
            "640/4708 - The training loss at 16th epoch : 0.09721640049060852  Training Accuracy:0.8658536585365854\n",
            "656/4708 - The training loss at 16th epoch : 0.09624519317431042  Training Accuracy:0.8660714285714286\n",
            "672/4708 - The training loss at 16th epoch : 0.09677426833024128  Training Accuracy:0.8662790697674418\n",
            "688/4708 - The training loss at 16th epoch : 0.09581543985502662  Training Accuracy:0.8678977272727273\n",
            "704/4708 - The training loss at 16th epoch : 0.09485912628152418  Training Accuracy:0.8694444444444445\n",
            "720/4708 - The training loss at 16th epoch : 0.09662467370938678  Training Accuracy:0.8682065217391305\n",
            "736/4708 - The training loss at 16th epoch : 0.09812326623987173  Training Accuracy:0.8656914893617021\n",
            "752/4708 - The training loss at 16th epoch : 0.09946213848263534  Training Accuracy:0.86328125\n",
            "768/4708 - The training loss at 16th epoch : 0.09983378805423938  Training Accuracy:0.8635204081632653\n",
            "784/4708 - The training loss at 16th epoch : 0.10054279826130569  Training Accuracy:0.8625\n",
            "800/4708 - The training loss at 16th epoch : 0.10025761548744415  Training Accuracy:0.8639705882352942\n",
            "816/4708 - The training loss at 16th epoch : 0.10085830824905394  Training Accuracy:0.8617788461538461\n",
            "832/4708 - The training loss at 16th epoch : 0.10100650751944071  Training Accuracy:0.8608490566037735\n",
            "848/4708 - The training loss at 16th epoch : 0.10132625664954482  Training Accuracy:0.8599537037037037\n",
            "864/4708 - The training loss at 16th epoch : 0.10264585380270465  Training Accuracy:0.8579545454545454\n",
            "880/4708 - The training loss at 16th epoch : 0.10156030356074777  Training Accuracy:0.859375\n",
            "896/4708 - The training loss at 16th epoch : 0.10007464606553504  Training Accuracy:0.8618421052631579\n",
            "912/4708 - The training loss at 16th epoch : 0.09854113109170484  Training Accuracy:0.8642241379310345\n",
            "928/4708 - The training loss at 16th epoch : 0.09776349272184276  Training Accuracy:0.8654661016949152\n",
            "944/4708 - The training loss at 16th epoch : 0.09783447704927263  Training Accuracy:0.865625\n",
            "960/4708 - The training loss at 16th epoch : 0.09884080930047018  Training Accuracy:0.8647540983606558\n",
            "976/4708 - The training loss at 16th epoch : 0.09960610208874271  Training Accuracy:0.8639112903225806\n",
            "992/4708 - The training loss at 16th epoch : 0.09913946812053855  Training Accuracy:0.8640873015873016\n",
            "1008/4708 - The training loss at 16th epoch : 0.09957260813147123  Training Accuracy:0.86328125\n",
            "1024/4708 - The training loss at 16th epoch : 0.10036082440941618  Training Accuracy:0.8605769230769231\n",
            "1040/4708 - The training loss at 16th epoch : 0.09975879893803923  Training Accuracy:0.8617424242424242\n",
            "1056/4708 - The training loss at 16th epoch : 0.10045806821949514  Training Accuracy:0.8610074626865671\n",
            "1072/4708 - The training loss at 16th epoch : 0.0996034978692965  Training Accuracy:0.8621323529411765\n",
            "1088/4708 - The training loss at 16th epoch : 0.10022057705667499  Training Accuracy:0.8614130434782609\n",
            "1104/4708 - The training loss at 16th epoch : 0.09997717794235186  Training Accuracy:0.8616071428571429\n",
            "1120/4708 - The training loss at 16th epoch : 0.10040035775229954  Training Accuracy:0.8609154929577465\n",
            "1136/4708 - The training loss at 16th epoch : 0.1005955041568808  Training Accuracy:0.8602430555555556\n",
            "1152/4708 - The training loss at 16th epoch : 0.09957687719089486  Training Accuracy:0.8621575342465754\n",
            "1168/4708 - The training loss at 16th epoch : 0.09975366134517798  Training Accuracy:0.862331081081081\n",
            "1184/4708 - The training loss at 16th epoch : 0.10021430755481188  Training Accuracy:0.8616666666666667\n",
            "1200/4708 - The training loss at 16th epoch : 0.09958283995846749  Training Accuracy:0.8626644736842105\n",
            "1216/4708 - The training loss at 16th epoch : 0.10082072324429467  Training Accuracy:0.8603896103896104\n",
            "1232/4708 - The training loss at 16th epoch : 0.10017197695803219  Training Accuracy:0.8613782051282052\n",
            "1248/4708 - The training loss at 16th epoch : 0.10019661224618265  Training Accuracy:0.8615506329113924\n",
            "1264/4708 - The training loss at 16th epoch : 0.1006272089017427  Training Accuracy:0.86015625\n",
            "1280/4708 - The training loss at 16th epoch : 0.10035393699816815  Training Accuracy:0.8603395061728395\n",
            "1296/4708 - The training loss at 16th epoch : 0.09947687635245372  Training Accuracy:0.8620426829268293\n",
            "1312/4708 - The training loss at 16th epoch : 0.09865832300429409  Training Accuracy:0.8629518072289156\n",
            "1328/4708 - The training loss at 16th epoch : 0.09776335638459795  Training Accuracy:0.8645833333333334\n",
            "1344/4708 - The training loss at 16th epoch : 0.0969973093301331  Training Accuracy:0.8661764705882353\n",
            "1360/4708 - The training loss at 16th epoch : 0.09784203569973533  Training Accuracy:0.8648255813953488\n",
            "1376/4708 - The training loss at 16th epoch : 0.09782052607389637  Training Accuracy:0.8649425287356322\n",
            "1392/4708 - The training loss at 16th epoch : 0.09859436011795011  Training Accuracy:0.8636363636363636\n",
            "1408/4708 - The training loss at 16th epoch : 0.0986219316514499  Training Accuracy:0.8637640449438202\n",
            "1424/4708 - The training loss at 16th epoch : 0.0992601883551891  Training Accuracy:0.8618055555555556\n",
            "1440/4708 - The training loss at 16th epoch : 0.09823534532298425  Training Accuracy:0.8633241758241759\n",
            "1456/4708 - The training loss at 16th epoch : 0.09952879609635593  Training Accuracy:0.860733695652174\n",
            "1472/4708 - The training loss at 16th epoch : 0.09950454764040988  Training Accuracy:0.8608870967741935\n",
            "1488/4708 - The training loss at 16th epoch : 0.09927768167350727  Training Accuracy:0.8610372340425532\n",
            "1504/4708 - The training loss at 16th epoch : 0.09926800705194586  Training Accuracy:0.8605263157894737\n",
            "1520/4708 - The training loss at 16th epoch : 0.09852187734404334  Training Accuracy:0.861328125\n",
            "1536/4708 - The training loss at 16th epoch : 0.09837654732812494  Training Accuracy:0.8614690721649485\n",
            "1552/4708 - The training loss at 16th epoch : 0.09810170200471112  Training Accuracy:0.8616071428571429\n",
            "1568/4708 - The training loss at 16th epoch : 0.09785385841291337  Training Accuracy:0.8617424242424242\n",
            "1584/4708 - The training loss at 16th epoch : 0.09774046468589265  Training Accuracy:0.861875\n",
            "1600/4708 - The training loss at 16th epoch : 0.0970567355349214  Training Accuracy:0.8632425742574258\n",
            "1616/4708 - The training loss at 16th epoch : 0.09640858828507427  Training Accuracy:0.8639705882352942\n",
            "1632/4708 - The training loss at 16th epoch : 0.09651502851311607  Training Accuracy:0.8640776699029126\n",
            "1648/4708 - The training loss at 16th epoch : 0.09620784852048854  Training Accuracy:0.8647836538461539\n",
            "1664/4708 - The training loss at 16th epoch : 0.09578249740204096  Training Accuracy:0.8648809523809524\n",
            "1680/4708 - The training loss at 16th epoch : 0.0949798575939015  Training Accuracy:0.8661556603773585\n",
            "1696/4708 - The training loss at 16th epoch : 0.0951159088380489  Training Accuracy:0.8656542056074766\n",
            "1712/4708 - The training loss at 16th epoch : 0.09504482276260472  Training Accuracy:0.8657407407407407\n",
            "1728/4708 - The training loss at 16th epoch : 0.09445299493372677  Training Accuracy:0.8663990825688074\n",
            "1744/4708 - The training loss at 16th epoch : 0.09417808853419511  Training Accuracy:0.8670454545454546\n",
            "1760/4708 - The training loss at 16th epoch : 0.09408194942058398  Training Accuracy:0.8671171171171171\n",
            "1776/4708 - The training loss at 16th epoch : 0.09359840852422795  Training Accuracy:0.8677455357142857\n",
            "1792/4708 - The training loss at 16th epoch : 0.09324766145558684  Training Accuracy:0.8683628318584071\n",
            "1808/4708 - The training loss at 16th epoch : 0.09348059784676534  Training Accuracy:0.868421052631579\n",
            "1824/4708 - The training loss at 16th epoch : 0.09367087625268522  Training Accuracy:0.8673913043478261\n",
            "1840/4708 - The training loss at 16th epoch : 0.09382911696040462  Training Accuracy:0.8669181034482759\n",
            "1856/4708 - The training loss at 16th epoch : 0.0936439345695736  Training Accuracy:0.8675213675213675\n",
            "1872/4708 - The training loss at 16th epoch : 0.09361774221719793  Training Accuracy:0.8675847457627118\n",
            "1888/4708 - The training loss at 16th epoch : 0.09327486413408512  Training Accuracy:0.868172268907563\n",
            "1904/4708 - The training loss at 16th epoch : 0.09286063071717741  Training Accuracy:0.86875\n",
            "1920/4708 - The training loss at 16th epoch : 0.09287501896004448  Training Accuracy:0.8693181818181818\n",
            "1936/4708 - The training loss at 16th epoch : 0.09262645184725357  Training Accuracy:0.8698770491803278\n",
            "1952/4708 - The training loss at 16th epoch : 0.09287078527685197  Training Accuracy:0.869410569105691\n",
            "1968/4708 - The training loss at 16th epoch : 0.0927674248845008  Training Accuracy:0.8694556451612904\n",
            "1984/4708 - The training loss at 16th epoch : 0.0932865171603305  Training Accuracy:0.869\n",
            "2000/4708 - The training loss at 16th epoch : 0.09343342339220746  Training Accuracy:0.8690476190476191\n",
            "2016/4708 - The training loss at 16th epoch : 0.09306397495362376  Training Accuracy:0.8695866141732284\n",
            "2032/4708 - The training loss at 16th epoch : 0.09235123437301046  Training Accuracy:0.87060546875\n",
            "2048/4708 - The training loss at 16th epoch : 0.09297477583783974  Training Accuracy:0.8701550387596899\n",
            "2064/4708 - The training loss at 16th epoch : 0.0926935579693056  Training Accuracy:0.8701923076923077\n",
            "2080/4708 - The training loss at 16th epoch : 0.09223386726341087  Training Accuracy:0.8711832061068703\n",
            "2096/4708 - The training loss at 16th epoch : 0.09217005091293848  Training Accuracy:0.8712121212121212\n",
            "2112/4708 - The training loss at 16th epoch : 0.0917879962141993  Training Accuracy:0.8721804511278195\n",
            "2128/4708 - The training loss at 16th epoch : 0.09152007627983799  Training Accuracy:0.8726679104477612\n",
            "2144/4708 - The training loss at 16th epoch : 0.0908639170995046  Training Accuracy:0.8736111111111111\n",
            "2160/4708 - The training loss at 16th epoch : 0.09095124410493946  Training Accuracy:0.8731617647058824\n",
            "2176/4708 - The training loss at 16th epoch : 0.09042558562904121  Training Accuracy:0.8740875912408759\n",
            "2192/4708 - The training loss at 16th epoch : 0.08992873803450917  Training Accuracy:0.875\n",
            "2208/4708 - The training loss at 16th epoch : 0.09006217906069165  Training Accuracy:0.875\n",
            "2224/4708 - The training loss at 16th epoch : 0.0896782469731206  Training Accuracy:0.8754464285714286\n",
            "2240/4708 - The training loss at 16th epoch : 0.08993667442970842  Training Accuracy:0.875\n",
            "2256/4708 - The training loss at 16th epoch : 0.08968622283027425  Training Accuracy:0.8754401408450704\n",
            "2272/4708 - The training loss at 16th epoch : 0.08937663372697084  Training Accuracy:0.8758741258741258\n",
            "2288/4708 - The training loss at 16th epoch : 0.08942899910212868  Training Accuracy:0.8758680555555556\n",
            "2304/4708 - The training loss at 16th epoch : 0.08914169056499505  Training Accuracy:0.8762931034482758\n",
            "2320/4708 - The training loss at 16th epoch : 0.08940198277775845  Training Accuracy:0.8762842465753424\n",
            "2336/4708 - The training loss at 16th epoch : 0.08955447300699768  Training Accuracy:0.8758503401360545\n",
            "2352/4708 - The training loss at 16th epoch : 0.0894331583079378  Training Accuracy:0.8762668918918919\n",
            "2368/4708 - The training loss at 16th epoch : 0.08971756790652356  Training Accuracy:0.8758389261744967\n",
            "2384/4708 - The training loss at 16th epoch : 0.08932881186666741  Training Accuracy:0.87625\n",
            "2400/4708 - The training loss at 16th epoch : 0.08955741825782555  Training Accuracy:0.8758278145695364\n",
            "2416/4708 - The training loss at 16th epoch : 0.08991348450737971  Training Accuracy:0.8758223684210527\n",
            "2432/4708 - The training loss at 16th epoch : 0.09044610980061896  Training Accuracy:0.8745915032679739\n",
            "2448/4708 - The training loss at 16th epoch : 0.09031353486580238  Training Accuracy:0.8745941558441559\n",
            "2464/4708 - The training loss at 16th epoch : 0.09069631136467725  Training Accuracy:0.8737903225806452\n",
            "2480/4708 - The training loss at 16th epoch : 0.09084050993025318  Training Accuracy:0.8729967948717948\n",
            "2496/4708 - The training loss at 16th epoch : 0.09105709804516636  Training Accuracy:0.8726114649681529\n",
            "2512/4708 - The training loss at 16th epoch : 0.09101866158154939  Training Accuracy:0.8730221518987342\n",
            "2528/4708 - The training loss at 16th epoch : 0.09049592406331929  Training Accuracy:0.8738207547169812\n",
            "2544/4708 - The training loss at 16th epoch : 0.09058522291872208  Training Accuracy:0.873828125\n",
            "2560/4708 - The training loss at 16th epoch : 0.0909968154088592  Training Accuracy:0.8734472049689441\n",
            "2576/4708 - The training loss at 16th epoch : 0.09095918524813842  Training Accuracy:0.8738425925925926\n",
            "2592/4708 - The training loss at 16th epoch : 0.091320635095462  Training Accuracy:0.8734662576687117\n",
            "2608/4708 - The training loss at 16th epoch : 0.09167701333033088  Training Accuracy:0.8727134146341463\n",
            "2624/4708 - The training loss at 16th epoch : 0.09207424402447562  Training Accuracy:0.871969696969697\n",
            "2640/4708 - The training loss at 16th epoch : 0.0916501578470832  Training Accuracy:0.8727409638554217\n",
            "2656/4708 - The training loss at 16th epoch : 0.09210026560277346  Training Accuracy:0.8723802395209581\n",
            "2672/4708 - The training loss at 16th epoch : 0.09160850221269948  Training Accuracy:0.8731398809523809\n",
            "2688/4708 - The training loss at 16th epoch : 0.09121710138813215  Training Accuracy:0.8738905325443787\n",
            "2704/4708 - The training loss at 16th epoch : 0.09103156563223469  Training Accuracy:0.8742647058823529\n",
            "2720/4708 - The training loss at 16th epoch : 0.09110202809809756  Training Accuracy:0.8739035087719298\n",
            "2736/4708 - The training loss at 16th epoch : 0.09079433562087842  Training Accuracy:0.8742732558139535\n",
            "2752/4708 - The training loss at 16th epoch : 0.09061611809979737  Training Accuracy:0.8746387283236994\n",
            "2768/4708 - The training loss at 16th epoch : 0.09051281778075908  Training Accuracy:0.8746408045977011\n",
            "2784/4708 - The training loss at 16th epoch : 0.09030134448010693  Training Accuracy:0.875\n",
            "2800/4708 - The training loss at 16th epoch : 0.09000054851984948  Training Accuracy:0.8757102272727273\n",
            "2816/4708 - The training loss at 16th epoch : 0.08994121135497084  Training Accuracy:0.8760593220338984\n",
            "2832/4708 - The training loss at 16th epoch : 0.08999040384619617  Training Accuracy:0.8757022471910112\n",
            "2848/4708 - The training loss at 16th epoch : 0.09044252412739694  Training Accuracy:0.8753491620111732\n",
            "2864/4708 - The training loss at 16th epoch : 0.09061625243988704  Training Accuracy:0.875\n",
            "2880/4708 - The training loss at 16th epoch : 0.09018246600583785  Training Accuracy:0.8756906077348067\n",
            "2896/4708 - The training loss at 16th epoch : 0.089939275599109  Training Accuracy:0.8760302197802198\n",
            "2912/4708 - The training loss at 16th epoch : 0.08967793613805393  Training Accuracy:0.8763661202185792\n",
            "2928/4708 - The training loss at 16th epoch : 0.08992438339631123  Training Accuracy:0.876358695652174\n",
            "2944/4708 - The training loss at 16th epoch : 0.08966228108836996  Training Accuracy:0.8766891891891891\n",
            "2960/4708 - The training loss at 16th epoch : 0.08938247606304445  Training Accuracy:0.8770161290322581\n",
            "2976/4708 - The training loss at 16th epoch : 0.0895222542586112  Training Accuracy:0.8770053475935828\n",
            "2992/4708 - The training loss at 16th epoch : 0.08934775302114141  Training Accuracy:0.8769946808510638\n",
            "3008/4708 - The training loss at 16th epoch : 0.08910659975531615  Training Accuracy:0.8776455026455027\n",
            "3024/4708 - The training loss at 16th epoch : 0.08927438457672543  Training Accuracy:0.8773026315789474\n",
            "3040/4708 - The training loss at 16th epoch : 0.08973121522797335  Training Accuracy:0.8766361256544503\n",
            "3056/4708 - The training loss at 16th epoch : 0.0896694123397993  Training Accuracy:0.876953125\n",
            "3072/4708 - The training loss at 16th epoch : 0.08976522715540138  Training Accuracy:0.876619170984456\n",
            "3088/4708 - The training loss at 16th epoch : 0.08986173918614809  Training Accuracy:0.876610824742268\n",
            "3104/4708 - The training loss at 16th epoch : 0.09004146728364991  Training Accuracy:0.8766025641025641\n",
            "3120/4708 - The training loss at 16th epoch : 0.09069387328845685  Training Accuracy:0.8759566326530612\n",
            "3136/4708 - The training loss at 16th epoch : 0.09077617766299136  Training Accuracy:0.8756345177664975\n",
            "3152/4708 - The training loss at 16th epoch : 0.09058593974476173  Training Accuracy:0.8759469696969697\n",
            "3168/4708 - The training loss at 16th epoch : 0.09046617168953743  Training Accuracy:0.8759422110552764\n",
            "3184/4708 - The training loss at 16th epoch : 0.09025420704908267  Training Accuracy:0.8759375\n",
            "3200/4708 - The training loss at 16th epoch : 0.09052169715611036  Training Accuracy:0.8753109452736318\n",
            "3216/4708 - The training loss at 16th epoch : 0.0902634168397417  Training Accuracy:0.8759282178217822\n",
            "3232/4708 - The training loss at 16th epoch : 0.09078047856196628  Training Accuracy:0.875307881773399\n",
            "3248/4708 - The training loss at 16th epoch : 0.09069243044470872  Training Accuracy:0.8756127450980392\n",
            "3264/4708 - The training loss at 16th epoch : 0.09052035336370085  Training Accuracy:0.8759146341463414\n",
            "3280/4708 - The training loss at 16th epoch : 0.09023430954754579  Training Accuracy:0.8765169902912622\n",
            "3296/4708 - The training loss at 16th epoch : 0.0904069907732485  Training Accuracy:0.8765096618357487\n",
            "3312/4708 - The training loss at 16th epoch : 0.09049858985704148  Training Accuracy:0.8765024038461539\n",
            "3328/4708 - The training loss at 16th epoch : 0.0901084261252464  Training Accuracy:0.8770933014354066\n",
            "3344/4708 - The training loss at 16th epoch : 0.08986041847462739  Training Accuracy:0.8773809523809524\n",
            "3360/4708 - The training loss at 16th epoch : 0.0899621422260383  Training Accuracy:0.8767772511848341\n",
            "3376/4708 - The training loss at 16th epoch : 0.0904966283784222  Training Accuracy:0.8758844339622641\n",
            "3392/4708 - The training loss at 16th epoch : 0.0903822208120296  Training Accuracy:0.8761737089201878\n",
            "3408/4708 - The training loss at 16th epoch : 0.09009086194767597  Training Accuracy:0.8764602803738317\n",
            "3424/4708 - The training loss at 16th epoch : 0.09027649181138153  Training Accuracy:0.876453488372093\n",
            "3440/4708 - The training loss at 16th epoch : 0.09022085260098496  Training Accuracy:0.8767361111111112\n",
            "3456/4708 - The training loss at 16th epoch : 0.09019445021017942  Training Accuracy:0.8767281105990783\n",
            "3472/4708 - The training loss at 16th epoch : 0.08989148107413604  Training Accuracy:0.8772935779816514\n",
            "3488/4708 - The training loss at 16th epoch : 0.08956796960586955  Training Accuracy:0.877568493150685\n",
            "3504/4708 - The training loss at 16th epoch : 0.08926490156155806  Training Accuracy:0.8778409090909091\n",
            "3520/4708 - The training loss at 16th epoch : 0.08912291849248179  Training Accuracy:0.8778280542986425\n",
            "3536/4708 - The training loss at 16th epoch : 0.08962074426749442  Training Accuracy:0.8769707207207207\n",
            "3552/4708 - The training loss at 16th epoch : 0.08975775343034702  Training Accuracy:0.8769618834080718\n",
            "3568/4708 - The training loss at 16th epoch : 0.08970237886423457  Training Accuracy:0.876953125\n",
            "3584/4708 - The training loss at 16th epoch : 0.08954270358633938  Training Accuracy:0.8772222222222222\n",
            "3600/4708 - The training loss at 16th epoch : 0.0893007571006375  Training Accuracy:0.8777654867256637\n",
            "3616/4708 - The training loss at 16th epoch : 0.089458263277715  Training Accuracy:0.8774779735682819\n",
            "3632/4708 - The training loss at 16th epoch : 0.0896358274170834  Training Accuracy:0.8771929824561403\n",
            "3648/4708 - The training loss at 16th epoch : 0.0893937600646773  Training Accuracy:0.8774563318777293\n",
            "3664/4708 - The training loss at 16th epoch : 0.08968791725661647  Training Accuracy:0.8766304347826087\n",
            "3680/4708 - The training loss at 16th epoch : 0.08943887030401211  Training Accuracy:0.8768939393939394\n",
            "3696/4708 - The training loss at 16th epoch : 0.08939244612677445  Training Accuracy:0.876885775862069\n",
            "3712/4708 - The training loss at 16th epoch : 0.08967862305499501  Training Accuracy:0.8763412017167382\n",
            "3728/4708 - The training loss at 16th epoch : 0.0896131176934494  Training Accuracy:0.8766025641025641\n",
            "3744/4708 - The training loss at 16th epoch : 0.08967768080052697  Training Accuracy:0.8765957446808511\n",
            "3760/4708 - The training loss at 16th epoch : 0.08967790115215285  Training Accuracy:0.8765889830508474\n",
            "3776/4708 - The training loss at 16th epoch : 0.08970529961898445  Training Accuracy:0.8765822784810127\n",
            "3792/4708 - The training loss at 16th epoch : 0.08973575837378175  Training Accuracy:0.8765756302521008\n",
            "3808/4708 - The training loss at 16th epoch : 0.0895004827794548  Training Accuracy:0.8768305439330544\n",
            "3824/4708 - The training loss at 16th epoch : 0.08920364036949029  Training Accuracy:0.87734375\n",
            "3840/4708 - The training loss at 16th epoch : 0.0894972921378125  Training Accuracy:0.8770746887966805\n",
            "3856/4708 - The training loss at 16th epoch : 0.08963993786147946  Training Accuracy:0.8768078512396694\n",
            "3872/4708 - The training loss at 16th epoch : 0.08967623307029514  Training Accuracy:0.8768004115226338\n",
            "3888/4708 - The training loss at 16th epoch : 0.08976487212833817  Training Accuracy:0.8765368852459017\n",
            "3904/4708 - The training loss at 16th epoch : 0.08994949848947628  Training Accuracy:0.8760204081632653\n",
            "3920/4708 - The training loss at 16th epoch : 0.09000840283657426  Training Accuracy:0.8760162601626016\n",
            "3936/4708 - The training loss at 16th epoch : 0.09010758766782136  Training Accuracy:0.8760121457489879\n",
            "3952/4708 - The training loss at 16th epoch : 0.09010340449619841  Training Accuracy:0.876008064516129\n",
            "3968/4708 - The training loss at 16th epoch : 0.09029457924418861  Training Accuracy:0.8752510040160643\n",
            "3984/4708 - The training loss at 16th epoch : 0.09026115768730492  Training Accuracy:0.87525\n",
            "4000/4708 - The training loss at 16th epoch : 0.09020830019420782  Training Accuracy:0.8754980079681275\n",
            "4016/4708 - The training loss at 16th epoch : 0.09059477281056846  Training Accuracy:0.875\n",
            "4032/4708 - The training loss at 16th epoch : 0.09057396993533677  Training Accuracy:0.875\n",
            "4048/4708 - The training loss at 16th epoch : 0.09071016397380897  Training Accuracy:0.874753937007874\n",
            "4064/4708 - The training loss at 16th epoch : 0.09054673743139215  Training Accuracy:0.8752450980392157\n",
            "4080/4708 - The training loss at 16th epoch : 0.09040737335154596  Training Accuracy:0.87548828125\n",
            "4096/4708 - The training loss at 16th epoch : 0.09043035768014782  Training Accuracy:0.8754863813229572\n",
            "4112/4708 - The training loss at 16th epoch : 0.09032203473238279  Training Accuracy:0.875968992248062\n",
            "4128/4708 - The training loss at 16th epoch : 0.09014429849282414  Training Accuracy:0.8762065637065637\n",
            "4144/4708 - The training loss at 16th epoch : 0.09003689676853846  Training Accuracy:0.8762019230769231\n",
            "4160/4708 - The training loss at 16th epoch : 0.08989859903485384  Training Accuracy:0.8764367816091954\n",
            "4176/4708 - The training loss at 16th epoch : 0.08959701053143661  Training Accuracy:0.8769083969465649\n",
            "4192/4708 - The training loss at 16th epoch : 0.08969264774527846  Training Accuracy:0.8766634980988594\n",
            "4208/4708 - The training loss at 16th epoch : 0.08949847392923833  Training Accuracy:0.8768939393939394\n",
            "4224/4708 - The training loss at 16th epoch : 0.08947169253843264  Training Accuracy:0.8768867924528302\n",
            "4240/4708 - The training loss at 16th epoch : 0.08963121424883845  Training Accuracy:0.8764097744360902\n",
            "4256/4708 - The training loss at 16th epoch : 0.08930934264575502  Training Accuracy:0.87687265917603\n",
            "4272/4708 - The training loss at 16th epoch : 0.08932193929149689  Training Accuracy:0.8768656716417911\n",
            "4288/4708 - The training loss at 16th epoch : 0.08923828696497861  Training Accuracy:0.8770910780669146\n",
            "4304/4708 - The training loss at 16th epoch : 0.08942250391162695  Training Accuracy:0.8768518518518519\n",
            "4320/4708 - The training loss at 16th epoch : 0.0896196193950218  Training Accuracy:0.8763837638376384\n",
            "4336/4708 - The training loss at 16th epoch : 0.08955237046093412  Training Accuracy:0.8766084558823529\n",
            "4352/4708 - The training loss at 16th epoch : 0.08943856689713131  Training Accuracy:0.8768315018315018\n",
            "4368/4708 - The training loss at 16th epoch : 0.08966871399643053  Training Accuracy:0.8768248175182481\n",
            "4384/4708 - The training loss at 16th epoch : 0.08982567634596272  Training Accuracy:0.8763636363636363\n",
            "4400/4708 - The training loss at 16th epoch : 0.08959603513665002  Training Accuracy:0.8768115942028986\n",
            "4416/4708 - The training loss at 16th epoch : 0.0897911500785922  Training Accuracy:0.8765794223826715\n",
            "4432/4708 - The training loss at 16th epoch : 0.09018786061080646  Training Accuracy:0.8761241007194245\n",
            "4448/4708 - The training loss at 16th epoch : 0.09016594241987395  Training Accuracy:0.8763440860215054\n",
            "4464/4708 - The training loss at 16th epoch : 0.08986967257358051  Training Accuracy:0.8767857142857143\n",
            "4480/4708 - The training loss at 16th epoch : 0.09001440802034875  Training Accuracy:0.8765569395017794\n",
            "4496/4708 - The training loss at 16th epoch : 0.09041656955619476  Training Accuracy:0.8761081560283688\n",
            "4512/4708 - The training loss at 16th epoch : 0.09019856940845405  Training Accuracy:0.8765459363957597\n",
            "4528/4708 - The training loss at 16th epoch : 0.08995252728093985  Training Accuracy:0.8767605633802817\n",
            "4544/4708 - The training loss at 16th epoch : 0.09018578601215566  Training Accuracy:0.8763157894736842\n",
            "4560/4708 - The training loss at 16th epoch : 0.09037389064973296  Training Accuracy:0.8758741258741258\n",
            "4576/4708 - The training loss at 16th epoch : 0.09047617710835383  Training Accuracy:0.8758710801393729\n",
            "4592/4708 - The training loss at 16th epoch : 0.09037937464111317  Training Accuracy:0.8760850694444444\n",
            "4608/4708 - The training loss at 16th epoch : 0.09035846492517483  Training Accuracy:0.8760813148788927\n",
            "4624/4708 - The training loss at 16th epoch : 0.09028572111950815  Training Accuracy:0.8762931034482758\n",
            "4640/4708 - The training loss at 16th epoch : 0.09040787195500213  Training Accuracy:0.876073883161512\n",
            "4656/4708 - The training loss at 16th epoch : 0.09048546230039195  Training Accuracy:0.876070205479452\n",
            "4672/4708 - The training loss at 16th epoch : 0.09038754899666472  Training Accuracy:0.8762798634812287\n",
            "4688/4708 - The training loss at 16th epoch : 0.0902037360169237  Training Accuracy:0.8764880952380952\n",
            "4704/4708 - The training loss at 16th epoch : 0.09001662284511674  Training Accuracy:0.8766949152542373\n",
            "4720/4708 - The training loss at 16th epoch : 0.08979950046108845  Training Accuracy:0.8769003378378378\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 17th epoch : 0.14635052332191306  Training Accuracy:0.75\n",
            "16/4708 - The training loss at 17th epoch : 0.11086657166164551  Training Accuracy:0.84375\n",
            "32/4708 - The training loss at 17th epoch : 0.10984244300371826  Training Accuracy:0.8333333333333334\n",
            "48/4708 - The training loss at 17th epoch : 0.08478614777196508  Training Accuracy:0.875\n",
            "64/4708 - The training loss at 17th epoch : 0.10796794133437085  Training Accuracy:0.8375\n",
            "80/4708 - The training loss at 17th epoch : 0.09727891736740064  Training Accuracy:0.8541666666666666\n",
            "96/4708 - The training loss at 17th epoch : 0.09154727353276562  Training Accuracy:0.8660714285714286\n",
            "112/4708 - The training loss at 17th epoch : 0.09607877194542447  Training Accuracy:0.859375\n",
            "128/4708 - The training loss at 17th epoch : 0.09280579673444335  Training Accuracy:0.8611111111111112\n",
            "144/4708 - The training loss at 17th epoch : 0.08698435111551846  Training Accuracy:0.86875\n",
            "160/4708 - The training loss at 17th epoch : 0.09472719082233745  Training Accuracy:0.8579545454545454\n",
            "176/4708 - The training loss at 17th epoch : 0.09784341036287188  Training Accuracy:0.8541666666666666\n",
            "192/4708 - The training loss at 17th epoch : 0.09943987456836424  Training Accuracy:0.8509615384615384\n",
            "208/4708 - The training loss at 17th epoch : 0.09830453204335354  Training Accuracy:0.8526785714285714\n",
            "224/4708 - The training loss at 17th epoch : 0.10103017377873551  Training Accuracy:0.8416666666666667\n",
            "240/4708 - The training loss at 17th epoch : 0.09693163086267659  Training Accuracy:0.8515625\n",
            "256/4708 - The training loss at 17th epoch : 0.09602981409307663  Training Accuracy:0.8529411764705882\n",
            "272/4708 - The training loss at 17th epoch : 0.09385831746897288  Training Accuracy:0.8541666666666666\n",
            "288/4708 - The training loss at 17th epoch : 0.0934388825640412  Training Accuracy:0.8552631578947368\n",
            "304/4708 - The training loss at 17th epoch : 0.09198030265401784  Training Accuracy:0.859375\n",
            "320/4708 - The training loss at 17th epoch : 0.0909001283568882  Training Accuracy:0.8601190476190477\n",
            "336/4708 - The training loss at 17th epoch : 0.09034610318762587  Training Accuracy:0.8636363636363636\n",
            "352/4708 - The training loss at 17th epoch : 0.09064559475233155  Training Accuracy:0.8641304347826086\n",
            "368/4708 - The training loss at 17th epoch : 0.08760341604543742  Training Accuracy:0.8697916666666666\n",
            "384/4708 - The training loss at 17th epoch : 0.08956123260454575  Training Accuracy:0.8675\n",
            "400/4708 - The training loss at 17th epoch : 0.0874455004698574  Training Accuracy:0.8701923076923077\n",
            "416/4708 - The training loss at 17th epoch : 0.08832698806019759  Training Accuracy:0.8680555555555556\n",
            "432/4708 - The training loss at 17th epoch : 0.08752528805571488  Training Accuracy:0.8705357142857143\n",
            "448/4708 - The training loss at 17th epoch : 0.08883661615489788  Training Accuracy:0.8685344827586207\n",
            "464/4708 - The training loss at 17th epoch : 0.08834109058127643  Training Accuracy:0.8708333333333333\n",
            "480/4708 - The training loss at 17th epoch : 0.088588627774037  Training Accuracy:0.8709677419354839\n",
            "496/4708 - The training loss at 17th epoch : 0.0894296080123462  Training Accuracy:0.869140625\n",
            "512/4708 - The training loss at 17th epoch : 0.08863543842913393  Training Accuracy:0.8693181818181818\n",
            "528/4708 - The training loss at 17th epoch : 0.08844949836206276  Training Accuracy:0.8713235294117647\n",
            "544/4708 - The training loss at 17th epoch : 0.08718178364648631  Training Accuracy:0.8732142857142857\n",
            "560/4708 - The training loss at 17th epoch : 0.08664266180873739  Training Accuracy:0.875\n",
            "576/4708 - The training loss at 17th epoch : 0.08679029890653164  Training Accuracy:0.8766891891891891\n",
            "592/4708 - The training loss at 17th epoch : 0.08796969460920091  Training Accuracy:0.875\n",
            "608/4708 - The training loss at 17th epoch : 0.08992156883890401  Training Accuracy:0.8733974358974359\n",
            "624/4708 - The training loss at 17th epoch : 0.09106758532837853  Training Accuracy:0.8734375\n",
            "640/4708 - The training loss at 17th epoch : 0.09115192057670764  Training Accuracy:0.8719512195121951\n",
            "656/4708 - The training loss at 17th epoch : 0.08976324174481412  Training Accuracy:0.8735119047619048\n",
            "672/4708 - The training loss at 17th epoch : 0.0886715569606293  Training Accuracy:0.875\n",
            "688/4708 - The training loss at 17th epoch : 0.08791068529898874  Training Accuracy:0.8764204545454546\n",
            "704/4708 - The training loss at 17th epoch : 0.08751727183373927  Training Accuracy:0.8777777777777778\n",
            "720/4708 - The training loss at 17th epoch : 0.08612483337807078  Training Accuracy:0.8804347826086957\n",
            "736/4708 - The training loss at 17th epoch : 0.0875900468116367  Training Accuracy:0.8789893617021277\n",
            "752/4708 - The training loss at 17th epoch : 0.08908067312800368  Training Accuracy:0.8776041666666666\n",
            "768/4708 - The training loss at 17th epoch : 0.08870879604362615  Training Accuracy:0.8775510204081632\n",
            "784/4708 - The training loss at 17th epoch : 0.08715387362882407  Training Accuracy:0.88\n",
            "800/4708 - The training loss at 17th epoch : 0.08678026234083176  Training Accuracy:0.8799019607843137\n",
            "816/4708 - The training loss at 17th epoch : 0.08735412264000292  Training Accuracy:0.8798076923076923\n",
            "832/4708 - The training loss at 17th epoch : 0.08676761698262833  Training Accuracy:0.8797169811320755\n",
            "848/4708 - The training loss at 17th epoch : 0.0870233259536473  Training Accuracy:0.8796296296296297\n",
            "864/4708 - The training loss at 17th epoch : 0.0867869068702818  Training Accuracy:0.8795454545454545\n",
            "880/4708 - The training loss at 17th epoch : 0.08570889110060986  Training Accuracy:0.8816964285714286\n",
            "896/4708 - The training loss at 17th epoch : 0.08524270293507918  Training Accuracy:0.881578947368421\n",
            "912/4708 - The training loss at 17th epoch : 0.08550273836957295  Training Accuracy:0.8814655172413793\n",
            "928/4708 - The training loss at 17th epoch : 0.08649099686995168  Training Accuracy:0.8813559322033898\n",
            "944/4708 - The training loss at 17th epoch : 0.08574224099248523  Training Accuracy:0.8822916666666667\n",
            "960/4708 - The training loss at 17th epoch : 0.08499328818695334  Training Accuracy:0.8831967213114754\n",
            "976/4708 - The training loss at 17th epoch : 0.08501108922033924  Training Accuracy:0.8830645161290323\n",
            "992/4708 - The training loss at 17th epoch : 0.08563288447592528  Training Accuracy:0.8819444444444444\n",
            "1008/4708 - The training loss at 17th epoch : 0.08502484820187109  Training Accuracy:0.8828125\n",
            "1024/4708 - The training loss at 17th epoch : 0.0859287380243181  Training Accuracy:0.8817307692307692\n",
            "1040/4708 - The training loss at 17th epoch : 0.08565611800016824  Training Accuracy:0.8816287878787878\n",
            "1056/4708 - The training loss at 17th epoch : 0.0848823631157175  Training Accuracy:0.8824626865671642\n",
            "1072/4708 - The training loss at 17th epoch : 0.08597526834361233  Training Accuracy:0.8805147058823529\n",
            "1088/4708 - The training loss at 17th epoch : 0.08583264039327862  Training Accuracy:0.8804347826086957\n",
            "1104/4708 - The training loss at 17th epoch : 0.0866183807669423  Training Accuracy:0.8794642857142857\n",
            "1120/4708 - The training loss at 17th epoch : 0.08692569775300343  Training Accuracy:0.8794014084507042\n",
            "1136/4708 - The training loss at 17th epoch : 0.08714614467997818  Training Accuracy:0.8793402777777778\n",
            "1152/4708 - The training loss at 17th epoch : 0.08688396468371634  Training Accuracy:0.8801369863013698\n",
            "1168/4708 - The training loss at 17th epoch : 0.0865859635731807  Training Accuracy:0.8809121621621622\n",
            "1184/4708 - The training loss at 17th epoch : 0.086935323617386  Training Accuracy:0.88\n",
            "1200/4708 - The training loss at 17th epoch : 0.08721886010931794  Training Accuracy:0.8799342105263158\n",
            "1216/4708 - The training loss at 17th epoch : 0.08740515084278966  Training Accuracy:0.8782467532467533\n",
            "1232/4708 - The training loss at 17th epoch : 0.08637847210919937  Training Accuracy:0.8798076923076923\n",
            "1248/4708 - The training loss at 17th epoch : 0.08609255368545224  Training Accuracy:0.8805379746835443\n",
            "1264/4708 - The training loss at 17th epoch : 0.0862240442745296  Training Accuracy:0.88125\n",
            "1280/4708 - The training loss at 17th epoch : 0.08624263116470775  Training Accuracy:0.8811728395061729\n",
            "1296/4708 - The training loss at 17th epoch : 0.08609733879204154  Training Accuracy:0.8810975609756098\n",
            "1312/4708 - The training loss at 17th epoch : 0.08746950908050502  Training Accuracy:0.8795180722891566\n",
            "1328/4708 - The training loss at 17th epoch : 0.08796501925160215  Training Accuracy:0.8794642857142857\n",
            "1344/4708 - The training loss at 17th epoch : 0.08706772068661053  Training Accuracy:0.8808823529411764\n",
            "1360/4708 - The training loss at 17th epoch : 0.08678275597945455  Training Accuracy:0.8808139534883721\n",
            "1376/4708 - The training loss at 17th epoch : 0.08614591906738876  Training Accuracy:0.8814655172413793\n",
            "1392/4708 - The training loss at 17th epoch : 0.08604223511610729  Training Accuracy:0.8821022727272727\n",
            "1408/4708 - The training loss at 17th epoch : 0.08545347336307899  Training Accuracy:0.8827247191011236\n",
            "1424/4708 - The training loss at 17th epoch : 0.08467108007738504  Training Accuracy:0.8840277777777777\n",
            "1440/4708 - The training loss at 17th epoch : 0.08478603083905743  Training Accuracy:0.8832417582417582\n",
            "1456/4708 - The training loss at 17th epoch : 0.0844983636599004  Training Accuracy:0.8838315217391305\n",
            "1472/4708 - The training loss at 17th epoch : 0.08425790519098843  Training Accuracy:0.8844086021505376\n",
            "1488/4708 - The training loss at 17th epoch : 0.08423958058594086  Training Accuracy:0.8843085106382979\n",
            "1504/4708 - The training loss at 17th epoch : 0.0847227906967782  Training Accuracy:0.8842105263157894\n",
            "1520/4708 - The training loss at 17th epoch : 0.08569397618022756  Training Accuracy:0.8828125\n",
            "1536/4708 - The training loss at 17th epoch : 0.08517674104686185  Training Accuracy:0.884020618556701\n",
            "1552/4708 - The training loss at 17th epoch : 0.08517245395383435  Training Accuracy:0.8839285714285714\n",
            "1568/4708 - The training loss at 17th epoch : 0.08619241098841549  Training Accuracy:0.8819444444444444\n",
            "1584/4708 - The training loss at 17th epoch : 0.08633500461372585  Training Accuracy:0.881875\n",
            "1600/4708 - The training loss at 17th epoch : 0.08732396786640777  Training Accuracy:0.880569306930693\n",
            "1616/4708 - The training loss at 17th epoch : 0.08785819631332713  Training Accuracy:0.8799019607843137\n",
            "1632/4708 - The training loss at 17th epoch : 0.0877432037170309  Training Accuracy:0.8798543689320388\n",
            "1648/4708 - The training loss at 17th epoch : 0.08884163670289179  Training Accuracy:0.8780048076923077\n",
            "1664/4708 - The training loss at 17th epoch : 0.08961967945892814  Training Accuracy:0.8773809523809524\n",
            "1680/4708 - The training loss at 17th epoch : 0.08989297102245097  Training Accuracy:0.8767688679245284\n",
            "1696/4708 - The training loss at 17th epoch : 0.09006417147563353  Training Accuracy:0.8767523364485982\n",
            "1712/4708 - The training loss at 17th epoch : 0.0896899467015315  Training Accuracy:0.8773148148148148\n",
            "1728/4708 - The training loss at 17th epoch : 0.08992433859937757  Training Accuracy:0.8761467889908257\n",
            "1744/4708 - The training loss at 17th epoch : 0.0902799821488136  Training Accuracy:0.875\n",
            "1760/4708 - The training loss at 17th epoch : 0.0901328590505112  Training Accuracy:0.8755630630630631\n",
            "1776/4708 - The training loss at 17th epoch : 0.0893962180083557  Training Accuracy:0.8766741071428571\n",
            "1792/4708 - The training loss at 17th epoch : 0.0893179586943455  Training Accuracy:0.8766592920353983\n",
            "1808/4708 - The training loss at 17th epoch : 0.08898370318474615  Training Accuracy:0.8771929824561403\n",
            "1824/4708 - The training loss at 17th epoch : 0.08922975321379574  Training Accuracy:0.8771739130434782\n",
            "1840/4708 - The training loss at 17th epoch : 0.08868064557473182  Training Accuracy:0.8782327586206896\n",
            "1856/4708 - The training loss at 17th epoch : 0.08915976893907256  Training Accuracy:0.8771367521367521\n",
            "1872/4708 - The training loss at 17th epoch : 0.08896275334218956  Training Accuracy:0.8776483050847458\n",
            "1888/4708 - The training loss at 17th epoch : 0.08947734015853753  Training Accuracy:0.8765756302521008\n",
            "1904/4708 - The training loss at 17th epoch : 0.08982721283050642  Training Accuracy:0.8755208333333333\n",
            "1920/4708 - The training loss at 17th epoch : 0.08969495663372315  Training Accuracy:0.8760330578512396\n",
            "1936/4708 - The training loss at 17th epoch : 0.0898122119573709  Training Accuracy:0.8755122950819673\n",
            "1952/4708 - The training loss at 17th epoch : 0.08979091059584168  Training Accuracy:0.875\n",
            "1968/4708 - The training loss at 17th epoch : 0.08943014102281242  Training Accuracy:0.8755040322580645\n",
            "1984/4708 - The training loss at 17th epoch : 0.08921601108343453  Training Accuracy:0.876\n",
            "2000/4708 - The training loss at 17th epoch : 0.08952460295158  Training Accuracy:0.8754960317460317\n",
            "2016/4708 - The training loss at 17th epoch : 0.08931852265596511  Training Accuracy:0.8759842519685039\n",
            "2032/4708 - The training loss at 17th epoch : 0.0890518304868781  Training Accuracy:0.87646484375\n",
            "2048/4708 - The training loss at 17th epoch : 0.08877849018860276  Training Accuracy:0.876453488372093\n",
            "2064/4708 - The training loss at 17th epoch : 0.08892969162708  Training Accuracy:0.8764423076923077\n",
            "2080/4708 - The training loss at 17th epoch : 0.09017897355578845  Training Accuracy:0.8745229007633588\n",
            "2096/4708 - The training loss at 17th epoch : 0.09000992400701285  Training Accuracy:0.875\n",
            "2112/4708 - The training loss at 17th epoch : 0.09003889146562165  Training Accuracy:0.875\n",
            "2128/4708 - The training loss at 17th epoch : 0.08944431335749754  Training Accuracy:0.8759328358208955\n",
            "2144/4708 - The training loss at 17th epoch : 0.08892200192591954  Training Accuracy:0.8768518518518519\n",
            "2160/4708 - The training loss at 17th epoch : 0.08901139040147354  Training Accuracy:0.8768382352941176\n",
            "2176/4708 - The training loss at 17th epoch : 0.08984040014537384  Training Accuracy:0.8754562043795621\n",
            "2192/4708 - The training loss at 17th epoch : 0.08988556365043407  Training Accuracy:0.8759057971014492\n",
            "2208/4708 - The training loss at 17th epoch : 0.09005356653716255  Training Accuracy:0.8758992805755396\n",
            "2224/4708 - The training loss at 17th epoch : 0.09093194445148818  Training Accuracy:0.8745535714285714\n",
            "2240/4708 - The training loss at 17th epoch : 0.09161975462571686  Training Accuracy:0.8736702127659575\n",
            "2256/4708 - The training loss at 17th epoch : 0.09174208294027786  Training Accuracy:0.8736795774647887\n",
            "2272/4708 - The training loss at 17th epoch : 0.09119471245989867  Training Accuracy:0.8745629370629371\n",
            "2288/4708 - The training loss at 17th epoch : 0.0908370520429971  Training Accuracy:0.875\n",
            "2304/4708 - The training loss at 17th epoch : 0.09096384029111426  Training Accuracy:0.8754310344827586\n",
            "2320/4708 - The training loss at 17th epoch : 0.09042746638684074  Training Accuracy:0.8762842465753424\n",
            "2336/4708 - The training loss at 17th epoch : 0.0902236015711464  Training Accuracy:0.8762755102040817\n",
            "2352/4708 - The training loss at 17th epoch : 0.09038226575869739  Training Accuracy:0.8762668918918919\n",
            "2368/4708 - The training loss at 17th epoch : 0.09004047554859416  Training Accuracy:0.8766778523489933\n",
            "2384/4708 - The training loss at 17th epoch : 0.08994058859384227  Training Accuracy:0.8770833333333333\n",
            "2400/4708 - The training loss at 17th epoch : 0.0901857775645993  Training Accuracy:0.8766556291390728\n",
            "2416/4708 - The training loss at 17th epoch : 0.08970117735811607  Training Accuracy:0.8774671052631579\n",
            "2432/4708 - The training loss at 17th epoch : 0.08941523891193529  Training Accuracy:0.877859477124183\n",
            "2448/4708 - The training loss at 17th epoch : 0.08935564326886593  Training Accuracy:0.8778409090909091\n",
            "2464/4708 - The training loss at 17th epoch : 0.08974871843825342  Training Accuracy:0.8770161290322581\n",
            "2480/4708 - The training loss at 17th epoch : 0.08940632687735943  Training Accuracy:0.8774038461538461\n",
            "2496/4708 - The training loss at 17th epoch : 0.08924139668992478  Training Accuracy:0.8773885350318471\n",
            "2512/4708 - The training loss at 17th epoch : 0.08904346584115784  Training Accuracy:0.8777689873417721\n",
            "2528/4708 - The training loss at 17th epoch : 0.08876956254528488  Training Accuracy:0.8781446540880503\n",
            "2544/4708 - The training loss at 17th epoch : 0.08838633698099593  Training Accuracy:0.87890625\n",
            "2560/4708 - The training loss at 17th epoch : 0.08796178677254465  Training Accuracy:0.8796583850931677\n",
            "2576/4708 - The training loss at 17th epoch : 0.08770000934412868  Training Accuracy:0.8800154320987654\n",
            "2592/4708 - The training loss at 17th epoch : 0.08802161646227366  Training Accuracy:0.879601226993865\n",
            "2608/4708 - The training loss at 17th epoch : 0.08763746842692562  Training Accuracy:0.8803353658536586\n",
            "2624/4708 - The training loss at 17th epoch : 0.08793249691527542  Training Accuracy:0.8799242424242424\n",
            "2640/4708 - The training loss at 17th epoch : 0.08806818288922236  Training Accuracy:0.879894578313253\n",
            "2656/4708 - The training loss at 17th epoch : 0.08763856819244825  Training Accuracy:0.8806137724550899\n",
            "2672/4708 - The training loss at 17th epoch : 0.08718102321412612  Training Accuracy:0.8813244047619048\n",
            "2688/4708 - The training loss at 17th epoch : 0.08686902616007092  Training Accuracy:0.8816568047337278\n",
            "2704/4708 - The training loss at 17th epoch : 0.0871519611344546  Training Accuracy:0.88125\n",
            "2720/4708 - The training loss at 17th epoch : 0.08715938691230146  Training Accuracy:0.8812134502923976\n",
            "2736/4708 - The training loss at 17th epoch : 0.08703370680349705  Training Accuracy:0.8811773255813954\n",
            "2752/4708 - The training loss at 17th epoch : 0.08748445743190718  Training Accuracy:0.8807803468208093\n",
            "2768/4708 - The training loss at 17th epoch : 0.08762512508930324  Training Accuracy:0.8807471264367817\n",
            "2784/4708 - The training loss at 17th epoch : 0.08733170826879916  Training Accuracy:0.8814285714285715\n",
            "2800/4708 - The training loss at 17th epoch : 0.087386579019519  Training Accuracy:0.8813920454545454\n",
            "2816/4708 - The training loss at 17th epoch : 0.08721521329719792  Training Accuracy:0.8817090395480226\n",
            "2832/4708 - The training loss at 17th epoch : 0.08706038390500827  Training Accuracy:0.8816713483146067\n",
            "2848/4708 - The training loss at 17th epoch : 0.08669428950192887  Training Accuracy:0.8823324022346368\n",
            "2864/4708 - The training loss at 17th epoch : 0.08701839915386424  Training Accuracy:0.8819444444444444\n",
            "2880/4708 - The training loss at 17th epoch : 0.08720106568234934  Training Accuracy:0.8819060773480663\n",
            "2896/4708 - The training loss at 17th epoch : 0.08712004715027509  Training Accuracy:0.8818681318681318\n",
            "2912/4708 - The training loss at 17th epoch : 0.08699484488275827  Training Accuracy:0.882172131147541\n",
            "2928/4708 - The training loss at 17th epoch : 0.08707562538959969  Training Accuracy:0.8821331521739131\n",
            "2944/4708 - The training loss at 17th epoch : 0.0868720346090512  Training Accuracy:0.8824324324324324\n",
            "2960/4708 - The training loss at 17th epoch : 0.08705479391050552  Training Accuracy:0.8823924731182796\n",
            "2976/4708 - The training loss at 17th epoch : 0.08678527272846075  Training Accuracy:0.8826871657754011\n",
            "2992/4708 - The training loss at 17th epoch : 0.08665340962694204  Training Accuracy:0.8826462765957447\n",
            "3008/4708 - The training loss at 17th epoch : 0.08658244467952682  Training Accuracy:0.8829365079365079\n",
            "3024/4708 - The training loss at 17th epoch : 0.0866180283055561  Training Accuracy:0.8828947368421053\n",
            "3040/4708 - The training loss at 17th epoch : 0.08681828805050773  Training Accuracy:0.8828534031413613\n",
            "3056/4708 - The training loss at 17th epoch : 0.08657432665610953  Training Accuracy:0.8834635416666666\n",
            "3072/4708 - The training loss at 17th epoch : 0.0865052234838586  Training Accuracy:0.8837435233160622\n",
            "3088/4708 - The training loss at 17th epoch : 0.08677404952538595  Training Accuracy:0.8830541237113402\n",
            "3104/4708 - The training loss at 17th epoch : 0.08685813425414786  Training Accuracy:0.8826923076923077\n",
            "3120/4708 - The training loss at 17th epoch : 0.08743216270074397  Training Accuracy:0.8813775510204082\n",
            "3136/4708 - The training loss at 17th epoch : 0.08719115679633942  Training Accuracy:0.8816624365482234\n",
            "3152/4708 - The training loss at 17th epoch : 0.08764813632234322  Training Accuracy:0.8809974747474747\n",
            "3168/4708 - The training loss at 17th epoch : 0.08736670877576425  Training Accuracy:0.8812814070351759\n",
            "3184/4708 - The training loss at 17th epoch : 0.08772752920183774  Training Accuracy:0.880625\n",
            "3200/4708 - The training loss at 17th epoch : 0.08758254408849757  Training Accuracy:0.880907960199005\n",
            "3216/4708 - The training loss at 17th epoch : 0.08744843803310735  Training Accuracy:0.8811881188118812\n",
            "3232/4708 - The training loss at 17th epoch : 0.08768268218907864  Training Accuracy:0.8805418719211823\n",
            "3248/4708 - The training loss at 17th epoch : 0.08754372238434947  Training Accuracy:0.8805147058823529\n",
            "3264/4708 - The training loss at 17th epoch : 0.0877346979835423  Training Accuracy:0.8801829268292682\n",
            "3280/4708 - The training loss at 17th epoch : 0.08783384764544563  Training Accuracy:0.8801577669902912\n",
            "3296/4708 - The training loss at 17th epoch : 0.0876636106934537  Training Accuracy:0.8804347826086957\n",
            "3312/4708 - The training loss at 17th epoch : 0.08742777812307649  Training Accuracy:0.8807091346153846\n",
            "3328/4708 - The training loss at 17th epoch : 0.08747910497241529  Training Accuracy:0.8806818181818182\n",
            "3344/4708 - The training loss at 17th epoch : 0.08749200335567033  Training Accuracy:0.8809523809523809\n",
            "3360/4708 - The training loss at 17th epoch : 0.08758041935389682  Training Accuracy:0.880627962085308\n",
            "3376/4708 - The training loss at 17th epoch : 0.08754603601846568  Training Accuracy:0.8806014150943396\n",
            "3392/4708 - The training loss at 17th epoch : 0.08755012266518797  Training Accuracy:0.880575117370892\n",
            "3408/4708 - The training loss at 17th epoch : 0.08716063381011517  Training Accuracy:0.8811331775700935\n",
            "3424/4708 - The training loss at 17th epoch : 0.0870559927995626  Training Accuracy:0.8811046511627907\n",
            "3440/4708 - The training loss at 17th epoch : 0.08695514632249317  Training Accuracy:0.8813657407407407\n",
            "3456/4708 - The training loss at 17th epoch : 0.08688584048116935  Training Accuracy:0.881336405529954\n",
            "3472/4708 - The training loss at 17th epoch : 0.08702622929777515  Training Accuracy:0.8807339449541285\n",
            "3488/4708 - The training loss at 17th epoch : 0.08676784925211609  Training Accuracy:0.8809931506849316\n",
            "3504/4708 - The training loss at 17th epoch : 0.08677615021527599  Training Accuracy:0.88125\n",
            "3520/4708 - The training loss at 17th epoch : 0.08678950656779981  Training Accuracy:0.8812217194570136\n",
            "3536/4708 - The training loss at 17th epoch : 0.08667335406604904  Training Accuracy:0.8814752252252253\n",
            "3552/4708 - The training loss at 17th epoch : 0.08653624307440715  Training Accuracy:0.8817264573991032\n",
            "3568/4708 - The training loss at 17th epoch : 0.08657371268215867  Training Accuracy:0.8816964285714286\n",
            "3584/4708 - The training loss at 17th epoch : 0.08648181691944043  Training Accuracy:0.8819444444444444\n",
            "3600/4708 - The training loss at 17th epoch : 0.08669152489433496  Training Accuracy:0.8813606194690266\n",
            "3616/4708 - The training loss at 17th epoch : 0.08695929345106156  Training Accuracy:0.8810572687224669\n",
            "3632/4708 - The training loss at 17th epoch : 0.08689964080074425  Training Accuracy:0.8810307017543859\n",
            "3648/4708 - The training loss at 17th epoch : 0.08690314614656466  Training Accuracy:0.8812772925764192\n",
            "3664/4708 - The training loss at 17th epoch : 0.08684209157504205  Training Accuracy:0.88125\n",
            "3680/4708 - The training loss at 17th epoch : 0.08657785176728226  Training Accuracy:0.8817640692640693\n",
            "3696/4708 - The training loss at 17th epoch : 0.08654943083085534  Training Accuracy:0.8817349137931034\n",
            "3712/4708 - The training loss at 17th epoch : 0.08651451205398011  Training Accuracy:0.881706008583691\n",
            "3728/4708 - The training loss at 17th epoch : 0.08683292535757518  Training Accuracy:0.8814102564102564\n",
            "3744/4708 - The training loss at 17th epoch : 0.08709033833575754  Training Accuracy:0.8811170212765957\n",
            "3760/4708 - The training loss at 17th epoch : 0.08732479651314053  Training Accuracy:0.8805614406779662\n",
            "3776/4708 - The training loss at 17th epoch : 0.08733695663353165  Training Accuracy:0.8805379746835443\n",
            "3792/4708 - The training loss at 17th epoch : 0.08735403057664806  Training Accuracy:0.8805147058823529\n",
            "3808/4708 - The training loss at 17th epoch : 0.08738239148311121  Training Accuracy:0.8804916317991632\n",
            "3824/4708 - The training loss at 17th epoch : 0.08749444740034251  Training Accuracy:0.8802083333333334\n",
            "3840/4708 - The training loss at 17th epoch : 0.08728784333347159  Training Accuracy:0.8804460580912863\n",
            "3856/4708 - The training loss at 17th epoch : 0.08727607843520084  Training Accuracy:0.8804235537190083\n",
            "3872/4708 - The training loss at 17th epoch : 0.0873678510070315  Training Accuracy:0.8804012345679012\n",
            "3888/4708 - The training loss at 17th epoch : 0.08754022429674704  Training Accuracy:0.8801229508196722\n",
            "3904/4708 - The training loss at 17th epoch : 0.08741200874731485  Training Accuracy:0.8803571428571428\n",
            "3920/4708 - The training loss at 17th epoch : 0.08709494384629492  Training Accuracy:0.8808434959349594\n",
            "3936/4708 - The training loss at 17th epoch : 0.08736187358423808  Training Accuracy:0.8805668016194332\n",
            "3952/4708 - The training loss at 17th epoch : 0.08730923252149615  Training Accuracy:0.8807963709677419\n",
            "3968/4708 - The training loss at 17th epoch : 0.08719404244245779  Training Accuracy:0.8810240963855421\n",
            "3984/4708 - The training loss at 17th epoch : 0.08721877307188876  Training Accuracy:0.881\n",
            "4000/4708 - The training loss at 17th epoch : 0.0871436619923506  Training Accuracy:0.8812250996015937\n",
            "4016/4708 - The training loss at 17th epoch : 0.08724192835971768  Training Accuracy:0.8812003968253969\n",
            "4032/4708 - The training loss at 17th epoch : 0.08713364592649742  Training Accuracy:0.8814229249011858\n",
            "4048/4708 - The training loss at 17th epoch : 0.08730124113108438  Training Accuracy:0.8811515748031497\n",
            "4064/4708 - The training loss at 17th epoch : 0.08696893373786513  Training Accuracy:0.8816176470588235\n",
            "4080/4708 - The training loss at 17th epoch : 0.08720611057189663  Training Accuracy:0.88134765625\n",
            "4096/4708 - The training loss at 17th epoch : 0.08717278982140803  Training Accuracy:0.8813229571984436\n",
            "4112/4708 - The training loss at 17th epoch : 0.08687678318793456  Training Accuracy:0.8817829457364341\n",
            "4128/4708 - The training loss at 17th epoch : 0.08657039393641702  Training Accuracy:0.8822393822393823\n",
            "4144/4708 - The training loss at 17th epoch : 0.08656709502148395  Training Accuracy:0.8824519230769231\n",
            "4160/4708 - The training loss at 17th epoch : 0.08675497229602967  Training Accuracy:0.8824233716475096\n",
            "4176/4708 - The training loss at 17th epoch : 0.08650668277617604  Training Accuracy:0.8828721374045801\n",
            "4192/4708 - The training loss at 17th epoch : 0.08636092888581044  Training Accuracy:0.8830798479087453\n",
            "4208/4708 - The training loss at 17th epoch : 0.08648128917706  Training Accuracy:0.8828125\n",
            "4224/4708 - The training loss at 17th epoch : 0.08653568283932273  Training Accuracy:0.8827830188679245\n",
            "4240/4708 - The training loss at 17th epoch : 0.08663277993688277  Training Accuracy:0.8825187969924813\n",
            "4256/4708 - The training loss at 17th epoch : 0.0863288228975505  Training Accuracy:0.8829588014981273\n",
            "4272/4708 - The training loss at 17th epoch : 0.08671205241600682  Training Accuracy:0.8824626865671642\n",
            "4288/4708 - The training loss at 17th epoch : 0.08660147708612499  Training Accuracy:0.8826672862453532\n",
            "4304/4708 - The training loss at 17th epoch : 0.08649610207522104  Training Accuracy:0.8826388888888889\n",
            "4320/4708 - The training loss at 17th epoch : 0.08670825391724618  Training Accuracy:0.8821494464944649\n",
            "4336/4708 - The training loss at 17th epoch : 0.08649871472460058  Training Accuracy:0.8825827205882353\n",
            "4352/4708 - The training loss at 17th epoch : 0.08664381532146238  Training Accuracy:0.8820970695970696\n",
            "4368/4708 - The training loss at 17th epoch : 0.08657243505894831  Training Accuracy:0.8822992700729927\n",
            "4384/4708 - The training loss at 17th epoch : 0.08660609007102975  Training Accuracy:0.8822727272727273\n",
            "4400/4708 - The training loss at 17th epoch : 0.08653224990737748  Training Accuracy:0.8822463768115942\n",
            "4416/4708 - The training loss at 17th epoch : 0.08679659687609295  Training Accuracy:0.8819945848375451\n",
            "4432/4708 - The training loss at 17th epoch : 0.08671278322331742  Training Accuracy:0.8821942446043165\n",
            "4448/4708 - The training loss at 17th epoch : 0.08660539650581241  Training Accuracy:0.8823924731182796\n",
            "4464/4708 - The training loss at 17th epoch : 0.08670281004644372  Training Accuracy:0.8823660714285714\n",
            "4480/4708 - The training loss at 17th epoch : 0.08648587932443406  Training Accuracy:0.8827846975088968\n",
            "4496/4708 - The training loss at 17th epoch : 0.08644430104673881  Training Accuracy:0.8829787234042553\n",
            "4512/4708 - The training loss at 17th epoch : 0.08635504745091337  Training Accuracy:0.8831713780918727\n",
            "4528/4708 - The training loss at 17th epoch : 0.08655779596815354  Training Accuracy:0.8827024647887324\n",
            "4544/4708 - The training loss at 17th epoch : 0.08651551073859472  Training Accuracy:0.8826754385964912\n",
            "4560/4708 - The training loss at 17th epoch : 0.08665759485467973  Training Accuracy:0.8822115384615384\n",
            "4576/4708 - The training loss at 17th epoch : 0.08656724330572549  Training Accuracy:0.882404181184669\n",
            "4592/4708 - The training loss at 17th epoch : 0.08648408572975169  Training Accuracy:0.8825954861111112\n",
            "4608/4708 - The training loss at 17th epoch : 0.08669744130243673  Training Accuracy:0.8823529411764706\n",
            "4624/4708 - The training loss at 17th epoch : 0.08662646651123367  Training Accuracy:0.8825431034482759\n",
            "4640/4708 - The training loss at 17th epoch : 0.08648086794471713  Training Accuracy:0.8827319587628866\n",
            "4656/4708 - The training loss at 17th epoch : 0.0862708490441611  Training Accuracy:0.8831335616438356\n",
            "4672/4708 - The training loss at 17th epoch : 0.086390904525781  Training Accuracy:0.8828924914675768\n",
            "4688/4708 - The training loss at 17th epoch : 0.08654944305153295  Training Accuracy:0.8826530612244898\n",
            "4704/4708 - The training loss at 17th epoch : 0.08648770782577306  Training Accuracy:0.8828389830508474\n",
            "4720/4708 - The training loss at 17th epoch : 0.08648747556537677  Training Accuracy:0.8826013513513513\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 18th epoch : 0.03422869688621966  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 18th epoch : 0.04552083659095704  Training Accuracy:0.9375\n",
            "32/4708 - The training loss at 18th epoch : 0.04141773260378068  Training Accuracy:0.9375\n",
            "48/4708 - The training loss at 18th epoch : 0.05335832410870238  Training Accuracy:0.921875\n",
            "64/4708 - The training loss at 18th epoch : 0.06318841235625139  Training Accuracy:0.9\n",
            "80/4708 - The training loss at 18th epoch : 0.0833158281784133  Training Accuracy:0.875\n",
            "96/4708 - The training loss at 18th epoch : 0.08277765854792743  Training Accuracy:0.8839285714285714\n",
            "112/4708 - The training loss at 18th epoch : 0.07768303965054509  Training Accuracy:0.890625\n",
            "128/4708 - The training loss at 18th epoch : 0.07997389193358977  Training Accuracy:0.8888888888888888\n",
            "144/4708 - The training loss at 18th epoch : 0.07243201553233045  Training Accuracy:0.9\n",
            "160/4708 - The training loss at 18th epoch : 0.07702344909728215  Training Accuracy:0.8977272727272727\n",
            "176/4708 - The training loss at 18th epoch : 0.07567695469502388  Training Accuracy:0.8958333333333334\n",
            "192/4708 - The training loss at 18th epoch : 0.07386392874089728  Training Accuracy:0.8990384615384616\n",
            "208/4708 - The training loss at 18th epoch : 0.07164535948910979  Training Accuracy:0.9017857142857143\n",
            "224/4708 - The training loss at 18th epoch : 0.06780913456326813  Training Accuracy:0.9083333333333333\n",
            "240/4708 - The training loss at 18th epoch : 0.06901630235036897  Training Accuracy:0.90625\n",
            "256/4708 - The training loss at 18th epoch : 0.07153261577460387  Training Accuracy:0.9044117647058824\n",
            "272/4708 - The training loss at 18th epoch : 0.07706010185378281  Training Accuracy:0.8958333333333334\n",
            "288/4708 - The training loss at 18th epoch : 0.07674710841178008  Training Accuracy:0.8947368421052632\n",
            "304/4708 - The training loss at 18th epoch : 0.0753123766060027  Training Accuracy:0.896875\n",
            "320/4708 - The training loss at 18th epoch : 0.07974073435902009  Training Accuracy:0.8898809523809523\n",
            "336/4708 - The training loss at 18th epoch : 0.08347601594521965  Training Accuracy:0.8835227272727273\n",
            "352/4708 - The training loss at 18th epoch : 0.08463461283756073  Training Accuracy:0.8831521739130435\n",
            "368/4708 - The training loss at 18th epoch : 0.08641155472896805  Training Accuracy:0.8802083333333334\n",
            "384/4708 - The training loss at 18th epoch : 0.08700726503536557  Training Accuracy:0.88\n",
            "400/4708 - The training loss at 18th epoch : 0.0865147688000047  Training Accuracy:0.8798076923076923\n",
            "416/4708 - The training loss at 18th epoch : 0.08907778054332077  Training Accuracy:0.8773148148148148\n",
            "432/4708 - The training loss at 18th epoch : 0.08919477006629428  Training Accuracy:0.875\n",
            "448/4708 - The training loss at 18th epoch : 0.09068014812523185  Training Accuracy:0.8706896551724138\n",
            "464/4708 - The training loss at 18th epoch : 0.09358252787143455  Training Accuracy:0.8666666666666667\n",
            "480/4708 - The training loss at 18th epoch : 0.09486053491015645  Training Accuracy:0.8629032258064516\n",
            "496/4708 - The training loss at 18th epoch : 0.09429551579904427  Training Accuracy:0.865234375\n",
            "512/4708 - The training loss at 18th epoch : 0.09443082361678803  Training Accuracy:0.865530303030303\n",
            "528/4708 - The training loss at 18th epoch : 0.09347163496945858  Training Accuracy:0.8676470588235294\n",
            "544/4708 - The training loss at 18th epoch : 0.0916720955387856  Training Accuracy:0.8696428571428572\n",
            "560/4708 - The training loss at 18th epoch : 0.0918841112986279  Training Accuracy:0.8697916666666666\n",
            "576/4708 - The training loss at 18th epoch : 0.09043718814580981  Training Accuracy:0.8716216216216216\n",
            "592/4708 - The training loss at 18th epoch : 0.08978937057637712  Training Accuracy:0.8733552631578947\n",
            "608/4708 - The training loss at 18th epoch : 0.08795683092408446  Training Accuracy:0.8766025641025641\n",
            "624/4708 - The training loss at 18th epoch : 0.0892309291874416  Training Accuracy:0.8765625\n",
            "640/4708 - The training loss at 18th epoch : 0.09028370440748712  Training Accuracy:0.8734756097560976\n",
            "656/4708 - The training loss at 18th epoch : 0.08989073144929717  Training Accuracy:0.8735119047619048\n",
            "672/4708 - The training loss at 18th epoch : 0.08943351776459528  Training Accuracy:0.873546511627907\n",
            "688/4708 - The training loss at 18th epoch : 0.08995329446116015  Training Accuracy:0.8735795454545454\n",
            "704/4708 - The training loss at 18th epoch : 0.08933616322131248  Training Accuracy:0.875\n",
            "720/4708 - The training loss at 18th epoch : 0.08817611912688783  Training Accuracy:0.876358695652174\n",
            "736/4708 - The training loss at 18th epoch : 0.08827663102006889  Training Accuracy:0.875\n",
            "752/4708 - The training loss at 18th epoch : 0.0907106928689035  Training Accuracy:0.8723958333333334\n",
            "768/4708 - The training loss at 18th epoch : 0.09061500440443392  Training Accuracy:0.8724489795918368\n",
            "784/4708 - The training loss at 18th epoch : 0.09104440256681233  Training Accuracy:0.87125\n",
            "800/4708 - The training loss at 18th epoch : 0.0923708089699913  Training Accuracy:0.8700980392156863\n",
            "816/4708 - The training loss at 18th epoch : 0.09316887111145314  Training Accuracy:0.8689903846153846\n",
            "832/4708 - The training loss at 18th epoch : 0.0933564452794291  Training Accuracy:0.8691037735849056\n",
            "848/4708 - The training loss at 18th epoch : 0.0941967278086205  Training Accuracy:0.8680555555555556\n",
            "864/4708 - The training loss at 18th epoch : 0.09657010228870024  Training Accuracy:0.865909090909091\n",
            "880/4708 - The training loss at 18th epoch : 0.09503419482347897  Training Accuracy:0.8683035714285714\n",
            "896/4708 - The training loss at 18th epoch : 0.09441043326089323  Training Accuracy:0.8695175438596491\n",
            "912/4708 - The training loss at 18th epoch : 0.0955230361513861  Training Accuracy:0.8685344827586207\n",
            "928/4708 - The training loss at 18th epoch : 0.09491439522297725  Training Accuracy:0.8686440677966102\n",
            "944/4708 - The training loss at 18th epoch : 0.09550275278671179  Training Accuracy:0.86875\n",
            "960/4708 - The training loss at 18th epoch : 0.09522052280202357  Training Accuracy:0.8688524590163934\n",
            "976/4708 - The training loss at 18th epoch : 0.09445211024653095  Training Accuracy:0.8709677419354839\n",
            "992/4708 - The training loss at 18th epoch : 0.0947922420304906  Training Accuracy:0.871031746031746\n",
            "1008/4708 - The training loss at 18th epoch : 0.09399609407081105  Training Accuracy:0.8720703125\n",
            "1024/4708 - The training loss at 18th epoch : 0.09443159176195065  Training Accuracy:0.8711538461538462\n",
            "1040/4708 - The training loss at 18th epoch : 0.09366300954564273  Training Accuracy:0.8721590909090909\n",
            "1056/4708 - The training loss at 18th epoch : 0.09292367002661359  Training Accuracy:0.8731343283582089\n",
            "1072/4708 - The training loss at 18th epoch : 0.09306979027375803  Training Accuracy:0.8722426470588235\n",
            "1088/4708 - The training loss at 18th epoch : 0.09259186512889875  Training Accuracy:0.8731884057971014\n",
            "1104/4708 - The training loss at 18th epoch : 0.09233859291272589  Training Accuracy:0.8732142857142857\n",
            "1120/4708 - The training loss at 18th epoch : 0.09293541459770774  Training Accuracy:0.8714788732394366\n",
            "1136/4708 - The training loss at 18th epoch : 0.09263800130195664  Training Accuracy:0.8706597222222222\n",
            "1152/4708 - The training loss at 18th epoch : 0.09248079493636611  Training Accuracy:0.8715753424657534\n",
            "1168/4708 - The training loss at 18th epoch : 0.09381129528483485  Training Accuracy:0.8690878378378378\n",
            "1184/4708 - The training loss at 18th epoch : 0.09502251151134547  Training Accuracy:0.8675\n",
            "1200/4708 - The training loss at 18th epoch : 0.0949611949229503  Training Accuracy:0.8675986842105263\n",
            "1216/4708 - The training loss at 18th epoch : 0.0955556821200346  Training Accuracy:0.8660714285714286\n",
            "1232/4708 - The training loss at 18th epoch : 0.09520807616958966  Training Accuracy:0.8669871794871795\n",
            "1248/4708 - The training loss at 18th epoch : 0.09515300340650316  Training Accuracy:0.867879746835443\n",
            "1264/4708 - The training loss at 18th epoch : 0.09507875839273836  Training Accuracy:0.8671875\n",
            "1280/4708 - The training loss at 18th epoch : 0.09476640023965177  Training Accuracy:0.8680555555555556\n",
            "1296/4708 - The training loss at 18th epoch : 0.09424201488534624  Training Accuracy:0.8689024390243902\n",
            "1312/4708 - The training loss at 18th epoch : 0.09375924179834985  Training Accuracy:0.8697289156626506\n",
            "1328/4708 - The training loss at 18th epoch : 0.0931268715244818  Training Accuracy:0.8705357142857143\n",
            "1344/4708 - The training loss at 18th epoch : 0.09227079162083346  Training Accuracy:0.8720588235294118\n",
            "1360/4708 - The training loss at 18th epoch : 0.09201148767160026  Training Accuracy:0.872093023255814\n",
            "1376/4708 - The training loss at 18th epoch : 0.09196502043262096  Training Accuracy:0.8721264367816092\n",
            "1392/4708 - The training loss at 18th epoch : 0.0934203619575153  Training Accuracy:0.8700284090909091\n",
            "1408/4708 - The training loss at 18th epoch : 0.09344859776899693  Training Accuracy:0.8700842696629213\n",
            "1424/4708 - The training loss at 18th epoch : 0.0935438919471435  Training Accuracy:0.8701388888888889\n",
            "1440/4708 - The training loss at 18th epoch : 0.09357443188998701  Training Accuracy:0.8701923076923077\n",
            "1456/4708 - The training loss at 18th epoch : 0.09299155984643878  Training Accuracy:0.8709239130434783\n",
            "1472/4708 - The training loss at 18th epoch : 0.09392852741708478  Training Accuracy:0.8689516129032258\n",
            "1488/4708 - The training loss at 18th epoch : 0.09346803161310709  Training Accuracy:0.8696808510638298\n",
            "1504/4708 - The training loss at 18th epoch : 0.09376270683932304  Training Accuracy:0.8690789473684211\n",
            "1520/4708 - The training loss at 18th epoch : 0.09377904337167668  Training Accuracy:0.869140625\n",
            "1536/4708 - The training loss at 18th epoch : 0.0934917158941913  Training Accuracy:0.8692010309278351\n",
            "1552/4708 - The training loss at 18th epoch : 0.09276893348409732  Training Accuracy:0.8698979591836735\n",
            "1568/4708 - The training loss at 18th epoch : 0.09216342408826264  Training Accuracy:0.8705808080808081\n",
            "1584/4708 - The training loss at 18th epoch : 0.09150184780734084  Training Accuracy:0.871875\n",
            "1600/4708 - The training loss at 18th epoch : 0.09136914110927465  Training Accuracy:0.8719059405940595\n",
            "1616/4708 - The training loss at 18th epoch : 0.09148496212616887  Training Accuracy:0.8719362745098039\n",
            "1632/4708 - The training loss at 18th epoch : 0.09111431708901546  Training Accuracy:0.8725728155339806\n",
            "1648/4708 - The training loss at 18th epoch : 0.09051617797087276  Training Accuracy:0.8731971153846154\n",
            "1664/4708 - The training loss at 18th epoch : 0.0910880574489409  Training Accuracy:0.8720238095238095\n",
            "1680/4708 - The training loss at 18th epoch : 0.09064373752413632  Training Accuracy:0.8726415094339622\n",
            "1696/4708 - The training loss at 18th epoch : 0.09165769746811372  Training Accuracy:0.8714953271028038\n",
            "1712/4708 - The training loss at 18th epoch : 0.09163702427363696  Training Accuracy:0.8715277777777778\n",
            "1728/4708 - The training loss at 18th epoch : 0.09164926815490369  Training Accuracy:0.8715596330275229\n",
            "1744/4708 - The training loss at 18th epoch : 0.09087633721705825  Training Accuracy:0.8727272727272727\n",
            "1760/4708 - The training loss at 18th epoch : 0.09130545168869593  Training Accuracy:0.8721846846846847\n",
            "1776/4708 - The training loss at 18th epoch : 0.09177314557105183  Training Accuracy:0.8716517857142857\n",
            "1792/4708 - The training loss at 18th epoch : 0.09148402253366147  Training Accuracy:0.8722345132743363\n",
            "1808/4708 - The training loss at 18th epoch : 0.09134512204973315  Training Accuracy:0.8722587719298246\n",
            "1824/4708 - The training loss at 18th epoch : 0.0907724623723562  Training Accuracy:0.8733695652173913\n",
            "1840/4708 - The training loss at 18th epoch : 0.09058371532232053  Training Accuracy:0.8733836206896551\n",
            "1856/4708 - The training loss at 18th epoch : 0.09095264363270227  Training Accuracy:0.8723290598290598\n",
            "1872/4708 - The training loss at 18th epoch : 0.09081639220626117  Training Accuracy:0.8728813559322034\n",
            "1888/4708 - The training loss at 18th epoch : 0.09104360895709351  Training Accuracy:0.8728991596638656\n",
            "1904/4708 - The training loss at 18th epoch : 0.09136382852592631  Training Accuracy:0.8729166666666667\n",
            "1920/4708 - The training loss at 18th epoch : 0.09108951034554284  Training Accuracy:0.8734504132231405\n",
            "1936/4708 - The training loss at 18th epoch : 0.09059232212386033  Training Accuracy:0.8744877049180327\n",
            "1952/4708 - The training loss at 18th epoch : 0.09063586160034981  Training Accuracy:0.8744918699186992\n",
            "1968/4708 - The training loss at 18th epoch : 0.09071687941290825  Training Accuracy:0.8744959677419355\n",
            "1984/4708 - The training loss at 18th epoch : 0.09013858653541859  Training Accuracy:0.8755\n",
            "2000/4708 - The training loss at 18th epoch : 0.090156131902886  Training Accuracy:0.8754960317460317\n",
            "2016/4708 - The training loss at 18th epoch : 0.08992273427016675  Training Accuracy:0.8759842519685039\n",
            "2032/4708 - The training loss at 18th epoch : 0.0898125465845473  Training Accuracy:0.8759765625\n",
            "2048/4708 - The training loss at 18th epoch : 0.08979424581052256  Training Accuracy:0.875484496124031\n",
            "2064/4708 - The training loss at 18th epoch : 0.08976107487835948  Training Accuracy:0.8759615384615385\n",
            "2080/4708 - The training loss at 18th epoch : 0.08980717935322051  Training Accuracy:0.8759541984732825\n",
            "2096/4708 - The training loss at 18th epoch : 0.08978326538776563  Training Accuracy:0.8764204545454546\n",
            "2112/4708 - The training loss at 18th epoch : 0.08935430380271833  Training Accuracy:0.8768796992481203\n",
            "2128/4708 - The training loss at 18th epoch : 0.08919328004604365  Training Accuracy:0.8768656716417911\n",
            "2144/4708 - The training loss at 18th epoch : 0.08882274948913127  Training Accuracy:0.8777777777777778\n",
            "2160/4708 - The training loss at 18th epoch : 0.08846824819708808  Training Accuracy:0.8782169117647058\n",
            "2176/4708 - The training loss at 18th epoch : 0.08840802315124217  Training Accuracy:0.8786496350364964\n",
            "2192/4708 - The training loss at 18th epoch : 0.08834795643896472  Training Accuracy:0.8790760869565217\n",
            "2208/4708 - The training loss at 18th epoch : 0.08834763438258254  Training Accuracy:0.8794964028776978\n",
            "2224/4708 - The training loss at 18th epoch : 0.08815828723540722  Training Accuracy:0.8794642857142857\n",
            "2240/4708 - The training loss at 18th epoch : 0.0885102146153658  Training Accuracy:0.8789893617021277\n",
            "2256/4708 - The training loss at 18th epoch : 0.08852701309270901  Training Accuracy:0.8789612676056338\n",
            "2272/4708 - The training loss at 18th epoch : 0.08822271015027704  Training Accuracy:0.8789335664335665\n",
            "2288/4708 - The training loss at 18th epoch : 0.08836391523561833  Training Accuracy:0.87890625\n",
            "2304/4708 - The training loss at 18th epoch : 0.08911392646690516  Training Accuracy:0.8780172413793104\n",
            "2320/4708 - The training loss at 18th epoch : 0.08909656247383275  Training Accuracy:0.8779965753424658\n",
            "2336/4708 - The training loss at 18th epoch : 0.08882541504248662  Training Accuracy:0.8784013605442177\n",
            "2352/4708 - The training loss at 18th epoch : 0.08888679664888688  Training Accuracy:0.877956081081081\n",
            "2368/4708 - The training loss at 18th epoch : 0.0883181823694795  Training Accuracy:0.8787751677852349\n",
            "2384/4708 - The training loss at 18th epoch : 0.08784848693146552  Training Accuracy:0.8795833333333334\n",
            "2400/4708 - The training loss at 18th epoch : 0.08813298825497921  Training Accuracy:0.8791390728476821\n",
            "2416/4708 - The training loss at 18th epoch : 0.08774517944733555  Training Accuracy:0.8795230263157895\n",
            "2432/4708 - The training loss at 18th epoch : 0.08815256943555401  Training Accuracy:0.8786764705882353\n",
            "2448/4708 - The training loss at 18th epoch : 0.08799179652172288  Training Accuracy:0.8790584415584416\n",
            "2464/4708 - The training loss at 18th epoch : 0.08807617443812504  Training Accuracy:0.8790322580645161\n",
            "2480/4708 - The training loss at 18th epoch : 0.08852263951224207  Training Accuracy:0.8790064102564102\n",
            "2496/4708 - The training loss at 18th epoch : 0.0884503540301849  Training Accuracy:0.8789808917197452\n",
            "2512/4708 - The training loss at 18th epoch : 0.08838611725807073  Training Accuracy:0.8789556962025317\n",
            "2528/4708 - The training loss at 18th epoch : 0.0879315676158854  Training Accuracy:0.8797169811320755\n",
            "2544/4708 - The training loss at 18th epoch : 0.08766693749936337  Training Accuracy:0.880078125\n",
            "2560/4708 - The training loss at 18th epoch : 0.08721204353955056  Training Accuracy:0.8808229813664596\n",
            "2576/4708 - The training loss at 18th epoch : 0.08716091061283156  Training Accuracy:0.8804012345679012\n",
            "2592/4708 - The training loss at 18th epoch : 0.08734023571655317  Training Accuracy:0.8799846625766872\n",
            "2608/4708 - The training loss at 18th epoch : 0.08687763148853682  Training Accuracy:0.8807164634146342\n",
            "2624/4708 - The training loss at 18th epoch : 0.08651526654911665  Training Accuracy:0.8810606060606061\n",
            "2640/4708 - The training loss at 18th epoch : 0.08642251141771685  Training Accuracy:0.8814006024096386\n",
            "2656/4708 - The training loss at 18th epoch : 0.08653536163586548  Training Accuracy:0.8813622754491018\n",
            "2672/4708 - The training loss at 18th epoch : 0.08636971181059043  Training Accuracy:0.8813244047619048\n",
            "2688/4708 - The training loss at 18th epoch : 0.08612915386403953  Training Accuracy:0.8812869822485208\n",
            "2704/4708 - The training loss at 18th epoch : 0.08620004496163709  Training Accuracy:0.88125\n",
            "2720/4708 - The training loss at 18th epoch : 0.08689487507712719  Training Accuracy:0.8801169590643275\n",
            "2736/4708 - The training loss at 18th epoch : 0.08697712735486354  Training Accuracy:0.8797238372093024\n",
            "2752/4708 - The training loss at 18th epoch : 0.08696691195335704  Training Accuracy:0.8796965317919075\n",
            "2768/4708 - The training loss at 18th epoch : 0.08737716226014965  Training Accuracy:0.8789511494252874\n",
            "2784/4708 - The training loss at 18th epoch : 0.08743989194448681  Training Accuracy:0.8785714285714286\n",
            "2800/4708 - The training loss at 18th epoch : 0.08707406497723834  Training Accuracy:0.8792613636363636\n",
            "2816/4708 - The training loss at 18th epoch : 0.08709548632668017  Training Accuracy:0.8792372881355932\n",
            "2832/4708 - The training loss at 18th epoch : 0.08665882072104712  Training Accuracy:0.8799157303370787\n",
            "2848/4708 - The training loss at 18th epoch : 0.0866445743590349  Training Accuracy:0.8798882681564246\n",
            "2864/4708 - The training loss at 18th epoch : 0.08668957893159797  Training Accuracy:0.8798611111111111\n",
            "2880/4708 - The training loss at 18th epoch : 0.08707376321425238  Training Accuracy:0.8791436464088398\n",
            "2896/4708 - The training loss at 18th epoch : 0.08694046658778934  Training Accuracy:0.8791208791208791\n",
            "2912/4708 - The training loss at 18th epoch : 0.08692630743399361  Training Accuracy:0.8790983606557377\n",
            "2928/4708 - The training loss at 18th epoch : 0.08710370431381911  Training Accuracy:0.8787364130434783\n",
            "2944/4708 - The training loss at 18th epoch : 0.08677263135776368  Training Accuracy:0.8793918918918919\n",
            "2960/4708 - The training loss at 18th epoch : 0.08669369033241937  Training Accuracy:0.8793682795698925\n",
            "2976/4708 - The training loss at 18th epoch : 0.08646187417661592  Training Accuracy:0.8796791443850267\n",
            "2992/4708 - The training loss at 18th epoch : 0.08680460557866747  Training Accuracy:0.8793218085106383\n",
            "3008/4708 - The training loss at 18th epoch : 0.08664848231522186  Training Accuracy:0.8796296296296297\n",
            "3024/4708 - The training loss at 18th epoch : 0.08641507249307616  Training Accuracy:0.8799342105263158\n",
            "3040/4708 - The training loss at 18th epoch : 0.08606110746238836  Training Accuracy:0.8805628272251309\n",
            "3056/4708 - The training loss at 18th epoch : 0.08582442514405707  Training Accuracy:0.880859375\n",
            "3072/4708 - The training loss at 18th epoch : 0.08548327066355446  Training Accuracy:0.8814766839378239\n",
            "3088/4708 - The training loss at 18th epoch : 0.08568190665895774  Training Accuracy:0.8811211340206185\n",
            "3104/4708 - The training loss at 18th epoch : 0.0857509780842595  Training Accuracy:0.8810897435897436\n",
            "3120/4708 - The training loss at 18th epoch : 0.08583570159957184  Training Accuracy:0.8810586734693877\n",
            "3136/4708 - The training loss at 18th epoch : 0.08643156486399511  Training Accuracy:0.8800761421319797\n",
            "3152/4708 - The training loss at 18th epoch : 0.08697256489767856  Training Accuracy:0.8794191919191919\n",
            "3168/4708 - The training loss at 18th epoch : 0.08680699710292354  Training Accuracy:0.8797110552763819\n",
            "3184/4708 - The training loss at 18th epoch : 0.08645533812168882  Training Accuracy:0.8803125\n",
            "3200/4708 - The training loss at 18th epoch : 0.08682295356931734  Training Accuracy:0.8796641791044776\n",
            "3216/4708 - The training loss at 18th epoch : 0.086845956108016  Training Accuracy:0.8796410891089109\n",
            "3232/4708 - The training loss at 18th epoch : 0.08666271235380889  Training Accuracy:0.8799261083743842\n",
            "3248/4708 - The training loss at 18th epoch : 0.08657808355239871  Training Accuracy:0.8799019607843137\n",
            "3264/4708 - The training loss at 18th epoch : 0.08687572081397638  Training Accuracy:0.8795731707317073\n",
            "3280/4708 - The training loss at 18th epoch : 0.08703798093645253  Training Accuracy:0.8795509708737864\n",
            "3296/4708 - The training loss at 18th epoch : 0.0867761614431628  Training Accuracy:0.8798309178743962\n",
            "3312/4708 - The training loss at 18th epoch : 0.08650508281022101  Training Accuracy:0.8801081730769231\n",
            "3328/4708 - The training loss at 18th epoch : 0.08637988108433702  Training Accuracy:0.8803827751196173\n",
            "3344/4708 - The training loss at 18th epoch : 0.08628930236165915  Training Accuracy:0.8806547619047619\n",
            "3360/4708 - The training loss at 18th epoch : 0.08631255320225835  Training Accuracy:0.880627962085308\n",
            "3376/4708 - The training loss at 18th epoch : 0.08622075081523016  Training Accuracy:0.8808962264150944\n",
            "3392/4708 - The training loss at 18th epoch : 0.08605289559813879  Training Accuracy:0.880868544600939\n",
            "3408/4708 - The training loss at 18th epoch : 0.08577525883095913  Training Accuracy:0.8811331775700935\n",
            "3424/4708 - The training loss at 18th epoch : 0.08541353206986775  Training Accuracy:0.8816860465116279\n",
            "3440/4708 - The training loss at 18th epoch : 0.08510955897859583  Training Accuracy:0.8822337962962963\n",
            "3456/4708 - The training loss at 18th epoch : 0.08507168174989309  Training Accuracy:0.8824884792626728\n",
            "3472/4708 - The training loss at 18th epoch : 0.08485946872229296  Training Accuracy:0.8827408256880734\n",
            "3488/4708 - The training loss at 18th epoch : 0.08481742549165516  Training Accuracy:0.8829908675799086\n",
            "3504/4708 - The training loss at 18th epoch : 0.08460754177811487  Training Accuracy:0.8835227272727273\n",
            "3520/4708 - The training loss at 18th epoch : 0.08463800266689366  Training Accuracy:0.8832013574660633\n",
            "3536/4708 - The training loss at 18th epoch : 0.08448017088685358  Training Accuracy:0.8834459459459459\n",
            "3552/4708 - The training loss at 18th epoch : 0.08448946134347  Training Accuracy:0.8834080717488789\n",
            "3568/4708 - The training loss at 18th epoch : 0.08453991109354766  Training Accuracy:0.8830915178571429\n",
            "3584/4708 - The training loss at 18th epoch : 0.08448751634104859  Training Accuracy:0.8830555555555556\n",
            "3600/4708 - The training loss at 18th epoch : 0.08463521365352937  Training Accuracy:0.8830199115044248\n",
            "3616/4708 - The training loss at 18th epoch : 0.08440050027833394  Training Accuracy:0.8835352422907489\n",
            "3632/4708 - The training loss at 18th epoch : 0.0843109750218825  Training Accuracy:0.8837719298245614\n",
            "3648/4708 - The training loss at 18th epoch : 0.08479760036348005  Training Accuracy:0.8831877729257642\n",
            "3664/4708 - The training loss at 18th epoch : 0.08514691905276461  Training Accuracy:0.8826086956521739\n",
            "3680/4708 - The training loss at 18th epoch : 0.08528170394972968  Training Accuracy:0.8820346320346321\n",
            "3696/4708 - The training loss at 18th epoch : 0.08537327008465764  Training Accuracy:0.8820043103448276\n",
            "3712/4708 - The training loss at 18th epoch : 0.08511918992400075  Training Accuracy:0.8825107296137339\n",
            "3728/4708 - The training loss at 18th epoch : 0.08525520139831094  Training Accuracy:0.8824786324786325\n",
            "3744/4708 - The training loss at 18th epoch : 0.08519043726815281  Training Accuracy:0.8824468085106383\n",
            "3760/4708 - The training loss at 18th epoch : 0.08493761794464565  Training Accuracy:0.8826800847457628\n",
            "3776/4708 - The training loss at 18th epoch : 0.08508625861602916  Training Accuracy:0.8826476793248945\n",
            "3792/4708 - The training loss at 18th epoch : 0.08559381118124892  Training Accuracy:0.8820903361344538\n",
            "3808/4708 - The training loss at 18th epoch : 0.08568405927200176  Training Accuracy:0.8817991631799164\n",
            "3824/4708 - The training loss at 18th epoch : 0.085781246520685  Training Accuracy:0.8817708333333333\n",
            "3840/4708 - The training loss at 18th epoch : 0.08593689523120225  Training Accuracy:0.8812240663900415\n",
            "3856/4708 - The training loss at 18th epoch : 0.08605298289105558  Training Accuracy:0.8806818181818182\n",
            "3872/4708 - The training loss at 18th epoch : 0.08599089504407158  Training Accuracy:0.8806584362139918\n",
            "3888/4708 - The training loss at 18th epoch : 0.08649677803803114  Training Accuracy:0.8798668032786885\n",
            "3904/4708 - The training loss at 18th epoch : 0.08650366921400462  Training Accuracy:0.8798469387755102\n",
            "3920/4708 - The training loss at 18th epoch : 0.08695281062050979  Training Accuracy:0.8793191056910569\n",
            "3936/4708 - The training loss at 18th epoch : 0.08669808396058175  Training Accuracy:0.8798076923076923\n",
            "3952/4708 - The training loss at 18th epoch : 0.08705284855151672  Training Accuracy:0.8795362903225806\n",
            "3968/4708 - The training loss at 18th epoch : 0.08708625052214018  Training Accuracy:0.8795180722891566\n",
            "3984/4708 - The training loss at 18th epoch : 0.08697159587663626  Training Accuracy:0.8795\n",
            "4000/4708 - The training loss at 18th epoch : 0.08685980888574736  Training Accuracy:0.8797310756972112\n",
            "4016/4708 - The training loss at 18th epoch : 0.08679026965686858  Training Accuracy:0.8797123015873016\n",
            "4032/4708 - The training loss at 18th epoch : 0.08699259204597558  Training Accuracy:0.8794466403162056\n",
            "4048/4708 - The training loss at 18th epoch : 0.08704698031585321  Training Accuracy:0.8791830708661418\n",
            "4064/4708 - The training loss at 18th epoch : 0.08684010561534614  Training Accuracy:0.879656862745098\n",
            "4080/4708 - The training loss at 18th epoch : 0.08658903648026527  Training Accuracy:0.880126953125\n",
            "4096/4708 - The training loss at 18th epoch : 0.0864017157252329  Training Accuracy:0.8803501945525292\n",
            "4112/4708 - The training loss at 18th epoch : 0.08614116157249233  Training Accuracy:0.8808139534883721\n",
            "4128/4708 - The training loss at 18th epoch : 0.08614829499857235  Training Accuracy:0.8807915057915058\n",
            "4144/4708 - The training loss at 18th epoch : 0.08601006977173323  Training Accuracy:0.8810096153846154\n",
            "4160/4708 - The training loss at 18th epoch : 0.08593078997378434  Training Accuracy:0.8809865900383141\n",
            "4176/4708 - The training loss at 18th epoch : 0.08590605994324019  Training Accuracy:0.8812022900763359\n",
            "4192/4708 - The training loss at 18th epoch : 0.08580637144945209  Training Accuracy:0.8814163498098859\n",
            "4208/4708 - The training loss at 18th epoch : 0.08573104057408419  Training Accuracy:0.8813920454545454\n",
            "4224/4708 - The training loss at 18th epoch : 0.08555950170473663  Training Accuracy:0.8816037735849057\n",
            "4240/4708 - The training loss at 18th epoch : 0.08540677651811349  Training Accuracy:0.8818139097744361\n",
            "4256/4708 - The training loss at 18th epoch : 0.08536200601706395  Training Accuracy:0.8817883895131086\n",
            "4272/4708 - The training loss at 18th epoch : 0.08540121953805113  Training Accuracy:0.8817630597014925\n",
            "4288/4708 - The training loss at 18th epoch : 0.08550351832442453  Training Accuracy:0.8815055762081785\n",
            "4304/4708 - The training loss at 18th epoch : 0.08540854000142822  Training Accuracy:0.881712962962963\n",
            "4320/4708 - The training loss at 18th epoch : 0.08534850065796137  Training Accuracy:0.8819188191881919\n",
            "4336/4708 - The training loss at 18th epoch : 0.08536081967978608  Training Accuracy:0.8818933823529411\n",
            "4352/4708 - The training loss at 18th epoch : 0.08531315374766447  Training Accuracy:0.8816391941391941\n",
            "4368/4708 - The training loss at 18th epoch : 0.08501752854539145  Training Accuracy:0.8820711678832117\n",
            "4384/4708 - The training loss at 18th epoch : 0.08511028225727599  Training Accuracy:0.8818181818181818\n",
            "4400/4708 - The training loss at 18th epoch : 0.08523309179512562  Training Accuracy:0.8817934782608695\n",
            "4416/4708 - The training loss at 18th epoch : 0.0853168856710097  Training Accuracy:0.881543321299639\n",
            "4432/4708 - The training loss at 18th epoch : 0.08533813737019336  Training Accuracy:0.8812949640287769\n",
            "4448/4708 - The training loss at 18th epoch : 0.08530981754892562  Training Accuracy:0.8814964157706093\n",
            "4464/4708 - The training loss at 18th epoch : 0.08534877580116107  Training Accuracy:0.8814732142857142\n",
            "4480/4708 - The training loss at 18th epoch : 0.08554388558058665  Training Accuracy:0.881450177935943\n",
            "4496/4708 - The training loss at 18th epoch : 0.08554615972305064  Training Accuracy:0.881427304964539\n",
            "4512/4708 - The training loss at 18th epoch : 0.08575920149911323  Training Accuracy:0.8811837455830389\n",
            "4528/4708 - The training loss at 18th epoch : 0.08565965175301936  Training Accuracy:0.8813820422535211\n",
            "4544/4708 - The training loss at 18th epoch : 0.08569747952172886  Training Accuracy:0.8813596491228071\n",
            "4560/4708 - The training loss at 18th epoch : 0.08582380006986726  Training Accuracy:0.8813374125874126\n",
            "4576/4708 - The training loss at 18th epoch : 0.08597049508499992  Training Accuracy:0.881315331010453\n",
            "4592/4708 - The training loss at 18th epoch : 0.08577966494657109  Training Accuracy:0.8815104166666666\n",
            "4608/4708 - The training loss at 18th epoch : 0.0858877363230408  Training Accuracy:0.8814878892733564\n",
            "4624/4708 - The training loss at 18th epoch : 0.086338014176863  Training Accuracy:0.8808189655172414\n",
            "4640/4708 - The training loss at 18th epoch : 0.08633200198548882  Training Accuracy:0.8805841924398625\n",
            "4656/4708 - The training loss at 18th epoch : 0.08616175526903294  Training Accuracy:0.880779109589041\n",
            "4672/4708 - The training loss at 18th epoch : 0.08616347875701827  Training Accuracy:0.8809726962457338\n",
            "4688/4708 - The training loss at 18th epoch : 0.08616285705083429  Training Accuracy:0.8811649659863946\n",
            "4704/4708 - The training loss at 18th epoch : 0.08590957153415987  Training Accuracy:0.8815677966101695\n",
            "4720/4708 - The training loss at 18th epoch : 0.08642068059776173  Training Accuracy:0.8809121621621622\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 19th epoch : 0.01153228165836969  Training Accuracy:1.0\n",
            "16/4708 - The training loss at 19th epoch : 0.016105462750630593  Training Accuracy:0.96875\n",
            "32/4708 - The training loss at 19th epoch : 0.012373807143924  Training Accuracy:0.9791666666666666\n",
            "48/4708 - The training loss at 19th epoch : 0.016468774507965293  Training Accuracy:0.984375\n",
            "64/4708 - The training loss at 19th epoch : 0.04514968624452578  Training Accuracy:0.95\n",
            "80/4708 - The training loss at 19th epoch : 0.051057928601093476  Training Accuracy:0.9375\n",
            "96/4708 - The training loss at 19th epoch : 0.04627203478344867  Training Accuracy:0.9464285714285714\n",
            "112/4708 - The training loss at 19th epoch : 0.05743264475330137  Training Accuracy:0.9296875\n",
            "128/4708 - The training loss at 19th epoch : 0.06357654786691491  Training Accuracy:0.9166666666666666\n",
            "144/4708 - The training loss at 19th epoch : 0.06617813358748562  Training Accuracy:0.9125\n",
            "160/4708 - The training loss at 19th epoch : 0.0643279006270171  Training Accuracy:0.9147727272727273\n",
            "176/4708 - The training loss at 19th epoch : 0.06239238628405724  Training Accuracy:0.9166666666666666\n",
            "192/4708 - The training loss at 19th epoch : 0.06103833656247656  Training Accuracy:0.9182692307692307\n",
            "208/4708 - The training loss at 19th epoch : 0.06589247860300887  Training Accuracy:0.9107142857142857\n",
            "224/4708 - The training loss at 19th epoch : 0.07115895291152942  Training Accuracy:0.9041666666666667\n",
            "240/4708 - The training loss at 19th epoch : 0.07212870583362369  Training Accuracy:0.90234375\n",
            "256/4708 - The training loss at 19th epoch : 0.06937565003416019  Training Accuracy:0.9080882352941176\n",
            "272/4708 - The training loss at 19th epoch : 0.06886166841164643  Training Accuracy:0.9097222222222222\n",
            "288/4708 - The training loss at 19th epoch : 0.07376255821267826  Training Accuracy:0.9046052631578947\n",
            "304/4708 - The training loss at 19th epoch : 0.08074167931221574  Training Accuracy:0.896875\n",
            "320/4708 - The training loss at 19th epoch : 0.07812749232039551  Training Accuracy:0.9017857142857143\n",
            "336/4708 - The training loss at 19th epoch : 0.07992979091123084  Training Accuracy:0.9005681818181818\n",
            "352/4708 - The training loss at 19th epoch : 0.07954186366159689  Training Accuracy:0.9021739130434783\n",
            "368/4708 - The training loss at 19th epoch : 0.07997370108791844  Training Accuracy:0.8984375\n",
            "384/4708 - The training loss at 19th epoch : 0.07939514466838465  Training Accuracy:0.8975\n",
            "400/4708 - The training loss at 19th epoch : 0.07980355995761491  Training Accuracy:0.8990384615384616\n",
            "416/4708 - The training loss at 19th epoch : 0.07988628239135193  Training Accuracy:0.8981481481481481\n",
            "432/4708 - The training loss at 19th epoch : 0.07805134379466339  Training Accuracy:0.8995535714285714\n",
            "448/4708 - The training loss at 19th epoch : 0.07859307235173113  Training Accuracy:0.896551724137931\n",
            "464/4708 - The training loss at 19th epoch : 0.07999055087387756  Training Accuracy:0.8958333333333334\n",
            "480/4708 - The training loss at 19th epoch : 0.08336673288086358  Training Accuracy:0.8891129032258065\n",
            "496/4708 - The training loss at 19th epoch : 0.08168321699341885  Training Accuracy:0.890625\n",
            "512/4708 - The training loss at 19th epoch : 0.0816227363821704  Training Accuracy:0.8901515151515151\n",
            "528/4708 - The training loss at 19th epoch : 0.08168927103710877  Training Accuracy:0.8897058823529411\n",
            "544/4708 - The training loss at 19th epoch : 0.0830386271583704  Training Accuracy:0.8892857142857142\n",
            "560/4708 - The training loss at 19th epoch : 0.08497640067117461  Training Accuracy:0.8871527777777778\n",
            "576/4708 - The training loss at 19th epoch : 0.08307741956042994  Training Accuracy:0.8902027027027027\n",
            "592/4708 - The training loss at 19th epoch : 0.08378425735398264  Training Accuracy:0.8881578947368421\n",
            "608/4708 - The training loss at 19th epoch : 0.08645219051114807  Training Accuracy:0.8830128205128205\n",
            "624/4708 - The training loss at 19th epoch : 0.08712254677105927  Training Accuracy:0.88125\n",
            "640/4708 - The training loss at 19th epoch : 0.08674891383210172  Training Accuracy:0.8826219512195121\n",
            "656/4708 - The training loss at 19th epoch : 0.0879192887536752  Training Accuracy:0.8824404761904762\n",
            "672/4708 - The training loss at 19th epoch : 0.0889403765048332  Training Accuracy:0.8808139534883721\n",
            "688/4708 - The training loss at 19th epoch : 0.08880729804318145  Training Accuracy:0.8806818181818182\n",
            "704/4708 - The training loss at 19th epoch : 0.08782477667496519  Training Accuracy:0.8819444444444444\n",
            "720/4708 - The training loss at 19th epoch : 0.08783048299307321  Training Accuracy:0.8817934782608695\n",
            "736/4708 - The training loss at 19th epoch : 0.08778251155295426  Training Accuracy:0.8816489361702128\n",
            "752/4708 - The training loss at 19th epoch : 0.08731867350619171  Training Accuracy:0.8815104166666666\n",
            "768/4708 - The training loss at 19th epoch : 0.08690997161928408  Training Accuracy:0.8826530612244898\n",
            "784/4708 - The training loss at 19th epoch : 0.08693261172215251  Training Accuracy:0.8825\n",
            "800/4708 - The training loss at 19th epoch : 0.08567261307953757  Training Accuracy:0.8848039215686274\n",
            "816/4708 - The training loss at 19th epoch : 0.08417873502695028  Training Accuracy:0.8870192307692307\n",
            "832/4708 - The training loss at 19th epoch : 0.08367920375760542  Training Accuracy:0.8879716981132075\n",
            "848/4708 - The training loss at 19th epoch : 0.08310537502923883  Training Accuracy:0.8877314814814815\n",
            "864/4708 - The training loss at 19th epoch : 0.08233249464744598  Training Accuracy:0.8886363636363637\n",
            "880/4708 - The training loss at 19th epoch : 0.08444525110412274  Training Accuracy:0.8861607142857143\n",
            "896/4708 - The training loss at 19th epoch : 0.08415441899851968  Training Accuracy:0.8870614035087719\n",
            "912/4708 - The training loss at 19th epoch : 0.08384370921914251  Training Accuracy:0.8879310344827587\n",
            "928/4708 - The training loss at 19th epoch : 0.08439294500422481  Training Accuracy:0.8877118644067796\n",
            "944/4708 - The training loss at 19th epoch : 0.08432468191530126  Training Accuracy:0.8875\n",
            "960/4708 - The training loss at 19th epoch : 0.08303483065771716  Training Accuracy:0.889344262295082\n",
            "976/4708 - The training loss at 19th epoch : 0.08196673568469437  Training Accuracy:0.8911290322580645\n",
            "992/4708 - The training loss at 19th epoch : 0.08258115941479299  Training Accuracy:0.8898809523809523\n",
            "1008/4708 - The training loss at 19th epoch : 0.08378627096849531  Training Accuracy:0.888671875\n",
            "1024/4708 - The training loss at 19th epoch : 0.08361203288016594  Training Accuracy:0.8894230769230769\n",
            "1040/4708 - The training loss at 19th epoch : 0.08273921912673748  Training Accuracy:0.8910984848484849\n",
            "1056/4708 - The training loss at 19th epoch : 0.08215695674193298  Training Accuracy:0.8917910447761194\n",
            "1072/4708 - The training loss at 19th epoch : 0.08271265877803191  Training Accuracy:0.8897058823529411\n",
            "1088/4708 - The training loss at 19th epoch : 0.08219622269502279  Training Accuracy:0.8894927536231884\n",
            "1104/4708 - The training loss at 19th epoch : 0.08289299922773267  Training Accuracy:0.8883928571428571\n",
            "1120/4708 - The training loss at 19th epoch : 0.08232697459884483  Training Accuracy:0.8899647887323944\n",
            "1136/4708 - The training loss at 19th epoch : 0.0840347540405989  Training Accuracy:0.8871527777777778\n",
            "1152/4708 - The training loss at 19th epoch : 0.08435109624668073  Training Accuracy:0.886986301369863\n",
            "1168/4708 - The training loss at 19th epoch : 0.08443986840095484  Training Accuracy:0.8868243243243243\n",
            "1184/4708 - The training loss at 19th epoch : 0.08418943944356737  Training Accuracy:0.8875\n",
            "1200/4708 - The training loss at 19th epoch : 0.08481558412384844  Training Accuracy:0.8865131578947368\n",
            "1216/4708 - The training loss at 19th epoch : 0.08472178499623421  Training Accuracy:0.8863636363636364\n",
            "1232/4708 - The training loss at 19th epoch : 0.08384248830396708  Training Accuracy:0.8878205128205128\n",
            "1248/4708 - The training loss at 19th epoch : 0.0845145780621406  Training Accuracy:0.8876582278481012\n",
            "1264/4708 - The training loss at 19th epoch : 0.086382656471244  Training Accuracy:0.884375\n",
            "1280/4708 - The training loss at 19th epoch : 0.0858776495757333  Training Accuracy:0.8850308641975309\n",
            "1296/4708 - The training loss at 19th epoch : 0.08534731803686837  Training Accuracy:0.8864329268292683\n",
            "1312/4708 - The training loss at 19th epoch : 0.08506210700118766  Training Accuracy:0.8862951807228916\n",
            "1328/4708 - The training loss at 19th epoch : 0.08490530061384997  Training Accuracy:0.8869047619047619\n",
            "1344/4708 - The training loss at 19th epoch : 0.0847067997685327  Training Accuracy:0.8875\n",
            "1360/4708 - The training loss at 19th epoch : 0.08393308508832134  Training Accuracy:0.8888081395348837\n",
            "1376/4708 - The training loss at 19th epoch : 0.08384013793252207  Training Accuracy:0.8886494252873564\n",
            "1392/4708 - The training loss at 19th epoch : 0.08395009844385978  Training Accuracy:0.8884943181818182\n",
            "1408/4708 - The training loss at 19th epoch : 0.08350032415778072  Training Accuracy:0.8890449438202247\n",
            "1424/4708 - The training loss at 19th epoch : 0.08307688581211876  Training Accuracy:0.8895833333333333\n",
            "1440/4708 - The training loss at 19th epoch : 0.08352512557439437  Training Accuracy:0.8887362637362637\n",
            "1456/4708 - The training loss at 19th epoch : 0.08276030274578441  Training Accuracy:0.8899456521739131\n",
            "1472/4708 - The training loss at 19th epoch : 0.0823416942324379  Training Accuracy:0.8904569892473119\n",
            "1488/4708 - The training loss at 19th epoch : 0.08170617016153858  Training Accuracy:0.8916223404255319\n",
            "1504/4708 - The training loss at 19th epoch : 0.08135279216687921  Training Accuracy:0.8921052631578947\n",
            "1520/4708 - The training loss at 19th epoch : 0.08130213509175736  Training Accuracy:0.8919270833333334\n",
            "1536/4708 - The training loss at 19th epoch : 0.08066796298121465  Training Accuracy:0.8930412371134021\n",
            "1552/4708 - The training loss at 19th epoch : 0.0809466075607177  Training Accuracy:0.8928571428571429\n",
            "1568/4708 - The training loss at 19th epoch : 0.08172973156380466  Training Accuracy:0.8920454545454546\n",
            "1584/4708 - The training loss at 19th epoch : 0.08235369786898811  Training Accuracy:0.89125\n",
            "1600/4708 - The training loss at 19th epoch : 0.08208921757245988  Training Accuracy:0.8917079207920792\n",
            "1616/4708 - The training loss at 19th epoch : 0.08157761909985788  Training Accuracy:0.8921568627450981\n",
            "1632/4708 - The training loss at 19th epoch : 0.08100182516505308  Training Accuracy:0.8932038834951457\n",
            "1648/4708 - The training loss at 19th epoch : 0.08117871453321526  Training Accuracy:0.8924278846153846\n",
            "1664/4708 - The training loss at 19th epoch : 0.08159553773264074  Training Accuracy:0.8910714285714286\n",
            "1680/4708 - The training loss at 19th epoch : 0.08177198105920164  Training Accuracy:0.8909198113207547\n",
            "1696/4708 - The training loss at 19th epoch : 0.08211043515097897  Training Accuracy:0.8901869158878505\n",
            "1712/4708 - The training loss at 19th epoch : 0.08304645020145882  Training Accuracy:0.8888888888888888\n",
            "1728/4708 - The training loss at 19th epoch : 0.0825663468671651  Training Accuracy:0.8893348623853211\n",
            "1744/4708 - The training loss at 19th epoch : 0.08268350328045565  Training Accuracy:0.8892045454545454\n",
            "1760/4708 - The training loss at 19th epoch : 0.0823767833573049  Training Accuracy:0.8896396396396397\n",
            "1776/4708 - The training loss at 19th epoch : 0.08243138719350789  Training Accuracy:0.8895089285714286\n",
            "1792/4708 - The training loss at 19th epoch : 0.08255722783524612  Training Accuracy:0.8893805309734514\n",
            "1808/4708 - The training loss at 19th epoch : 0.08246803079319041  Training Accuracy:0.8898026315789473\n",
            "1824/4708 - The training loss at 19th epoch : 0.08249995828633234  Training Accuracy:0.8896739130434783\n",
            "1840/4708 - The training loss at 19th epoch : 0.08214118756904722  Training Accuracy:0.890625\n",
            "1856/4708 - The training loss at 19th epoch : 0.08247935205938514  Training Accuracy:0.8899572649572649\n",
            "1872/4708 - The training loss at 19th epoch : 0.08259669270278178  Training Accuracy:0.8898305084745762\n",
            "1888/4708 - The training loss at 19th epoch : 0.08233734817978669  Training Accuracy:0.8902310924369747\n",
            "1904/4708 - The training loss at 19th epoch : 0.08266827929337488  Training Accuracy:0.8895833333333333\n",
            "1920/4708 - The training loss at 19th epoch : 0.08200522714338195  Training Accuracy:0.890495867768595\n",
            "1936/4708 - The training loss at 19th epoch : 0.08213720048541416  Training Accuracy:0.8898565573770492\n",
            "1952/4708 - The training loss at 19th epoch : 0.08236740025289518  Training Accuracy:0.8892276422764228\n",
            "1968/4708 - The training loss at 19th epoch : 0.08271140128736232  Training Accuracy:0.8886088709677419\n",
            "1984/4708 - The training loss at 19th epoch : 0.0828418767902017  Training Accuracy:0.8885\n",
            "2000/4708 - The training loss at 19th epoch : 0.08258177838761434  Training Accuracy:0.8888888888888888\n",
            "2016/4708 - The training loss at 19th epoch : 0.0827531378641424  Training Accuracy:0.8882874015748031\n",
            "2032/4708 - The training loss at 19th epoch : 0.08319289235373568  Training Accuracy:0.88818359375\n",
            "2048/4708 - The training loss at 19th epoch : 0.08337347091741804  Training Accuracy:0.8880813953488372\n",
            "2064/4708 - The training loss at 19th epoch : 0.08399458105507553  Training Accuracy:0.8875\n",
            "2080/4708 - The training loss at 19th epoch : 0.08410727838893  Training Accuracy:0.8874045801526718\n",
            "2096/4708 - The training loss at 19th epoch : 0.08367417570429742  Training Accuracy:0.8882575757575758\n",
            "2112/4708 - The training loss at 19th epoch : 0.08399054956704133  Training Accuracy:0.887687969924812\n",
            "2128/4708 - The training loss at 19th epoch : 0.08366868293551465  Training Accuracy:0.8885261194029851\n",
            "2144/4708 - The training loss at 19th epoch : 0.083460682922564  Training Accuracy:0.8888888888888888\n",
            "2160/4708 - The training loss at 19th epoch : 0.08369798095844223  Training Accuracy:0.8883272058823529\n",
            "2176/4708 - The training loss at 19th epoch : 0.0836874531325372  Training Accuracy:0.8882299270072993\n",
            "2192/4708 - The training loss at 19th epoch : 0.08409196653921196  Training Accuracy:0.8872282608695652\n",
            "2208/4708 - The training loss at 19th epoch : 0.08432545519079505  Training Accuracy:0.8871402877697842\n",
            "2224/4708 - The training loss at 19th epoch : 0.08387949469858084  Training Accuracy:0.8879464285714286\n",
            "2240/4708 - The training loss at 19th epoch : 0.08382578576109209  Training Accuracy:0.8882978723404256\n",
            "2256/4708 - The training loss at 19th epoch : 0.08344841038657828  Training Accuracy:0.8886443661971831\n",
            "2272/4708 - The training loss at 19th epoch : 0.08397141607127954  Training Accuracy:0.8876748251748252\n",
            "2288/4708 - The training loss at 19th epoch : 0.08392795155593807  Training Accuracy:0.8875868055555556\n",
            "2304/4708 - The training loss at 19th epoch : 0.08403149870816835  Training Accuracy:0.8875\n",
            "2320/4708 - The training loss at 19th epoch : 0.08435809976995452  Training Accuracy:0.8874143835616438\n",
            "2336/4708 - The training loss at 19th epoch : 0.08387763086597837  Training Accuracy:0.8881802721088435\n",
            "2352/4708 - The training loss at 19th epoch : 0.08366015830052626  Training Accuracy:0.8885135135135135\n",
            "2368/4708 - The training loss at 19th epoch : 0.08363800124991379  Training Accuracy:0.8884228187919463\n",
            "2384/4708 - The training loss at 19th epoch : 0.08374174681912848  Training Accuracy:0.8883333333333333\n",
            "2400/4708 - The training loss at 19th epoch : 0.0839738459665256  Training Accuracy:0.8882450331125827\n",
            "2416/4708 - The training loss at 19th epoch : 0.08402779525107362  Training Accuracy:0.8881578947368421\n",
            "2432/4708 - The training loss at 19th epoch : 0.08461132624750115  Training Accuracy:0.8876633986928104\n",
            "2448/4708 - The training loss at 19th epoch : 0.08423795887568125  Training Accuracy:0.887987012987013\n",
            "2464/4708 - The training loss at 19th epoch : 0.0839398225234583  Training Accuracy:0.8883064516129032\n",
            "2480/4708 - The training loss at 19th epoch : 0.083721657504375  Training Accuracy:0.8886217948717948\n",
            "2496/4708 - The training loss at 19th epoch : 0.08417845113701854  Training Accuracy:0.8877388535031847\n",
            "2512/4708 - The training loss at 19th epoch : 0.08412360434191553  Training Accuracy:0.8876582278481012\n",
            "2528/4708 - The training loss at 19th epoch : 0.08386378330087353  Training Accuracy:0.8879716981132075\n",
            "2544/4708 - The training loss at 19th epoch : 0.08411507194199068  Training Accuracy:0.8875\n",
            "2560/4708 - The training loss at 19th epoch : 0.08390370600976052  Training Accuracy:0.8874223602484472\n",
            "2576/4708 - The training loss at 19th epoch : 0.08412831668427817  Training Accuracy:0.8869598765432098\n",
            "2592/4708 - The training loss at 19th epoch : 0.08417281641523751  Training Accuracy:0.8868865030674846\n",
            "2608/4708 - The training loss at 19th epoch : 0.08394216580670404  Training Accuracy:0.8871951219512195\n",
            "2624/4708 - The training loss at 19th epoch : 0.08360964554598335  Training Accuracy:0.8878787878787879\n",
            "2640/4708 - The training loss at 19th epoch : 0.08361385760775807  Training Accuracy:0.8878012048192772\n",
            "2656/4708 - The training loss at 19th epoch : 0.08327428050319967  Training Accuracy:0.8884730538922155\n",
            "2672/4708 - The training loss at 19th epoch : 0.0831488765142615  Training Accuracy:0.8887648809523809\n",
            "2688/4708 - The training loss at 19th epoch : 0.08282423779191476  Training Accuracy:0.8890532544378699\n",
            "2704/4708 - The training loss at 19th epoch : 0.08259100711392227  Training Accuracy:0.8897058823529411\n",
            "2720/4708 - The training loss at 19th epoch : 0.08290011846475885  Training Accuracy:0.8892543859649122\n",
            "2736/4708 - The training loss at 19th epoch : 0.08303538469499663  Training Accuracy:0.889171511627907\n",
            "2752/4708 - The training loss at 19th epoch : 0.0825783155157584  Training Accuracy:0.8898121387283237\n",
            "2768/4708 - The training loss at 19th epoch : 0.08293593640940486  Training Accuracy:0.8890086206896551\n",
            "2784/4708 - The training loss at 19th epoch : 0.08278241534304852  Training Accuracy:0.8892857142857142\n",
            "2800/4708 - The training loss at 19th epoch : 0.08307459221337224  Training Accuracy:0.8888494318181818\n",
            "2816/4708 - The training loss at 19th epoch : 0.08319671436194412  Training Accuracy:0.8884180790960452\n",
            "2832/4708 - The training loss at 19th epoch : 0.08294792430087461  Training Accuracy:0.8886938202247191\n",
            "2848/4708 - The training loss at 19th epoch : 0.08276094226235173  Training Accuracy:0.8889664804469274\n",
            "2864/4708 - The training loss at 19th epoch : 0.08287371275739328  Training Accuracy:0.8888888888888888\n",
            "2880/4708 - The training loss at 19th epoch : 0.08284603489861968  Training Accuracy:0.8888121546961326\n",
            "2896/4708 - The training loss at 19th epoch : 0.08243469529696716  Training Accuracy:0.8894230769230769\n",
            "2912/4708 - The training loss at 19th epoch : 0.0823633870024318  Training Accuracy:0.8896857923497268\n",
            "2928/4708 - The training loss at 19th epoch : 0.08210616125286015  Training Accuracy:0.8899456521739131\n",
            "2944/4708 - The training loss at 19th epoch : 0.08188134740062615  Training Accuracy:0.8902027027027027\n",
            "2960/4708 - The training loss at 19th epoch : 0.08192380937825137  Training Accuracy:0.8901209677419355\n",
            "2976/4708 - The training loss at 19th epoch : 0.08155533459445598  Training Accuracy:0.8907085561497327\n",
            "2992/4708 - The training loss at 19th epoch : 0.08146369144552276  Training Accuracy:0.890625\n",
            "3008/4708 - The training loss at 19th epoch : 0.08159990015893594  Training Accuracy:0.890542328042328\n",
            "3024/4708 - The training loss at 19th epoch : 0.08164316949009527  Training Accuracy:0.8904605263157894\n",
            "3040/4708 - The training loss at 19th epoch : 0.08178700465042443  Training Accuracy:0.8897251308900523\n",
            "3056/4708 - The training loss at 19th epoch : 0.08154040297775444  Training Accuracy:0.8899739583333334\n",
            "3072/4708 - The training loss at 19th epoch : 0.08170882534442832  Training Accuracy:0.8895725388601037\n",
            "3088/4708 - The training loss at 19th epoch : 0.0817672874370051  Training Accuracy:0.8894974226804123\n",
            "3104/4708 - The training loss at 19th epoch : 0.08145322749953399  Training Accuracy:0.8900641025641025\n",
            "3120/4708 - The training loss at 19th epoch : 0.08149882955005681  Training Accuracy:0.8899872448979592\n",
            "3136/4708 - The training loss at 19th epoch : 0.0813299081865563  Training Accuracy:0.8902284263959391\n",
            "3152/4708 - The training loss at 19th epoch : 0.08096053136457738  Training Accuracy:0.8907828282828283\n",
            "3168/4708 - The training loss at 19th epoch : 0.08092706341869536  Training Accuracy:0.8903894472361809\n",
            "3184/4708 - The training loss at 19th epoch : 0.08126928302255201  Training Accuracy:0.8896875\n",
            "3200/4708 - The training loss at 19th epoch : 0.08201136716303735  Training Accuracy:0.888681592039801\n",
            "3216/4708 - The training loss at 19th epoch : 0.08191330780747798  Training Accuracy:0.8889232673267327\n",
            "3232/4708 - The training loss at 19th epoch : 0.08196565608956144  Training Accuracy:0.8888546798029556\n",
            "3248/4708 - The training loss at 19th epoch : 0.08195233758794847  Training Accuracy:0.8887867647058824\n",
            "3264/4708 - The training loss at 19th epoch : 0.08207165933056237  Training Accuracy:0.8884146341463415\n",
            "3280/4708 - The training loss at 19th epoch : 0.08223281837193828  Training Accuracy:0.8880461165048543\n",
            "3296/4708 - The training loss at 19th epoch : 0.082289426367607  Training Accuracy:0.8879830917874396\n",
            "3312/4708 - The training loss at 19th epoch : 0.08252874676206041  Training Accuracy:0.8876201923076923\n",
            "3328/4708 - The training loss at 19th epoch : 0.08264634130509967  Training Accuracy:0.8875598086124402\n",
            "3344/4708 - The training loss at 19th epoch : 0.08250001338823287  Training Accuracy:0.887797619047619\n",
            "3360/4708 - The training loss at 19th epoch : 0.08231037409972249  Training Accuracy:0.8880331753554502\n",
            "3376/4708 - The training loss at 19th epoch : 0.0827472549759054  Training Accuracy:0.8876768867924528\n",
            "3392/4708 - The training loss at 19th epoch : 0.08271780545198845  Training Accuracy:0.8879107981220657\n",
            "3408/4708 - The training loss at 19th epoch : 0.08286274707900397  Training Accuracy:0.8875584112149533\n",
            "3424/4708 - The training loss at 19th epoch : 0.08263654126400505  Training Accuracy:0.8877906976744186\n",
            "3440/4708 - The training loss at 19th epoch : 0.08239934181799242  Training Accuracy:0.8880208333333334\n",
            "3456/4708 - The training loss at 19th epoch : 0.08215424941850324  Training Accuracy:0.8882488479262672\n",
            "3472/4708 - The training loss at 19th epoch : 0.08218010175915322  Training Accuracy:0.8881880733944955\n",
            "3488/4708 - The training loss at 19th epoch : 0.08229851392231761  Training Accuracy:0.8878424657534246\n",
            "3504/4708 - The training loss at 19th epoch : 0.08279683681996589  Training Accuracy:0.8869318181818182\n",
            "3520/4708 - The training loss at 19th epoch : 0.08255251603579536  Training Accuracy:0.8874434389140271\n",
            "3536/4708 - The training loss at 19th epoch : 0.08249638158529113  Training Accuracy:0.887668918918919\n",
            "3552/4708 - The training loss at 19th epoch : 0.08242129368677652  Training Accuracy:0.8878923766816144\n",
            "3568/4708 - The training loss at 19th epoch : 0.08263922107200915  Training Accuracy:0.8875558035714286\n",
            "3584/4708 - The training loss at 19th epoch : 0.08263679133078389  Training Accuracy:0.8875\n",
            "3600/4708 - The training loss at 19th epoch : 0.08265857790494005  Training Accuracy:0.8874446902654868\n",
            "3616/4708 - The training loss at 19th epoch : 0.08300119896734914  Training Accuracy:0.8868392070484582\n",
            "3632/4708 - The training loss at 19th epoch : 0.08308141542370034  Training Accuracy:0.8865131578947368\n",
            "3648/4708 - The training loss at 19th epoch : 0.08295255085267338  Training Accuracy:0.886735807860262\n",
            "3664/4708 - The training loss at 19th epoch : 0.08285063159224161  Training Accuracy:0.8869565217391304\n",
            "3680/4708 - The training loss at 19th epoch : 0.0831875474802267  Training Accuracy:0.8866341991341992\n",
            "3696/4708 - The training loss at 19th epoch : 0.08323367285174077  Training Accuracy:0.8865840517241379\n",
            "3712/4708 - The training loss at 19th epoch : 0.08351757896188064  Training Accuracy:0.8862660944206009\n",
            "3728/4708 - The training loss at 19th epoch : 0.08335348830074059  Training Accuracy:0.8864850427350427\n",
            "3744/4708 - The training loss at 19th epoch : 0.08342611647691561  Training Accuracy:0.886436170212766\n",
            "3760/4708 - The training loss at 19th epoch : 0.08310902863493766  Training Accuracy:0.886917372881356\n",
            "3776/4708 - The training loss at 19th epoch : 0.08287611438001295  Training Accuracy:0.8871308016877637\n",
            "3792/4708 - The training loss at 19th epoch : 0.08313208845507335  Training Accuracy:0.8868172268907563\n",
            "3808/4708 - The training loss at 19th epoch : 0.08298758357329276  Training Accuracy:0.8872907949790795\n",
            "3824/4708 - The training loss at 19th epoch : 0.08310027399660051  Training Accuracy:0.8869791666666667\n",
            "3840/4708 - The training loss at 19th epoch : 0.08311123126501273  Training Accuracy:0.8869294605809128\n",
            "3856/4708 - The training loss at 19th epoch : 0.08340344553388178  Training Accuracy:0.8863636363636364\n",
            "3872/4708 - The training loss at 19th epoch : 0.08350074988107595  Training Accuracy:0.8863168724279835\n",
            "3888/4708 - The training loss at 19th epoch : 0.08345602730366665  Training Accuracy:0.8865266393442623\n",
            "3904/4708 - The training loss at 19th epoch : 0.08323423667618988  Training Accuracy:0.886734693877551\n",
            "3920/4708 - The training loss at 19th epoch : 0.0829907864740345  Training Accuracy:0.8871951219512195\n",
            "3936/4708 - The training loss at 19th epoch : 0.08329316455545303  Training Accuracy:0.8866396761133604\n",
            "3952/4708 - The training loss at 19th epoch : 0.08302738519853438  Training Accuracy:0.8870967741935484\n",
            "3968/4708 - The training loss at 19th epoch : 0.08296143312394649  Training Accuracy:0.8870481927710844\n",
            "3984/4708 - The training loss at 19th epoch : 0.0831927371064552  Training Accuracy:0.8865\n",
            "4000/4708 - The training loss at 19th epoch : 0.08346814085162373  Training Accuracy:0.8862051792828686\n",
            "4016/4708 - The training loss at 19th epoch : 0.08351828199674532  Training Accuracy:0.8859126984126984\n",
            "4032/4708 - The training loss at 19th epoch : 0.08333751584846597  Training Accuracy:0.8861166007905138\n",
            "4048/4708 - The training loss at 19th epoch : 0.08326765110379451  Training Accuracy:0.8860728346456693\n",
            "4064/4708 - The training loss at 19th epoch : 0.08335819463324737  Training Accuracy:0.8860294117647058\n",
            "4080/4708 - The training loss at 19th epoch : 0.08325841236545677  Training Accuracy:0.885986328125\n",
            "4096/4708 - The training loss at 19th epoch : 0.08328734379144734  Training Accuracy:0.8859435797665369\n",
            "4112/4708 - The training loss at 19th epoch : 0.08348872381731977  Training Accuracy:0.8856589147286822\n",
            "4128/4708 - The training loss at 19th epoch : 0.08323430859565936  Training Accuracy:0.8861003861003861\n",
            "4144/4708 - The training loss at 19th epoch : 0.08364714656019755  Training Accuracy:0.8853365384615385\n",
            "4160/4708 - The training loss at 19th epoch : 0.08352040501810438  Training Accuracy:0.8855363984674329\n",
            "4176/4708 - The training loss at 19th epoch : 0.08389494227575983  Training Accuracy:0.884780534351145\n",
            "4192/4708 - The training loss at 19th epoch : 0.08390125519677503  Training Accuracy:0.8847433460076045\n",
            "4208/4708 - The training loss at 19th epoch : 0.08366131760238792  Training Accuracy:0.8851799242424242\n",
            "4224/4708 - The training loss at 19th epoch : 0.08366390192212271  Training Accuracy:0.8851415094339623\n",
            "4240/4708 - The training loss at 19th epoch : 0.08382282051089814  Training Accuracy:0.8848684210526315\n",
            "4256/4708 - The training loss at 19th epoch : 0.08395701913601357  Training Accuracy:0.8845973782771536\n",
            "4272/4708 - The training loss at 19th epoch : 0.08413372771835143  Training Accuracy:0.8845615671641791\n",
            "4288/4708 - The training loss at 19th epoch : 0.0841841146688052  Training Accuracy:0.8845260223048327\n",
            "4304/4708 - The training loss at 19th epoch : 0.08393228370942886  Training Accuracy:0.8849537037037037\n",
            "4320/4708 - The training loss at 19th epoch : 0.08374573572155293  Training Accuracy:0.8853782287822878\n",
            "4336/4708 - The training loss at 19th epoch : 0.08372908586303525  Training Accuracy:0.8855698529411765\n",
            "4352/4708 - The training loss at 19th epoch : 0.08375959227300372  Training Accuracy:0.8857600732600732\n",
            "4368/4708 - The training loss at 19th epoch : 0.0838672530488829  Training Accuracy:0.885492700729927\n",
            "4384/4708 - The training loss at 19th epoch : 0.08404086438525367  Training Accuracy:0.885\n",
            "4400/4708 - The training loss at 19th epoch : 0.08421938546952014  Training Accuracy:0.8847373188405797\n",
            "4416/4708 - The training loss at 19th epoch : 0.0843721353780564  Training Accuracy:0.8844765342960289\n",
            "4432/4708 - The training loss at 19th epoch : 0.08431395600873351  Training Accuracy:0.8846672661870504\n",
            "4448/4708 - The training loss at 19th epoch : 0.08481961197631954  Training Accuracy:0.8839605734767025\n",
            "4464/4708 - The training loss at 19th epoch : 0.08466112369991675  Training Accuracy:0.8841517857142858\n",
            "4480/4708 - The training loss at 19th epoch : 0.08452444726214725  Training Accuracy:0.8843416370106761\n",
            "4496/4708 - The training loss at 19th epoch : 0.08472101018146751  Training Accuracy:0.8840868794326241\n",
            "4512/4708 - The training loss at 19th epoch : 0.08470683606160785  Training Accuracy:0.883833922261484\n",
            "4528/4708 - The training loss at 19th epoch : 0.08462213704074618  Training Accuracy:0.8838028169014085\n",
            "4544/4708 - The training loss at 19th epoch : 0.08435371062702203  Training Accuracy:0.8842105263157894\n",
            "4560/4708 - The training loss at 19th epoch : 0.08447996547435045  Training Accuracy:0.8841783216783217\n",
            "4576/4708 - The training loss at 19th epoch : 0.08445755805548748  Training Accuracy:0.8839285714285714\n",
            "4592/4708 - The training loss at 19th epoch : 0.08425983226898431  Training Accuracy:0.8841145833333334\n",
            "4608/4708 - The training loss at 19th epoch : 0.08435304380887611  Training Accuracy:0.884083044982699\n",
            "4624/4708 - The training loss at 19th epoch : 0.08460419224670718  Training Accuracy:0.8836206896551724\n",
            "4640/4708 - The training loss at 19th epoch : 0.08481220085897356  Training Accuracy:0.8833762886597938\n",
            "4656/4708 - The training loss at 19th epoch : 0.08467770161673656  Training Accuracy:0.8835616438356164\n",
            "4672/4708 - The training loss at 19th epoch : 0.08453205043764268  Training Accuracy:0.8837457337883959\n",
            "4688/4708 - The training loss at 19th epoch : 0.08453044545712841  Training Accuracy:0.8835034013605442\n",
            "4704/4708 - The training loss at 19th epoch : 0.08465063936078976  Training Accuracy:0.8834745762711864\n",
            "4720/4708 - The training loss at 19th epoch : 0.08453260801677893  Training Accuracy:0.8836570945945946\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 20th epoch : 0.12658070909989655  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 20th epoch : 0.14230854304173193  Training Accuracy:0.84375\n",
            "32/4708 - The training loss at 20th epoch : 0.12208737923514741  Training Accuracy:0.8541666666666666\n",
            "48/4708 - The training loss at 20th epoch : 0.1296854510728298  Training Accuracy:0.84375\n",
            "64/4708 - The training loss at 20th epoch : 0.11842611938315684  Training Accuracy:0.85\n",
            "80/4708 - The training loss at 20th epoch : 0.1057997262139269  Training Accuracy:0.8645833333333334\n",
            "96/4708 - The training loss at 20th epoch : 0.10681307655545022  Training Accuracy:0.8571428571428571\n",
            "112/4708 - The training loss at 20th epoch : 0.09750235079926643  Training Accuracy:0.8671875\n",
            "128/4708 - The training loss at 20th epoch : 0.08816695177403233  Training Accuracy:0.8819444444444444\n",
            "144/4708 - The training loss at 20th epoch : 0.08610763483778908  Training Accuracy:0.8875\n",
            "160/4708 - The training loss at 20th epoch : 0.08016262310960327  Training Accuracy:0.8977272727272727\n",
            "176/4708 - The training loss at 20th epoch : 0.08336306221952057  Training Accuracy:0.890625\n",
            "192/4708 - The training loss at 20th epoch : 0.08152744119964259  Training Accuracy:0.8942307692307693\n",
            "208/4708 - The training loss at 20th epoch : 0.07661231996722859  Training Accuracy:0.9017857142857143\n",
            "224/4708 - The training loss at 20th epoch : 0.07534929205765954  Training Accuracy:0.9\n",
            "240/4708 - The training loss at 20th epoch : 0.07674057096599911  Training Accuracy:0.89453125\n",
            "256/4708 - The training loss at 20th epoch : 0.07620559795535559  Training Accuracy:0.8933823529411765\n",
            "272/4708 - The training loss at 20th epoch : 0.07446473237570099  Training Accuracy:0.8993055555555556\n",
            "288/4708 - The training loss at 20th epoch : 0.07367827895135594  Training Accuracy:0.8980263157894737\n",
            "304/4708 - The training loss at 20th epoch : 0.0731517213761755  Training Accuracy:0.896875\n",
            "320/4708 - The training loss at 20th epoch : 0.0704499464410603  Training Accuracy:0.9017857142857143\n",
            "336/4708 - The training loss at 20th epoch : 0.0719648158699942  Training Accuracy:0.9005681818181818\n",
            "352/4708 - The training loss at 20th epoch : 0.07057608618870688  Training Accuracy:0.9021739130434783\n",
            "368/4708 - The training loss at 20th epoch : 0.07207840319880929  Training Accuracy:0.9036458333333334\n",
            "384/4708 - The training loss at 20th epoch : 0.0714140535663068  Training Accuracy:0.905\n",
            "400/4708 - The training loss at 20th epoch : 0.0727873863195476  Training Accuracy:0.9014423076923077\n",
            "416/4708 - The training loss at 20th epoch : 0.07072458553438958  Training Accuracy:0.9050925925925926\n",
            "432/4708 - The training loss at 20th epoch : 0.07310563203638198  Training Accuracy:0.8995535714285714\n",
            "448/4708 - The training loss at 20th epoch : 0.07302054978772196  Training Accuracy:0.8987068965517241\n",
            "464/4708 - The training loss at 20th epoch : 0.07318282858071662  Training Accuracy:0.8979166666666667\n",
            "480/4708 - The training loss at 20th epoch : 0.07267047066167455  Training Accuracy:0.8971774193548387\n",
            "496/4708 - The training loss at 20th epoch : 0.07076390030331825  Training Accuracy:0.900390625\n",
            "512/4708 - The training loss at 20th epoch : 0.0722004356662073  Training Accuracy:0.8996212121212122\n",
            "528/4708 - The training loss at 20th epoch : 0.07248086924574901  Training Accuracy:0.8988970588235294\n",
            "544/4708 - The training loss at 20th epoch : 0.07090196835757728  Training Accuracy:0.9017857142857143\n",
            "560/4708 - The training loss at 20th epoch : 0.0712043266844269  Training Accuracy:0.9027777777777778\n",
            "576/4708 - The training loss at 20th epoch : 0.07310358400157223  Training Accuracy:0.9003378378378378\n",
            "592/4708 - The training loss at 20th epoch : 0.07689209745473118  Training Accuracy:0.8947368421052632\n",
            "608/4708 - The training loss at 20th epoch : 0.07612613032827592  Training Accuracy:0.8958333333333334\n",
            "624/4708 - The training loss at 20th epoch : 0.07577727504023016  Training Accuracy:0.8953125\n",
            "640/4708 - The training loss at 20th epoch : 0.07404617307374428  Training Accuracy:0.8978658536585366\n",
            "656/4708 - The training loss at 20th epoch : 0.07308230567346492  Training Accuracy:0.8988095238095238\n",
            "672/4708 - The training loss at 20th epoch : 0.07341379400099887  Training Accuracy:0.8982558139534884\n",
            "688/4708 - The training loss at 20th epoch : 0.07385223959309983  Training Accuracy:0.8977272727272727\n",
            "704/4708 - The training loss at 20th epoch : 0.07316163440334467  Training Accuracy:0.8986111111111111\n",
            "720/4708 - The training loss at 20th epoch : 0.07259111755648054  Training Accuracy:0.8994565217391305\n",
            "736/4708 - The training loss at 20th epoch : 0.07182530295289972  Training Accuracy:0.9002659574468085\n",
            "752/4708 - The training loss at 20th epoch : 0.07096595281911063  Training Accuracy:0.9010416666666666\n",
            "768/4708 - The training loss at 20th epoch : 0.07215205087256792  Training Accuracy:0.8992346938775511\n",
            "784/4708 - The training loss at 20th epoch : 0.0725088794378934  Training Accuracy:0.89875\n",
            "800/4708 - The training loss at 20th epoch : 0.07475710854552758  Training Accuracy:0.8958333333333334\n",
            "816/4708 - The training loss at 20th epoch : 0.07583549290782571  Training Accuracy:0.8942307692307693\n",
            "832/4708 - The training loss at 20th epoch : 0.07479115509462017  Training Accuracy:0.8962264150943396\n",
            "848/4708 - The training loss at 20th epoch : 0.0740570688517349  Training Accuracy:0.8981481481481481\n",
            "864/4708 - The training loss at 20th epoch : 0.07609661869484373  Training Accuracy:0.8954545454545455\n",
            "880/4708 - The training loss at 20th epoch : 0.07566962298825579  Training Accuracy:0.8962053571428571\n",
            "896/4708 - The training loss at 20th epoch : 0.07576812163461483  Training Accuracy:0.8958333333333334\n",
            "912/4708 - The training loss at 20th epoch : 0.07572798810931136  Training Accuracy:0.8954741379310345\n",
            "928/4708 - The training loss at 20th epoch : 0.07489304409071199  Training Accuracy:0.8972457627118644\n",
            "944/4708 - The training loss at 20th epoch : 0.07630332695220145  Training Accuracy:0.8947916666666667\n",
            "960/4708 - The training loss at 20th epoch : 0.07713100897394808  Training Accuracy:0.8934426229508197\n",
            "976/4708 - The training loss at 20th epoch : 0.07716575083987105  Training Accuracy:0.8931451612903226\n",
            "992/4708 - The training loss at 20th epoch : 0.07682064813876996  Training Accuracy:0.8938492063492064\n",
            "1008/4708 - The training loss at 20th epoch : 0.07628024717311402  Training Accuracy:0.89453125\n",
            "1024/4708 - The training loss at 20th epoch : 0.07637469798638447  Training Accuracy:0.8942307692307693\n",
            "1040/4708 - The training loss at 20th epoch : 0.07657653429055125  Training Accuracy:0.8929924242424242\n",
            "1056/4708 - The training loss at 20th epoch : 0.07591733481133905  Training Accuracy:0.8936567164179104\n",
            "1072/4708 - The training loss at 20th epoch : 0.07508735176659555  Training Accuracy:0.8952205882352942\n",
            "1088/4708 - The training loss at 20th epoch : 0.0750340834346363  Training Accuracy:0.894927536231884\n",
            "1104/4708 - The training loss at 20th epoch : 0.07575680182417939  Training Accuracy:0.89375\n",
            "1120/4708 - The training loss at 20th epoch : 0.07589337359133481  Training Accuracy:0.8934859154929577\n",
            "1136/4708 - The training loss at 20th epoch : 0.07655604588651799  Training Accuracy:0.8923611111111112\n",
            "1152/4708 - The training loss at 20th epoch : 0.07560180901807131  Training Accuracy:0.8938356164383562\n",
            "1168/4708 - The training loss at 20th epoch : 0.07604729890640266  Training Accuracy:0.893581081081081\n",
            "1184/4708 - The training loss at 20th epoch : 0.07633973448498466  Training Accuracy:0.8933333333333333\n",
            "1200/4708 - The training loss at 20th epoch : 0.07778310034837016  Training Accuracy:0.8914473684210527\n",
            "1216/4708 - The training loss at 20th epoch : 0.07751302459145058  Training Accuracy:0.8912337662337663\n",
            "1232/4708 - The training loss at 20th epoch : 0.07782749554668673  Training Accuracy:0.8910256410256411\n",
            "1248/4708 - The training loss at 20th epoch : 0.07742131343330705  Training Accuracy:0.8916139240506329\n",
            "1264/4708 - The training loss at 20th epoch : 0.07688469206048475  Training Accuracy:0.8921875\n",
            "1280/4708 - The training loss at 20th epoch : 0.0771485939632317  Training Accuracy:0.8919753086419753\n",
            "1296/4708 - The training loss at 20th epoch : 0.07717288216828919  Training Accuracy:0.8925304878048781\n",
            "1312/4708 - The training loss at 20th epoch : 0.07727570545107373  Training Accuracy:0.8923192771084337\n",
            "1328/4708 - The training loss at 20th epoch : 0.07804275887708056  Training Accuracy:0.8913690476190477\n",
            "1344/4708 - The training loss at 20th epoch : 0.07740363872198419  Training Accuracy:0.8926470588235295\n",
            "1360/4708 - The training loss at 20th epoch : 0.07726389050221336  Training Accuracy:0.8924418604651163\n",
            "1376/4708 - The training loss at 20th epoch : 0.07668368706087435  Training Accuracy:0.8936781609195402\n",
            "1392/4708 - The training loss at 20th epoch : 0.07687936130191156  Training Accuracy:0.8934659090909091\n",
            "1408/4708 - The training loss at 20th epoch : 0.07716572384900788  Training Accuracy:0.8925561797752809\n",
            "1424/4708 - The training loss at 20th epoch : 0.07769332226660769  Training Accuracy:0.8916666666666667\n",
            "1440/4708 - The training loss at 20th epoch : 0.07694829391784312  Training Accuracy:0.8928571428571429\n",
            "1456/4708 - The training loss at 20th epoch : 0.07738841158607448  Training Accuracy:0.8926630434782609\n",
            "1472/4708 - The training loss at 20th epoch : 0.07674407330685412  Training Accuracy:0.8938172043010753\n",
            "1488/4708 - The training loss at 20th epoch : 0.07610163864749085  Training Accuracy:0.8949468085106383\n",
            "1504/4708 - The training loss at 20th epoch : 0.07625025738551301  Training Accuracy:0.8947368421052632\n",
            "1520/4708 - The training loss at 20th epoch : 0.0762786087239225  Training Accuracy:0.8951822916666666\n",
            "1536/4708 - The training loss at 20th epoch : 0.07620328962870487  Training Accuracy:0.8949742268041238\n",
            "1552/4708 - The training loss at 20th epoch : 0.07559480156017225  Training Accuracy:0.8960459183673469\n",
            "1568/4708 - The training loss at 20th epoch : 0.07560252525719259  Training Accuracy:0.8958333333333334\n",
            "1584/4708 - The training loss at 20th epoch : 0.07525813245477084  Training Accuracy:0.896875\n",
            "1600/4708 - The training loss at 20th epoch : 0.07495279286153281  Training Accuracy:0.8972772277227723\n",
            "1616/4708 - The training loss at 20th epoch : 0.0755368363308695  Training Accuracy:0.8964460784313726\n",
            "1632/4708 - The training loss at 20th epoch : 0.07499138170125298  Training Accuracy:0.8974514563106796\n",
            "1648/4708 - The training loss at 20th epoch : 0.07469646983715977  Training Accuracy:0.8978365384615384\n",
            "1664/4708 - The training loss at 20th epoch : 0.07445012808469659  Training Accuracy:0.8982142857142857\n",
            "1680/4708 - The training loss at 20th epoch : 0.07399279143685758  Training Accuracy:0.8985849056603774\n",
            "1696/4708 - The training loss at 20th epoch : 0.07394021418858786  Training Accuracy:0.8989485981308412\n",
            "1712/4708 - The training loss at 20th epoch : 0.07411967671122124  Training Accuracy:0.8993055555555556\n",
            "1728/4708 - The training loss at 20th epoch : 0.07395142508637166  Training Accuracy:0.8996559633027523\n",
            "1744/4708 - The training loss at 20th epoch : 0.0743036373644773  Training Accuracy:0.8994318181818182\n",
            "1760/4708 - The training loss at 20th epoch : 0.07377072623618142  Training Accuracy:0.9003378378378378\n",
            "1776/4708 - The training loss at 20th epoch : 0.07343695125984764  Training Accuracy:0.9006696428571429\n",
            "1792/4708 - The training loss at 20th epoch : 0.07315681730693854  Training Accuracy:0.900995575221239\n",
            "1808/4708 - The training loss at 20th epoch : 0.07315407911456925  Training Accuracy:0.9007675438596491\n",
            "1824/4708 - The training loss at 20th epoch : 0.07330898823386195  Training Accuracy:0.9005434782608696\n",
            "1840/4708 - The training loss at 20th epoch : 0.07302350270357079  Training Accuracy:0.9008620689655172\n",
            "1856/4708 - The training loss at 20th epoch : 0.0730018834480932  Training Accuracy:0.9006410256410257\n",
            "1872/4708 - The training loss at 20th epoch : 0.07261648814212864  Training Accuracy:0.9009533898305084\n",
            "1888/4708 - The training loss at 20th epoch : 0.07290600315183686  Training Accuracy:0.9007352941176471\n",
            "1904/4708 - The training loss at 20th epoch : 0.0730653080777097  Training Accuracy:0.9010416666666666\n",
            "1920/4708 - The training loss at 20th epoch : 0.07324392440889041  Training Accuracy:0.9013429752066116\n",
            "1936/4708 - The training loss at 20th epoch : 0.07358680862235538  Training Accuracy:0.9011270491803278\n",
            "1952/4708 - The training loss at 20th epoch : 0.07329132801940234  Training Accuracy:0.9014227642276422\n",
            "1968/4708 - The training loss at 20th epoch : 0.07341968895942753  Training Accuracy:0.9012096774193549\n",
            "1984/4708 - The training loss at 20th epoch : 0.07331892819635207  Training Accuracy:0.9015\n",
            "2000/4708 - The training loss at 20th epoch : 0.07285061538850726  Training Accuracy:0.902281746031746\n",
            "2016/4708 - The training loss at 20th epoch : 0.07319515227084546  Training Accuracy:0.9015748031496063\n",
            "2032/4708 - The training loss at 20th epoch : 0.07338449355938736  Training Accuracy:0.9013671875\n",
            "2048/4708 - The training loss at 20th epoch : 0.07344954598137794  Training Accuracy:0.9011627906976745\n",
            "2064/4708 - The training loss at 20th epoch : 0.07371295587509939  Training Accuracy:0.9004807692307693\n",
            "2080/4708 - The training loss at 20th epoch : 0.0739524958454999  Training Accuracy:0.8998091603053435\n",
            "2096/4708 - The training loss at 20th epoch : 0.0743068594886711  Training Accuracy:0.8991477272727273\n",
            "2112/4708 - The training loss at 20th epoch : 0.07405361242650346  Training Accuracy:0.8994360902255639\n",
            "2128/4708 - The training loss at 20th epoch : 0.0739121986398584  Training Accuracy:0.8992537313432836\n",
            "2144/4708 - The training loss at 20th epoch : 0.07375180638161247  Training Accuracy:0.899537037037037\n",
            "2160/4708 - The training loss at 20th epoch : 0.07329931114884554  Training Accuracy:0.9002757352941176\n",
            "2176/4708 - The training loss at 20th epoch : 0.07301329879588583  Training Accuracy:0.9010036496350365\n",
            "2192/4708 - The training loss at 20th epoch : 0.07367013868937623  Training Accuracy:0.8999094202898551\n",
            "2208/4708 - The training loss at 20th epoch : 0.07364446670063929  Training Accuracy:0.9001798561151079\n",
            "2224/4708 - The training loss at 20th epoch : 0.07424740291349344  Training Accuracy:0.8986607142857143\n",
            "2240/4708 - The training loss at 20th epoch : 0.07409465826271025  Training Accuracy:0.898936170212766\n",
            "2256/4708 - The training loss at 20th epoch : 0.07379856197617002  Training Accuracy:0.8992077464788732\n",
            "2272/4708 - The training loss at 20th epoch : 0.07443415279775469  Training Accuracy:0.8981643356643356\n",
            "2288/4708 - The training loss at 20th epoch : 0.07416509032792856  Training Accuracy:0.8984375\n",
            "2304/4708 - The training loss at 20th epoch : 0.07410411896402944  Training Accuracy:0.8982758620689655\n",
            "2320/4708 - The training loss at 20th epoch : 0.07408878215139358  Training Accuracy:0.8985445205479452\n",
            "2336/4708 - The training loss at 20th epoch : 0.07533191335944174  Training Accuracy:0.8966836734693877\n",
            "2352/4708 - The training loss at 20th epoch : 0.07532232713660503  Training Accuracy:0.8965371621621622\n",
            "2368/4708 - The training loss at 20th epoch : 0.07543078834619663  Training Accuracy:0.8963926174496645\n",
            "2384/4708 - The training loss at 20th epoch : 0.07577269676825046  Training Accuracy:0.8958333333333334\n",
            "2400/4708 - The training loss at 20th epoch : 0.07579719063863272  Training Accuracy:0.8956953642384106\n",
            "2416/4708 - The training loss at 20th epoch : 0.07595480682858637  Training Accuracy:0.8955592105263158\n",
            "2432/4708 - The training loss at 20th epoch : 0.0764990686731623  Training Accuracy:0.8946078431372549\n",
            "2448/4708 - The training loss at 20th epoch : 0.07614820905568297  Training Accuracy:0.8952922077922078\n",
            "2464/4708 - The training loss at 20th epoch : 0.07636420222310465  Training Accuracy:0.894758064516129\n",
            "2480/4708 - The training loss at 20th epoch : 0.0767808759524413  Training Accuracy:0.8942307692307693\n",
            "2496/4708 - The training loss at 20th epoch : 0.0767810328343262  Training Accuracy:0.8945063694267515\n",
            "2512/4708 - The training loss at 20th epoch : 0.07686263487526564  Training Accuracy:0.8947784810126582\n",
            "2528/4708 - The training loss at 20th epoch : 0.07688336185764583  Training Accuracy:0.8950471698113207\n",
            "2544/4708 - The training loss at 20th epoch : 0.07664963952956542  Training Accuracy:0.8953125\n",
            "2560/4708 - The training loss at 20th epoch : 0.07694207701188097  Training Accuracy:0.8947981366459627\n",
            "2576/4708 - The training loss at 20th epoch : 0.07706881221986445  Training Accuracy:0.8942901234567902\n",
            "2592/4708 - The training loss at 20th epoch : 0.0770207539573725  Training Accuracy:0.8945552147239264\n",
            "2608/4708 - The training loss at 20th epoch : 0.07711061149219511  Training Accuracy:0.8944359756097561\n",
            "2624/4708 - The training loss at 20th epoch : 0.07706675087606095  Training Accuracy:0.8943181818181818\n",
            "2640/4708 - The training loss at 20th epoch : 0.07699670278659276  Training Accuracy:0.8942018072289156\n",
            "2656/4708 - The training loss at 20th epoch : 0.07672219464674661  Training Accuracy:0.8944610778443114\n",
            "2672/4708 - The training loss at 20th epoch : 0.07656739867651935  Training Accuracy:0.8947172619047619\n",
            "2688/4708 - The training loss at 20th epoch : 0.07711204632721816  Training Accuracy:0.8942307692307693\n",
            "2704/4708 - The training loss at 20th epoch : 0.07713113845750669  Training Accuracy:0.8941176470588236\n",
            "2720/4708 - The training loss at 20th epoch : 0.07736499366841607  Training Accuracy:0.8940058479532164\n",
            "2736/4708 - The training loss at 20th epoch : 0.07730345318110297  Training Accuracy:0.8942587209302325\n",
            "2752/4708 - The training loss at 20th epoch : 0.07695435680370168  Training Accuracy:0.8948699421965318\n",
            "2768/4708 - The training loss at 20th epoch : 0.07699297506500721  Training Accuracy:0.8947557471264368\n",
            "2784/4708 - The training loss at 20th epoch : 0.07728013244560247  Training Accuracy:0.8939285714285714\n",
            "2800/4708 - The training loss at 20th epoch : 0.07711058737255068  Training Accuracy:0.8941761363636364\n",
            "2816/4708 - The training loss at 20th epoch : 0.07708356652207761  Training Accuracy:0.8944209039548022\n",
            "2832/4708 - The training loss at 20th epoch : 0.07717469545439665  Training Accuracy:0.894311797752809\n",
            "2848/4708 - The training loss at 20th epoch : 0.07733140553262872  Training Accuracy:0.8942039106145251\n",
            "2864/4708 - The training loss at 20th epoch : 0.07774078616606411  Training Accuracy:0.8940972222222222\n",
            "2880/4708 - The training loss at 20th epoch : 0.07791506606895175  Training Accuracy:0.8939917127071824\n",
            "2896/4708 - The training loss at 20th epoch : 0.07773541135284395  Training Accuracy:0.8942307692307693\n",
            "2912/4708 - The training loss at 20th epoch : 0.07747031363146718  Training Accuracy:0.8944672131147541\n",
            "2928/4708 - The training loss at 20th epoch : 0.07737209668559995  Training Accuracy:0.8947010869565217\n",
            "2944/4708 - The training loss at 20th epoch : 0.07719036885941997  Training Accuracy:0.8949324324324325\n",
            "2960/4708 - The training loss at 20th epoch : 0.078036149678741  Training Accuracy:0.8938172043010753\n",
            "2976/4708 - The training loss at 20th epoch : 0.07831455194796887  Training Accuracy:0.8937165775401069\n",
            "2992/4708 - The training loss at 20th epoch : 0.07873067567985328  Training Accuracy:0.8929521276595744\n",
            "3008/4708 - The training loss at 20th epoch : 0.0787311888084038  Training Accuracy:0.8928571428571429\n",
            "3024/4708 - The training loss at 20th epoch : 0.07929598967882098  Training Accuracy:0.8917763157894737\n",
            "3040/4708 - The training loss at 20th epoch : 0.07932371790967345  Training Accuracy:0.8913612565445026\n",
            "3056/4708 - The training loss at 20th epoch : 0.07915482594280888  Training Accuracy:0.8916015625\n",
            "3072/4708 - The training loss at 20th epoch : 0.07926679437878749  Training Accuracy:0.8915155440414507\n",
            "3088/4708 - The training loss at 20th epoch : 0.07925519020173638  Training Accuracy:0.8914304123711341\n",
            "3104/4708 - The training loss at 20th epoch : 0.07931455433650351  Training Accuracy:0.8916666666666667\n",
            "3120/4708 - The training loss at 20th epoch : 0.07925744944109955  Training Accuracy:0.8919005102040817\n",
            "3136/4708 - The training loss at 20th epoch : 0.0801573814188929  Training Accuracy:0.8908629441624365\n",
            "3152/4708 - The training loss at 20th epoch : 0.08011500742461083  Training Accuracy:0.8907828282828283\n",
            "3168/4708 - The training loss at 20th epoch : 0.07978568170766541  Training Accuracy:0.8913316582914573\n",
            "3184/4708 - The training loss at 20th epoch : 0.07970525827269051  Training Accuracy:0.8915625\n",
            "3200/4708 - The training loss at 20th epoch : 0.0795702844189162  Training Accuracy:0.8917910447761194\n",
            "3216/4708 - The training loss at 20th epoch : 0.07932488226136906  Training Accuracy:0.8923267326732673\n",
            "3232/4708 - The training loss at 20th epoch : 0.07917571232965542  Training Accuracy:0.8925492610837439\n",
            "3248/4708 - The training loss at 20th epoch : 0.07903961359578295  Training Accuracy:0.8927696078431373\n",
            "3264/4708 - The training loss at 20th epoch : 0.07898711478988332  Training Accuracy:0.8929878048780487\n",
            "3280/4708 - The training loss at 20th epoch : 0.07925770374880967  Training Accuracy:0.8925970873786407\n",
            "3296/4708 - The training loss at 20th epoch : 0.07949084091179408  Training Accuracy:0.892512077294686\n",
            "3312/4708 - The training loss at 20th epoch : 0.07937593603287073  Training Accuracy:0.8924278846153846\n",
            "3328/4708 - The training loss at 20th epoch : 0.0794597205330994  Training Accuracy:0.8920454545454546\n",
            "3344/4708 - The training loss at 20th epoch : 0.07945266436089286  Training Accuracy:0.8919642857142858\n",
            "3360/4708 - The training loss at 20th epoch : 0.0792552979606553  Training Accuracy:0.8921800947867299\n",
            "3376/4708 - The training loss at 20th epoch : 0.0792034668740848  Training Accuracy:0.8920990566037735\n",
            "3392/4708 - The training loss at 20th epoch : 0.079236133041073  Training Accuracy:0.891725352112676\n",
            "3408/4708 - The training loss at 20th epoch : 0.07924152417459286  Training Accuracy:0.8916471962616822\n",
            "3424/4708 - The training loss at 20th epoch : 0.07925523893583038  Training Accuracy:0.8915697674418605\n",
            "3440/4708 - The training loss at 20th epoch : 0.07938627308733445  Training Accuracy:0.8914930555555556\n",
            "3456/4708 - The training loss at 20th epoch : 0.07932282733109948  Training Accuracy:0.8914170506912442\n",
            "3472/4708 - The training loss at 20th epoch : 0.07933632522279623  Training Accuracy:0.8913417431192661\n",
            "3488/4708 - The training loss at 20th epoch : 0.07935383215143864  Training Accuracy:0.8912671232876712\n",
            "3504/4708 - The training loss at 20th epoch : 0.07925765888982848  Training Accuracy:0.8914772727272727\n",
            "3520/4708 - The training loss at 20th epoch : 0.07944205222404127  Training Accuracy:0.8914027149321267\n",
            "3536/4708 - The training loss at 20th epoch : 0.07936170674362772  Training Accuracy:0.8913288288288288\n",
            "3552/4708 - The training loss at 20th epoch : 0.07929017002983757  Training Accuracy:0.8915358744394619\n",
            "3568/4708 - The training loss at 20th epoch : 0.07916511260604077  Training Accuracy:0.8917410714285714\n",
            "3584/4708 - The training loss at 20th epoch : 0.07904942965881831  Training Accuracy:0.8919444444444444\n",
            "3600/4708 - The training loss at 20th epoch : 0.07916758238784047  Training Accuracy:0.8915929203539823\n",
            "3616/4708 - The training loss at 20th epoch : 0.07929081336103169  Training Accuracy:0.8915198237885462\n",
            "3632/4708 - The training loss at 20th epoch : 0.07907525220856802  Training Accuracy:0.8919956140350878\n",
            "3648/4708 - The training loss at 20th epoch : 0.07942075603693645  Training Accuracy:0.8913755458515283\n",
            "3664/4708 - The training loss at 20th epoch : 0.07946907324437022  Training Accuracy:0.8913043478260869\n",
            "3680/4708 - The training loss at 20th epoch : 0.07925758109257136  Training Accuracy:0.891504329004329\n",
            "3696/4708 - The training loss at 20th epoch : 0.07936398502351029  Training Accuracy:0.8914331896551724\n",
            "3712/4708 - The training loss at 20th epoch : 0.07956214768777858  Training Accuracy:0.8910944206008584\n",
            "3728/4708 - The training loss at 20th epoch : 0.07935189951209225  Training Accuracy:0.8915598290598291\n",
            "3744/4708 - The training loss at 20th epoch : 0.07975673828930904  Training Accuracy:0.8912234042553191\n",
            "3760/4708 - The training loss at 20th epoch : 0.07942531116242288  Training Accuracy:0.8916843220338984\n",
            "3776/4708 - The training loss at 20th epoch : 0.07995197120514459  Training Accuracy:0.8908227848101266\n",
            "3792/4708 - The training loss at 20th epoch : 0.08010379190898366  Training Accuracy:0.8904936974789915\n",
            "3808/4708 - The training loss at 20th epoch : 0.08027875790711285  Training Accuracy:0.8901673640167364\n",
            "3824/4708 - The training loss at 20th epoch : 0.08020264011278755  Training Accuracy:0.8903645833333333\n",
            "3840/4708 - The training loss at 20th epoch : 0.0799033411076045  Training Accuracy:0.8908195020746889\n",
            "3856/4708 - The training loss at 20th epoch : 0.08009797055057001  Training Accuracy:0.890754132231405\n",
            "3872/4708 - The training loss at 20th epoch : 0.0801665148633929  Training Accuracy:0.8906893004115226\n",
            "3888/4708 - The training loss at 20th epoch : 0.08001875878824315  Training Accuracy:0.890625\n",
            "3904/4708 - The training loss at 20th epoch : 0.07984047541032599  Training Accuracy:0.8910714285714286\n",
            "3920/4708 - The training loss at 20th epoch : 0.0798522271268547  Training Accuracy:0.8910060975609756\n",
            "3936/4708 - The training loss at 20th epoch : 0.07959513535757895  Training Accuracy:0.8914473684210527\n",
            "3952/4708 - The training loss at 20th epoch : 0.07987250796709984  Training Accuracy:0.8911290322580645\n",
            "3968/4708 - The training loss at 20th epoch : 0.08016128308751935  Training Accuracy:0.8908132530120482\n",
            "3984/4708 - The training loss at 20th epoch : 0.08081028070932392  Training Accuracy:0.89\n",
            "4000/4708 - The training loss at 20th epoch : 0.08092094102159937  Training Accuracy:0.889691235059761\n",
            "4016/4708 - The training loss at 20th epoch : 0.08094731145329387  Training Accuracy:0.8893849206349206\n",
            "4032/4708 - The training loss at 20th epoch : 0.08081921761957202  Training Accuracy:0.8895750988142292\n",
            "4048/4708 - The training loss at 20th epoch : 0.08118299276151636  Training Accuracy:0.8890255905511811\n",
            "4064/4708 - The training loss at 20th epoch : 0.08165021200128185  Training Accuracy:0.8884803921568627\n",
            "4080/4708 - The training loss at 20th epoch : 0.0816956221556968  Training Accuracy:0.888427734375\n",
            "4096/4708 - The training loss at 20th epoch : 0.08188447248064197  Training Accuracy:0.8878891050583657\n",
            "4112/4708 - The training loss at 20th epoch : 0.08193109026750485  Training Accuracy:0.8878391472868217\n",
            "4128/4708 - The training loss at 20th epoch : 0.08176982100849799  Training Accuracy:0.888030888030888\n",
            "4144/4708 - The training loss at 20th epoch : 0.08190438467233718  Training Accuracy:0.8879807692307692\n",
            "4160/4708 - The training loss at 20th epoch : 0.08194154072104191  Training Accuracy:0.8879310344827587\n",
            "4176/4708 - The training loss at 20th epoch : 0.08245079492544811  Training Accuracy:0.8871660305343512\n",
            "4192/4708 - The training loss at 20th epoch : 0.08258101358020385  Training Accuracy:0.8871197718631179\n",
            "4208/4708 - The training loss at 20th epoch : 0.0826186931076126  Training Accuracy:0.8870738636363636\n",
            "4224/4708 - The training loss at 20th epoch : 0.08243150351989091  Training Accuracy:0.8875\n",
            "4240/4708 - The training loss at 20th epoch : 0.08222127094576741  Training Accuracy:0.887687969924812\n",
            "4256/4708 - The training loss at 20th epoch : 0.08205696898539185  Training Accuracy:0.887874531835206\n",
            "4272/4708 - The training loss at 20th epoch : 0.08190269421540416  Training Accuracy:0.8880597014925373\n",
            "4288/4708 - The training loss at 20th epoch : 0.08178097267789573  Training Accuracy:0.8882434944237918\n",
            "4304/4708 - The training loss at 20th epoch : 0.0819045546356998  Training Accuracy:0.8881944444444444\n",
            "4320/4708 - The training loss at 20th epoch : 0.08169864209584542  Training Accuracy:0.8886070110701108\n",
            "4336/4708 - The training loss at 20th epoch : 0.08161804912623156  Training Accuracy:0.8885569852941176\n",
            "4352/4708 - The training loss at 20th epoch : 0.08156211430679244  Training Accuracy:0.8887362637362637\n",
            "4368/4708 - The training loss at 20th epoch : 0.08139859284196167  Training Accuracy:0.8889142335766423\n",
            "4384/4708 - The training loss at 20th epoch : 0.08132721551643723  Training Accuracy:0.889090909090909\n",
            "4400/4708 - The training loss at 20th epoch : 0.08125190841339627  Training Accuracy:0.889266304347826\n",
            "4416/4708 - The training loss at 20th epoch : 0.08145076445844181  Training Accuracy:0.8887635379061372\n",
            "4432/4708 - The training loss at 20th epoch : 0.08174077796627283  Training Accuracy:0.8882643884892086\n",
            "4448/4708 - The training loss at 20th epoch : 0.08162629378351469  Training Accuracy:0.8884408602150538\n",
            "4464/4708 - The training loss at 20th epoch : 0.08164937535296779  Training Accuracy:0.8883928571428571\n",
            "4480/4708 - The training loss at 20th epoch : 0.08176937668822828  Training Accuracy:0.8881227758007118\n",
            "4496/4708 - The training loss at 20th epoch : 0.0819322636017313  Training Accuracy:0.887854609929078\n",
            "4512/4708 - The training loss at 20th epoch : 0.08216981261831431  Training Accuracy:0.8875883392226148\n",
            "4528/4708 - The training loss at 20th epoch : 0.0822193014071636  Training Accuracy:0.887544014084507\n",
            "4544/4708 - The training loss at 20th epoch : 0.08198246101344162  Training Accuracy:0.8879385964912281\n",
            "4560/4708 - The training loss at 20th epoch : 0.0822094917693517  Training Accuracy:0.8876748251748252\n",
            "4576/4708 - The training loss at 20th epoch : 0.0822177062631024  Training Accuracy:0.8878484320557491\n",
            "4592/4708 - The training loss at 20th epoch : 0.08229938893436033  Training Accuracy:0.8875868055555556\n",
            "4608/4708 - The training loss at 20th epoch : 0.08254649219115662  Training Accuracy:0.8873269896193772\n",
            "4624/4708 - The training loss at 20th epoch : 0.08243775399884264  Training Accuracy:0.8872844827586207\n",
            "4640/4708 - The training loss at 20th epoch : 0.08243278443287408  Training Accuracy:0.8872422680412371\n",
            "4656/4708 - The training loss at 20th epoch : 0.08216462304553276  Training Accuracy:0.8876284246575342\n",
            "4672/4708 - The training loss at 20th epoch : 0.08203033700449539  Training Accuracy:0.8880119453924915\n",
            "4688/4708 - The training loss at 20th epoch : 0.08186190602220994  Training Accuracy:0.8883928571428571\n",
            "4704/4708 - The training loss at 20th epoch : 0.08174707653877998  Training Accuracy:0.888771186440678\n",
            "4720/4708 - The training loss at 20th epoch : 0.08152579480891621  Training Accuracy:0.8891469594594594\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 21th epoch : 0.028233484007831426  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 21th epoch : 0.058582739494177416  Training Accuracy:0.90625\n",
            "32/4708 - The training loss at 21th epoch : 0.1236432693950662  Training Accuracy:0.8125\n",
            "48/4708 - The training loss at 21th epoch : 0.11266020648790309  Training Accuracy:0.828125\n",
            "64/4708 - The training loss at 21th epoch : 0.09907605740124514  Training Accuracy:0.85\n",
            "80/4708 - The training loss at 21th epoch : 0.10048981449145318  Training Accuracy:0.84375\n",
            "96/4708 - The training loss at 21th epoch : 0.09930833272832272  Training Accuracy:0.8571428571428571\n",
            "112/4708 - The training loss at 21th epoch : 0.08724702153168823  Training Accuracy:0.875\n",
            "128/4708 - The training loss at 21th epoch : 0.08389494798204074  Training Accuracy:0.8819444444444444\n",
            "144/4708 - The training loss at 21th epoch : 0.07671655896823573  Training Accuracy:0.89375\n",
            "160/4708 - The training loss at 21th epoch : 0.0764469690412761  Training Accuracy:0.8977272727272727\n",
            "176/4708 - The training loss at 21th epoch : 0.08026195372120616  Training Accuracy:0.8958333333333334\n",
            "192/4708 - The training loss at 21th epoch : 0.08456376853183635  Training Accuracy:0.8894230769230769\n",
            "208/4708 - The training loss at 21th epoch : 0.07933547989511225  Training Accuracy:0.8973214285714286\n",
            "224/4708 - The training loss at 21th epoch : 0.07876959515755472  Training Accuracy:0.9\n",
            "240/4708 - The training loss at 21th epoch : 0.07650753368942871  Training Accuracy:0.90234375\n",
            "256/4708 - The training loss at 21th epoch : 0.07406690100125415  Training Accuracy:0.9080882352941176\n",
            "272/4708 - The training loss at 21th epoch : 0.07144084913403626  Training Accuracy:0.9097222222222222\n",
            "288/4708 - The training loss at 21th epoch : 0.07722458018673858  Training Accuracy:0.9013157894736842\n",
            "304/4708 - The training loss at 21th epoch : 0.07562239733535485  Training Accuracy:0.903125\n",
            "320/4708 - The training loss at 21th epoch : 0.07592493454556987  Training Accuracy:0.9017857142857143\n",
            "336/4708 - The training loss at 21th epoch : 0.076408945337913  Training Accuracy:0.9005681818181818\n",
            "352/4708 - The training loss at 21th epoch : 0.07622215129548975  Training Accuracy:0.9021739130434783\n",
            "368/4708 - The training loss at 21th epoch : 0.07839667838476551  Training Accuracy:0.8984375\n",
            "384/4708 - The training loss at 21th epoch : 0.07675832405703328  Training Accuracy:0.9\n",
            "400/4708 - The training loss at 21th epoch : 0.074869542567616  Training Accuracy:0.9014423076923077\n",
            "416/4708 - The training loss at 21th epoch : 0.07681423678222765  Training Accuracy:0.9004629629629629\n",
            "432/4708 - The training loss at 21th epoch : 0.0799609210611949  Training Accuracy:0.8973214285714286\n",
            "448/4708 - The training loss at 21th epoch : 0.0787772979087772  Training Accuracy:0.8987068965517241\n",
            "464/4708 - The training loss at 21th epoch : 0.08013716695922461  Training Accuracy:0.8958333333333334\n",
            "480/4708 - The training loss at 21th epoch : 0.07934520586257011  Training Accuracy:0.8971774193548387\n",
            "496/4708 - The training loss at 21th epoch : 0.08180247385052859  Training Accuracy:0.892578125\n",
            "512/4708 - The training loss at 21th epoch : 0.08187058312487776  Training Accuracy:0.8939393939393939\n",
            "528/4708 - The training loss at 21th epoch : 0.08366945951349107  Training Accuracy:0.8897058823529411\n",
            "544/4708 - The training loss at 21th epoch : 0.08323121962793197  Training Accuracy:0.8910714285714286\n",
            "560/4708 - The training loss at 21th epoch : 0.08399994156842892  Training Accuracy:0.8871527777777778\n",
            "576/4708 - The training loss at 21th epoch : 0.08222043033081343  Training Accuracy:0.8902027027027027\n",
            "592/4708 - The training loss at 21th epoch : 0.08129408825544894  Training Accuracy:0.8914473684210527\n",
            "608/4708 - The training loss at 21th epoch : 0.08190378935247976  Training Accuracy:0.8910256410256411\n",
            "624/4708 - The training loss at 21th epoch : 0.08282509539856268  Training Accuracy:0.890625\n",
            "640/4708 - The training loss at 21th epoch : 0.08286197703250339  Training Accuracy:0.8887195121951219\n",
            "656/4708 - The training loss at 21th epoch : 0.0817589259164711  Training Accuracy:0.8898809523809523\n",
            "672/4708 - The training loss at 21th epoch : 0.08050050688945767  Training Accuracy:0.8909883720930233\n",
            "688/4708 - The training loss at 21th epoch : 0.07958622326599471  Training Accuracy:0.8920454545454546\n",
            "704/4708 - The training loss at 21th epoch : 0.07848083922030964  Training Accuracy:0.8930555555555556\n",
            "720/4708 - The training loss at 21th epoch : 0.07873424569654233  Training Accuracy:0.8926630434782609\n",
            "736/4708 - The training loss at 21th epoch : 0.07940944746542695  Training Accuracy:0.8922872340425532\n",
            "752/4708 - The training loss at 21th epoch : 0.07864684168989887  Training Accuracy:0.8932291666666666\n",
            "768/4708 - The training loss at 21th epoch : 0.07975807840265131  Training Accuracy:0.8903061224489796\n",
            "784/4708 - The training loss at 21th epoch : 0.0786783276910849  Training Accuracy:0.8925\n",
            "800/4708 - The training loss at 21th epoch : 0.07737621914342364  Training Accuracy:0.8946078431372549\n",
            "816/4708 - The training loss at 21th epoch : 0.07706312282926656  Training Accuracy:0.8954326923076923\n",
            "832/4708 - The training loss at 21th epoch : 0.07842135403004058  Training Accuracy:0.8938679245283019\n",
            "848/4708 - The training loss at 21th epoch : 0.08048204322319048  Training Accuracy:0.8900462962962963\n",
            "864/4708 - The training loss at 21th epoch : 0.08054684283716615  Training Accuracy:0.8909090909090909\n",
            "880/4708 - The training loss at 21th epoch : 0.07993995961559666  Training Accuracy:0.8917410714285714\n",
            "896/4708 - The training loss at 21th epoch : 0.07954559218340665  Training Accuracy:0.8925438596491229\n",
            "912/4708 - The training loss at 21th epoch : 0.07930375681229664  Training Accuracy:0.8922413793103449\n",
            "928/4708 - The training loss at 21th epoch : 0.08207007603851864  Training Accuracy:0.888771186440678\n",
            "944/4708 - The training loss at 21th epoch : 0.08202874276743867  Training Accuracy:0.8895833333333333\n",
            "960/4708 - The training loss at 21th epoch : 0.08194956125073144  Training Accuracy:0.8883196721311475\n",
            "976/4708 - The training loss at 21th epoch : 0.08259022694692274  Training Accuracy:0.8870967741935484\n",
            "992/4708 - The training loss at 21th epoch : 0.08264866471530627  Training Accuracy:0.8869047619047619\n",
            "1008/4708 - The training loss at 21th epoch : 0.08193812327535444  Training Accuracy:0.8876953125\n",
            "1024/4708 - The training loss at 21th epoch : 0.08353653075407573  Training Accuracy:0.885576923076923\n",
            "1040/4708 - The training loss at 21th epoch : 0.08365698454211687  Training Accuracy:0.8854166666666666\n",
            "1056/4708 - The training loss at 21th epoch : 0.08306508338183871  Training Accuracy:0.8861940298507462\n",
            "1072/4708 - The training loss at 21th epoch : 0.08353206141155772  Training Accuracy:0.8841911764705882\n",
            "1088/4708 - The training loss at 21th epoch : 0.08433272671335539  Training Accuracy:0.8831521739130435\n",
            "1104/4708 - The training loss at 21th epoch : 0.08344968745323346  Training Accuracy:0.8848214285714285\n",
            "1120/4708 - The training loss at 21th epoch : 0.0830636588555261  Training Accuracy:0.8855633802816901\n",
            "1136/4708 - The training loss at 21th epoch : 0.08257788614561622  Training Accuracy:0.8862847222222222\n",
            "1152/4708 - The training loss at 21th epoch : 0.08229565980251041  Training Accuracy:0.886986301369863\n",
            "1168/4708 - The training loss at 21th epoch : 0.08166058892873988  Training Accuracy:0.887668918918919\n",
            "1184/4708 - The training loss at 21th epoch : 0.08172650445006785  Training Accuracy:0.8875\n",
            "1200/4708 - The training loss at 21th epoch : 0.08188037748759715  Training Accuracy:0.8873355263157895\n",
            "1216/4708 - The training loss at 21th epoch : 0.08189132798824188  Training Accuracy:0.8871753246753247\n",
            "1232/4708 - The training loss at 21th epoch : 0.08134648819620634  Training Accuracy:0.8878205128205128\n",
            "1248/4708 - The training loss at 21th epoch : 0.08107428972765285  Training Accuracy:0.8884493670886076\n",
            "1264/4708 - The training loss at 21th epoch : 0.08139609598359346  Training Accuracy:0.8875\n",
            "1280/4708 - The training loss at 21th epoch : 0.0817804431616727  Training Accuracy:0.8873456790123457\n",
            "1296/4708 - The training loss at 21th epoch : 0.0812348200774036  Training Accuracy:0.8887195121951219\n",
            "1312/4708 - The training loss at 21th epoch : 0.08103753807006847  Training Accuracy:0.8893072289156626\n",
            "1328/4708 - The training loss at 21th epoch : 0.08166428874400809  Training Accuracy:0.8883928571428571\n",
            "1344/4708 - The training loss at 21th epoch : 0.0826426544168886  Training Accuracy:0.8867647058823529\n",
            "1360/4708 - The training loss at 21th epoch : 0.08328915566312257  Training Accuracy:0.8866279069767442\n",
            "1376/4708 - The training loss at 21th epoch : 0.0834123235996009  Training Accuracy:0.8857758620689655\n",
            "1392/4708 - The training loss at 21th epoch : 0.08387496223437287  Training Accuracy:0.8842329545454546\n",
            "1408/4708 - The training loss at 21th epoch : 0.08329628739284221  Training Accuracy:0.8848314606741573\n",
            "1424/4708 - The training loss at 21th epoch : 0.08413124456739852  Training Accuracy:0.8833333333333333\n",
            "1440/4708 - The training loss at 21th epoch : 0.08380537936847392  Training Accuracy:0.8839285714285714\n",
            "1456/4708 - The training loss at 21th epoch : 0.08355827939054623  Training Accuracy:0.8838315217391305\n",
            "1472/4708 - The training loss at 21th epoch : 0.08357328119671767  Training Accuracy:0.8830645161290323\n",
            "1488/4708 - The training loss at 21th epoch : 0.08289226399442172  Training Accuracy:0.8843085106382979\n",
            "1504/4708 - The training loss at 21th epoch : 0.08358148006823826  Training Accuracy:0.8828947368421053\n",
            "1520/4708 - The training loss at 21th epoch : 0.08294940017487656  Training Accuracy:0.8841145833333334\n",
            "1536/4708 - The training loss at 21th epoch : 0.08315304914733543  Training Accuracy:0.8846649484536082\n",
            "1552/4708 - The training loss at 21th epoch : 0.0834039379199406  Training Accuracy:0.8845663265306123\n",
            "1568/4708 - The training loss at 21th epoch : 0.08323488991387484  Training Accuracy:0.884469696969697\n",
            "1584/4708 - The training loss at 21th epoch : 0.08356218175667234  Training Accuracy:0.88375\n",
            "1600/4708 - The training loss at 21th epoch : 0.084242335422191  Training Accuracy:0.8824257425742574\n",
            "1616/4708 - The training loss at 21th epoch : 0.08400217688105249  Training Accuracy:0.8829656862745098\n",
            "1632/4708 - The training loss at 21th epoch : 0.0835038638959549  Training Accuracy:0.883495145631068\n",
            "1648/4708 - The training loss at 21th epoch : 0.08361184784614618  Training Accuracy:0.8828125\n",
            "1664/4708 - The training loss at 21th epoch : 0.08401557357114542  Training Accuracy:0.8821428571428571\n",
            "1680/4708 - The training loss at 21th epoch : 0.08468986905599227  Training Accuracy:0.8814858490566038\n",
            "1696/4708 - The training loss at 21th epoch : 0.08478553745345949  Training Accuracy:0.8820093457943925\n",
            "1712/4708 - The training loss at 21th epoch : 0.08504266333368295  Training Accuracy:0.8807870370370371\n",
            "1728/4708 - The training loss at 21th epoch : 0.08521116826357068  Training Accuracy:0.8801605504587156\n",
            "1744/4708 - The training loss at 21th epoch : 0.08513445299443922  Training Accuracy:0.8801136363636364\n",
            "1760/4708 - The training loss at 21th epoch : 0.0852006874181273  Training Accuracy:0.8800675675675675\n",
            "1776/4708 - The training loss at 21th epoch : 0.08532488807444887  Training Accuracy:0.8800223214285714\n",
            "1792/4708 - The training loss at 21th epoch : 0.08524024056830719  Training Accuracy:0.879424778761062\n",
            "1808/4708 - The training loss at 21th epoch : 0.08459687722258231  Training Accuracy:0.8804824561403509\n",
            "1824/4708 - The training loss at 21th epoch : 0.08410186819282607  Training Accuracy:0.8815217391304347\n",
            "1840/4708 - The training loss at 21th epoch : 0.08413161394672403  Training Accuracy:0.8814655172413793\n",
            "1856/4708 - The training loss at 21th epoch : 0.08416312662532766  Training Accuracy:0.8819444444444444\n",
            "1872/4708 - The training loss at 21th epoch : 0.08394038159919627  Training Accuracy:0.8824152542372882\n",
            "1888/4708 - The training loss at 21th epoch : 0.08446842407266984  Training Accuracy:0.881827731092437\n",
            "1904/4708 - The training loss at 21th epoch : 0.0849010957421731  Training Accuracy:0.88125\n",
            "1920/4708 - The training loss at 21th epoch : 0.08473804794541813  Training Accuracy:0.881198347107438\n",
            "1936/4708 - The training loss at 21th epoch : 0.08426411858250539  Training Accuracy:0.8816598360655737\n",
            "1952/4708 - The training loss at 21th epoch : 0.08406698647711518  Training Accuracy:0.8821138211382114\n",
            "1968/4708 - The training loss at 21th epoch : 0.08389886479898394  Training Accuracy:0.8825604838709677\n",
            "1984/4708 - The training loss at 21th epoch : 0.08345947726240302  Training Accuracy:0.883\n",
            "2000/4708 - The training loss at 21th epoch : 0.08319381696825902  Training Accuracy:0.8834325396825397\n",
            "2016/4708 - The training loss at 21th epoch : 0.08341794973273436  Training Accuracy:0.8828740157480315\n",
            "2032/4708 - The training loss at 21th epoch : 0.08298985813615711  Training Accuracy:0.8837890625\n",
            "2048/4708 - The training loss at 21th epoch : 0.08266958356570246  Training Accuracy:0.8846899224806202\n",
            "2064/4708 - The training loss at 21th epoch : 0.08341067031470155  Training Accuracy:0.8836538461538461\n",
            "2080/4708 - The training loss at 21th epoch : 0.08326347070852352  Training Accuracy:0.8840648854961832\n",
            "2096/4708 - The training loss at 21th epoch : 0.08319551145551005  Training Accuracy:0.884469696969697\n",
            "2112/4708 - The training loss at 21th epoch : 0.08302654683950775  Training Accuracy:0.8848684210526315\n",
            "2128/4708 - The training loss at 21th epoch : 0.08333529739768258  Training Accuracy:0.8847947761194029\n",
            "2144/4708 - The training loss at 21th epoch : 0.08357956120549459  Training Accuracy:0.8842592592592593\n",
            "2160/4708 - The training loss at 21th epoch : 0.08298501314401314  Training Accuracy:0.8851102941176471\n",
            "2176/4708 - The training loss at 21th epoch : 0.08273137413434777  Training Accuracy:0.885492700729927\n",
            "2192/4708 - The training loss at 21th epoch : 0.08254184986572255  Training Accuracy:0.8858695652173914\n",
            "2208/4708 - The training loss at 21th epoch : 0.08223728186079905  Training Accuracy:0.8862410071942446\n",
            "2224/4708 - The training loss at 21th epoch : 0.08169753752530684  Training Accuracy:0.8870535714285714\n",
            "2240/4708 - The training loss at 21th epoch : 0.08129268321649286  Training Accuracy:0.887854609929078\n",
            "2256/4708 - The training loss at 21th epoch : 0.08153393789298659  Training Accuracy:0.8877640845070423\n",
            "2272/4708 - The training loss at 21th epoch : 0.08105990565219252  Training Accuracy:0.888548951048951\n",
            "2288/4708 - The training loss at 21th epoch : 0.08135465938911583  Training Accuracy:0.8880208333333334\n",
            "2304/4708 - The training loss at 21th epoch : 0.08111572640032726  Training Accuracy:0.8883620689655173\n",
            "2320/4708 - The training loss at 21th epoch : 0.08106232142002733  Training Accuracy:0.8886986301369864\n",
            "2336/4708 - The training loss at 21th epoch : 0.08064249073722349  Training Accuracy:0.8894557823129252\n",
            "2352/4708 - The training loss at 21th epoch : 0.08044651557019432  Training Accuracy:0.8893581081081081\n",
            "2368/4708 - The training loss at 21th epoch : 0.07999898827983118  Training Accuracy:0.8901006711409396\n",
            "2384/4708 - The training loss at 21th epoch : 0.07994934190972745  Training Accuracy:0.89\n",
            "2400/4708 - The training loss at 21th epoch : 0.08026419476981349  Training Accuracy:0.8894867549668874\n",
            "2416/4708 - The training loss at 21th epoch : 0.08005828538826518  Training Accuracy:0.8898026315789473\n",
            "2432/4708 - The training loss at 21th epoch : 0.08013266820877007  Training Accuracy:0.889297385620915\n",
            "2448/4708 - The training loss at 21th epoch : 0.0805505281237231  Training Accuracy:0.8892045454545454\n",
            "2464/4708 - The training loss at 21th epoch : 0.08042150229688319  Training Accuracy:0.8895161290322581\n",
            "2480/4708 - The training loss at 21th epoch : 0.0803976913572073  Training Accuracy:0.8894230769230769\n",
            "2496/4708 - The training loss at 21th epoch : 0.08087378395151823  Training Accuracy:0.8885350318471338\n",
            "2512/4708 - The training loss at 21th epoch : 0.08111642945007393  Training Accuracy:0.8884493670886076\n",
            "2528/4708 - The training loss at 21th epoch : 0.08098503786688531  Training Accuracy:0.8887578616352201\n",
            "2544/4708 - The training loss at 21th epoch : 0.08116484905906755  Training Accuracy:0.888671875\n",
            "2560/4708 - The training loss at 21th epoch : 0.08152216448010814  Training Accuracy:0.8881987577639752\n",
            "2576/4708 - The training loss at 21th epoch : 0.08155667794519111  Training Accuracy:0.8881172839506173\n",
            "2592/4708 - The training loss at 21th epoch : 0.08117672385537206  Training Accuracy:0.8888036809815951\n",
            "2608/4708 - The training loss at 21th epoch : 0.0813745427757676  Training Accuracy:0.8883384146341463\n",
            "2624/4708 - The training loss at 21th epoch : 0.08179140700742164  Training Accuracy:0.8878787878787879\n",
            "2640/4708 - The training loss at 21th epoch : 0.08160285204527024  Training Accuracy:0.8881777108433735\n",
            "2656/4708 - The training loss at 21th epoch : 0.08213968002715524  Training Accuracy:0.8873502994011976\n",
            "2672/4708 - The training loss at 21th epoch : 0.08214712705664651  Training Accuracy:0.8872767857142857\n",
            "2688/4708 - The training loss at 21th epoch : 0.0823780382584992  Training Accuracy:0.8868343195266272\n",
            "2704/4708 - The training loss at 21th epoch : 0.08223013792663092  Training Accuracy:0.8871323529411764\n",
            "2720/4708 - The training loss at 21th epoch : 0.08221350989514108  Training Accuracy:0.8870614035087719\n",
            "2736/4708 - The training loss at 21th epoch : 0.0818895314842919  Training Accuracy:0.887718023255814\n",
            "2752/4708 - The training loss at 21th epoch : 0.08205970888903218  Training Accuracy:0.8872832369942196\n",
            "2768/4708 - The training loss at 21th epoch : 0.08203556712977973  Training Accuracy:0.8875718390804598\n",
            "2784/4708 - The training loss at 21th epoch : 0.08181610809502168  Training Accuracy:0.8878571428571429\n",
            "2800/4708 - The training loss at 21th epoch : 0.08196649553810477  Training Accuracy:0.8874289772727273\n",
            "2816/4708 - The training loss at 21th epoch : 0.08193474106816825  Training Accuracy:0.8870056497175142\n",
            "2832/4708 - The training loss at 21th epoch : 0.08196760769358605  Training Accuracy:0.8872893258426966\n",
            "2848/4708 - The training loss at 21th epoch : 0.08199523936402113  Training Accuracy:0.8872206703910615\n",
            "2864/4708 - The training loss at 21th epoch : 0.0818862993688391  Training Accuracy:0.8871527777777778\n",
            "2880/4708 - The training loss at 21th epoch : 0.0816217373602415  Training Accuracy:0.8874309392265194\n",
            "2896/4708 - The training loss at 21th epoch : 0.0822653708498008  Training Accuracy:0.8866758241758241\n",
            "2912/4708 - The training loss at 21th epoch : 0.08298878413732372  Training Accuracy:0.8855874316939891\n",
            "2928/4708 - The training loss at 21th epoch : 0.08331983032789901  Training Accuracy:0.8851902173913043\n",
            "2944/4708 - The training loss at 21th epoch : 0.08375844108698643  Training Accuracy:0.8847972972972973\n",
            "2960/4708 - The training loss at 21th epoch : 0.08404340685538925  Training Accuracy:0.884744623655914\n",
            "2976/4708 - The training loss at 21th epoch : 0.0843931381190224  Training Accuracy:0.884024064171123\n",
            "2992/4708 - The training loss at 21th epoch : 0.08410916451293435  Training Accuracy:0.8843085106382979\n",
            "3008/4708 - The training loss at 21th epoch : 0.08421030995613353  Training Accuracy:0.8839285714285714\n",
            "3024/4708 - The training loss at 21th epoch : 0.08419346753191934  Training Accuracy:0.8838815789473684\n",
            "3040/4708 - The training loss at 21th epoch : 0.08482668858691127  Training Accuracy:0.8828534031413613\n",
            "3056/4708 - The training loss at 21th epoch : 0.08486108087846134  Training Accuracy:0.8828125\n",
            "3072/4708 - The training loss at 21th epoch : 0.08495214060124877  Training Accuracy:0.8824481865284974\n",
            "3088/4708 - The training loss at 21th epoch : 0.08474298321919853  Training Accuracy:0.8827319587628866\n",
            "3104/4708 - The training loss at 21th epoch : 0.08469621620277193  Training Accuracy:0.8830128205128205\n",
            "3120/4708 - The training loss at 21th epoch : 0.08468186877934032  Training Accuracy:0.8829719387755102\n",
            "3136/4708 - The training loss at 21th epoch : 0.08466784372983696  Training Accuracy:0.883248730964467\n",
            "3152/4708 - The training loss at 21th epoch : 0.08491611892419405  Training Accuracy:0.8825757575757576\n",
            "3168/4708 - The training loss at 21th epoch : 0.08524678060720552  Training Accuracy:0.8819095477386935\n",
            "3184/4708 - The training loss at 21th epoch : 0.08484102196685363  Training Accuracy:0.8825\n",
            "3200/4708 - The training loss at 21th epoch : 0.08477264468323663  Training Accuracy:0.8824626865671642\n",
            "3216/4708 - The training loss at 21th epoch : 0.08470053932650819  Training Accuracy:0.8827351485148515\n",
            "3232/4708 - The training loss at 21th epoch : 0.0846733842088989  Training Accuracy:0.8826970443349754\n",
            "3248/4708 - The training loss at 21th epoch : 0.08439479292483522  Training Accuracy:0.8829656862745098\n",
            "3264/4708 - The training loss at 21th epoch : 0.08444322763434382  Training Accuracy:0.8829268292682927\n",
            "3280/4708 - The training loss at 21th epoch : 0.08427603158945962  Training Accuracy:0.8831917475728155\n",
            "3296/4708 - The training loss at 21th epoch : 0.08395792099800273  Training Accuracy:0.883756038647343\n",
            "3312/4708 - The training loss at 21th epoch : 0.08368705550240728  Training Accuracy:0.8843149038461539\n",
            "3328/4708 - The training loss at 21th epoch : 0.08339702513472597  Training Accuracy:0.8848684210526315\n",
            "3344/4708 - The training loss at 21th epoch : 0.08366852440707043  Training Accuracy:0.8848214285714285\n",
            "3360/4708 - The training loss at 21th epoch : 0.08364573116574854  Training Accuracy:0.8847748815165877\n",
            "3376/4708 - The training loss at 21th epoch : 0.08329573675513118  Training Accuracy:0.8853183962264151\n",
            "3392/4708 - The training loss at 21th epoch : 0.0830579613520752  Training Accuracy:0.8855633802816901\n",
            "3408/4708 - The training loss at 21th epoch : 0.08312289728945059  Training Accuracy:0.8852219626168224\n",
            "3424/4708 - The training loss at 21th epoch : 0.08287747496995541  Training Accuracy:0.8854651162790698\n",
            "3440/4708 - The training loss at 21th epoch : 0.08302228533587351  Training Accuracy:0.8854166666666666\n",
            "3456/4708 - The training loss at 21th epoch : 0.08317459656377364  Training Accuracy:0.8850806451612904\n",
            "3472/4708 - The training loss at 21th epoch : 0.08313145741879888  Training Accuracy:0.8853211009174312\n",
            "3488/4708 - The training loss at 21th epoch : 0.0829017581301176  Training Accuracy:0.8855593607305936\n",
            "3504/4708 - The training loss at 21th epoch : 0.08294791315647232  Training Accuracy:0.8855113636363636\n",
            "3520/4708 - The training loss at 21th epoch : 0.08283150324740111  Training Accuracy:0.8857466063348416\n",
            "3536/4708 - The training loss at 21th epoch : 0.08317602712177348  Training Accuracy:0.8854166666666666\n",
            "3552/4708 - The training loss at 21th epoch : 0.08315939830862817  Training Accuracy:0.8856502242152466\n",
            "3568/4708 - The training loss at 21th epoch : 0.08324028668568897  Training Accuracy:0.8856026785714286\n",
            "3584/4708 - The training loss at 21th epoch : 0.08333754718898917  Training Accuracy:0.8855555555555555\n",
            "3600/4708 - The training loss at 21th epoch : 0.08369177732480751  Training Accuracy:0.8852323008849557\n",
            "3616/4708 - The training loss at 21th epoch : 0.08334424200339949  Training Accuracy:0.885737885462555\n",
            "3632/4708 - The training loss at 21th epoch : 0.08328652299025484  Training Accuracy:0.8856907894736842\n",
            "3648/4708 - The training loss at 21th epoch : 0.08320748197234067  Training Accuracy:0.8859170305676856\n",
            "3664/4708 - The training loss at 21th epoch : 0.08344683155689413  Training Accuracy:0.8855978260869565\n",
            "3680/4708 - The training loss at 21th epoch : 0.08314425970289765  Training Accuracy:0.8860930735930735\n",
            "3696/4708 - The training loss at 21th epoch : 0.08292028545334867  Training Accuracy:0.8865840517241379\n",
            "3712/4708 - The training loss at 21th epoch : 0.08295287515076262  Training Accuracy:0.8865343347639485\n",
            "3728/4708 - The training loss at 21th epoch : 0.08276273661698928  Training Accuracy:0.8867521367521367\n",
            "3744/4708 - The training loss at 21th epoch : 0.08277303773053708  Training Accuracy:0.8867021276595745\n",
            "3760/4708 - The training loss at 21th epoch : 0.08251419251239009  Training Accuracy:0.8871822033898306\n",
            "3776/4708 - The training loss at 21th epoch : 0.08236125785680264  Training Accuracy:0.8873945147679325\n",
            "3792/4708 - The training loss at 21th epoch : 0.08264825207607861  Training Accuracy:0.8870798319327731\n",
            "3808/4708 - The training loss at 21th epoch : 0.08236134953962804  Training Accuracy:0.8875523012552301\n",
            "3824/4708 - The training loss at 21th epoch : 0.08273958007295243  Training Accuracy:0.88671875\n",
            "3840/4708 - The training loss at 21th epoch : 0.08243127121313393  Training Accuracy:0.8871887966804979\n",
            "3856/4708 - The training loss at 21th epoch : 0.08248873438710336  Training Accuracy:0.8868801652892562\n",
            "3872/4708 - The training loss at 21th epoch : 0.08262993904606951  Training Accuracy:0.8868312757201646\n",
            "3888/4708 - The training loss at 21th epoch : 0.08289840547776192  Training Accuracy:0.8865266393442623\n",
            "3904/4708 - The training loss at 21th epoch : 0.0829209693037879  Training Accuracy:0.886734693877551\n",
            "3920/4708 - The training loss at 21th epoch : 0.08262532876547912  Training Accuracy:0.8871951219512195\n",
            "3936/4708 - The training loss at 21th epoch : 0.08288802900666072  Training Accuracy:0.8868927125506073\n",
            "3952/4708 - The training loss at 21th epoch : 0.08320134639151648  Training Accuracy:0.8865927419354839\n",
            "3968/4708 - The training loss at 21th epoch : 0.08337945033106686  Training Accuracy:0.8862951807228916\n",
            "3984/4708 - The training loss at 21th epoch : 0.08343434763787955  Training Accuracy:0.886\n",
            "4000/4708 - The training loss at 21th epoch : 0.08318462433079807  Training Accuracy:0.8862051792828686\n",
            "4016/4708 - The training loss at 21th epoch : 0.08317637011308933  Training Accuracy:0.8861607142857143\n",
            "4032/4708 - The training loss at 21th epoch : 0.08294870201415157  Training Accuracy:0.8866106719367589\n",
            "4048/4708 - The training loss at 21th epoch : 0.08268776321979177  Training Accuracy:0.8870570866141733\n",
            "4064/4708 - The training loss at 21th epoch : 0.08259645333910438  Training Accuracy:0.8872549019607843\n",
            "4080/4708 - The training loss at 21th epoch : 0.08272951864219062  Training Accuracy:0.88720703125\n",
            "4096/4708 - The training loss at 21th epoch : 0.08249548963191725  Training Accuracy:0.8876459143968871\n",
            "4112/4708 - The training loss at 21th epoch : 0.08222331630925504  Training Accuracy:0.8880813953488372\n",
            "4128/4708 - The training loss at 21th epoch : 0.0823148039310569  Training Accuracy:0.8877895752895753\n",
            "4144/4708 - The training loss at 21th epoch : 0.08250078733101353  Training Accuracy:0.8872596153846154\n",
            "4160/4708 - The training loss at 21th epoch : 0.0824341587841945  Training Accuracy:0.8872126436781609\n",
            "4176/4708 - The training loss at 21th epoch : 0.08258978737731673  Training Accuracy:0.8871660305343512\n",
            "4192/4708 - The training loss at 21th epoch : 0.0829072043453562  Training Accuracy:0.8868821292775665\n",
            "4208/4708 - The training loss at 21th epoch : 0.08282449914637245  Training Accuracy:0.8870738636363636\n",
            "4224/4708 - The training loss at 21th epoch : 0.08303914578396401  Training Accuracy:0.8870283018867925\n",
            "4240/4708 - The training loss at 21th epoch : 0.08292865271365639  Training Accuracy:0.8872180451127819\n",
            "4256/4708 - The training loss at 21th epoch : 0.08272074184931584  Training Accuracy:0.8874063670411985\n",
            "4272/4708 - The training loss at 21th epoch : 0.08261047363628082  Training Accuracy:0.8873600746268657\n",
            "4288/4708 - The training loss at 21th epoch : 0.08253851999852312  Training Accuracy:0.887314126394052\n",
            "4304/4708 - The training loss at 21th epoch : 0.08272052202295097  Training Accuracy:0.8870370370370371\n",
            "4320/4708 - The training loss at 21th epoch : 0.08258354399307805  Training Accuracy:0.8872232472324724\n",
            "4336/4708 - The training loss at 21th epoch : 0.08245494123836031  Training Accuracy:0.8874080882352942\n",
            "4352/4708 - The training loss at 21th epoch : 0.08244727216255983  Training Accuracy:0.8873626373626373\n",
            "4368/4708 - The training loss at 21th epoch : 0.08220305097123182  Training Accuracy:0.8877737226277372\n",
            "4384/4708 - The training loss at 21th epoch : 0.0824344990099454  Training Accuracy:0.8875\n",
            "4400/4708 - The training loss at 21th epoch : 0.08264421713307872  Training Accuracy:0.8870018115942029\n",
            "4416/4708 - The training loss at 21th epoch : 0.08264993621075438  Training Accuracy:0.8869584837545126\n",
            "4432/4708 - The training loss at 21th epoch : 0.08272491711807752  Training Accuracy:0.8871402877697842\n",
            "4448/4708 - The training loss at 21th epoch : 0.08289809232391172  Training Accuracy:0.8868727598566308\n",
            "4464/4708 - The training loss at 21th epoch : 0.08269317996797947  Training Accuracy:0.8872767857142857\n",
            "4480/4708 - The training loss at 21th epoch : 0.08269009480936192  Training Accuracy:0.8872330960854092\n",
            "4496/4708 - The training loss at 21th epoch : 0.08280610438570882  Training Accuracy:0.886968085106383\n",
            "4512/4708 - The training loss at 21th epoch : 0.0829019972253756  Training Accuracy:0.8869257950530035\n",
            "4528/4708 - The training loss at 21th epoch : 0.083094252861812  Training Accuracy:0.8866637323943662\n",
            "4544/4708 - The training loss at 21th epoch : 0.08293546775517913  Training Accuracy:0.8868421052631579\n",
            "4560/4708 - The training loss at 21th epoch : 0.0829582752366886  Training Accuracy:0.8868006993006993\n",
            "4576/4708 - The training loss at 21th epoch : 0.08296661127083292  Training Accuracy:0.8865418118466899\n",
            "4592/4708 - The training loss at 21th epoch : 0.08289788584124305  Training Accuracy:0.8865017361111112\n",
            "4608/4708 - The training loss at 21th epoch : 0.08286465862037913  Training Accuracy:0.8866782006920415\n",
            "4624/4708 - The training loss at 21th epoch : 0.0830354136353304  Training Accuracy:0.8859913793103448\n",
            "4640/4708 - The training loss at 21th epoch : 0.08302727974636424  Training Accuracy:0.8859536082474226\n",
            "4656/4708 - The training loss at 21th epoch : 0.08316202520745847  Training Accuracy:0.8854880136986302\n",
            "4672/4708 - The training loss at 21th epoch : 0.08309819145193635  Training Accuracy:0.8854522184300341\n",
            "4688/4708 - The training loss at 21th epoch : 0.08293273721849721  Training Accuracy:0.8858418367346939\n",
            "4704/4708 - The training loss at 21th epoch : 0.08330407545369367  Training Accuracy:0.8851694915254237\n",
            "4720/4708 - The training loss at 21th epoch : 0.08312788170782631  Training Accuracy:0.8855574324324325\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 22th epoch : 0.07256293827020951  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 22th epoch : 0.10101491245772111  Training Accuracy:0.90625\n",
            "32/4708 - The training loss at 22th epoch : 0.10803700583267818  Training Accuracy:0.8958333333333334\n",
            "48/4708 - The training loss at 22th epoch : 0.10958488103916557  Training Accuracy:0.875\n",
            "64/4708 - The training loss at 22th epoch : 0.12905624322803216  Training Accuracy:0.85\n",
            "80/4708 - The training loss at 22th epoch : 0.1174008061173366  Training Accuracy:0.8645833333333334\n",
            "96/4708 - The training loss at 22th epoch : 0.11841357796368268  Training Accuracy:0.8660714285714286\n",
            "112/4708 - The training loss at 22th epoch : 0.12781331556982553  Training Accuracy:0.8515625\n",
            "128/4708 - The training loss at 22th epoch : 0.11409882225178432  Training Accuracy:0.8680555555555556\n",
            "144/4708 - The training loss at 22th epoch : 0.11257326216597056  Training Accuracy:0.86875\n",
            "160/4708 - The training loss at 22th epoch : 0.10438046722395161  Training Accuracy:0.8806818181818182\n",
            "176/4708 - The training loss at 22th epoch : 0.09584198236208451  Training Accuracy:0.890625\n",
            "192/4708 - The training loss at 22th epoch : 0.10418699110623944  Training Accuracy:0.875\n",
            "208/4708 - The training loss at 22th epoch : 0.09705608613918233  Training Accuracy:0.8839285714285714\n",
            "224/4708 - The training loss at 22th epoch : 0.0939541780494735  Training Accuracy:0.8875\n",
            "240/4708 - The training loss at 22th epoch : 0.096422424806203  Training Accuracy:0.87890625\n",
            "256/4708 - The training loss at 22th epoch : 0.09542771989505137  Training Accuracy:0.8786764705882353\n",
            "272/4708 - The training loss at 22th epoch : 0.09345016769316322  Training Accuracy:0.8819444444444444\n",
            "288/4708 - The training loss at 22th epoch : 0.09551092853519158  Training Accuracy:0.881578947368421\n",
            "304/4708 - The training loss at 22th epoch : 0.09338876949326438  Training Accuracy:0.884375\n",
            "320/4708 - The training loss at 22th epoch : 0.0917490761464251  Training Accuracy:0.8839285714285714\n",
            "336/4708 - The training loss at 22th epoch : 0.09215983613017288  Training Accuracy:0.8806818181818182\n",
            "352/4708 - The training loss at 22th epoch : 0.09140072036042703  Training Accuracy:0.8804347826086957\n",
            "368/4708 - The training loss at 22th epoch : 0.093266322265164  Training Accuracy:0.8776041666666666\n",
            "384/4708 - The training loss at 22th epoch : 0.09060349290785799  Training Accuracy:0.8825\n",
            "400/4708 - The training loss at 22th epoch : 0.08918992850770927  Training Accuracy:0.8822115384615384\n",
            "416/4708 - The training loss at 22th epoch : 0.09103151190398966  Training Accuracy:0.8796296296296297\n",
            "432/4708 - The training loss at 22th epoch : 0.09011928884608213  Training Accuracy:0.8772321428571429\n",
            "448/4708 - The training loss at 22th epoch : 0.09178615860079899  Training Accuracy:0.875\n",
            "464/4708 - The training loss at 22th epoch : 0.09162819821217147  Training Accuracy:0.875\n",
            "480/4708 - The training loss at 22th epoch : 0.08957263210911624  Training Accuracy:0.8790322580645161\n",
            "496/4708 - The training loss at 22th epoch : 0.0911613876992611  Training Accuracy:0.875\n",
            "512/4708 - The training loss at 22th epoch : 0.09053306578708933  Training Accuracy:0.8768939393939394\n",
            "528/4708 - The training loss at 22th epoch : 0.09506714189429807  Training Accuracy:0.8713235294117647\n",
            "544/4708 - The training loss at 22th epoch : 0.0927936877945618  Training Accuracy:0.875\n",
            "560/4708 - The training loss at 22th epoch : 0.09220670934986813  Training Accuracy:0.875\n",
            "576/4708 - The training loss at 22th epoch : 0.09556995397992817  Training Accuracy:0.8699324324324325\n",
            "592/4708 - The training loss at 22th epoch : 0.09752452250886245  Training Accuracy:0.868421052631579\n",
            "608/4708 - The training loss at 22th epoch : 0.09760061048310116  Training Accuracy:0.8669871794871795\n",
            "624/4708 - The training loss at 22th epoch : 0.09724101211192837  Training Accuracy:0.86875\n",
            "640/4708 - The training loss at 22th epoch : 0.0963446247723678  Training Accuracy:0.8704268292682927\n",
            "656/4708 - The training loss at 22th epoch : 0.09767769916450081  Training Accuracy:0.8690476190476191\n",
            "672/4708 - The training loss at 22th epoch : 0.09649279033376601  Training Accuracy:0.8706395348837209\n",
            "688/4708 - The training loss at 22th epoch : 0.09663365069682137  Training Accuracy:0.8678977272727273\n",
            "704/4708 - The training loss at 22th epoch : 0.09621902624118506  Training Accuracy:0.8694444444444445\n",
            "720/4708 - The training loss at 22th epoch : 0.09537230439034818  Training Accuracy:0.8709239130434783\n",
            "736/4708 - The training loss at 22th epoch : 0.09555246659651734  Training Accuracy:0.8710106382978723\n",
            "752/4708 - The training loss at 22th epoch : 0.09390802780816909  Training Accuracy:0.8736979166666666\n",
            "768/4708 - The training loss at 22th epoch : 0.0932213721468529  Training Accuracy:0.875\n",
            "784/4708 - The training loss at 22th epoch : 0.09220475609368854  Training Accuracy:0.87625\n",
            "800/4708 - The training loss at 22th epoch : 0.09175214338402533  Training Accuracy:0.8762254901960784\n",
            "816/4708 - The training loss at 22th epoch : 0.09112972431544275  Training Accuracy:0.8774038461538461\n",
            "832/4708 - The training loss at 22th epoch : 0.09076841615722513  Training Accuracy:0.8785377358490566\n",
            "848/4708 - The training loss at 22th epoch : 0.08940143342362464  Training Accuracy:0.8807870370370371\n",
            "864/4708 - The training loss at 22th epoch : 0.08977860891468838  Training Accuracy:0.8795454545454545\n",
            "880/4708 - The training loss at 22th epoch : 0.08920290007451946  Training Accuracy:0.8805803571428571\n",
            "896/4708 - The training loss at 22th epoch : 0.08780767122066284  Training Accuracy:0.8826754385964912\n",
            "912/4708 - The training loss at 22th epoch : 0.08667169439716225  Training Accuracy:0.884698275862069\n",
            "928/4708 - The training loss at 22th epoch : 0.08621224066245896  Training Accuracy:0.885593220338983\n",
            "944/4708 - The training loss at 22th epoch : 0.0851367266146572  Training Accuracy:0.8875\n",
            "960/4708 - The training loss at 22th epoch : 0.08471573272508674  Training Accuracy:0.8883196721311475\n",
            "976/4708 - The training loss at 22th epoch : 0.08356303163317211  Training Accuracy:0.8901209677419355\n",
            "992/4708 - The training loss at 22th epoch : 0.08343402108844238  Training Accuracy:0.8908730158730159\n",
            "1008/4708 - The training loss at 22th epoch : 0.08429246774665376  Training Accuracy:0.8896484375\n",
            "1024/4708 - The training loss at 22th epoch : 0.08336846050812938  Training Accuracy:0.8913461538461539\n",
            "1040/4708 - The training loss at 22th epoch : 0.08265221220075594  Training Accuracy:0.8920454545454546\n",
            "1056/4708 - The training loss at 22th epoch : 0.08335566703994056  Training Accuracy:0.8899253731343284\n",
            "1072/4708 - The training loss at 22th epoch : 0.08307203068423978  Training Accuracy:0.890625\n",
            "1088/4708 - The training loss at 22th epoch : 0.08223128288423717  Training Accuracy:0.8922101449275363\n",
            "1104/4708 - The training loss at 22th epoch : 0.08141629727077203  Training Accuracy:0.89375\n",
            "1120/4708 - The training loss at 22th epoch : 0.08265030352697858  Training Accuracy:0.891725352112676\n",
            "1136/4708 - The training loss at 22th epoch : 0.08393522079418897  Training Accuracy:0.8897569444444444\n",
            "1152/4708 - The training loss at 22th epoch : 0.08354333354000007  Training Accuracy:0.8904109589041096\n",
            "1168/4708 - The training loss at 22th epoch : 0.08333277955405798  Training Accuracy:0.8902027027027027\n",
            "1184/4708 - The training loss at 22th epoch : 0.08386266458343723  Training Accuracy:0.8891666666666667\n",
            "1200/4708 - The training loss at 22th epoch : 0.08378753478414143  Training Accuracy:0.8889802631578947\n",
            "1216/4708 - The training loss at 22th epoch : 0.0836172799083223  Training Accuracy:0.8896103896103896\n",
            "1232/4708 - The training loss at 22th epoch : 0.08404017061165964  Training Accuracy:0.8894230769230769\n",
            "1248/4708 - The training loss at 22th epoch : 0.08398281099460717  Training Accuracy:0.8900316455696202\n",
            "1264/4708 - The training loss at 22th epoch : 0.08310686168463306  Training Accuracy:0.89140625\n",
            "1280/4708 - The training loss at 22th epoch : 0.08349229183392412  Training Accuracy:0.8904320987654321\n",
            "1296/4708 - The training loss at 22th epoch : 0.08348542574718427  Training Accuracy:0.8902439024390244\n",
            "1312/4708 - The training loss at 22th epoch : 0.08350020798242523  Training Accuracy:0.8893072289156626\n",
            "1328/4708 - The training loss at 22th epoch : 0.08415845934893318  Training Accuracy:0.8883928571428571\n",
            "1344/4708 - The training loss at 22th epoch : 0.08378880732734938  Training Accuracy:0.8889705882352941\n",
            "1360/4708 - The training loss at 22th epoch : 0.08332732509188744  Training Accuracy:0.8895348837209303\n",
            "1376/4708 - The training loss at 22th epoch : 0.08267347784408047  Training Accuracy:0.8908045977011494\n",
            "1392/4708 - The training loss at 22th epoch : 0.0818243496473199  Training Accuracy:0.8920454545454546\n",
            "1408/4708 - The training loss at 22th epoch : 0.08231948481228767  Training Accuracy:0.8911516853932584\n",
            "1424/4708 - The training loss at 22th epoch : 0.0820396153231905  Training Accuracy:0.8909722222222223\n",
            "1440/4708 - The training loss at 22th epoch : 0.08129067054413676  Training Accuracy:0.8921703296703297\n",
            "1456/4708 - The training loss at 22th epoch : 0.08214082504138794  Training Accuracy:0.890625\n",
            "1472/4708 - The training loss at 22th epoch : 0.08187248645518462  Training Accuracy:0.8911290322580645\n",
            "1488/4708 - The training loss at 22th epoch : 0.08123958302749199  Training Accuracy:0.8922872340425532\n",
            "1504/4708 - The training loss at 22th epoch : 0.08184155520556803  Training Accuracy:0.8914473684210527\n",
            "1520/4708 - The training loss at 22th epoch : 0.0817484129873198  Training Accuracy:0.8912760416666666\n",
            "1536/4708 - The training loss at 22th epoch : 0.08204193898956694  Training Accuracy:0.8904639175257731\n",
            "1552/4708 - The training loss at 22th epoch : 0.08301722725658907  Training Accuracy:0.8896683673469388\n",
            "1568/4708 - The training loss at 22th epoch : 0.08235959627252062  Training Accuracy:0.8907828282828283\n",
            "1584/4708 - The training loss at 22th epoch : 0.08162644751904141  Training Accuracy:0.891875\n",
            "1600/4708 - The training loss at 22th epoch : 0.08145657589391345  Training Accuracy:0.8923267326732673\n",
            "1616/4708 - The training loss at 22th epoch : 0.08077905356647007  Training Accuracy:0.8933823529411765\n",
            "1632/4708 - The training loss at 22th epoch : 0.08123717924267834  Training Accuracy:0.8925970873786407\n",
            "1648/4708 - The training loss at 22th epoch : 0.08054380389871518  Training Accuracy:0.8936298076923077\n",
            "1664/4708 - The training loss at 22th epoch : 0.07983480005472852  Training Accuracy:0.8946428571428572\n",
            "1680/4708 - The training loss at 22th epoch : 0.07957141699674153  Training Accuracy:0.8956367924528302\n",
            "1696/4708 - The training loss at 22th epoch : 0.07978436429655238  Training Accuracy:0.8942757009345794\n",
            "1712/4708 - The training loss at 22th epoch : 0.07984928174191605  Training Accuracy:0.8946759259259259\n",
            "1728/4708 - The training loss at 22th epoch : 0.07954279507973971  Training Accuracy:0.8950688073394495\n",
            "1744/4708 - The training loss at 22th epoch : 0.07959144910434518  Training Accuracy:0.8948863636363636\n",
            "1760/4708 - The training loss at 22th epoch : 0.07907578528636129  Training Accuracy:0.8958333333333334\n",
            "1776/4708 - The training loss at 22th epoch : 0.07848599148467063  Training Accuracy:0.8967633928571429\n",
            "1792/4708 - The training loss at 22th epoch : 0.07817875531228326  Training Accuracy:0.896570796460177\n",
            "1808/4708 - The training loss at 22th epoch : 0.07852221687648714  Training Accuracy:0.8958333333333334\n",
            "1824/4708 - The training loss at 22th epoch : 0.07888076788198022  Training Accuracy:0.8956521739130435\n",
            "1840/4708 - The training loss at 22th epoch : 0.07844191889495453  Training Accuracy:0.8960129310344828\n",
            "1856/4708 - The training loss at 22th epoch : 0.0786527832782856  Training Accuracy:0.8952991452991453\n",
            "1872/4708 - The training loss at 22th epoch : 0.07842063311746254  Training Accuracy:0.8951271186440678\n",
            "1888/4708 - The training loss at 22th epoch : 0.07859778388717159  Training Accuracy:0.8949579831932774\n",
            "1904/4708 - The training loss at 22th epoch : 0.07830594439783635  Training Accuracy:0.8953125\n",
            "1920/4708 - The training loss at 22th epoch : 0.07815769587247776  Training Accuracy:0.8956611570247934\n",
            "1936/4708 - The training loss at 22th epoch : 0.07829171371255322  Training Accuracy:0.8954918032786885\n",
            "1952/4708 - The training loss at 22th epoch : 0.0780472766417365  Training Accuracy:0.8958333333333334\n",
            "1968/4708 - The training loss at 22th epoch : 0.07816690627580515  Training Accuracy:0.8956653225806451\n",
            "1984/4708 - The training loss at 22th epoch : 0.07874965336949494  Training Accuracy:0.8945\n",
            "2000/4708 - The training loss at 22th epoch : 0.07864966423188428  Training Accuracy:0.8948412698412699\n",
            "2016/4708 - The training loss at 22th epoch : 0.07901611151274729  Training Accuracy:0.8946850393700787\n",
            "2032/4708 - The training loss at 22th epoch : 0.0791051496124894  Training Accuracy:0.89453125\n",
            "2048/4708 - The training loss at 22th epoch : 0.07877651849318484  Training Accuracy:0.8948643410852714\n",
            "2064/4708 - The training loss at 22th epoch : 0.07957597761135095  Training Accuracy:0.8932692307692308\n",
            "2080/4708 - The training loss at 22th epoch : 0.07975709148460067  Training Accuracy:0.8931297709923665\n",
            "2096/4708 - The training loss at 22th epoch : 0.07937971453950714  Training Accuracy:0.8934659090909091\n",
            "2112/4708 - The training loss at 22th epoch : 0.07999813222271507  Training Accuracy:0.8919172932330827\n",
            "2128/4708 - The training loss at 22th epoch : 0.07960416502970848  Training Accuracy:0.8922574626865671\n",
            "2144/4708 - The training loss at 22th epoch : 0.0796382235347126  Training Accuracy:0.8921296296296296\n",
            "2160/4708 - The training loss at 22th epoch : 0.07943795596375439  Training Accuracy:0.8924632352941176\n",
            "2176/4708 - The training loss at 22th epoch : 0.07996149125932993  Training Accuracy:0.8918795620437956\n",
            "2192/4708 - The training loss at 22th epoch : 0.0803481300428632  Training Accuracy:0.8917572463768116\n",
            "2208/4708 - The training loss at 22th epoch : 0.0800014634604536  Training Accuracy:0.8920863309352518\n",
            "2224/4708 - The training loss at 22th epoch : 0.08073257230519233  Training Accuracy:0.8910714285714286\n",
            "2240/4708 - The training loss at 22th epoch : 0.08071593015988919  Training Accuracy:0.8909574468085106\n",
            "2256/4708 - The training loss at 22th epoch : 0.08055607104572807  Training Accuracy:0.8912852112676056\n",
            "2272/4708 - The training loss at 22th epoch : 0.08011603168594102  Training Accuracy:0.8920454545454546\n",
            "2288/4708 - The training loss at 22th epoch : 0.07974105756025403  Training Accuracy:0.8923611111111112\n",
            "2304/4708 - The training loss at 22th epoch : 0.07942051209395169  Training Accuracy:0.8926724137931035\n",
            "2320/4708 - The training loss at 22th epoch : 0.07935327579627863  Training Accuracy:0.8929794520547946\n",
            "2336/4708 - The training loss at 22th epoch : 0.07906139963519965  Training Accuracy:0.8937074829931972\n",
            "2352/4708 - The training loss at 22th epoch : 0.07941956454033008  Training Accuracy:0.8931587837837838\n",
            "2368/4708 - The training loss at 22th epoch : 0.07934671977349908  Training Accuracy:0.8930369127516778\n",
            "2384/4708 - The training loss at 22th epoch : 0.07908120258443223  Training Accuracy:0.8933333333333333\n",
            "2400/4708 - The training loss at 22th epoch : 0.07911355313582095  Training Accuracy:0.8932119205298014\n",
            "2416/4708 - The training loss at 22th epoch : 0.07979615186563739  Training Accuracy:0.8922697368421053\n",
            "2432/4708 - The training loss at 22th epoch : 0.07995699134583324  Training Accuracy:0.8921568627450981\n",
            "2448/4708 - The training loss at 22th epoch : 0.0798984789288968  Training Accuracy:0.8924512987012987\n",
            "2464/4708 - The training loss at 22th epoch : 0.08011234847231363  Training Accuracy:0.8915322580645161\n",
            "2480/4708 - The training loss at 22th epoch : 0.08024981332964856  Training Accuracy:0.891426282051282\n",
            "2496/4708 - The training loss at 22th epoch : 0.07983845406473053  Training Accuracy:0.8921178343949044\n",
            "2512/4708 - The training loss at 22th epoch : 0.08014846011524529  Training Accuracy:0.8920094936708861\n",
            "2528/4708 - The training loss at 22th epoch : 0.08019279515102244  Training Accuracy:0.8915094339622641\n",
            "2544/4708 - The training loss at 22th epoch : 0.08019710823576924  Training Accuracy:0.891796875\n",
            "2560/4708 - The training loss at 22th epoch : 0.08010125809512035  Training Accuracy:0.8920807453416149\n",
            "2576/4708 - The training loss at 22th epoch : 0.07988700836219087  Training Accuracy:0.8923611111111112\n",
            "2592/4708 - The training loss at 22th epoch : 0.07985708350721282  Training Accuracy:0.8922546012269938\n",
            "2608/4708 - The training loss at 22th epoch : 0.08011624758786615  Training Accuracy:0.8917682926829268\n",
            "2624/4708 - The training loss at 22th epoch : 0.08028737887303472  Training Accuracy:0.8912878787878787\n",
            "2640/4708 - The training loss at 22th epoch : 0.08008615642472018  Training Accuracy:0.891566265060241\n",
            "2656/4708 - The training loss at 22th epoch : 0.08006478425708097  Training Accuracy:0.8918413173652695\n",
            "2672/4708 - The training loss at 22th epoch : 0.08008978381804958  Training Accuracy:0.8917410714285714\n",
            "2688/4708 - The training loss at 22th epoch : 0.07980027541356534  Training Accuracy:0.8920118343195266\n",
            "2704/4708 - The training loss at 22th epoch : 0.07956993073887944  Training Accuracy:0.8926470588235295\n",
            "2720/4708 - The training loss at 22th epoch : 0.07988188661391381  Training Accuracy:0.8918128654970761\n",
            "2736/4708 - The training loss at 22th epoch : 0.07945832353111877  Training Accuracy:0.8924418604651163\n",
            "2752/4708 - The training loss at 22th epoch : 0.07922886207978884  Training Accuracy:0.8930635838150289\n",
            "2768/4708 - The training loss at 22th epoch : 0.07900417470600511  Training Accuracy:0.8936781609195402\n",
            "2784/4708 - The training loss at 22th epoch : 0.07889172220476107  Training Accuracy:0.8939285714285714\n",
            "2800/4708 - The training loss at 22th epoch : 0.07947548093111546  Training Accuracy:0.8924005681818182\n",
            "2816/4708 - The training loss at 22th epoch : 0.07951884736293381  Training Accuracy:0.8926553672316384\n",
            "2832/4708 - The training loss at 22th epoch : 0.07952659016295166  Training Accuracy:0.8925561797752809\n",
            "2848/4708 - The training loss at 22th epoch : 0.07956196378004966  Training Accuracy:0.8921089385474861\n",
            "2864/4708 - The training loss at 22th epoch : 0.07948260138417419  Training Accuracy:0.8923611111111112\n",
            "2880/4708 - The training loss at 22th epoch : 0.07964203174730806  Training Accuracy:0.8922651933701657\n",
            "2896/4708 - The training loss at 22th epoch : 0.07968147826748623  Training Accuracy:0.8921703296703297\n",
            "2912/4708 - The training loss at 22th epoch : 0.07946500456535534  Training Accuracy:0.8924180327868853\n",
            "2928/4708 - The training loss at 22th epoch : 0.0797498729840916  Training Accuracy:0.891983695652174\n",
            "2944/4708 - The training loss at 22th epoch : 0.07979971996895019  Training Accuracy:0.8922297297297297\n",
            "2960/4708 - The training loss at 22th epoch : 0.08017590394655591  Training Accuracy:0.8918010752688172\n",
            "2976/4708 - The training loss at 22th epoch : 0.08000038913006641  Training Accuracy:0.8920454545454546\n",
            "2992/4708 - The training loss at 22th epoch : 0.07971259409912344  Training Accuracy:0.8922872340425532\n",
            "3008/4708 - The training loss at 22th epoch : 0.07955420036343895  Training Accuracy:0.892526455026455\n",
            "3024/4708 - The training loss at 22th epoch : 0.07951738023152227  Training Accuracy:0.8924342105263158\n",
            "3040/4708 - The training loss at 22th epoch : 0.07957802834170054  Training Accuracy:0.8923429319371727\n",
            "3056/4708 - The training loss at 22th epoch : 0.07961372136833574  Training Accuracy:0.8922526041666666\n",
            "3072/4708 - The training loss at 22th epoch : 0.07979538063269233  Training Accuracy:0.8921632124352331\n",
            "3088/4708 - The training loss at 22th epoch : 0.0796313357991314  Training Accuracy:0.8923969072164949\n",
            "3104/4708 - The training loss at 22th epoch : 0.07953786958203835  Training Accuracy:0.8926282051282052\n",
            "3120/4708 - The training loss at 22th epoch : 0.07951978377698038  Training Accuracy:0.8925382653061225\n",
            "3136/4708 - The training loss at 22th epoch : 0.07965270872568024  Training Accuracy:0.8924492385786802\n",
            "3152/4708 - The training loss at 22th epoch : 0.07961049793870859  Training Accuracy:0.8923611111111112\n",
            "3168/4708 - The training loss at 22th epoch : 0.07925867605339042  Training Accuracy:0.8929020100502513\n",
            "3184/4708 - The training loss at 22th epoch : 0.07957965221796696  Training Accuracy:0.8925\n",
            "3200/4708 - The training loss at 22th epoch : 0.07978622513578007  Training Accuracy:0.8921019900497512\n",
            "3216/4708 - The training loss at 22th epoch : 0.07973856283241977  Training Accuracy:0.8923267326732673\n",
            "3232/4708 - The training loss at 22th epoch : 0.08002578242663305  Training Accuracy:0.8919334975369458\n",
            "3248/4708 - The training loss at 22th epoch : 0.07989694894299591  Training Accuracy:0.8921568627450981\n",
            "3264/4708 - The training loss at 22th epoch : 0.07980205370483157  Training Accuracy:0.8923780487804878\n",
            "3280/4708 - The training loss at 22th epoch : 0.07954033389886858  Training Accuracy:0.8929004854368932\n",
            "3296/4708 - The training loss at 22th epoch : 0.07923901315023583  Training Accuracy:0.8934178743961353\n",
            "3312/4708 - The training loss at 22th epoch : 0.07951296656618155  Training Accuracy:0.8927283653846154\n",
            "3328/4708 - The training loss at 22th epoch : 0.07945357605550633  Training Accuracy:0.8929425837320574\n",
            "3344/4708 - The training loss at 22th epoch : 0.07936538067067508  Training Accuracy:0.8928571428571429\n",
            "3360/4708 - The training loss at 22th epoch : 0.07901208689638523  Training Accuracy:0.8933649289099526\n",
            "3376/4708 - The training loss at 22th epoch : 0.07904593072489056  Training Accuracy:0.8929834905660378\n",
            "3392/4708 - The training loss at 22th epoch : 0.07917142140859214  Training Accuracy:0.8928990610328639\n",
            "3408/4708 - The training loss at 22th epoch : 0.07915501880019642  Training Accuracy:0.893107476635514\n",
            "3424/4708 - The training loss at 22th epoch : 0.079223000538706  Training Accuracy:0.8927325581395349\n",
            "3440/4708 - The training loss at 22th epoch : 0.07895308108927322  Training Accuracy:0.8932291666666666\n",
            "3456/4708 - The training loss at 22th epoch : 0.07891599297867057  Training Accuracy:0.8931451612903226\n",
            "3472/4708 - The training loss at 22th epoch : 0.07898271976616397  Training Accuracy:0.8927752293577982\n",
            "3488/4708 - The training loss at 22th epoch : 0.07918685774301051  Training Accuracy:0.8924086757990868\n",
            "3504/4708 - The training loss at 22th epoch : 0.07933925169579678  Training Accuracy:0.8923295454545455\n",
            "3520/4708 - The training loss at 22th epoch : 0.07905416103184576  Training Accuracy:0.892816742081448\n",
            "3536/4708 - The training loss at 22th epoch : 0.07875294161913068  Training Accuracy:0.8932995495495496\n",
            "3552/4708 - The training loss at 22th epoch : 0.0788685367423537  Training Accuracy:0.8932174887892377\n",
            "3568/4708 - The training loss at 22th epoch : 0.07940198462524199  Training Accuracy:0.8922991071428571\n",
            "3584/4708 - The training loss at 22th epoch : 0.07918172161260538  Training Accuracy:0.8925\n",
            "3600/4708 - The training loss at 22th epoch : 0.07890561630741263  Training Accuracy:0.8929756637168141\n",
            "3616/4708 - The training loss at 22th epoch : 0.0790320644381779  Training Accuracy:0.8926211453744494\n",
            "3632/4708 - The training loss at 22th epoch : 0.0793812565709941  Training Accuracy:0.8919956140350878\n",
            "3648/4708 - The training loss at 22th epoch : 0.0793249809010668  Training Accuracy:0.8919213973799127\n",
            "3664/4708 - The training loss at 22th epoch : 0.07902102563883885  Training Accuracy:0.8923913043478261\n",
            "3680/4708 - The training loss at 22th epoch : 0.07936827010901876  Training Accuracy:0.8920454545454546\n",
            "3696/4708 - The training loss at 22th epoch : 0.0794900823721382  Training Accuracy:0.8917025862068966\n",
            "3712/4708 - The training loss at 22th epoch : 0.07963607454221479  Training Accuracy:0.891362660944206\n",
            "3728/4708 - The training loss at 22th epoch : 0.07951620334968426  Training Accuracy:0.8915598290598291\n",
            "3744/4708 - The training loss at 22th epoch : 0.07927824551476817  Training Accuracy:0.8920212765957447\n",
            "3760/4708 - The training loss at 22th epoch : 0.0795263678042377  Training Accuracy:0.8916843220338984\n",
            "3776/4708 - The training loss at 22th epoch : 0.07944419331191374  Training Accuracy:0.8918776371308017\n",
            "3792/4708 - The training loss at 22th epoch : 0.07929391781716934  Training Accuracy:0.8920693277310925\n",
            "3808/4708 - The training loss at 22th epoch : 0.07902285851393855  Training Accuracy:0.8925209205020921\n",
            "3824/4708 - The training loss at 22th epoch : 0.0790631689611611  Training Accuracy:0.8924479166666667\n",
            "3840/4708 - The training loss at 22th epoch : 0.0790053954862145  Training Accuracy:0.8926348547717843\n",
            "3856/4708 - The training loss at 22th epoch : 0.07894242017325089  Training Accuracy:0.8925619834710744\n",
            "3872/4708 - The training loss at 22th epoch : 0.07905232572299538  Training Accuracy:0.8924897119341564\n",
            "3888/4708 - The training loss at 22th epoch : 0.07959623876092911  Training Accuracy:0.8916495901639344\n",
            "3904/4708 - The training loss at 22th epoch : 0.07981748168478815  Training Accuracy:0.8910714285714286\n",
            "3920/4708 - The training loss at 22th epoch : 0.07996617017085514  Training Accuracy:0.8910060975609756\n",
            "3936/4708 - The training loss at 22th epoch : 0.07996535362933425  Training Accuracy:0.8909412955465587\n",
            "3952/4708 - The training loss at 22th epoch : 0.07989633143878437  Training Accuracy:0.8911290322580645\n",
            "3968/4708 - The training loss at 22th epoch : 0.07998582087762705  Training Accuracy:0.8910642570281124\n",
            "3984/4708 - The training loss at 22th epoch : 0.07988135565908731  Training Accuracy:0.89125\n",
            "4000/4708 - The training loss at 22th epoch : 0.07980946920396052  Training Accuracy:0.8914342629482072\n",
            "4016/4708 - The training loss at 22th epoch : 0.0797902146834641  Training Accuracy:0.8916170634920635\n",
            "4032/4708 - The training loss at 22th epoch : 0.07951810204196194  Training Accuracy:0.8920454545454546\n",
            "4048/4708 - The training loss at 22th epoch : 0.07929656933341103  Training Accuracy:0.8924704724409449\n",
            "4064/4708 - The training loss at 22th epoch : 0.07925837083140631  Training Accuracy:0.8926470588235295\n",
            "4080/4708 - The training loss at 22th epoch : 0.07979654830561773  Training Accuracy:0.891845703125\n",
            "4096/4708 - The training loss at 22th epoch : 0.07956337996451686  Training Accuracy:0.892023346303502\n",
            "4112/4708 - The training loss at 22th epoch : 0.07974903626969433  Training Accuracy:0.8917151162790697\n",
            "4128/4708 - The training loss at 22th epoch : 0.07986209788230579  Training Accuracy:0.8916505791505791\n",
            "4144/4708 - The training loss at 22th epoch : 0.0797037511879568  Training Accuracy:0.8920673076923077\n",
            "4160/4708 - The training loss at 22th epoch : 0.07957384474931418  Training Accuracy:0.8924808429118773\n",
            "4176/4708 - The training loss at 22th epoch : 0.07942029964244891  Training Accuracy:0.8926526717557252\n",
            "4192/4708 - The training loss at 22th epoch : 0.07953751271923999  Training Accuracy:0.8923479087452472\n",
            "4208/4708 - The training loss at 22th epoch : 0.07972590261928317  Training Accuracy:0.892282196969697\n",
            "4224/4708 - The training loss at 22th epoch : 0.07985336840676657  Training Accuracy:0.8919811320754717\n",
            "4240/4708 - The training loss at 22th epoch : 0.07977507822707586  Training Accuracy:0.8921522556390977\n",
            "4256/4708 - The training loss at 22th epoch : 0.07989314791226494  Training Accuracy:0.8918539325842697\n",
            "4272/4708 - The training loss at 22th epoch : 0.07981942807709178  Training Accuracy:0.8917910447761194\n",
            "4288/4708 - The training loss at 22th epoch : 0.07972814494194312  Training Accuracy:0.891728624535316\n",
            "4304/4708 - The training loss at 22th epoch : 0.07954859832709216  Training Accuracy:0.8918981481481482\n",
            "4320/4708 - The training loss at 22th epoch : 0.07948455930060261  Training Accuracy:0.8920664206642066\n",
            "4336/4708 - The training loss at 22th epoch : 0.07941325472496148  Training Accuracy:0.8922334558823529\n",
            "4352/4708 - The training loss at 22th epoch : 0.07958912023169037  Training Accuracy:0.8921703296703297\n",
            "4368/4708 - The training loss at 22th epoch : 0.07963599712969416  Training Accuracy:0.8921076642335767\n",
            "4384/4708 - The training loss at 22th epoch : 0.0795565434814277  Training Accuracy:0.8920454545454546\n",
            "4400/4708 - The training loss at 22th epoch : 0.07961529147666552  Training Accuracy:0.891983695652174\n",
            "4416/4708 - The training loss at 22th epoch : 0.07956056022205131  Training Accuracy:0.8919223826714802\n",
            "4432/4708 - The training loss at 22th epoch : 0.07975532613358888  Training Accuracy:0.8914118705035972\n",
            "4448/4708 - The training loss at 22th epoch : 0.07984977944707143  Training Accuracy:0.891353046594982\n",
            "4464/4708 - The training loss at 22th epoch : 0.07969600622285511  Training Accuracy:0.8917410714285714\n",
            "4480/4708 - The training loss at 22th epoch : 0.07968425331135592  Training Accuracy:0.8916814946619217\n",
            "4496/4708 - The training loss at 22th epoch : 0.07960222862389706  Training Accuracy:0.8918439716312057\n",
            "4512/4708 - The training loss at 22th epoch : 0.0797984113090287  Training Accuracy:0.8915636042402827\n",
            "4528/4708 - The training loss at 22th epoch : 0.07992693540714854  Training Accuracy:0.8915052816901409\n",
            "4544/4708 - The training loss at 22th epoch : 0.0798874397944786  Training Accuracy:0.8914473684210527\n",
            "4560/4708 - The training loss at 22th epoch : 0.07973567883294258  Training Accuracy:0.8916083916083916\n",
            "4576/4708 - The training loss at 22th epoch : 0.07977704217059899  Training Accuracy:0.8915505226480837\n",
            "4592/4708 - The training loss at 22th epoch : 0.07969562149484267  Training Accuracy:0.8917100694444444\n",
            "4608/4708 - The training loss at 22th epoch : 0.07967882449121379  Training Accuracy:0.8916522491349481\n",
            "4624/4708 - The training loss at 22th epoch : 0.07989107628660247  Training Accuracy:0.8913793103448275\n",
            "4640/4708 - The training loss at 22th epoch : 0.07969122120601516  Training Accuracy:0.8917525773195877\n",
            "4656/4708 - The training loss at 22th epoch : 0.07967980180132811  Training Accuracy:0.891695205479452\n",
            "4672/4708 - The training loss at 22th epoch : 0.07942925173972107  Training Accuracy:0.8920648464163823\n",
            "4688/4708 - The training loss at 22th epoch : 0.07955694838637051  Training Accuracy:0.8917942176870748\n",
            "4704/4708 - The training loss at 22th epoch : 0.07955011266275536  Training Accuracy:0.8917372881355933\n",
            "4720/4708 - The training loss at 22th epoch : 0.07973056148230484  Training Accuracy:0.8912584459459459\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 23th epoch : 0.04841402683534782  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 23th epoch : 0.04407234073384448  Training Accuracy:0.96875\n",
            "32/4708 - The training loss at 23th epoch : 0.04195695369026558  Training Accuracy:0.9583333333333334\n",
            "48/4708 - The training loss at 23th epoch : 0.04048106623729632  Training Accuracy:0.96875\n",
            "64/4708 - The training loss at 23th epoch : 0.06374702806005715  Training Accuracy:0.9125\n",
            "80/4708 - The training loss at 23th epoch : 0.061017459317088275  Training Accuracy:0.9166666666666666\n",
            "96/4708 - The training loss at 23th epoch : 0.06628845476877467  Training Accuracy:0.9107142857142857\n",
            "112/4708 - The training loss at 23th epoch : 0.07942256751908394  Training Accuracy:0.890625\n",
            "128/4708 - The training loss at 23th epoch : 0.07818578567914437  Training Accuracy:0.8958333333333334\n",
            "144/4708 - The training loss at 23th epoch : 0.08777162501271253  Training Accuracy:0.8875\n",
            "160/4708 - The training loss at 23th epoch : 0.08594737415572398  Training Accuracy:0.8920454545454546\n",
            "176/4708 - The training loss at 23th epoch : 0.08076618760360713  Training Accuracy:0.9010416666666666\n",
            "192/4708 - The training loss at 23th epoch : 0.0875880525648042  Training Accuracy:0.8894230769230769\n",
            "208/4708 - The training loss at 23th epoch : 0.08362659063525502  Training Accuracy:0.8928571428571429\n",
            "224/4708 - The training loss at 23th epoch : 0.08183770595809167  Training Accuracy:0.8958333333333334\n",
            "240/4708 - The training loss at 23th epoch : 0.07988482520586113  Training Accuracy:0.8984375\n",
            "256/4708 - The training loss at 23th epoch : 0.07559401452182046  Training Accuracy:0.9044117647058824\n",
            "272/4708 - The training loss at 23th epoch : 0.07445065307771388  Training Accuracy:0.9027777777777778\n",
            "288/4708 - The training loss at 23th epoch : 0.07691646550631304  Training Accuracy:0.8980263157894737\n",
            "304/4708 - The training loss at 23th epoch : 0.07339853088568192  Training Accuracy:0.903125\n",
            "320/4708 - The training loss at 23th epoch : 0.07200797977948888  Training Accuracy:0.9077380952380952\n",
            "336/4708 - The training loss at 23th epoch : 0.07098019752074783  Training Accuracy:0.9090909090909091\n",
            "352/4708 - The training loss at 23th epoch : 0.06867089567731426  Training Accuracy:0.9130434782608695\n",
            "368/4708 - The training loss at 23th epoch : 0.07061876865776788  Training Accuracy:0.9114583333333334\n",
            "384/4708 - The training loss at 23th epoch : 0.0708223773791378  Training Accuracy:0.91\n",
            "400/4708 - The training loss at 23th epoch : 0.06824930147701985  Training Accuracy:0.9134615384615384\n",
            "416/4708 - The training loss at 23th epoch : 0.06829414760606783  Training Accuracy:0.9120370370370371\n",
            "432/4708 - The training loss at 23th epoch : 0.06644301074576743  Training Accuracy:0.9151785714285714\n",
            "448/4708 - The training loss at 23th epoch : 0.06750607058085492  Training Accuracy:0.9116379310344828\n",
            "464/4708 - The training loss at 23th epoch : 0.0654983333859362  Training Accuracy:0.9145833333333333\n",
            "480/4708 - The training loss at 23th epoch : 0.0636024609694387  Training Accuracy:0.9173387096774194\n",
            "496/4708 - The training loss at 23th epoch : 0.06577133633695978  Training Accuracy:0.9140625\n",
            "512/4708 - The training loss at 23th epoch : 0.0647814849206525  Training Accuracy:0.9166666666666666\n",
            "528/4708 - The training loss at 23th epoch : 0.06643322529308955  Training Accuracy:0.9136029411764706\n",
            "544/4708 - The training loss at 23th epoch : 0.06604392615160598  Training Accuracy:0.9142857142857143\n",
            "560/4708 - The training loss at 23th epoch : 0.06453172965254142  Training Accuracy:0.9166666666666666\n",
            "576/4708 - The training loss at 23th epoch : 0.06438961610526245  Training Accuracy:0.9172297297297297\n",
            "592/4708 - The training loss at 23th epoch : 0.0649048934156508  Training Accuracy:0.9161184210526315\n",
            "608/4708 - The training loss at 23th epoch : 0.06609157231631663  Training Accuracy:0.9150641025641025\n",
            "624/4708 - The training loss at 23th epoch : 0.06605113012525539  Training Accuracy:0.9140625\n",
            "640/4708 - The training loss at 23th epoch : 0.06740344797417037  Training Accuracy:0.9115853658536586\n",
            "656/4708 - The training loss at 23th epoch : 0.06868656701427583  Training Accuracy:0.9107142857142857\n",
            "672/4708 - The training loss at 23th epoch : 0.07040672414262962  Training Accuracy:0.9084302325581395\n",
            "688/4708 - The training loss at 23th epoch : 0.07130527040351452  Training Accuracy:0.9076704545454546\n",
            "704/4708 - The training loss at 23th epoch : 0.07291613123883657  Training Accuracy:0.9069444444444444\n",
            "720/4708 - The training loss at 23th epoch : 0.07255630158830727  Training Accuracy:0.90625\n",
            "736/4708 - The training loss at 23th epoch : 0.07303393664250707  Training Accuracy:0.9055851063829787\n",
            "752/4708 - The training loss at 23th epoch : 0.07371564223825727  Training Accuracy:0.9049479166666666\n",
            "768/4708 - The training loss at 23th epoch : 0.07310756817090913  Training Accuracy:0.9056122448979592\n",
            "784/4708 - The training loss at 23th epoch : 0.0730396239863963  Training Accuracy:0.90625\n",
            "800/4708 - The training loss at 23th epoch : 0.07376355246590968  Training Accuracy:0.9056372549019608\n",
            "816/4708 - The training loss at 23th epoch : 0.0738022736569331  Training Accuracy:0.9038461538461539\n",
            "832/4708 - The training loss at 23th epoch : 0.07336232597688663  Training Accuracy:0.9033018867924528\n",
            "848/4708 - The training loss at 23th epoch : 0.07443955349802188  Training Accuracy:0.9004629629629629\n",
            "864/4708 - The training loss at 23th epoch : 0.07442447958154386  Training Accuracy:0.9011363636363636\n",
            "880/4708 - The training loss at 23th epoch : 0.07523202382750749  Training Accuracy:0.8995535714285714\n",
            "896/4708 - The training loss at 23th epoch : 0.07547479366126765  Training Accuracy:0.8991228070175439\n",
            "912/4708 - The training loss at 23th epoch : 0.07610799387349541  Training Accuracy:0.8987068965517241\n",
            "928/4708 - The training loss at 23th epoch : 0.07694240440312818  Training Accuracy:0.8983050847457628\n",
            "944/4708 - The training loss at 23th epoch : 0.07582516392608021  Training Accuracy:0.9\n",
            "960/4708 - The training loss at 23th epoch : 0.07570832216188354  Training Accuracy:0.9006147540983607\n",
            "976/4708 - The training loss at 23th epoch : 0.07578293555063603  Training Accuracy:0.9012096774193549\n",
            "992/4708 - The training loss at 23th epoch : 0.07717276803299668  Training Accuracy:0.8988095238095238\n",
            "1008/4708 - The training loss at 23th epoch : 0.07772640382095436  Training Accuracy:0.8984375\n",
            "1024/4708 - The training loss at 23th epoch : 0.07696685754086112  Training Accuracy:0.9\n",
            "1040/4708 - The training loss at 23th epoch : 0.07772315211172134  Training Accuracy:0.8996212121212122\n",
            "1056/4708 - The training loss at 23th epoch : 0.07747971842659998  Training Accuracy:0.9001865671641791\n",
            "1072/4708 - The training loss at 23th epoch : 0.07922416793953203  Training Accuracy:0.8970588235294118\n",
            "1088/4708 - The training loss at 23th epoch : 0.07983904598699686  Training Accuracy:0.8967391304347826\n",
            "1104/4708 - The training loss at 23th epoch : 0.08050189459606905  Training Accuracy:0.8946428571428572\n",
            "1120/4708 - The training loss at 23th epoch : 0.08047045244116645  Training Accuracy:0.8952464788732394\n",
            "1136/4708 - The training loss at 23th epoch : 0.08139974325066263  Training Accuracy:0.8923611111111112\n",
            "1152/4708 - The training loss at 23th epoch : 0.08136526280124279  Training Accuracy:0.8929794520547946\n",
            "1168/4708 - The training loss at 23th epoch : 0.08055168602547083  Training Accuracy:0.8944256756756757\n",
            "1184/4708 - The training loss at 23th epoch : 0.08021806497499329  Training Accuracy:0.895\n",
            "1200/4708 - The training loss at 23th epoch : 0.07977308362123418  Training Accuracy:0.8955592105263158\n",
            "1216/4708 - The training loss at 23th epoch : 0.08029225889210896  Training Accuracy:0.8952922077922078\n",
            "1232/4708 - The training loss at 23th epoch : 0.07963332442389243  Training Accuracy:0.8958333333333334\n",
            "1248/4708 - The training loss at 23th epoch : 0.08031109973105062  Training Accuracy:0.8939873417721519\n",
            "1264/4708 - The training loss at 23th epoch : 0.07956862700194231  Training Accuracy:0.8953125\n",
            "1280/4708 - The training loss at 23th epoch : 0.07866879521257074  Training Accuracy:0.8966049382716049\n",
            "1296/4708 - The training loss at 23th epoch : 0.07917386611584244  Training Accuracy:0.8963414634146342\n",
            "1312/4708 - The training loss at 23th epoch : 0.07947374642787729  Training Accuracy:0.8960843373493976\n",
            "1328/4708 - The training loss at 23th epoch : 0.0797286378806334  Training Accuracy:0.8950892857142857\n",
            "1344/4708 - The training loss at 23th epoch : 0.08009538733408389  Training Accuracy:0.8941176470588236\n",
            "1360/4708 - The training loss at 23th epoch : 0.07980946388984365  Training Accuracy:0.8938953488372093\n",
            "1376/4708 - The training loss at 23th epoch : 0.07929319664129549  Training Accuracy:0.8951149425287356\n",
            "1392/4708 - The training loss at 23th epoch : 0.07850542957209367  Training Accuracy:0.8963068181818182\n",
            "1408/4708 - The training loss at 23th epoch : 0.07854343013427127  Training Accuracy:0.8960674157303371\n",
            "1424/4708 - The training loss at 23th epoch : 0.07899002051532818  Training Accuracy:0.8951388888888889\n",
            "1440/4708 - The training loss at 23th epoch : 0.07903535093890075  Training Accuracy:0.8949175824175825\n",
            "1456/4708 - The training loss at 23th epoch : 0.07891805668906962  Training Accuracy:0.8953804347826086\n",
            "1472/4708 - The training loss at 23th epoch : 0.07956483068599883  Training Accuracy:0.8951612903225806\n",
            "1488/4708 - The training loss at 23th epoch : 0.0791593283559536  Training Accuracy:0.8956117021276596\n",
            "1504/4708 - The training loss at 23th epoch : 0.07976540145446581  Training Accuracy:0.8947368421052632\n",
            "1520/4708 - The training loss at 23th epoch : 0.07989328982897038  Training Accuracy:0.89453125\n",
            "1536/4708 - The training loss at 23th epoch : 0.0795182483113848  Training Accuracy:0.895618556701031\n",
            "1552/4708 - The training loss at 23th epoch : 0.08025219662342255  Training Accuracy:0.8947704081632653\n",
            "1568/4708 - The training loss at 23th epoch : 0.0805173389498732  Training Accuracy:0.8945707070707071\n",
            "1584/4708 - The training loss at 23th epoch : 0.08052135799854997  Training Accuracy:0.894375\n",
            "1600/4708 - The training loss at 23th epoch : 0.08013461166522418  Training Accuracy:0.8948019801980198\n",
            "1616/4708 - The training loss at 23th epoch : 0.07958930338140972  Training Accuracy:0.8958333333333334\n",
            "1632/4708 - The training loss at 23th epoch : 0.07985198505868217  Training Accuracy:0.8950242718446602\n",
            "1648/4708 - The training loss at 23th epoch : 0.0796105367266334  Training Accuracy:0.8960336538461539\n",
            "1664/4708 - The training loss at 23th epoch : 0.08051946479914099  Training Accuracy:0.8940476190476191\n",
            "1680/4708 - The training loss at 23th epoch : 0.08055167571709107  Training Accuracy:0.8938679245283019\n",
            "1696/4708 - The training loss at 23th epoch : 0.08079120037680948  Training Accuracy:0.8936915887850467\n",
            "1712/4708 - The training loss at 23th epoch : 0.08094161007820834  Training Accuracy:0.8935185185185185\n",
            "1728/4708 - The training loss at 23th epoch : 0.08096788623110711  Training Accuracy:0.893348623853211\n",
            "1744/4708 - The training loss at 23th epoch : 0.08100951474950227  Training Accuracy:0.8931818181818182\n",
            "1760/4708 - The training loss at 23th epoch : 0.08161222720382963  Training Accuracy:0.8918918918918919\n",
            "1776/4708 - The training loss at 23th epoch : 0.08096666522964248  Training Accuracy:0.8928571428571429\n",
            "1792/4708 - The training loss at 23th epoch : 0.08116354728392447  Training Accuracy:0.8921460176991151\n",
            "1808/4708 - The training loss at 23th epoch : 0.08094537031809101  Training Accuracy:0.8925438596491229\n",
            "1824/4708 - The training loss at 23th epoch : 0.08029856958147194  Training Accuracy:0.8934782608695652\n",
            "1840/4708 - The training loss at 23th epoch : 0.08066196235825383  Training Accuracy:0.8922413793103449\n",
            "1856/4708 - The training loss at 23th epoch : 0.08109083788114672  Training Accuracy:0.8915598290598291\n",
            "1872/4708 - The training loss at 23th epoch : 0.0811066083521425  Training Accuracy:0.8914194915254238\n",
            "1888/4708 - The training loss at 23th epoch : 0.08088423296535273  Training Accuracy:0.8918067226890757\n",
            "1904/4708 - The training loss at 23th epoch : 0.08121272369026288  Training Accuracy:0.8916666666666667\n",
            "1920/4708 - The training loss at 23th epoch : 0.08089560305880013  Training Accuracy:0.8920454545454546\n",
            "1936/4708 - The training loss at 23th epoch : 0.08057794829271418  Training Accuracy:0.8924180327868853\n",
            "1952/4708 - The training loss at 23th epoch : 0.08046644035119498  Training Accuracy:0.8932926829268293\n",
            "1968/4708 - The training loss at 23th epoch : 0.08073253325881563  Training Accuracy:0.8926411290322581\n",
            "1984/4708 - The training loss at 23th epoch : 0.08099586226626251  Training Accuracy:0.892\n",
            "2000/4708 - The training loss at 23th epoch : 0.08129794921746362  Training Accuracy:0.8913690476190477\n",
            "2016/4708 - The training loss at 23th epoch : 0.08134090978950324  Training Accuracy:0.8912401574803149\n",
            "2032/4708 - The training loss at 23th epoch : 0.08113581141765416  Training Accuracy:0.8916015625\n",
            "2048/4708 - The training loss at 23th epoch : 0.0810815247906453  Training Accuracy:0.8914728682170543\n",
            "2064/4708 - The training loss at 23th epoch : 0.08126823248543984  Training Accuracy:0.8913461538461539\n",
            "2080/4708 - The training loss at 23th epoch : 0.08070958654362155  Training Accuracy:0.892175572519084\n",
            "2096/4708 - The training loss at 23th epoch : 0.08114800350538813  Training Accuracy:0.8915719696969697\n",
            "2112/4708 - The training loss at 23th epoch : 0.08181478553762996  Training Accuracy:0.8900375939849624\n",
            "2128/4708 - The training loss at 23th epoch : 0.08174020590962067  Training Accuracy:0.8903917910447762\n",
            "2144/4708 - The training loss at 23th epoch : 0.08168344105229901  Training Accuracy:0.8902777777777777\n",
            "2160/4708 - The training loss at 23th epoch : 0.08201135500182725  Training Accuracy:0.8897058823529411\n",
            "2176/4708 - The training loss at 23th epoch : 0.08245620014417292  Training Accuracy:0.8891423357664233\n",
            "2192/4708 - The training loss at 23th epoch : 0.08205305311162815  Training Accuracy:0.8894927536231884\n",
            "2208/4708 - The training loss at 23th epoch : 0.08241968646806551  Training Accuracy:0.8889388489208633\n",
            "2224/4708 - The training loss at 23th epoch : 0.08194077621858775  Training Accuracy:0.8897321428571429\n",
            "2240/4708 - The training loss at 23th epoch : 0.0828225108518643  Training Accuracy:0.8887411347517731\n",
            "2256/4708 - The training loss at 23th epoch : 0.0826530514458783  Training Accuracy:0.8886443661971831\n",
            "2272/4708 - The training loss at 23th epoch : 0.08284553525637678  Training Accuracy:0.8881118881118881\n",
            "2288/4708 - The training loss at 23th epoch : 0.08274576384330187  Training Accuracy:0.8884548611111112\n",
            "2304/4708 - The training loss at 23th epoch : 0.08257644822723019  Training Accuracy:0.8887931034482759\n",
            "2320/4708 - The training loss at 23th epoch : 0.08225057640548199  Training Accuracy:0.8891267123287672\n",
            "2336/4708 - The training loss at 23th epoch : 0.08205118735627785  Training Accuracy:0.8894557823129252\n",
            "2352/4708 - The training loss at 23th epoch : 0.08171384387896485  Training Accuracy:0.8897804054054054\n",
            "2368/4708 - The training loss at 23th epoch : 0.08156946452485059  Training Accuracy:0.8896812080536913\n",
            "2384/4708 - The training loss at 23th epoch : 0.0812714674328612  Training Accuracy:0.89\n",
            "2400/4708 - The training loss at 23th epoch : 0.08132407149191509  Training Accuracy:0.8899006622516556\n",
            "2416/4708 - The training loss at 23th epoch : 0.08121292298770051  Training Accuracy:0.8898026315789473\n",
            "2432/4708 - The training loss at 23th epoch : 0.08074125493181707  Training Accuracy:0.8905228758169934\n",
            "2448/4708 - The training loss at 23th epoch : 0.08070617618669035  Training Accuracy:0.890422077922078\n",
            "2464/4708 - The training loss at 23th epoch : 0.080389081732597  Training Accuracy:0.8907258064516129\n",
            "2480/4708 - The training loss at 23th epoch : 0.08091736591913644  Training Accuracy:0.8902243589743589\n",
            "2496/4708 - The training loss at 23th epoch : 0.0804792106550902  Training Accuracy:0.8909235668789809\n",
            "2512/4708 - The training loss at 23th epoch : 0.0799842957444778  Training Accuracy:0.8916139240506329\n",
            "2528/4708 - The training loss at 23th epoch : 0.07976449110628997  Training Accuracy:0.8919025157232704\n",
            "2544/4708 - The training loss at 23th epoch : 0.07999501312004642  Training Accuracy:0.891015625\n",
            "2560/4708 - The training loss at 23th epoch : 0.0799247210703439  Training Accuracy:0.8913043478260869\n",
            "2576/4708 - The training loss at 23th epoch : 0.07963551830223561  Training Accuracy:0.8915895061728395\n",
            "2592/4708 - The training loss at 23th epoch : 0.07957207429597056  Training Accuracy:0.8918711656441718\n",
            "2608/4708 - The training loss at 23th epoch : 0.07971267814682227  Training Accuracy:0.8917682926829268\n",
            "2624/4708 - The training loss at 23th epoch : 0.0794327584038051  Training Accuracy:0.8920454545454546\n",
            "2640/4708 - The training loss at 23th epoch : 0.07906255651262371  Training Accuracy:0.8926957831325302\n",
            "2656/4708 - The training loss at 23th epoch : 0.07973966349083599  Training Accuracy:0.8918413173652695\n",
            "2672/4708 - The training loss at 23th epoch : 0.0797288192324829  Training Accuracy:0.8917410714285714\n",
            "2688/4708 - The training loss at 23th epoch : 0.07956699500735487  Training Accuracy:0.8916420118343196\n",
            "2704/4708 - The training loss at 23th epoch : 0.0791978891755105  Training Accuracy:0.8922794117647059\n",
            "2720/4708 - The training loss at 23th epoch : 0.07928252940886188  Training Accuracy:0.8921783625730995\n",
            "2736/4708 - The training loss at 23th epoch : 0.07918168542723818  Training Accuracy:0.8924418604651163\n",
            "2752/4708 - The training loss at 23th epoch : 0.07890972331702215  Training Accuracy:0.8927023121387283\n",
            "2768/4708 - The training loss at 23th epoch : 0.07871371156067722  Training Accuracy:0.8929597701149425\n",
            "2784/4708 - The training loss at 23th epoch : 0.07836721557589756  Training Accuracy:0.8935714285714286\n",
            "2800/4708 - The training loss at 23th epoch : 0.07825908834575089  Training Accuracy:0.8938210227272727\n",
            "2816/4708 - The training loss at 23th epoch : 0.07835970727599759  Training Accuracy:0.8937146892655368\n",
            "2832/4708 - The training loss at 23th epoch : 0.07886807175538714  Training Accuracy:0.8932584269662921\n",
            "2848/4708 - The training loss at 23th epoch : 0.07845007537385268  Training Accuracy:0.8938547486033519\n",
            "2864/4708 - The training loss at 23th epoch : 0.07857694117358438  Training Accuracy:0.89375\n",
            "2880/4708 - The training loss at 23th epoch : 0.07829054981629491  Training Accuracy:0.8939917127071824\n",
            "2896/4708 - The training loss at 23th epoch : 0.07834043190670388  Training Accuracy:0.8938873626373627\n",
            "2912/4708 - The training loss at 23th epoch : 0.07847073631502008  Training Accuracy:0.8934426229508197\n",
            "2928/4708 - The training loss at 23th epoch : 0.07811076247539195  Training Accuracy:0.8940217391304348\n",
            "2944/4708 - The training loss at 23th epoch : 0.0779991545569312  Training Accuracy:0.893918918918919\n",
            "2960/4708 - The training loss at 23th epoch : 0.07809577626898055  Training Accuracy:0.8938172043010753\n",
            "2976/4708 - The training loss at 23th epoch : 0.07861238440271373  Training Accuracy:0.893048128342246\n",
            "2992/4708 - The training loss at 23th epoch : 0.07820835413539629  Training Accuracy:0.8936170212765957\n",
            "3008/4708 - The training loss at 23th epoch : 0.07811935593763546  Training Accuracy:0.8935185185185185\n",
            "3024/4708 - The training loss at 23th epoch : 0.07785846579322214  Training Accuracy:0.89375\n",
            "3040/4708 - The training loss at 23th epoch : 0.07768283401134346  Training Accuracy:0.893979057591623\n",
            "3056/4708 - The training loss at 23th epoch : 0.0774330401330884  Training Accuracy:0.89453125\n",
            "3072/4708 - The training loss at 23th epoch : 0.07749707876809842  Training Accuracy:0.8944300518134715\n",
            "3088/4708 - The training loss at 23th epoch : 0.07765104148937398  Training Accuracy:0.8940077319587629\n",
            "3104/4708 - The training loss at 23th epoch : 0.07735044780096542  Training Accuracy:0.8945512820512821\n",
            "3120/4708 - The training loss at 23th epoch : 0.07697158538579774  Training Accuracy:0.8950892857142857\n",
            "3136/4708 - The training loss at 23th epoch : 0.07711325593862264  Training Accuracy:0.8949873096446701\n",
            "3152/4708 - The training loss at 23th epoch : 0.07733206246022206  Training Accuracy:0.8945707070707071\n",
            "3168/4708 - The training loss at 23th epoch : 0.07751041874804998  Training Accuracy:0.8941582914572864\n",
            "3184/4708 - The training loss at 23th epoch : 0.07742527829349033  Training Accuracy:0.894375\n",
            "3200/4708 - The training loss at 23th epoch : 0.07706878188578477  Training Accuracy:0.8949004975124378\n",
            "3216/4708 - The training loss at 23th epoch : 0.0773055120835348  Training Accuracy:0.8948019801980198\n",
            "3232/4708 - The training loss at 23th epoch : 0.07735727177885392  Training Accuracy:0.8947044334975369\n",
            "3248/4708 - The training loss at 23th epoch : 0.07708648983218969  Training Accuracy:0.8952205882352942\n",
            "3264/4708 - The training loss at 23th epoch : 0.07709298258044528  Training Accuracy:0.8951219512195122\n",
            "3280/4708 - The training loss at 23th epoch : 0.07703639285150578  Training Accuracy:0.8953276699029126\n",
            "3296/4708 - The training loss at 23th epoch : 0.07669657414336753  Training Accuracy:0.8958333333333334\n",
            "3312/4708 - The training loss at 23th epoch : 0.07699777882951048  Training Accuracy:0.8954326923076923\n",
            "3328/4708 - The training loss at 23th epoch : 0.07708734247922314  Training Accuracy:0.8953349282296651\n",
            "3344/4708 - The training loss at 23th epoch : 0.07750640921299795  Training Accuracy:0.8949404761904762\n",
            "3360/4708 - The training loss at 23th epoch : 0.077579504132963  Training Accuracy:0.8951421800947867\n",
            "3376/4708 - The training loss at 23th epoch : 0.0781288918237469  Training Accuracy:0.8941627358490566\n",
            "3392/4708 - The training loss at 23th epoch : 0.0781580861812876  Training Accuracy:0.8940727699530516\n",
            "3408/4708 - The training loss at 23th epoch : 0.07815022291702119  Training Accuracy:0.8936915887850467\n",
            "3424/4708 - The training loss at 23th epoch : 0.07814985390552955  Training Accuracy:0.8938953488372093\n",
            "3440/4708 - The training loss at 23th epoch : 0.07827465658700326  Training Accuracy:0.8938078703703703\n",
            "3456/4708 - The training loss at 23th epoch : 0.07793648371211236  Training Accuracy:0.8942972350230415\n",
            "3472/4708 - The training loss at 23th epoch : 0.0778910959607368  Training Accuracy:0.8944954128440367\n",
            "3488/4708 - The training loss at 23th epoch : 0.07812482096199772  Training Accuracy:0.89412100456621\n",
            "3504/4708 - The training loss at 23th epoch : 0.07826886953332717  Training Accuracy:0.8934659090909091\n",
            "3520/4708 - The training loss at 23th epoch : 0.0781544427320124  Training Accuracy:0.8936651583710408\n",
            "3536/4708 - The training loss at 23th epoch : 0.07826994314445772  Training Accuracy:0.893581081081081\n",
            "3552/4708 - The training loss at 23th epoch : 0.07833470335718108  Training Accuracy:0.8937780269058296\n",
            "3568/4708 - The training loss at 23th epoch : 0.07834691290309481  Training Accuracy:0.8936941964285714\n",
            "3584/4708 - The training loss at 23th epoch : 0.07846422313959923  Training Accuracy:0.8936111111111111\n",
            "3600/4708 - The training loss at 23th epoch : 0.07892690272034816  Training Accuracy:0.8929756637168141\n",
            "3616/4708 - The training loss at 23th epoch : 0.07910697391363816  Training Accuracy:0.8923458149779736\n",
            "3632/4708 - The training loss at 23th epoch : 0.07914527792740135  Training Accuracy:0.8922697368421053\n",
            "3648/4708 - The training loss at 23th epoch : 0.07911763367663227  Training Accuracy:0.8921943231441049\n",
            "3664/4708 - The training loss at 23th epoch : 0.07883173351896518  Training Accuracy:0.8926630434782609\n",
            "3680/4708 - The training loss at 23th epoch : 0.07886642225148702  Training Accuracy:0.8925865800865801\n",
            "3696/4708 - The training loss at 23th epoch : 0.07860999998442406  Training Accuracy:0.8930495689655172\n",
            "3712/4708 - The training loss at 23th epoch : 0.07853898291125919  Training Accuracy:0.8932403433476395\n",
            "3728/4708 - The training loss at 23th epoch : 0.07853374572713094  Training Accuracy:0.8934294871794872\n",
            "3744/4708 - The training loss at 23th epoch : 0.07827762415355963  Training Accuracy:0.8938829787234043\n",
            "3760/4708 - The training loss at 23th epoch : 0.07847963273634312  Training Accuracy:0.8935381355932204\n",
            "3776/4708 - The training loss at 23th epoch : 0.07822311421459349  Training Accuracy:0.8939873417721519\n",
            "3792/4708 - The training loss at 23th epoch : 0.07821161327198367  Training Accuracy:0.8939075630252101\n",
            "3808/4708 - The training loss at 23th epoch : 0.07813139523667591  Training Accuracy:0.8938284518828452\n",
            "3824/4708 - The training loss at 23th epoch : 0.07896199253972042  Training Accuracy:0.8924479166666667\n",
            "3840/4708 - The training loss at 23th epoch : 0.07930463573311494  Training Accuracy:0.891597510373444\n",
            "3856/4708 - The training loss at 23th epoch : 0.0794029701392066  Training Accuracy:0.8915289256198347\n",
            "3872/4708 - The training loss at 23th epoch : 0.07947295999864855  Training Accuracy:0.8914609053497943\n",
            "3888/4708 - The training loss at 23th epoch : 0.07940734001218842  Training Accuracy:0.8916495901639344\n",
            "3904/4708 - The training loss at 23th epoch : 0.0792895929452646  Training Accuracy:0.8918367346938776\n",
            "3920/4708 - The training loss at 23th epoch : 0.07918281619782155  Training Accuracy:0.8920223577235772\n",
            "3936/4708 - The training loss at 23th epoch : 0.07894676596167241  Training Accuracy:0.8924595141700404\n",
            "3952/4708 - The training loss at 23th epoch : 0.07884963865069639  Training Accuracy:0.8926411290322581\n",
            "3968/4708 - The training loss at 23th epoch : 0.07901807792876626  Training Accuracy:0.892570281124498\n",
            "3984/4708 - The training loss at 23th epoch : 0.07874013542189869  Training Accuracy:0.893\n",
            "4000/4708 - The training loss at 23th epoch : 0.07935235180268814  Training Accuracy:0.8921812749003984\n",
            "4016/4708 - The training loss at 23th epoch : 0.07951949376322338  Training Accuracy:0.8918650793650794\n",
            "4032/4708 - The training loss at 23th epoch : 0.07968558849318932  Training Accuracy:0.8915513833992095\n",
            "4048/4708 - The training loss at 23th epoch : 0.07975646545603202  Training Accuracy:0.891486220472441\n",
            "4064/4708 - The training loss at 23th epoch : 0.07982752826208973  Training Accuracy:0.8911764705882353\n",
            "4080/4708 - The training loss at 23th epoch : 0.07956724065160825  Training Accuracy:0.8916015625\n",
            "4096/4708 - The training loss at 23th epoch : 0.0794397059896102  Training Accuracy:0.8917801556420234\n",
            "4112/4708 - The training loss at 23th epoch : 0.07925289120524494  Training Accuracy:0.8919573643410853\n",
            "4128/4708 - The training loss at 23th epoch : 0.07963901556724286  Training Accuracy:0.8914092664092664\n",
            "4144/4708 - The training loss at 23th epoch : 0.08001812796454463  Training Accuracy:0.890625\n",
            "4160/4708 - The training loss at 23th epoch : 0.08000144035672098  Training Accuracy:0.8905651340996169\n",
            "4176/4708 - The training loss at 23th epoch : 0.0800245596947928  Training Accuracy:0.8905057251908397\n",
            "4192/4708 - The training loss at 23th epoch : 0.08008269360110548  Training Accuracy:0.8904467680608364\n",
            "4208/4708 - The training loss at 23th epoch : 0.08036283250509874  Training Accuracy:0.8901515151515151\n",
            "4224/4708 - The training loss at 23th epoch : 0.08064971152844709  Training Accuracy:0.8898584905660377\n",
            "4240/4708 - The training loss at 23th epoch : 0.08063147935015857  Training Accuracy:0.8898026315789473\n",
            "4256/4708 - The training loss at 23th epoch : 0.08057929535015598  Training Accuracy:0.8899812734082397\n",
            "4272/4708 - The training loss at 23th epoch : 0.08055997506129572  Training Accuracy:0.8901585820895522\n",
            "4288/4708 - The training loss at 23th epoch : 0.08029317325942181  Training Accuracy:0.8905669144981413\n",
            "4304/4708 - The training loss at 23th epoch : 0.08008834483288561  Training Accuracy:0.8909722222222223\n",
            "4320/4708 - The training loss at 23th epoch : 0.0801323835738183  Training Accuracy:0.8906826568265682\n",
            "4336/4708 - The training loss at 23th epoch : 0.08027515878563767  Training Accuracy:0.890625\n",
            "4352/4708 - The training loss at 23th epoch : 0.08028697924458711  Training Accuracy:0.8905677655677655\n",
            "4368/4708 - The training loss at 23th epoch : 0.08010615789725156  Training Accuracy:0.8909671532846716\n",
            "4384/4708 - The training loss at 23th epoch : 0.07992385410792277  Training Accuracy:0.8913636363636364\n",
            "4400/4708 - The training loss at 23th epoch : 0.07985043465791425  Training Accuracy:0.8915307971014492\n",
            "4416/4708 - The training loss at 23th epoch : 0.07986208757814897  Training Accuracy:0.891245487364621\n",
            "4432/4708 - The training loss at 23th epoch : 0.07971522261448542  Training Accuracy:0.891636690647482\n",
            "4448/4708 - The training loss at 23th epoch : 0.07962339375382499  Training Accuracy:0.8915770609318996\n",
            "4464/4708 - The training loss at 23th epoch : 0.0796038619167848  Training Accuracy:0.8915178571428571\n",
            "4480/4708 - The training loss at 23th epoch : 0.07956133570697524  Training Accuracy:0.8916814946619217\n",
            "4496/4708 - The training loss at 23th epoch : 0.07930074476646101  Training Accuracy:0.8920656028368794\n",
            "4512/4708 - The training loss at 23th epoch : 0.07926118636484149  Training Accuracy:0.8920053003533569\n",
            "4528/4708 - The training loss at 23th epoch : 0.07948617789075868  Training Accuracy:0.891725352112676\n",
            "4544/4708 - The training loss at 23th epoch : 0.07941174822694679  Training Accuracy:0.8918859649122807\n",
            "4560/4708 - The training loss at 23th epoch : 0.07914797613873154  Training Accuracy:0.892263986013986\n",
            "4576/4708 - The training loss at 23th epoch : 0.0789078350692988  Training Accuracy:0.8926393728222997\n",
            "4592/4708 - The training loss at 23th epoch : 0.07883866901895543  Training Accuracy:0.8927951388888888\n",
            "4608/4708 - The training loss at 23th epoch : 0.07902919186375568  Training Accuracy:0.8925173010380623\n",
            "4624/4708 - The training loss at 23th epoch : 0.07900437605639249  Training Accuracy:0.8926724137931035\n",
            "4640/4708 - The training loss at 23th epoch : 0.07907361426909586  Training Accuracy:0.8926116838487973\n",
            "4656/4708 - The training loss at 23th epoch : 0.07911194270027311  Training Accuracy:0.8925513698630136\n",
            "4672/4708 - The training loss at 23th epoch : 0.07912869374146003  Training Accuracy:0.8924914675767918\n",
            "4688/4708 - The training loss at 23th epoch : 0.07894661155918763  Training Accuracy:0.8928571428571429\n",
            "4704/4708 - The training loss at 23th epoch : 0.0792179112612556  Training Accuracy:0.8925847457627119\n",
            "4720/4708 - The training loss at 23th epoch : 0.07910014531037894  Training Accuracy:0.8927364864864865\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 24th epoch : 0.029265902635966803  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 24th epoch : 0.022030056593932257  Training Accuracy:0.96875\n",
            "32/4708 - The training loss at 24th epoch : 0.03945276387037021  Training Accuracy:0.9375\n",
            "48/4708 - The training loss at 24th epoch : 0.05087048445055181  Training Accuracy:0.921875\n",
            "64/4708 - The training loss at 24th epoch : 0.0656216580199512  Training Accuracy:0.9\n",
            "80/4708 - The training loss at 24th epoch : 0.063928581019643  Training Accuracy:0.90625\n",
            "96/4708 - The training loss at 24th epoch : 0.077581483467282  Training Accuracy:0.8928571428571429\n",
            "112/4708 - The training loss at 24th epoch : 0.08344581258692586  Training Accuracy:0.8828125\n",
            "128/4708 - The training loss at 24th epoch : 0.07459927695173997  Training Accuracy:0.8958333333333334\n",
            "144/4708 - The training loss at 24th epoch : 0.0771894329790048  Training Accuracy:0.89375\n",
            "160/4708 - The training loss at 24th epoch : 0.07447882691928892  Training Accuracy:0.9034090909090909\n",
            "176/4708 - The training loss at 24th epoch : 0.07359275890837079  Training Accuracy:0.90625\n",
            "192/4708 - The training loss at 24th epoch : 0.07568286845499216  Training Accuracy:0.8990384615384616\n",
            "208/4708 - The training loss at 24th epoch : 0.0730155555108956  Training Accuracy:0.9017857142857143\n",
            "224/4708 - The training loss at 24th epoch : 0.0722763020088766  Training Accuracy:0.9041666666666667\n",
            "240/4708 - The training loss at 24th epoch : 0.07462182665475302  Training Accuracy:0.8984375\n",
            "256/4708 - The training loss at 24th epoch : 0.07259460627491031  Training Accuracy:0.9007352941176471\n",
            "272/4708 - The training loss at 24th epoch : 0.0699583824308022  Training Accuracy:0.9027777777777778\n",
            "288/4708 - The training loss at 24th epoch : 0.07041190599989484  Training Accuracy:0.9013157894736842\n",
            "304/4708 - The training loss at 24th epoch : 0.07061190919853494  Training Accuracy:0.903125\n",
            "320/4708 - The training loss at 24th epoch : 0.07409900402610252  Training Accuracy:0.8958333333333334\n",
            "336/4708 - The training loss at 24th epoch : 0.07513946011080984  Training Accuracy:0.8948863636363636\n",
            "352/4708 - The training loss at 24th epoch : 0.0759719200736385  Training Accuracy:0.8940217391304348\n",
            "368/4708 - The training loss at 24th epoch : 0.07478700360684765  Training Accuracy:0.8932291666666666\n",
            "384/4708 - The training loss at 24th epoch : 0.07671613487741012  Training Accuracy:0.89\n",
            "400/4708 - The training loss at 24th epoch : 0.07497703858846616  Training Accuracy:0.8918269230769231\n",
            "416/4708 - The training loss at 24th epoch : 0.07249184179923365  Training Accuracy:0.8958333333333334\n",
            "432/4708 - The training loss at 24th epoch : 0.073625990058103  Training Accuracy:0.8928571428571429\n",
            "448/4708 - The training loss at 24th epoch : 0.07224670228538335  Training Accuracy:0.8943965517241379\n",
            "464/4708 - The training loss at 24th epoch : 0.07465221573171199  Training Accuracy:0.8916666666666667\n",
            "480/4708 - The training loss at 24th epoch : 0.07404333636248224  Training Accuracy:0.8931451612903226\n",
            "496/4708 - The training loss at 24th epoch : 0.07898655620076922  Training Accuracy:0.8828125\n",
            "512/4708 - The training loss at 24th epoch : 0.080374813493121  Training Accuracy:0.8825757575757576\n",
            "528/4708 - The training loss at 24th epoch : 0.08209606769998422  Training Accuracy:0.8768382352941176\n",
            "544/4708 - The training loss at 24th epoch : 0.082221399336236  Training Accuracy:0.8785714285714286\n",
            "560/4708 - The training loss at 24th epoch : 0.08260706437332338  Training Accuracy:0.8802083333333334\n",
            "576/4708 - The training loss at 24th epoch : 0.08234575965561522  Training Accuracy:0.8800675675675675\n",
            "592/4708 - The training loss at 24th epoch : 0.0814672445895475  Training Accuracy:0.881578947368421\n",
            "608/4708 - The training loss at 24th epoch : 0.08214219607548737  Training Accuracy:0.8798076923076923\n",
            "624/4708 - The training loss at 24th epoch : 0.08359523626638007  Training Accuracy:0.878125\n",
            "640/4708 - The training loss at 24th epoch : 0.08666994897974765  Training Accuracy:0.875\n",
            "656/4708 - The training loss at 24th epoch : 0.08591108546842874  Training Accuracy:0.8764880952380952\n",
            "672/4708 - The training loss at 24th epoch : 0.0891747350607739  Training Accuracy:0.873546511627907\n",
            "688/4708 - The training loss at 24th epoch : 0.09047712192241474  Training Accuracy:0.8707386363636364\n",
            "704/4708 - The training loss at 24th epoch : 0.08977592760810102  Training Accuracy:0.8722222222222222\n",
            "720/4708 - The training loss at 24th epoch : 0.0889213363041529  Training Accuracy:0.873641304347826\n",
            "736/4708 - The training loss at 24th epoch : 0.08849267048522794  Training Accuracy:0.875\n",
            "752/4708 - The training loss at 24th epoch : 0.0901760978785024  Training Accuracy:0.8723958333333334\n",
            "768/4708 - The training loss at 24th epoch : 0.08939619994531015  Training Accuracy:0.875\n",
            "784/4708 - The training loss at 24th epoch : 0.09095554193955913  Training Accuracy:0.87375\n",
            "800/4708 - The training loss at 24th epoch : 0.09151150097373423  Training Accuracy:0.8737745098039216\n",
            "816/4708 - The training loss at 24th epoch : 0.09146838559383373  Training Accuracy:0.8737980769230769\n",
            "832/4708 - The training loss at 24th epoch : 0.09002544559861786  Training Accuracy:0.8761792452830188\n",
            "848/4708 - The training loss at 24th epoch : 0.09015733116633709  Training Accuracy:0.8761574074074074\n",
            "864/4708 - The training loss at 24th epoch : 0.08942355143774067  Training Accuracy:0.8772727272727273\n",
            "880/4708 - The training loss at 24th epoch : 0.08812942696275565  Training Accuracy:0.8794642857142857\n",
            "896/4708 - The training loss at 24th epoch : 0.08742907405759363  Training Accuracy:0.8804824561403509\n",
            "912/4708 - The training loss at 24th epoch : 0.08874167671180533  Training Accuracy:0.8782327586206896\n",
            "928/4708 - The training loss at 24th epoch : 0.08985892500757117  Training Accuracy:0.8771186440677966\n",
            "944/4708 - The training loss at 24th epoch : 0.0892018812380307  Training Accuracy:0.878125\n",
            "960/4708 - The training loss at 24th epoch : 0.08987483706083195  Training Accuracy:0.8780737704918032\n",
            "976/4708 - The training loss at 24th epoch : 0.08870758903698137  Training Accuracy:0.8800403225806451\n",
            "992/4708 - The training loss at 24th epoch : 0.08860832804439975  Training Accuracy:0.8799603174603174\n",
            "1008/4708 - The training loss at 24th epoch : 0.08738989157883528  Training Accuracy:0.8818359375\n",
            "1024/4708 - The training loss at 24th epoch : 0.08706283615925964  Training Accuracy:0.8817307692307692\n",
            "1040/4708 - The training loss at 24th epoch : 0.0871686107662706  Training Accuracy:0.8816287878787878\n",
            "1056/4708 - The training loss at 24th epoch : 0.0879026805738913  Training Accuracy:0.8805970149253731\n",
            "1072/4708 - The training loss at 24th epoch : 0.08671221962378099  Training Accuracy:0.8823529411764706\n",
            "1088/4708 - The training loss at 24th epoch : 0.0855318141879519  Training Accuracy:0.8840579710144928\n",
            "1104/4708 - The training loss at 24th epoch : 0.0850739974929872  Training Accuracy:0.8848214285714285\n",
            "1120/4708 - The training loss at 24th epoch : 0.08463673954648934  Training Accuracy:0.8855633802816901\n",
            "1136/4708 - The training loss at 24th epoch : 0.08394402956102098  Training Accuracy:0.8862847222222222\n",
            "1152/4708 - The training loss at 24th epoch : 0.08344684023773768  Training Accuracy:0.886986301369863\n",
            "1168/4708 - The training loss at 24th epoch : 0.08297641341222664  Training Accuracy:0.8868243243243243\n",
            "1184/4708 - The training loss at 24th epoch : 0.08438565473731476  Training Accuracy:0.8841666666666667\n",
            "1200/4708 - The training loss at 24th epoch : 0.08337954422334933  Training Accuracy:0.8856907894736842\n",
            "1216/4708 - The training loss at 24th epoch : 0.08281007366288957  Training Accuracy:0.8863636363636364\n",
            "1232/4708 - The training loss at 24th epoch : 0.08197613601189224  Training Accuracy:0.8878205128205128\n",
            "1248/4708 - The training loss at 24th epoch : 0.08122003876228158  Training Accuracy:0.8884493670886076\n",
            "1264/4708 - The training loss at 24th epoch : 0.0809376011115928  Training Accuracy:0.8890625\n",
            "1280/4708 - The training loss at 24th epoch : 0.08071113703679378  Training Accuracy:0.8896604938271605\n",
            "1296/4708 - The training loss at 24th epoch : 0.08100205334610729  Training Accuracy:0.8894817073170732\n",
            "1312/4708 - The training loss at 24th epoch : 0.08107509398538452  Training Accuracy:0.8893072289156626\n",
            "1328/4708 - The training loss at 24th epoch : 0.08016950087667138  Training Accuracy:0.890625\n",
            "1344/4708 - The training loss at 24th epoch : 0.07999532755048709  Training Accuracy:0.8911764705882353\n",
            "1360/4708 - The training loss at 24th epoch : 0.08088331615071763  Training Accuracy:0.8902616279069767\n",
            "1376/4708 - The training loss at 24th epoch : 0.0801243986829765  Training Accuracy:0.8915229885057471\n",
            "1392/4708 - The training loss at 24th epoch : 0.0800442995485574  Training Accuracy:0.8920454545454546\n",
            "1408/4708 - The training loss at 24th epoch : 0.0799745754605258  Training Accuracy:0.8918539325842697\n",
            "1424/4708 - The training loss at 24th epoch : 0.079566426760847  Training Accuracy:0.8923611111111112\n",
            "1440/4708 - The training loss at 24th epoch : 0.07880811687637398  Training Accuracy:0.8935439560439561\n",
            "1456/4708 - The training loss at 24th epoch : 0.07860668540437774  Training Accuracy:0.8940217391304348\n",
            "1472/4708 - The training loss at 24th epoch : 0.07817570314704281  Training Accuracy:0.894489247311828\n",
            "1488/4708 - The training loss at 24th epoch : 0.07911515395007067  Training Accuracy:0.8929521276595744\n",
            "1504/4708 - The training loss at 24th epoch : 0.07985315448872608  Training Accuracy:0.8914473684210527\n",
            "1520/4708 - The training loss at 24th epoch : 0.07949083604445946  Training Accuracy:0.8919270833333334\n",
            "1536/4708 - The training loss at 24th epoch : 0.08136020954684273  Training Accuracy:0.8891752577319587\n",
            "1552/4708 - The training loss at 24th epoch : 0.08121621029265763  Training Accuracy:0.8896683673469388\n",
            "1568/4708 - The training loss at 24th epoch : 0.08153482663005983  Training Accuracy:0.8888888888888888\n",
            "1584/4708 - The training loss at 24th epoch : 0.08157732489879715  Training Accuracy:0.88875\n",
            "1600/4708 - The training loss at 24th epoch : 0.0813679046970455  Training Accuracy:0.8892326732673267\n",
            "1616/4708 - The training loss at 24th epoch : 0.081075742774163  Training Accuracy:0.8897058823529411\n",
            "1632/4708 - The training loss at 24th epoch : 0.08090467954929345  Training Accuracy:0.8895631067961165\n",
            "1648/4708 - The training loss at 24th epoch : 0.08103125150958679  Training Accuracy:0.8894230769230769\n",
            "1664/4708 - The training loss at 24th epoch : 0.08096243909983056  Training Accuracy:0.8892857142857142\n",
            "1680/4708 - The training loss at 24th epoch : 0.08168517115828086  Training Accuracy:0.8879716981132075\n",
            "1696/4708 - The training loss at 24th epoch : 0.08142515320833528  Training Accuracy:0.8884345794392523\n",
            "1712/4708 - The training loss at 24th epoch : 0.08094104101606579  Training Accuracy:0.8888888888888888\n",
            "1728/4708 - The training loss at 24th epoch : 0.08155639926796984  Training Accuracy:0.8881880733944955\n",
            "1744/4708 - The training loss at 24th epoch : 0.08157730665847682  Training Accuracy:0.8880681818181818\n",
            "1760/4708 - The training loss at 24th epoch : 0.08133953295183204  Training Accuracy:0.8885135135135135\n",
            "1776/4708 - The training loss at 24th epoch : 0.08127740938200989  Training Accuracy:0.8883928571428571\n",
            "1792/4708 - The training loss at 24th epoch : 0.08146680170827257  Training Accuracy:0.8882743362831859\n",
            "1808/4708 - The training loss at 24th epoch : 0.08130516366988506  Training Accuracy:0.8887061403508771\n",
            "1824/4708 - The training loss at 24th epoch : 0.08185013316485237  Training Accuracy:0.8875\n",
            "1840/4708 - The training loss at 24th epoch : 0.08178576924007291  Training Accuracy:0.8873922413793104\n",
            "1856/4708 - The training loss at 24th epoch : 0.08121458007106465  Training Accuracy:0.8883547008547008\n",
            "1872/4708 - The training loss at 24th epoch : 0.08104527766322034  Training Accuracy:0.888771186440678\n",
            "1888/4708 - The training loss at 24th epoch : 0.08130732186645805  Training Accuracy:0.8886554621848739\n",
            "1904/4708 - The training loss at 24th epoch : 0.08180174185722384  Training Accuracy:0.8880208333333334\n",
            "1920/4708 - The training loss at 24th epoch : 0.08127707820650194  Training Accuracy:0.8889462809917356\n",
            "1936/4708 - The training loss at 24th epoch : 0.08128776664577546  Training Accuracy:0.8888319672131147\n",
            "1952/4708 - The training loss at 24th epoch : 0.08125401337898995  Training Accuracy:0.8892276422764228\n",
            "1968/4708 - The training loss at 24th epoch : 0.08088801110290758  Training Accuracy:0.8901209677419355\n",
            "1984/4708 - The training loss at 24th epoch : 0.08161231897072106  Training Accuracy:0.8885\n",
            "2000/4708 - The training loss at 24th epoch : 0.08223107078944669  Training Accuracy:0.8878968253968254\n",
            "2016/4708 - The training loss at 24th epoch : 0.08258169683924034  Training Accuracy:0.8868110236220472\n",
            "2032/4708 - The training loss at 24th epoch : 0.08262220362339856  Training Accuracy:0.88671875\n",
            "2048/4708 - The training loss at 24th epoch : 0.08287858122331927  Training Accuracy:0.8861434108527132\n",
            "2064/4708 - The training loss at 24th epoch : 0.08256690120254213  Training Accuracy:0.8870192307692307\n",
            "2080/4708 - The training loss at 24th epoch : 0.08272999355265964  Training Accuracy:0.8864503816793893\n",
            "2096/4708 - The training loss at 24th epoch : 0.08237053539346648  Training Accuracy:0.8868371212121212\n",
            "2112/4708 - The training loss at 24th epoch : 0.08239738736823118  Training Accuracy:0.8867481203007519\n",
            "2128/4708 - The training loss at 24th epoch : 0.08291925428606968  Training Accuracy:0.8861940298507462\n",
            "2144/4708 - The training loss at 24th epoch : 0.08248088277484614  Training Accuracy:0.8870370370370371\n",
            "2160/4708 - The training loss at 24th epoch : 0.08258951558031884  Training Accuracy:0.8860294117647058\n",
            "2176/4708 - The training loss at 24th epoch : 0.08264941171834839  Training Accuracy:0.8859489051094891\n",
            "2192/4708 - The training loss at 24th epoch : 0.08261023934394165  Training Accuracy:0.886322463768116\n",
            "2208/4708 - The training loss at 24th epoch : 0.08251713423018966  Training Accuracy:0.8862410071942446\n",
            "2224/4708 - The training loss at 24th epoch : 0.08219762728502869  Training Accuracy:0.8866071428571428\n",
            "2240/4708 - The training loss at 24th epoch : 0.08202118141695848  Training Accuracy:0.8865248226950354\n",
            "2256/4708 - The training loss at 24th epoch : 0.08149627144517353  Training Accuracy:0.8873239436619719\n",
            "2272/4708 - The training loss at 24th epoch : 0.08110295130774381  Training Accuracy:0.8881118881118881\n",
            "2288/4708 - The training loss at 24th epoch : 0.08115588703624776  Training Accuracy:0.8880208333333334\n",
            "2304/4708 - The training loss at 24th epoch : 0.08104706962889603  Training Accuracy:0.8883620689655173\n",
            "2320/4708 - The training loss at 24th epoch : 0.08120497184770158  Training Accuracy:0.8878424657534246\n",
            "2336/4708 - The training loss at 24th epoch : 0.0812043534091346  Training Accuracy:0.8877551020408163\n",
            "2352/4708 - The training loss at 24th epoch : 0.0812082624219904  Training Accuracy:0.8880912162162162\n",
            "2368/4708 - The training loss at 24th epoch : 0.0811496522375809  Training Accuracy:0.8884228187919463\n",
            "2384/4708 - The training loss at 24th epoch : 0.08123064665542719  Training Accuracy:0.8879166666666667\n",
            "2400/4708 - The training loss at 24th epoch : 0.08218253993606366  Training Accuracy:0.8865894039735099\n",
            "2416/4708 - The training loss at 24th epoch : 0.08197251484433365  Training Accuracy:0.8869243421052632\n",
            "2432/4708 - The training loss at 24th epoch : 0.08241880556605097  Training Accuracy:0.8860294117647058\n",
            "2448/4708 - The training loss at 24th epoch : 0.08196363208485832  Training Accuracy:0.8867694805194806\n",
            "2464/4708 - The training loss at 24th epoch : 0.08148545659679886  Training Accuracy:0.8875\n",
            "2480/4708 - The training loss at 24th epoch : 0.08118222024803934  Training Accuracy:0.8878205128205128\n",
            "2496/4708 - The training loss at 24th epoch : 0.08135831924642231  Training Accuracy:0.8877388535031847\n",
            "2512/4708 - The training loss at 24th epoch : 0.08126895670698805  Training Accuracy:0.8876582278481012\n",
            "2528/4708 - The training loss at 24th epoch : 0.08114676100847115  Training Accuracy:0.8875786163522013\n",
            "2544/4708 - The training loss at 24th epoch : 0.08099369124967383  Training Accuracy:0.8875\n",
            "2560/4708 - The training loss at 24th epoch : 0.08065692250761597  Training Accuracy:0.8881987577639752\n",
            "2576/4708 - The training loss at 24th epoch : 0.08025923435256421  Training Accuracy:0.8888888888888888\n",
            "2592/4708 - The training loss at 24th epoch : 0.0803246950766998  Training Accuracy:0.888420245398773\n",
            "2608/4708 - The training loss at 24th epoch : 0.08060848286016126  Training Accuracy:0.8879573170731707\n",
            "2624/4708 - The training loss at 24th epoch : 0.08057977834664505  Training Accuracy:0.8882575757575758\n",
            "2640/4708 - The training loss at 24th epoch : 0.08037391599016808  Training Accuracy:0.8885542168674698\n",
            "2656/4708 - The training loss at 24th epoch : 0.0800346155696912  Training Accuracy:0.8888473053892215\n",
            "2672/4708 - The training loss at 24th epoch : 0.08019078566358354  Training Accuracy:0.8887648809523809\n",
            "2688/4708 - The training loss at 24th epoch : 0.07975450639757634  Training Accuracy:0.8894230769230769\n",
            "2704/4708 - The training loss at 24th epoch : 0.07934595268424693  Training Accuracy:0.8900735294117647\n",
            "2720/4708 - The training loss at 24th epoch : 0.07953796597222156  Training Accuracy:0.889985380116959\n",
            "2736/4708 - The training loss at 24th epoch : 0.07927521385726471  Training Accuracy:0.8902616279069767\n",
            "2752/4708 - The training loss at 24th epoch : 0.0789758132634017  Training Accuracy:0.8908959537572254\n",
            "2768/4708 - The training loss at 24th epoch : 0.07868959110636023  Training Accuracy:0.8915229885057471\n",
            "2784/4708 - The training loss at 24th epoch : 0.07849239992465805  Training Accuracy:0.8917857142857143\n",
            "2800/4708 - The training loss at 24th epoch : 0.07861968949887238  Training Accuracy:0.8916903409090909\n",
            "2816/4708 - The training loss at 24th epoch : 0.07819619721490811  Training Accuracy:0.8923022598870056\n",
            "2832/4708 - The training loss at 24th epoch : 0.07808367374241001  Training Accuracy:0.8925561797752809\n",
            "2848/4708 - The training loss at 24th epoch : 0.07809094670704696  Training Accuracy:0.8924581005586593\n",
            "2864/4708 - The training loss at 24th epoch : 0.07785334246433531  Training Accuracy:0.8927083333333333\n",
            "2880/4708 - The training loss at 24th epoch : 0.07767961852946555  Training Accuracy:0.892610497237569\n",
            "2896/4708 - The training loss at 24th epoch : 0.07757911854143591  Training Accuracy:0.8928571428571429\n",
            "2912/4708 - The training loss at 24th epoch : 0.07778042439013887  Training Accuracy:0.8920765027322405\n",
            "2928/4708 - The training loss at 24th epoch : 0.07789183263686293  Training Accuracy:0.8916440217391305\n",
            "2944/4708 - The training loss at 24th epoch : 0.07799275710757603  Training Accuracy:0.8915540540540541\n",
            "2960/4708 - The training loss at 24th epoch : 0.07798190658086057  Training Accuracy:0.8914650537634409\n",
            "2976/4708 - The training loss at 24th epoch : 0.07775979366429714  Training Accuracy:0.8920454545454546\n",
            "2992/4708 - The training loss at 24th epoch : 0.07741036567482204  Training Accuracy:0.8926196808510638\n",
            "3008/4708 - The training loss at 24th epoch : 0.07724038006166364  Training Accuracy:0.8928571428571429\n",
            "3024/4708 - The training loss at 24th epoch : 0.07745416014983386  Training Accuracy:0.8924342105263158\n",
            "3040/4708 - The training loss at 24th epoch : 0.07743818380192911  Training Accuracy:0.8923429319371727\n",
            "3056/4708 - The training loss at 24th epoch : 0.07732748383388909  Training Accuracy:0.892578125\n",
            "3072/4708 - The training loss at 24th epoch : 0.07728523246197873  Training Accuracy:0.8928108808290155\n",
            "3088/4708 - The training loss at 24th epoch : 0.0774578951184912  Training Accuracy:0.8923969072164949\n",
            "3104/4708 - The training loss at 24th epoch : 0.07766418181278929  Training Accuracy:0.8919871794871795\n",
            "3120/4708 - The training loss at 24th epoch : 0.07735176475249692  Training Accuracy:0.8925382653061225\n",
            "3136/4708 - The training loss at 24th epoch : 0.07708951739133235  Training Accuracy:0.8930837563451777\n",
            "3152/4708 - The training loss at 24th epoch : 0.07700430175525007  Training Accuracy:0.8929924242424242\n",
            "3168/4708 - The training loss at 24th epoch : 0.07745911045617225  Training Accuracy:0.8925879396984925\n",
            "3184/4708 - The training loss at 24th epoch : 0.07746053542462661  Training Accuracy:0.8928125\n",
            "3200/4708 - The training loss at 24th epoch : 0.07767784374260128  Training Accuracy:0.8924129353233831\n",
            "3216/4708 - The training loss at 24th epoch : 0.07744276024154553  Training Accuracy:0.8929455445544554\n",
            "3232/4708 - The training loss at 24th epoch : 0.07761974287321442  Training Accuracy:0.8928571428571429\n",
            "3248/4708 - The training loss at 24th epoch : 0.07745376944238146  Training Accuracy:0.8930759803921569\n",
            "3264/4708 - The training loss at 24th epoch : 0.07750782406363067  Training Accuracy:0.8932926829268293\n",
            "3280/4708 - The training loss at 24th epoch : 0.07786501773092931  Training Accuracy:0.8929004854368932\n",
            "3296/4708 - The training loss at 24th epoch : 0.07794165328800337  Training Accuracy:0.8928140096618358\n",
            "3312/4708 - The training loss at 24th epoch : 0.07764955307214134  Training Accuracy:0.8933293269230769\n",
            "3328/4708 - The training loss at 24th epoch : 0.07782457249330357  Training Accuracy:0.8926435406698564\n",
            "3344/4708 - The training loss at 24th epoch : 0.078790774425511  Training Accuracy:0.8916666666666667\n",
            "3360/4708 - The training loss at 24th epoch : 0.07859097888941656  Training Accuracy:0.8918838862559242\n",
            "3376/4708 - The training loss at 24th epoch : 0.07849372642123176  Training Accuracy:0.8920990566037735\n",
            "3392/4708 - The training loss at 24th epoch : 0.07866831976268313  Training Accuracy:0.892018779342723\n",
            "3408/4708 - The training loss at 24th epoch : 0.07881965132420832  Training Accuracy:0.8916471962616822\n",
            "3424/4708 - The training loss at 24th epoch : 0.07881951345516869  Training Accuracy:0.8915697674418605\n",
            "3440/4708 - The training loss at 24th epoch : 0.07928259214130062  Training Accuracy:0.8909143518518519\n",
            "3456/4708 - The training loss at 24th epoch : 0.07917489526199789  Training Accuracy:0.8911290322580645\n",
            "3472/4708 - The training loss at 24th epoch : 0.07917319416252025  Training Accuracy:0.8910550458715596\n",
            "3488/4708 - The training loss at 24th epoch : 0.07967009457015645  Training Accuracy:0.8904109589041096\n",
            "3504/4708 - The training loss at 24th epoch : 0.07996111721838954  Training Accuracy:0.8897727272727273\n",
            "3520/4708 - The training loss at 24th epoch : 0.0800025653603509  Training Accuracy:0.8897058823529411\n",
            "3536/4708 - The training loss at 24th epoch : 0.07983350958137765  Training Accuracy:0.8902027027027027\n",
            "3552/4708 - The training loss at 24th epoch : 0.07951702147180753  Training Accuracy:0.890695067264574\n",
            "3568/4708 - The training loss at 24th epoch : 0.07952002516151149  Training Accuracy:0.8909040178571429\n",
            "3584/4708 - The training loss at 24th epoch : 0.0794393276779652  Training Accuracy:0.8911111111111111\n",
            "3600/4708 - The training loss at 24th epoch : 0.07962585267858426  Training Accuracy:0.8907632743362832\n",
            "3616/4708 - The training loss at 24th epoch : 0.07963225937610349  Training Accuracy:0.8909691629955947\n",
            "3632/4708 - The training loss at 24th epoch : 0.07988949050762333  Training Accuracy:0.8903508771929824\n",
            "3648/4708 - The training loss at 24th epoch : 0.07961012162400995  Training Accuracy:0.8908296943231441\n",
            "3664/4708 - The training loss at 24th epoch : 0.07950729049955618  Training Accuracy:0.8910326086956522\n",
            "3680/4708 - The training loss at 24th epoch : 0.07981358356966153  Training Accuracy:0.8906926406926406\n",
            "3696/4708 - The training loss at 24th epoch : 0.07972452932896769  Training Accuracy:0.8908943965517241\n",
            "3712/4708 - The training loss at 24th epoch : 0.07994811677260336  Training Accuracy:0.8905579399141631\n",
            "3728/4708 - The training loss at 24th epoch : 0.07963064605067598  Training Accuracy:0.8910256410256411\n",
            "3744/4708 - The training loss at 24th epoch : 0.07945738779065117  Training Accuracy:0.8912234042553191\n",
            "3760/4708 - The training loss at 24th epoch : 0.07912943971398903  Training Accuracy:0.8916843220338984\n",
            "3776/4708 - The training loss at 24th epoch : 0.0793205077342595  Training Accuracy:0.8913502109704642\n",
            "3792/4708 - The training loss at 24th epoch : 0.07946269878574594  Training Accuracy:0.8912815126050421\n",
            "3808/4708 - The training loss at 24th epoch : 0.07942143308927642  Training Accuracy:0.8914748953974896\n",
            "3824/4708 - The training loss at 24th epoch : 0.07958295793797729  Training Accuracy:0.8911458333333333\n",
            "3840/4708 - The training loss at 24th epoch : 0.07945760913181583  Training Accuracy:0.891338174273859\n",
            "3856/4708 - The training loss at 24th epoch : 0.07955299168468863  Training Accuracy:0.8910123966942148\n",
            "3872/4708 - The training loss at 24th epoch : 0.07975148340466653  Training Accuracy:0.8906893004115226\n",
            "3888/4708 - The training loss at 24th epoch : 0.07950998929295898  Training Accuracy:0.8911372950819673\n",
            "3904/4708 - The training loss at 24th epoch : 0.07970544978930495  Training Accuracy:0.8908163265306123\n",
            "3920/4708 - The training loss at 24th epoch : 0.07979054564624097  Training Accuracy:0.8904979674796748\n",
            "3936/4708 - The training loss at 24th epoch : 0.07954795845975517  Training Accuracy:0.8909412955465587\n",
            "3952/4708 - The training loss at 24th epoch : 0.07930518726239119  Training Accuracy:0.8911290322580645\n",
            "3968/4708 - The training loss at 24th epoch : 0.07935765497169607  Training Accuracy:0.8910642570281124\n",
            "3984/4708 - The training loss at 24th epoch : 0.07946082200644904  Training Accuracy:0.89075\n",
            "4000/4708 - The training loss at 24th epoch : 0.07917445874362017  Training Accuracy:0.8911852589641435\n",
            "4016/4708 - The training loss at 24th epoch : 0.07948975062387717  Training Accuracy:0.8908730158730159\n",
            "4032/4708 - The training loss at 24th epoch : 0.07946817984695906  Training Accuracy:0.8908102766798419\n",
            "4048/4708 - The training loss at 24th epoch : 0.0792313020737097  Training Accuracy:0.8912401574803149\n",
            "4064/4708 - The training loss at 24th epoch : 0.07922869016285648  Training Accuracy:0.8911764705882353\n",
            "4080/4708 - The training loss at 24th epoch : 0.07958206397946352  Training Accuracy:0.89013671875\n",
            "4096/4708 - The training loss at 24th epoch : 0.07967945592639891  Training Accuracy:0.8898346303501945\n",
            "4112/4708 - The training loss at 24th epoch : 0.07969320652066174  Training Accuracy:0.8897771317829457\n",
            "4128/4708 - The training loss at 24th epoch : 0.07969542302119854  Training Accuracy:0.8897200772200772\n",
            "4144/4708 - The training loss at 24th epoch : 0.07949453545959728  Training Accuracy:0.8899038461538461\n",
            "4160/4708 - The training loss at 24th epoch : 0.0793162809401678  Training Accuracy:0.8903256704980843\n",
            "4176/4708 - The training loss at 24th epoch : 0.07928001050618588  Training Accuracy:0.8902671755725191\n",
            "4192/4708 - The training loss at 24th epoch : 0.07940561530353427  Training Accuracy:0.8902091254752852\n",
            "4208/4708 - The training loss at 24th epoch : 0.07955627675793049  Training Accuracy:0.8901515151515151\n",
            "4224/4708 - The training loss at 24th epoch : 0.07946681716602626  Training Accuracy:0.8903301886792453\n",
            "4240/4708 - The training loss at 24th epoch : 0.07974107556567549  Training Accuracy:0.8900375939849624\n",
            "4256/4708 - The training loss at 24th epoch : 0.07953201844995914  Training Accuracy:0.8904494382022472\n",
            "4272/4708 - The training loss at 24th epoch : 0.07996559596164891  Training Accuracy:0.8896921641791045\n",
            "4288/4708 - The training loss at 24th epoch : 0.07981383487712605  Training Accuracy:0.8901022304832714\n",
            "4304/4708 - The training loss at 24th epoch : 0.07967186356801939  Training Accuracy:0.8902777777777777\n",
            "4320/4708 - The training loss at 24th epoch : 0.07984849229787135  Training Accuracy:0.889990774907749\n",
            "4336/4708 - The training loss at 24th epoch : 0.07958718355719671  Training Accuracy:0.8903952205882353\n",
            "4352/4708 - The training loss at 24th epoch : 0.0796228080637827  Training Accuracy:0.8903388278388278\n",
            "4368/4708 - The training loss at 24th epoch : 0.0793511962564832  Training Accuracy:0.8907390510948905\n",
            "4384/4708 - The training loss at 24th epoch : 0.07913078214239856  Training Accuracy:0.8911363636363636\n",
            "4400/4708 - The training loss at 24th epoch : 0.07900859944046972  Training Accuracy:0.8913043478260869\n",
            "4416/4708 - The training loss at 24th epoch : 0.07916859664439514  Training Accuracy:0.8910198555956679\n",
            "4432/4708 - The training loss at 24th epoch : 0.07912250556042918  Training Accuracy:0.8909622302158273\n",
            "4448/4708 - The training loss at 24th epoch : 0.07899327437795123  Training Accuracy:0.8911290322580645\n",
            "4464/4708 - The training loss at 24th epoch : 0.07872848777611854  Training Accuracy:0.8915178571428571\n",
            "4480/4708 - The training loss at 24th epoch : 0.07849620686411653  Training Accuracy:0.8919039145907474\n",
            "4496/4708 - The training loss at 24th epoch : 0.0782929990085871  Training Accuracy:0.8922872340425532\n",
            "4512/4708 - The training loss at 24th epoch : 0.07852411671121873  Training Accuracy:0.8920053003533569\n",
            "4528/4708 - The training loss at 24th epoch : 0.07839349230163774  Training Accuracy:0.8921654929577465\n",
            "4544/4708 - The training loss at 24th epoch : 0.07826305488117163  Training Accuracy:0.8923245614035088\n",
            "4560/4708 - The training loss at 24th epoch : 0.07864526994990935  Training Accuracy:0.8918269230769231\n",
            "4576/4708 - The training loss at 24th epoch : 0.07840055486439569  Training Accuracy:0.8922038327526133\n",
            "4592/4708 - The training loss at 24th epoch : 0.07847858217810254  Training Accuracy:0.8921440972222222\n",
            "4608/4708 - The training loss at 24th epoch : 0.07849148953679719  Training Accuracy:0.8920847750865052\n",
            "4624/4708 - The training loss at 24th epoch : 0.07849402158830182  Training Accuracy:0.8920258620689655\n",
            "4640/4708 - The training loss at 24th epoch : 0.07839830250389378  Training Accuracy:0.8921821305841925\n",
            "4656/4708 - The training loss at 24th epoch : 0.0781674226503853  Training Accuracy:0.8925513698630136\n",
            "4672/4708 - The training loss at 24th epoch : 0.07819185271321764  Training Accuracy:0.8927047781569966\n",
            "4688/4708 - The training loss at 24th epoch : 0.07827740705806292  Training Accuracy:0.8924319727891157\n",
            "4704/4708 - The training loss at 24th epoch : 0.07827272572942559  Training Accuracy:0.8925847457627119\n",
            "4720/4708 - The training loss at 24th epoch : 0.07818983818629197  Training Accuracy:0.8927364864864865\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 25th epoch : 0.04743436843006337  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 25th epoch : 0.05203440654470161  Training Accuracy:0.90625\n",
            "32/4708 - The training loss at 25th epoch : 0.05548893586813017  Training Accuracy:0.9166666666666666\n",
            "48/4708 - The training loss at 25th epoch : 0.06850447919230256  Training Accuracy:0.90625\n",
            "64/4708 - The training loss at 25th epoch : 0.05615744964981343  Training Accuracy:0.925\n",
            "80/4708 - The training loss at 25th epoch : 0.07204515237091962  Training Accuracy:0.90625\n",
            "96/4708 - The training loss at 25th epoch : 0.0791255989903646  Training Accuracy:0.9017857142857143\n",
            "112/4708 - The training loss at 25th epoch : 0.08692525092365473  Training Accuracy:0.890625\n",
            "128/4708 - The training loss at 25th epoch : 0.0874547328686886  Training Accuracy:0.8958333333333334\n",
            "144/4708 - The training loss at 25th epoch : 0.08111516509928964  Training Accuracy:0.90625\n",
            "160/4708 - The training loss at 25th epoch : 0.08553832281763002  Training Accuracy:0.8977272727272727\n",
            "176/4708 - The training loss at 25th epoch : 0.08990471447707521  Training Accuracy:0.8854166666666666\n",
            "192/4708 - The training loss at 25th epoch : 0.0877582495598789  Training Accuracy:0.8894230769230769\n",
            "208/4708 - The training loss at 25th epoch : 0.0877254050234352  Training Accuracy:0.8928571428571429\n",
            "224/4708 - The training loss at 25th epoch : 0.08617683006788975  Training Accuracy:0.8958333333333334\n",
            "240/4708 - The training loss at 25th epoch : 0.08556373670950643  Training Accuracy:0.8984375\n",
            "256/4708 - The training loss at 25th epoch : 0.08308482840429493  Training Accuracy:0.9007352941176471\n",
            "272/4708 - The training loss at 25th epoch : 0.08736295191516713  Training Accuracy:0.8923611111111112\n",
            "288/4708 - The training loss at 25th epoch : 0.0882107570818413  Training Accuracy:0.8914473684210527\n",
            "304/4708 - The training loss at 25th epoch : 0.08550203290702905  Training Accuracy:0.89375\n",
            "320/4708 - The training loss at 25th epoch : 0.08637351619846283  Training Accuracy:0.8869047619047619\n",
            "336/4708 - The training loss at 25th epoch : 0.09249415296787196  Training Accuracy:0.875\n",
            "352/4708 - The training loss at 25th epoch : 0.09419533475687371  Training Accuracy:0.875\n",
            "368/4708 - The training loss at 25th epoch : 0.09245694379576104  Training Accuracy:0.8776041666666666\n",
            "384/4708 - The training loss at 25th epoch : 0.0932572258932052  Training Accuracy:0.8775\n",
            "400/4708 - The training loss at 25th epoch : 0.0940969054704907  Training Accuracy:0.875\n",
            "416/4708 - The training loss at 25th epoch : 0.09127715169629953  Training Accuracy:0.8796296296296297\n",
            "432/4708 - The training loss at 25th epoch : 0.09170272177445436  Training Accuracy:0.8794642857142857\n",
            "448/4708 - The training loss at 25th epoch : 0.08977218643867928  Training Accuracy:0.8814655172413793\n",
            "464/4708 - The training loss at 25th epoch : 0.09181938895940284  Training Accuracy:0.8770833333333333\n",
            "480/4708 - The training loss at 25th epoch : 0.08974233525018531  Training Accuracy:0.8810483870967742\n",
            "496/4708 - The training loss at 25th epoch : 0.09239957575061965  Training Accuracy:0.87890625\n",
            "512/4708 - The training loss at 25th epoch : 0.09503292548899371  Training Accuracy:0.875\n",
            "528/4708 - The training loss at 25th epoch : 0.09429696304367319  Training Accuracy:0.875\n",
            "544/4708 - The training loss at 25th epoch : 0.09373214207663216  Training Accuracy:0.8767857142857143\n",
            "560/4708 - The training loss at 25th epoch : 0.09202877804543123  Training Accuracy:0.8802083333333334\n",
            "576/4708 - The training loss at 25th epoch : 0.09180927821952518  Training Accuracy:0.8800675675675675\n",
            "592/4708 - The training loss at 25th epoch : 0.09064719527429112  Training Accuracy:0.881578947368421\n",
            "608/4708 - The training loss at 25th epoch : 0.08920847035741755  Training Accuracy:0.8846153846153846\n",
            "624/4708 - The training loss at 25th epoch : 0.08965765196209649  Training Accuracy:0.884375\n",
            "640/4708 - The training loss at 25th epoch : 0.09092515148475866  Training Accuracy:0.8826219512195121\n",
            "656/4708 - The training loss at 25th epoch : 0.09078783185216026  Training Accuracy:0.8824404761904762\n",
            "672/4708 - The training loss at 25th epoch : 0.09185980630224613  Training Accuracy:0.8808139534883721\n",
            "688/4708 - The training loss at 25th epoch : 0.09190743780954089  Training Accuracy:0.8792613636363636\n",
            "704/4708 - The training loss at 25th epoch : 0.09362462062315997  Training Accuracy:0.8763888888888889\n",
            "720/4708 - The training loss at 25th epoch : 0.0931535148904624  Training Accuracy:0.8777173913043478\n",
            "736/4708 - The training loss at 25th epoch : 0.09274634556543465  Training Accuracy:0.8789893617021277\n",
            "752/4708 - The training loss at 25th epoch : 0.0945428408485417  Training Accuracy:0.8763020833333334\n",
            "768/4708 - The training loss at 25th epoch : 0.09488423932245837  Training Accuracy:0.875\n",
            "784/4708 - The training loss at 25th epoch : 0.09335048733867306  Training Accuracy:0.8775\n",
            "800/4708 - The training loss at 25th epoch : 0.09454222699381948  Training Accuracy:0.875\n",
            "816/4708 - The training loss at 25th epoch : 0.09411998652127838  Training Accuracy:0.8762019230769231\n",
            "832/4708 - The training loss at 25th epoch : 0.09489731447492152  Training Accuracy:0.875\n",
            "848/4708 - The training loss at 25th epoch : 0.0938105024949935  Training Accuracy:0.8761574074074074\n",
            "864/4708 - The training loss at 25th epoch : 0.09338900353601222  Training Accuracy:0.8761363636363636\n",
            "880/4708 - The training loss at 25th epoch : 0.09249078468960129  Training Accuracy:0.8772321428571429\n",
            "896/4708 - The training loss at 25th epoch : 0.09222716733690707  Training Accuracy:0.8782894736842105\n",
            "912/4708 - The training loss at 25th epoch : 0.09204590271109592  Training Accuracy:0.8782327586206896\n",
            "928/4708 - The training loss at 25th epoch : 0.09279470147802502  Training Accuracy:0.8771186440677966\n",
            "944/4708 - The training loss at 25th epoch : 0.09135382875183806  Training Accuracy:0.8791666666666667\n",
            "960/4708 - The training loss at 25th epoch : 0.09084344828786081  Training Accuracy:0.8801229508196722\n",
            "976/4708 - The training loss at 25th epoch : 0.0896183882087819  Training Accuracy:0.8820564516129032\n",
            "992/4708 - The training loss at 25th epoch : 0.08905999442820133  Training Accuracy:0.8829365079365079\n",
            "1008/4708 - The training loss at 25th epoch : 0.08813242504771437  Training Accuracy:0.884765625\n",
            "1024/4708 - The training loss at 25th epoch : 0.08813468731109131  Training Accuracy:0.8846153846153846\n",
            "1040/4708 - The training loss at 25th epoch : 0.08753772240693727  Training Accuracy:0.8854166666666666\n",
            "1056/4708 - The training loss at 25th epoch : 0.0884850909122394  Training Accuracy:0.8843283582089553\n",
            "1072/4708 - The training loss at 25th epoch : 0.08788162576880744  Training Accuracy:0.8841911764705882\n",
            "1088/4708 - The training loss at 25th epoch : 0.08932890788614024  Training Accuracy:0.8813405797101449\n",
            "1104/4708 - The training loss at 25th epoch : 0.08939133942245987  Training Accuracy:0.88125\n",
            "1120/4708 - The training loss at 25th epoch : 0.08822511939153754  Training Accuracy:0.8829225352112676\n",
            "1136/4708 - The training loss at 25th epoch : 0.08757761421335354  Training Accuracy:0.8836805555555556\n",
            "1152/4708 - The training loss at 25th epoch : 0.08847534797137882  Training Accuracy:0.8818493150684932\n",
            "1168/4708 - The training loss at 25th epoch : 0.08779650099487728  Training Accuracy:0.8834459459459459\n",
            "1184/4708 - The training loss at 25th epoch : 0.08745839098059732  Training Accuracy:0.8833333333333333\n",
            "1200/4708 - The training loss at 25th epoch : 0.0881233577840986  Training Accuracy:0.8824013157894737\n",
            "1216/4708 - The training loss at 25th epoch : 0.08751589763839422  Training Accuracy:0.8831168831168831\n",
            "1232/4708 - The training loss at 25th epoch : 0.08801671960974156  Training Accuracy:0.8814102564102564\n",
            "1248/4708 - The training loss at 25th epoch : 0.08701225049078382  Training Accuracy:0.8829113924050633\n",
            "1264/4708 - The training loss at 25th epoch : 0.08742135472786397  Training Accuracy:0.8828125\n",
            "1280/4708 - The training loss at 25th epoch : 0.08717081814553151  Training Accuracy:0.8834876543209876\n",
            "1296/4708 - The training loss at 25th epoch : 0.08718396100786843  Training Accuracy:0.8833841463414634\n",
            "1312/4708 - The training loss at 25th epoch : 0.08780493305603013  Training Accuracy:0.8825301204819277\n",
            "1328/4708 - The training loss at 25th epoch : 0.08874314059498299  Training Accuracy:0.8802083333333334\n",
            "1344/4708 - The training loss at 25th epoch : 0.08932858662761335  Training Accuracy:0.8794117647058823\n",
            "1360/4708 - The training loss at 25th epoch : 0.09023790761266975  Training Accuracy:0.8786337209302325\n",
            "1376/4708 - The training loss at 25th epoch : 0.0901367105612537  Training Accuracy:0.8785919540229885\n",
            "1392/4708 - The training loss at 25th epoch : 0.09096419095092778  Training Accuracy:0.8771306818181818\n",
            "1408/4708 - The training loss at 25th epoch : 0.09049261624142785  Training Accuracy:0.8778089887640449\n",
            "1424/4708 - The training loss at 25th epoch : 0.08983110039470475  Training Accuracy:0.8784722222222222\n",
            "1440/4708 - The training loss at 25th epoch : 0.08950040634729078  Training Accuracy:0.8791208791208791\n",
            "1456/4708 - The training loss at 25th epoch : 0.08933719251955126  Training Accuracy:0.8797554347826086\n",
            "1472/4708 - The training loss at 25th epoch : 0.08890346382160633  Training Accuracy:0.8803763440860215\n",
            "1488/4708 - The training loss at 25th epoch : 0.08954632460605981  Training Accuracy:0.879654255319149\n",
            "1504/4708 - The training loss at 25th epoch : 0.08979582209527624  Training Accuracy:0.8796052631578948\n",
            "1520/4708 - The training loss at 25th epoch : 0.08933338980512906  Training Accuracy:0.8802083333333334\n",
            "1536/4708 - The training loss at 25th epoch : 0.0886395564742318  Training Accuracy:0.8814432989690721\n",
            "1552/4708 - The training loss at 25th epoch : 0.08837101995151043  Training Accuracy:0.8813775510204082\n",
            "1568/4708 - The training loss at 25th epoch : 0.08823258579673522  Training Accuracy:0.8819444444444444\n",
            "1584/4708 - The training loss at 25th epoch : 0.08805197193690319  Training Accuracy:0.8825\n",
            "1600/4708 - The training loss at 25th epoch : 0.08774854537744574  Training Accuracy:0.8830445544554455\n",
            "1616/4708 - The training loss at 25th epoch : 0.08796514504507723  Training Accuracy:0.8829656862745098\n",
            "1632/4708 - The training loss at 25th epoch : 0.08786813287891165  Training Accuracy:0.8828883495145631\n",
            "1648/4708 - The training loss at 25th epoch : 0.08832329459435383  Training Accuracy:0.8810096153846154\n",
            "1664/4708 - The training loss at 25th epoch : 0.0877482440299869  Training Accuracy:0.8821428571428571\n",
            "1680/4708 - The training loss at 25th epoch : 0.08718365563954306  Training Accuracy:0.8832547169811321\n",
            "1696/4708 - The training loss at 25th epoch : 0.08671644743122996  Training Accuracy:0.8837616822429907\n",
            "1712/4708 - The training loss at 25th epoch : 0.0870301795251726  Training Accuracy:0.8831018518518519\n",
            "1728/4708 - The training loss at 25th epoch : 0.08699151758601446  Training Accuracy:0.8830275229357798\n",
            "1744/4708 - The training loss at 25th epoch : 0.08705652561040163  Training Accuracy:0.8829545454545454\n",
            "1760/4708 - The training loss at 25th epoch : 0.08784338551070704  Training Accuracy:0.8817567567567568\n",
            "1776/4708 - The training loss at 25th epoch : 0.08719681665171888  Training Accuracy:0.8828125\n",
            "1792/4708 - The training loss at 25th epoch : 0.08687560763589891  Training Accuracy:0.8832964601769911\n",
            "1808/4708 - The training loss at 25th epoch : 0.08657366701200075  Training Accuracy:0.8832236842105263\n",
            "1824/4708 - The training loss at 25th epoch : 0.08640839747069139  Training Accuracy:0.883695652173913\n",
            "1840/4708 - The training loss at 25th epoch : 0.0862752180058484  Training Accuracy:0.8836206896551724\n",
            "1856/4708 - The training loss at 25th epoch : 0.08584977086192584  Training Accuracy:0.8840811965811965\n",
            "1872/4708 - The training loss at 25th epoch : 0.0859030480349048  Training Accuracy:0.8834745762711864\n",
            "1888/4708 - The training loss at 25th epoch : 0.08538869377926336  Training Accuracy:0.884453781512605\n",
            "1904/4708 - The training loss at 25th epoch : 0.08509718156688713  Training Accuracy:0.8848958333333333\n",
            "1920/4708 - The training loss at 25th epoch : 0.08548695073218633  Training Accuracy:0.8848140495867769\n",
            "1936/4708 - The training loss at 25th epoch : 0.08489991404617166  Training Accuracy:0.8857581967213115\n",
            "1952/4708 - The training loss at 25th epoch : 0.08471340454944795  Training Accuracy:0.8861788617886179\n",
            "1968/4708 - The training loss at 25th epoch : 0.08461883343432738  Training Accuracy:0.8865927419354839\n",
            "1984/4708 - The training loss at 25th epoch : 0.0852749937959836  Training Accuracy:0.885\n",
            "2000/4708 - The training loss at 25th epoch : 0.08485800655963863  Training Accuracy:0.8854166666666666\n",
            "2016/4708 - The training loss at 25th epoch : 0.08428423998010547  Training Accuracy:0.8863188976377953\n",
            "2032/4708 - The training loss at 25th epoch : 0.08447616654734746  Training Accuracy:0.8857421875\n",
            "2048/4708 - The training loss at 25th epoch : 0.08440749524956588  Training Accuracy:0.8856589147286822\n",
            "2064/4708 - The training loss at 25th epoch : 0.08442326429217853  Training Accuracy:0.8860576923076923\n",
            "2080/4708 - The training loss at 25th epoch : 0.08430472303395195  Training Accuracy:0.8859732824427481\n",
            "2096/4708 - The training loss at 25th epoch : 0.08425128205104178  Training Accuracy:0.8858901515151515\n",
            "2112/4708 - The training loss at 25th epoch : 0.08407357708495516  Training Accuracy:0.8862781954887218\n",
            "2128/4708 - The training loss at 25th epoch : 0.08369342050669887  Training Accuracy:0.886660447761194\n",
            "2144/4708 - The training loss at 25th epoch : 0.08373729246415496  Training Accuracy:0.8870370370370371\n",
            "2160/4708 - The training loss at 25th epoch : 0.0839979374088855  Training Accuracy:0.8864889705882353\n",
            "2176/4708 - The training loss at 25th epoch : 0.0843562973490304  Training Accuracy:0.8859489051094891\n",
            "2192/4708 - The training loss at 25th epoch : 0.0842559358189907  Training Accuracy:0.8858695652173914\n",
            "2208/4708 - The training loss at 25th epoch : 0.08456685994588996  Training Accuracy:0.885341726618705\n",
            "2224/4708 - The training loss at 25th epoch : 0.08450421222905827  Training Accuracy:0.8857142857142857\n",
            "2240/4708 - The training loss at 25th epoch : 0.08528365740605875  Training Accuracy:0.8847517730496454\n",
            "2256/4708 - The training loss at 25th epoch : 0.08492202006725659  Training Accuracy:0.8855633802816901\n",
            "2272/4708 - The training loss at 25th epoch : 0.08492140914253045  Training Accuracy:0.8859265734265734\n",
            "2288/4708 - The training loss at 25th epoch : 0.08462192959245184  Training Accuracy:0.8862847222222222\n",
            "2304/4708 - The training loss at 25th epoch : 0.08408901423886128  Training Accuracy:0.8870689655172413\n",
            "2320/4708 - The training loss at 25th epoch : 0.08377798171016014  Training Accuracy:0.8874143835616438\n",
            "2336/4708 - The training loss at 25th epoch : 0.08377909889354906  Training Accuracy:0.8877551020408163\n",
            "2352/4708 - The training loss at 25th epoch : 0.08374189307617615  Training Accuracy:0.8880912162162162\n",
            "2368/4708 - The training loss at 25th epoch : 0.08383038448438392  Training Accuracy:0.888003355704698\n",
            "2384/4708 - The training loss at 25th epoch : 0.08456602202521152  Training Accuracy:0.8866666666666667\n",
            "2400/4708 - The training loss at 25th epoch : 0.08407586528501236  Training Accuracy:0.8874172185430463\n",
            "2416/4708 - The training loss at 25th epoch : 0.08406021835276437  Training Accuracy:0.8873355263157895\n",
            "2432/4708 - The training loss at 25th epoch : 0.08409070754554998  Training Accuracy:0.8872549019607843\n",
            "2448/4708 - The training loss at 25th epoch : 0.08439123017488151  Training Accuracy:0.8867694805194806\n",
            "2464/4708 - The training loss at 25th epoch : 0.08417077532484402  Training Accuracy:0.8870967741935484\n",
            "2480/4708 - The training loss at 25th epoch : 0.0841354206997255  Training Accuracy:0.8874198717948718\n",
            "2496/4708 - The training loss at 25th epoch : 0.083620578931222  Training Accuracy:0.8881369426751592\n",
            "2512/4708 - The training loss at 25th epoch : 0.08409585082341442  Training Accuracy:0.8876582278481012\n",
            "2528/4708 - The training loss at 25th epoch : 0.08380897381750158  Training Accuracy:0.8879716981132075\n",
            "2544/4708 - The training loss at 25th epoch : 0.08378585964846379  Training Accuracy:0.887890625\n",
            "2560/4708 - The training loss at 25th epoch : 0.0840625922767376  Training Accuracy:0.8874223602484472\n",
            "2576/4708 - The training loss at 25th epoch : 0.08365875141428944  Training Accuracy:0.8881172839506173\n",
            "2592/4708 - The training loss at 25th epoch : 0.08364114001288991  Training Accuracy:0.8880368098159509\n",
            "2608/4708 - The training loss at 25th epoch : 0.08340302899984553  Training Accuracy:0.8883384146341463\n",
            "2624/4708 - The training loss at 25th epoch : 0.08314345749670034  Training Accuracy:0.8886363636363637\n",
            "2640/4708 - The training loss at 25th epoch : 0.08289724825430826  Training Accuracy:0.8889307228915663\n",
            "2656/4708 - The training loss at 25th epoch : 0.08342187278381494  Training Accuracy:0.8877245508982036\n",
            "2672/4708 - The training loss at 25th epoch : 0.08315935776976165  Training Accuracy:0.8880208333333334\n",
            "2688/4708 - The training loss at 25th epoch : 0.083169325454066  Training Accuracy:0.8879437869822485\n",
            "2704/4708 - The training loss at 25th epoch : 0.08318438541047442  Training Accuracy:0.8878676470588235\n",
            "2720/4708 - The training loss at 25th epoch : 0.08287447289962299  Training Accuracy:0.8885233918128655\n",
            "2736/4708 - The training loss at 25th epoch : 0.08304916757688581  Training Accuracy:0.8884447674418605\n",
            "2752/4708 - The training loss at 25th epoch : 0.0830531728753577  Training Accuracy:0.8883670520231214\n",
            "2768/4708 - The training loss at 25th epoch : 0.08317994994174002  Training Accuracy:0.8882902298850575\n",
            "2784/4708 - The training loss at 25th epoch : 0.08288150706175217  Training Accuracy:0.8885714285714286\n",
            "2800/4708 - The training loss at 25th epoch : 0.08298273350556672  Training Accuracy:0.8884943181818182\n",
            "2816/4708 - The training loss at 25th epoch : 0.0832811382265813  Training Accuracy:0.8877118644067796\n",
            "2832/4708 - The training loss at 25th epoch : 0.08351603831057601  Training Accuracy:0.8876404494382022\n",
            "2848/4708 - The training loss at 25th epoch : 0.08338457361951904  Training Accuracy:0.8879189944134078\n",
            "2864/4708 - The training loss at 25th epoch : 0.08361212844966724  Training Accuracy:0.8875\n",
            "2880/4708 - The training loss at 25th epoch : 0.0833639931475087  Training Accuracy:0.8877762430939227\n",
            "2896/4708 - The training loss at 25th epoch : 0.08318496370448139  Training Accuracy:0.8880494505494505\n",
            "2912/4708 - The training loss at 25th epoch : 0.08311612764451955  Training Accuracy:0.8879781420765027\n",
            "2928/4708 - The training loss at 25th epoch : 0.0829896474253754  Training Accuracy:0.8882472826086957\n",
            "2944/4708 - The training loss at 25th epoch : 0.08283769313002888  Training Accuracy:0.8885135135135135\n",
            "2960/4708 - The training loss at 25th epoch : 0.08256562305350353  Training Accuracy:0.8887768817204301\n",
            "2976/4708 - The training loss at 25th epoch : 0.08246350757750666  Training Accuracy:0.8890374331550802\n",
            "2992/4708 - The training loss at 25th epoch : 0.08229710726016157  Training Accuracy:0.8889627659574468\n",
            "3008/4708 - The training loss at 25th epoch : 0.0820606195201174  Training Accuracy:0.8892195767195767\n",
            "3024/4708 - The training loss at 25th epoch : 0.08179771663942925  Training Accuracy:0.8894736842105263\n",
            "3040/4708 - The training loss at 25th epoch : 0.08168060784907748  Training Accuracy:0.8897251308900523\n",
            "3056/4708 - The training loss at 25th epoch : 0.08167838724489153  Training Accuracy:0.8899739583333334\n",
            "3072/4708 - The training loss at 25th epoch : 0.08185529114952719  Training Accuracy:0.8898963730569949\n",
            "3088/4708 - The training loss at 25th epoch : 0.08188235714738991  Training Accuracy:0.8901417525773195\n",
            "3104/4708 - The training loss at 25th epoch : 0.08173330719813009  Training Accuracy:0.8903846153846153\n",
            "3120/4708 - The training loss at 25th epoch : 0.08142769538304512  Training Accuracy:0.890625\n",
            "3136/4708 - The training loss at 25th epoch : 0.08134478001388847  Training Accuracy:0.8908629441624365\n",
            "3152/4708 - The training loss at 25th epoch : 0.08138608982994767  Training Accuracy:0.8904671717171717\n",
            "3168/4708 - The training loss at 25th epoch : 0.08156807034697915  Training Accuracy:0.8903894472361809\n",
            "3184/4708 - The training loss at 25th epoch : 0.0812275889069495  Training Accuracy:0.8909375\n",
            "3200/4708 - The training loss at 25th epoch : 0.08101648092993753  Training Accuracy:0.8911691542288557\n",
            "3216/4708 - The training loss at 25th epoch : 0.0807441632303105  Training Accuracy:0.8917079207920792\n",
            "3232/4708 - The training loss at 25th epoch : 0.08090251330544375  Training Accuracy:0.8916256157635468\n",
            "3248/4708 - The training loss at 25th epoch : 0.08102696368959418  Training Accuracy:0.8915441176470589\n",
            "3264/4708 - The training loss at 25th epoch : 0.08083163683861457  Training Accuracy:0.8917682926829268\n",
            "3280/4708 - The training loss at 25th epoch : 0.08104840175941841  Training Accuracy:0.8913834951456311\n",
            "3296/4708 - The training loss at 25th epoch : 0.08114458047370218  Training Accuracy:0.8913043478260869\n",
            "3312/4708 - The training loss at 25th epoch : 0.08091380006433245  Training Accuracy:0.8915264423076923\n",
            "3328/4708 - The training loss at 25th epoch : 0.08095044581020557  Training Accuracy:0.8911483253588517\n",
            "3344/4708 - The training loss at 25th epoch : 0.08103933457355152  Training Accuracy:0.8910714285714286\n",
            "3360/4708 - The training loss at 25th epoch : 0.08104435880700896  Training Accuracy:0.8906990521327014\n",
            "3376/4708 - The training loss at 25th epoch : 0.08140558886588399  Training Accuracy:0.8900353773584906\n",
            "3392/4708 - The training loss at 25th epoch : 0.08107392736300145  Training Accuracy:0.8905516431924883\n",
            "3408/4708 - The training loss at 25th epoch : 0.08090496133184218  Training Accuracy:0.8907710280373832\n",
            "3424/4708 - The training loss at 25th epoch : 0.08071178001839185  Training Accuracy:0.8909883720930233\n",
            "3440/4708 - The training loss at 25th epoch : 0.08041901826364697  Training Accuracy:0.8914930555555556\n",
            "3456/4708 - The training loss at 25th epoch : 0.08031899520889957  Training Accuracy:0.8914170506912442\n",
            "3472/4708 - The training loss at 25th epoch : 0.08018121001583463  Training Accuracy:0.8916284403669725\n",
            "3488/4708 - The training loss at 25th epoch : 0.08052426039366177  Training Accuracy:0.8909817351598174\n",
            "3504/4708 - The training loss at 25th epoch : 0.08032652315068176  Training Accuracy:0.8911931818181819\n",
            "3520/4708 - The training loss at 25th epoch : 0.08045752442935941  Training Accuracy:0.8911199095022625\n",
            "3536/4708 - The training loss at 25th epoch : 0.08035580948121077  Training Accuracy:0.8910472972972973\n",
            "3552/4708 - The training loss at 25th epoch : 0.08035150789712554  Training Accuracy:0.8912556053811659\n",
            "3568/4708 - The training loss at 25th epoch : 0.08023178926586956  Training Accuracy:0.8914620535714286\n",
            "3584/4708 - The training loss at 25th epoch : 0.07996491167048136  Training Accuracy:0.8919444444444444\n",
            "3600/4708 - The training loss at 25th epoch : 0.07963561434043401  Training Accuracy:0.8924225663716814\n",
            "3616/4708 - The training loss at 25th epoch : 0.079624820296618  Training Accuracy:0.8926211453744494\n",
            "3632/4708 - The training loss at 25th epoch : 0.07960915648268076  Training Accuracy:0.8925438596491229\n",
            "3648/4708 - The training loss at 25th epoch : 0.07956638485761443  Training Accuracy:0.892467248908297\n",
            "3664/4708 - The training loss at 25th epoch : 0.07973366290626338  Training Accuracy:0.8923913043478261\n",
            "3680/4708 - The training loss at 25th epoch : 0.07968352282495725  Training Accuracy:0.8925865800865801\n",
            "3696/4708 - The training loss at 25th epoch : 0.07954653876171935  Training Accuracy:0.8927801724137931\n",
            "3712/4708 - The training loss at 25th epoch : 0.07961999245130989  Training Accuracy:0.8927038626609443\n",
            "3728/4708 - The training loss at 25th epoch : 0.07955323792999186  Training Accuracy:0.8931623931623932\n",
            "3744/4708 - The training loss at 25th epoch : 0.0792468458639767  Training Accuracy:0.8936170212765957\n",
            "3760/4708 - The training loss at 25th epoch : 0.07918004588315669  Training Accuracy:0.893802966101695\n",
            "3776/4708 - The training loss at 25th epoch : 0.07927880330735979  Training Accuracy:0.8934599156118144\n",
            "3792/4708 - The training loss at 25th epoch : 0.07896397680710292  Training Accuracy:0.8939075630252101\n",
            "3808/4708 - The training loss at 25th epoch : 0.07890156913973108  Training Accuracy:0.8940899581589958\n",
            "3824/4708 - The training loss at 25th epoch : 0.07919301389015694  Training Accuracy:0.89375\n",
            "3840/4708 - The training loss at 25th epoch : 0.07913690315523668  Training Accuracy:0.8936721991701245\n",
            "3856/4708 - The training loss at 25th epoch : 0.07896988758465842  Training Accuracy:0.893853305785124\n",
            "3872/4708 - The training loss at 25th epoch : 0.07904731892160756  Training Accuracy:0.8935185185185185\n",
            "3888/4708 - The training loss at 25th epoch : 0.07874854104948677  Training Accuracy:0.8939549180327869\n",
            "3904/4708 - The training loss at 25th epoch : 0.07868024315624392  Training Accuracy:0.8941326530612245\n",
            "3920/4708 - The training loss at 25th epoch : 0.07852825402411846  Training Accuracy:0.8943089430894309\n",
            "3936/4708 - The training loss at 25th epoch : 0.07869566795113657  Training Accuracy:0.8942307692307693\n",
            "3952/4708 - The training loss at 25th epoch : 0.07888437941121584  Training Accuracy:0.8939012096774194\n",
            "3968/4708 - The training loss at 25th epoch : 0.07865562119931778  Training Accuracy:0.8943273092369478\n",
            "3984/4708 - The training loss at 25th epoch : 0.07873393005645113  Training Accuracy:0.8945\n",
            "4000/4708 - The training loss at 25th epoch : 0.07888451362414942  Training Accuracy:0.8941733067729084\n",
            "4016/4708 - The training loss at 25th epoch : 0.07895736424240286  Training Accuracy:0.8940972222222222\n",
            "4032/4708 - The training loss at 25th epoch : 0.07929991251241433  Training Accuracy:0.8935276679841897\n",
            "4048/4708 - The training loss at 25th epoch : 0.07940984681647252  Training Accuracy:0.8934547244094488\n",
            "4064/4708 - The training loss at 25th epoch : 0.07929897786407529  Training Accuracy:0.8936274509803922\n",
            "4080/4708 - The training loss at 25th epoch : 0.07910778462907143  Training Accuracy:0.893798828125\n",
            "4096/4708 - The training loss at 25th epoch : 0.07889255041871103  Training Accuracy:0.8942120622568094\n",
            "4112/4708 - The training loss at 25th epoch : 0.07888584293399009  Training Accuracy:0.8941375968992248\n",
            "4128/4708 - The training loss at 25th epoch : 0.07889485328736134  Training Accuracy:0.8940637065637066\n",
            "4144/4708 - The training loss at 25th epoch : 0.0793135463790961  Training Accuracy:0.89375\n",
            "4160/4708 - The training loss at 25th epoch : 0.07923784133242154  Training Accuracy:0.8939176245210728\n",
            "4176/4708 - The training loss at 25th epoch : 0.07904586331448141  Training Accuracy:0.8943225190839694\n",
            "4192/4708 - The training loss at 25th epoch : 0.07908364768372406  Training Accuracy:0.8940114068441065\n",
            "4208/4708 - The training loss at 25th epoch : 0.07891781537761791  Training Accuracy:0.8941761363636364\n",
            "4224/4708 - The training loss at 25th epoch : 0.07869505581056443  Training Accuracy:0.8945754716981132\n",
            "4240/4708 - The training loss at 25th epoch : 0.0790912156935346  Training Accuracy:0.8940319548872181\n",
            "4256/4708 - The training loss at 25th epoch : 0.07882465623243587  Training Accuracy:0.8944288389513109\n",
            "4272/4708 - The training loss at 25th epoch : 0.07866092655669811  Training Accuracy:0.8948227611940298\n",
            "4288/4708 - The training loss at 25th epoch : 0.07904902262471573  Training Accuracy:0.8942843866171004\n",
            "4304/4708 - The training loss at 25th epoch : 0.07896389614840205  Training Accuracy:0.8942129629629629\n",
            "4320/4708 - The training loss at 25th epoch : 0.0788799225486506  Training Accuracy:0.8943726937269373\n",
            "4336/4708 - The training loss at 25th epoch : 0.07864487081063233  Training Accuracy:0.8947610294117647\n",
            "4352/4708 - The training loss at 25th epoch : 0.07844790999621404  Training Accuracy:0.8951465201465202\n",
            "4368/4708 - The training loss at 25th epoch : 0.07826038188007597  Training Accuracy:0.895529197080292\n",
            "4384/4708 - The training loss at 25th epoch : 0.07872742997156812  Training Accuracy:0.895\n",
            "4400/4708 - The training loss at 25th epoch : 0.07895794737202967  Training Accuracy:0.8947010869565217\n",
            "4416/4708 - The training loss at 25th epoch : 0.07902275712191155  Training Accuracy:0.894404332129964\n",
            "4432/4708 - The training loss at 25th epoch : 0.07927857236280171  Training Accuracy:0.8941097122302158\n",
            "4448/4708 - The training loss at 25th epoch : 0.07908409422796675  Training Accuracy:0.894489247311828\n",
            "4464/4708 - The training loss at 25th epoch : 0.07937164262862273  Training Accuracy:0.8939732142857143\n",
            "4480/4708 - The training loss at 25th epoch : 0.07912777139440891  Training Accuracy:0.8943505338078291\n",
            "4496/4708 - The training loss at 25th epoch : 0.07900103538867868  Training Accuracy:0.8945035460992907\n",
            "4512/4708 - The training loss at 25th epoch : 0.07884764403812199  Training Accuracy:0.8946554770318021\n",
            "4528/4708 - The training loss at 25th epoch : 0.07890915105254726  Training Accuracy:0.8945862676056338\n",
            "4544/4708 - The training loss at 25th epoch : 0.07911432134923431  Training Accuracy:0.894298245614035\n",
            "4560/4708 - The training loss at 25th epoch : 0.07916908837769972  Training Accuracy:0.8942307692307693\n",
            "4576/4708 - The training loss at 25th epoch : 0.078988428805336  Training Accuracy:0.8945993031358885\n",
            "4592/4708 - The training loss at 25th epoch : 0.07892649518571265  Training Accuracy:0.89453125\n",
            "4608/4708 - The training loss at 25th epoch : 0.07870860302600335  Training Accuracy:0.8948961937716263\n",
            "4624/4708 - The training loss at 25th epoch : 0.07870468049555257  Training Accuracy:0.8948275862068965\n",
            "4640/4708 - The training loss at 25th epoch : 0.07868417447226227  Training Accuracy:0.8947594501718213\n",
            "4656/4708 - The training loss at 25th epoch : 0.07880634294167442  Training Accuracy:0.8946917808219178\n",
            "4672/4708 - The training loss at 25th epoch : 0.07883254945502893  Training Accuracy:0.8946245733788396\n",
            "4688/4708 - The training loss at 25th epoch : 0.07888121967697569  Training Accuracy:0.8945578231292517\n",
            "4704/4708 - The training loss at 25th epoch : 0.07862957807727093  Training Accuracy:0.8949152542372881\n",
            "4720/4708 - The training loss at 25th epoch : 0.07852123280079433  Training Accuracy:0.8950591216216216\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 26th epoch : 0.009465412461712433  Training Accuracy:1.0\n",
            "16/4708 - The training loss at 26th epoch : 0.14627754561409148  Training Accuracy:0.8125\n",
            "32/4708 - The training loss at 26th epoch : 0.11450974973693799  Training Accuracy:0.8333333333333334\n",
            "48/4708 - The training loss at 26th epoch : 0.1146270709368429  Training Accuracy:0.828125\n",
            "64/4708 - The training loss at 26th epoch : 0.11333525893085587  Training Accuracy:0.8375\n",
            "80/4708 - The training loss at 26th epoch : 0.10833017205785585  Training Accuracy:0.84375\n",
            "96/4708 - The training loss at 26th epoch : 0.10547724830668138  Training Accuracy:0.8482142857142857\n",
            "112/4708 - The training loss at 26th epoch : 0.10394516797643955  Training Accuracy:0.8515625\n",
            "128/4708 - The training loss at 26th epoch : 0.11011538985078184  Training Accuracy:0.8472222222222222\n",
            "144/4708 - The training loss at 26th epoch : 0.10758837713066646  Training Accuracy:0.85\n",
            "160/4708 - The training loss at 26th epoch : 0.11142653786938772  Training Accuracy:0.8465909090909091\n",
            "176/4708 - The training loss at 26th epoch : 0.10753702579491514  Training Accuracy:0.8541666666666666\n",
            "192/4708 - The training loss at 26th epoch : 0.10212079891606582  Training Accuracy:0.8653846153846154\n",
            "208/4708 - The training loss at 26th epoch : 0.10432198722935244  Training Accuracy:0.8616071428571429\n",
            "224/4708 - The training loss at 26th epoch : 0.10458124004529694  Training Accuracy:0.8625\n",
            "240/4708 - The training loss at 26th epoch : 0.10135182795845091  Training Accuracy:0.8671875\n",
            "256/4708 - The training loss at 26th epoch : 0.09970100835277743  Training Accuracy:0.8713235294117647\n",
            "272/4708 - The training loss at 26th epoch : 0.09501260238443125  Training Accuracy:0.8784722222222222\n",
            "288/4708 - The training loss at 26th epoch : 0.09890277109302854  Training Accuracy:0.875\n",
            "304/4708 - The training loss at 26th epoch : 0.09773971554957539  Training Accuracy:0.875\n",
            "320/4708 - The training loss at 26th epoch : 0.1018039552457725  Training Accuracy:0.8690476190476191\n",
            "336/4708 - The training loss at 26th epoch : 0.10307777915717448  Training Accuracy:0.8664772727272727\n",
            "352/4708 - The training loss at 26th epoch : 0.10041155287132782  Training Accuracy:0.8695652173913043\n",
            "368/4708 - The training loss at 26th epoch : 0.09703943711951606  Training Accuracy:0.875\n",
            "384/4708 - The training loss at 26th epoch : 0.09935017831082565  Training Accuracy:0.8725\n",
            "400/4708 - The training loss at 26th epoch : 0.09928902052446639  Training Accuracy:0.8701923076923077\n",
            "416/4708 - The training loss at 26th epoch : 0.100228020179224  Training Accuracy:0.8703703703703703\n",
            "432/4708 - The training loss at 26th epoch : 0.09804818249440492  Training Accuracy:0.8727678571428571\n",
            "448/4708 - The training loss at 26th epoch : 0.098764001227467  Training Accuracy:0.8706896551724138\n",
            "464/4708 - The training loss at 26th epoch : 0.09684316980820475  Training Accuracy:0.8729166666666667\n",
            "480/4708 - The training loss at 26th epoch : 0.09612682524329196  Training Accuracy:0.8729838709677419\n",
            "496/4708 - The training loss at 26th epoch : 0.09498851867230043  Training Accuracy:0.873046875\n",
            "512/4708 - The training loss at 26th epoch : 0.09220699245467738  Training Accuracy:0.8768939393939394\n",
            "528/4708 - The training loss at 26th epoch : 0.09188056534060628  Training Accuracy:0.8768382352941176\n",
            "544/4708 - The training loss at 26th epoch : 0.09149489298408628  Training Accuracy:0.875\n",
            "560/4708 - The training loss at 26th epoch : 0.09367089572402226  Training Accuracy:0.8732638888888888\n",
            "576/4708 - The training loss at 26th epoch : 0.09299439301814015  Training Accuracy:0.875\n",
            "592/4708 - The training loss at 26th epoch : 0.09236411672918972  Training Accuracy:0.875\n",
            "608/4708 - The training loss at 26th epoch : 0.09202809520327873  Training Accuracy:0.875\n",
            "624/4708 - The training loss at 26th epoch : 0.09245854221375172  Training Accuracy:0.8734375\n",
            "640/4708 - The training loss at 26th epoch : 0.09128795891155117  Training Accuracy:0.8734756097560976\n",
            "656/4708 - The training loss at 26th epoch : 0.0912753225701623  Training Accuracy:0.8735119047619048\n",
            "672/4708 - The training loss at 26th epoch : 0.09022800288290048  Training Accuracy:0.875\n",
            "688/4708 - The training loss at 26th epoch : 0.09092080921582987  Training Accuracy:0.875\n",
            "704/4708 - The training loss at 26th epoch : 0.09016075474704244  Training Accuracy:0.8763888888888889\n",
            "720/4708 - The training loss at 26th epoch : 0.08951617721097885  Training Accuracy:0.8777173913043478\n",
            "736/4708 - The training loss at 26th epoch : 0.08927270953785066  Training Accuracy:0.8789893617021277\n",
            "752/4708 - The training loss at 26th epoch : 0.08876090642677022  Training Accuracy:0.8802083333333334\n",
            "768/4708 - The training loss at 26th epoch : 0.08788993482250049  Training Accuracy:0.8801020408163265\n",
            "784/4708 - The training loss at 26th epoch : 0.08836603906105589  Training Accuracy:0.87875\n",
            "800/4708 - The training loss at 26th epoch : 0.0878872902259659  Training Accuracy:0.8799019607843137\n",
            "816/4708 - The training loss at 26th epoch : 0.08704221496415053  Training Accuracy:0.8810096153846154\n",
            "832/4708 - The training loss at 26th epoch : 0.08753071746879086  Training Accuracy:0.8808962264150944\n",
            "848/4708 - The training loss at 26th epoch : 0.08672441841642348  Training Accuracy:0.8807870370370371\n",
            "864/4708 - The training loss at 26th epoch : 0.08748331932308885  Training Accuracy:0.8795454545454545\n",
            "880/4708 - The training loss at 26th epoch : 0.08721479806807755  Training Accuracy:0.8805803571428571\n",
            "896/4708 - The training loss at 26th epoch : 0.0862804107599252  Training Accuracy:0.8826754385964912\n",
            "912/4708 - The training loss at 26th epoch : 0.08652336023263855  Training Accuracy:0.8814655172413793\n",
            "928/4708 - The training loss at 26th epoch : 0.085567357285477  Training Accuracy:0.8824152542372882\n",
            "944/4708 - The training loss at 26th epoch : 0.08549159541304384  Training Accuracy:0.8822916666666667\n",
            "960/4708 - The training loss at 26th epoch : 0.08639535064886755  Training Accuracy:0.8811475409836066\n",
            "976/4708 - The training loss at 26th epoch : 0.08727692376494055  Training Accuracy:0.8800403225806451\n",
            "992/4708 - The training loss at 26th epoch : 0.08687417904650704  Training Accuracy:0.8799603174603174\n",
            "1008/4708 - The training loss at 26th epoch : 0.08657916476976323  Training Accuracy:0.880859375\n",
            "1024/4708 - The training loss at 26th epoch : 0.08696832888768448  Training Accuracy:0.8807692307692307\n",
            "1040/4708 - The training loss at 26th epoch : 0.0880478747599256  Training Accuracy:0.8797348484848485\n",
            "1056/4708 - The training loss at 26th epoch : 0.08761769867847494  Training Accuracy:0.8805970149253731\n",
            "1072/4708 - The training loss at 26th epoch : 0.08750806710499108  Training Accuracy:0.8805147058823529\n",
            "1088/4708 - The training loss at 26th epoch : 0.08872412291731939  Training Accuracy:0.8786231884057971\n",
            "1104/4708 - The training loss at 26th epoch : 0.08754373488991285  Training Accuracy:0.8803571428571428\n",
            "1120/4708 - The training loss at 26th epoch : 0.08711772911561999  Training Accuracy:0.8811619718309859\n",
            "1136/4708 - The training loss at 26th epoch : 0.08845115761560803  Training Accuracy:0.8776041666666666\n",
            "1152/4708 - The training loss at 26th epoch : 0.08864673516795522  Training Accuracy:0.877568493150685\n",
            "1168/4708 - The training loss at 26th epoch : 0.08842918718404431  Training Accuracy:0.8783783783783784\n",
            "1184/4708 - The training loss at 26th epoch : 0.08734012012554142  Training Accuracy:0.88\n",
            "1200/4708 - The training loss at 26th epoch : 0.0876230520629258  Training Accuracy:0.8799342105263158\n",
            "1216/4708 - The training loss at 26th epoch : 0.08766129516290848  Training Accuracy:0.8790584415584416\n",
            "1232/4708 - The training loss at 26th epoch : 0.08767705389829827  Training Accuracy:0.8790064102564102\n",
            "1248/4708 - The training loss at 26th epoch : 0.08688101240072167  Training Accuracy:0.8805379746835443\n",
            "1264/4708 - The training loss at 26th epoch : 0.0868537715919114  Training Accuracy:0.88125\n",
            "1280/4708 - The training loss at 26th epoch : 0.08589623478813854  Training Accuracy:0.8827160493827161\n",
            "1296/4708 - The training loss at 26th epoch : 0.08624656205641888  Training Accuracy:0.8826219512195121\n",
            "1312/4708 - The training loss at 26th epoch : 0.08660233551452404  Training Accuracy:0.8817771084337349\n",
            "1328/4708 - The training loss at 26th epoch : 0.08767518092554895  Training Accuracy:0.8802083333333334\n",
            "1344/4708 - The training loss at 26th epoch : 0.0870397203302636  Training Accuracy:0.8816176470588235\n",
            "1360/4708 - The training loss at 26th epoch : 0.08664547162636996  Training Accuracy:0.8815406976744186\n",
            "1376/4708 - The training loss at 26th epoch : 0.08629047139893467  Training Accuracy:0.882183908045977\n",
            "1392/4708 - The training loss at 26th epoch : 0.08664631969168252  Training Accuracy:0.8821022727272727\n",
            "1408/4708 - The training loss at 26th epoch : 0.08630266740185723  Training Accuracy:0.8820224719101124\n",
            "1424/4708 - The training loss at 26th epoch : 0.08588199069395155  Training Accuracy:0.8826388888888889\n",
            "1440/4708 - The training loss at 26th epoch : 0.08541620853801044  Training Accuracy:0.8832417582417582\n",
            "1456/4708 - The training loss at 26th epoch : 0.0863227388612502  Training Accuracy:0.8817934782608695\n",
            "1472/4708 - The training loss at 26th epoch : 0.08574122283112451  Training Accuracy:0.8823924731182796\n",
            "1488/4708 - The training loss at 26th epoch : 0.08570880489146268  Training Accuracy:0.882313829787234\n",
            "1504/4708 - The training loss at 26th epoch : 0.0853462981505051  Training Accuracy:0.8828947368421053\n",
            "1520/4708 - The training loss at 26th epoch : 0.08558726231525583  Training Accuracy:0.8828125\n",
            "1536/4708 - The training loss at 26th epoch : 0.0867298219902032  Training Accuracy:0.8814432989690721\n",
            "1552/4708 - The training loss at 26th epoch : 0.08651854925753763  Training Accuracy:0.8820153061224489\n",
            "1568/4708 - The training loss at 26th epoch : 0.08686973191046307  Training Accuracy:0.8819444444444444\n",
            "1584/4708 - The training loss at 26th epoch : 0.0868309534146883  Training Accuracy:0.881875\n",
            "1600/4708 - The training loss at 26th epoch : 0.08652136891186121  Training Accuracy:0.8818069306930693\n",
            "1616/4708 - The training loss at 26th epoch : 0.08809048903573771  Training Accuracy:0.8792892156862745\n",
            "1632/4708 - The training loss at 26th epoch : 0.08829918352254756  Training Accuracy:0.8786407766990292\n",
            "1648/4708 - The training loss at 26th epoch : 0.08866067790206313  Training Accuracy:0.8786057692307693\n",
            "1664/4708 - The training loss at 26th epoch : 0.08828536541315601  Training Accuracy:0.8791666666666667\n",
            "1680/4708 - The training loss at 26th epoch : 0.0879662182046072  Training Accuracy:0.8797169811320755\n",
            "1696/4708 - The training loss at 26th epoch : 0.08778113575435219  Training Accuracy:0.8796728971962616\n",
            "1712/4708 - The training loss at 26th epoch : 0.087774620855947  Training Accuracy:0.8796296296296297\n",
            "1728/4708 - The training loss at 26th epoch : 0.08804189413246832  Training Accuracy:0.8795871559633027\n",
            "1744/4708 - The training loss at 26th epoch : 0.08775396124681313  Training Accuracy:0.8801136363636364\n",
            "1760/4708 - The training loss at 26th epoch : 0.0876969369018139  Training Accuracy:0.8800675675675675\n",
            "1776/4708 - The training loss at 26th epoch : 0.08730334563303342  Training Accuracy:0.8805803571428571\n",
            "1792/4708 - The training loss at 26th epoch : 0.08681852282015945  Training Accuracy:0.8810840707964602\n",
            "1808/4708 - The training loss at 26th epoch : 0.08646544641415578  Training Accuracy:0.8810307017543859\n",
            "1824/4708 - The training loss at 26th epoch : 0.08629515763443932  Training Accuracy:0.8809782608695652\n",
            "1840/4708 - The training loss at 26th epoch : 0.08608925270556925  Training Accuracy:0.8814655172413793\n",
            "1856/4708 - The training loss at 26th epoch : 0.08619672237361338  Training Accuracy:0.8808760683760684\n",
            "1872/4708 - The training loss at 26th epoch : 0.08637999034341813  Training Accuracy:0.8802966101694916\n",
            "1888/4708 - The training loss at 26th epoch : 0.08672122994330889  Training Accuracy:0.8797268907563025\n",
            "1904/4708 - The training loss at 26th epoch : 0.086832090845649  Training Accuracy:0.8796875\n",
            "1920/4708 - The training loss at 26th epoch : 0.08744118341866841  Training Accuracy:0.8786157024793388\n",
            "1936/4708 - The training loss at 26th epoch : 0.08722300727270998  Training Accuracy:0.8790983606557377\n",
            "1952/4708 - The training loss at 26th epoch : 0.0874096282447382  Training Accuracy:0.8785569105691057\n",
            "1968/4708 - The training loss at 26th epoch : 0.08739058059638288  Training Accuracy:0.8790322580645161\n",
            "1984/4708 - The training loss at 26th epoch : 0.08690150513205513  Training Accuracy:0.88\n",
            "2000/4708 - The training loss at 26th epoch : 0.08702995972182016  Training Accuracy:0.8794642857142857\n",
            "2016/4708 - The training loss at 26th epoch : 0.08709275742067159  Training Accuracy:0.8794291338582677\n",
            "2032/4708 - The training loss at 26th epoch : 0.08660728997078422  Training Accuracy:0.8798828125\n",
            "2048/4708 - The training loss at 26th epoch : 0.08618684794281932  Training Accuracy:0.8808139534883721\n",
            "2064/4708 - The training loss at 26th epoch : 0.0861121756968701  Training Accuracy:0.88125\n",
            "2080/4708 - The training loss at 26th epoch : 0.08691676653469466  Training Accuracy:0.8802480916030534\n",
            "2096/4708 - The training loss at 26th epoch : 0.08656064713883045  Training Accuracy:0.8806818181818182\n",
            "2112/4708 - The training loss at 26th epoch : 0.08700577746390896  Training Accuracy:0.8801691729323309\n",
            "2128/4708 - The training loss at 26th epoch : 0.0869719811599601  Training Accuracy:0.8801305970149254\n",
            "2144/4708 - The training loss at 26th epoch : 0.08660633651073638  Training Accuracy:0.8810185185185185\n",
            "2160/4708 - The training loss at 26th epoch : 0.08659087384615534  Training Accuracy:0.8809742647058824\n",
            "2176/4708 - The training loss at 26th epoch : 0.08632964239901142  Training Accuracy:0.8813868613138686\n",
            "2192/4708 - The training loss at 26th epoch : 0.0865529572059881  Training Accuracy:0.8813405797101449\n",
            "2208/4708 - The training loss at 26th epoch : 0.08629645274337666  Training Accuracy:0.8812949640287769\n",
            "2224/4708 - The training loss at 26th epoch : 0.0859257578296212  Training Accuracy:0.8816964285714286\n",
            "2240/4708 - The training loss at 26th epoch : 0.08550658997976555  Training Accuracy:0.8820921985815603\n",
            "2256/4708 - The training loss at 26th epoch : 0.08572628638159642  Training Accuracy:0.8820422535211268\n",
            "2272/4708 - The training loss at 26th epoch : 0.0857182972810475  Training Accuracy:0.8824300699300699\n",
            "2288/4708 - The training loss at 26th epoch : 0.08515219498776377  Training Accuracy:0.8832465277777778\n",
            "2304/4708 - The training loss at 26th epoch : 0.08539087772167292  Training Accuracy:0.8831896551724138\n",
            "2320/4708 - The training loss at 26th epoch : 0.08534358843331252  Training Accuracy:0.8831335616438356\n",
            "2336/4708 - The training loss at 26th epoch : 0.08478950536229161  Training Accuracy:0.8839285714285714\n",
            "2352/4708 - The training loss at 26th epoch : 0.08479255211705192  Training Accuracy:0.8838682432432432\n",
            "2368/4708 - The training loss at 26th epoch : 0.08480790391717108  Training Accuracy:0.8838087248322147\n",
            "2384/4708 - The training loss at 26th epoch : 0.08480992123024196  Training Accuracy:0.8841666666666667\n",
            "2400/4708 - The training loss at 26th epoch : 0.08459758444354583  Training Accuracy:0.8845198675496688\n",
            "2416/4708 - The training loss at 26th epoch : 0.08413367324807457  Training Accuracy:0.8852796052631579\n",
            "2432/4708 - The training loss at 26th epoch : 0.0837865158677997  Training Accuracy:0.8856209150326797\n",
            "2448/4708 - The training loss at 26th epoch : 0.08378325973357657  Training Accuracy:0.885551948051948\n",
            "2464/4708 - The training loss at 26th epoch : 0.08382676379428412  Training Accuracy:0.885483870967742\n",
            "2480/4708 - The training loss at 26th epoch : 0.0841904673020733  Training Accuracy:0.8846153846153846\n",
            "2496/4708 - The training loss at 26th epoch : 0.083733067496733  Training Accuracy:0.8853503184713376\n",
            "2512/4708 - The training loss at 26th epoch : 0.08382301880743256  Training Accuracy:0.8852848101265823\n",
            "2528/4708 - The training loss at 26th epoch : 0.08339633787943142  Training Accuracy:0.8860062893081762\n",
            "2544/4708 - The training loss at 26th epoch : 0.0832191815896854  Training Accuracy:0.886328125\n",
            "2560/4708 - The training loss at 26th epoch : 0.08309783266535363  Training Accuracy:0.8862577639751553\n",
            "2576/4708 - The training loss at 26th epoch : 0.08293070562888313  Training Accuracy:0.8861882716049383\n",
            "2592/4708 - The training loss at 26th epoch : 0.08269662181567887  Training Accuracy:0.8865030674846626\n",
            "2608/4708 - The training loss at 26th epoch : 0.0830388783321099  Training Accuracy:0.8860518292682927\n",
            "2624/4708 - The training loss at 26th epoch : 0.08278348205075242  Training Accuracy:0.8863636363636364\n",
            "2640/4708 - The training loss at 26th epoch : 0.08275599814824411  Training Accuracy:0.8862951807228916\n",
            "2656/4708 - The training loss at 26th epoch : 0.08260416471408867  Training Accuracy:0.8862275449101796\n",
            "2672/4708 - The training loss at 26th epoch : 0.08237014686785674  Training Accuracy:0.8861607142857143\n",
            "2688/4708 - The training loss at 26th epoch : 0.08195139669393667  Training Accuracy:0.8868343195266272\n",
            "2704/4708 - The training loss at 26th epoch : 0.08195573880599118  Training Accuracy:0.8871323529411764\n",
            "2720/4708 - The training loss at 26th epoch : 0.08183113229711428  Training Accuracy:0.8870614035087719\n",
            "2736/4708 - The training loss at 26th epoch : 0.08191880532691628  Training Accuracy:0.8869912790697675\n",
            "2752/4708 - The training loss at 26th epoch : 0.08186308582030491  Training Accuracy:0.8872832369942196\n",
            "2768/4708 - The training loss at 26th epoch : 0.08163007533419706  Training Accuracy:0.8875718390804598\n",
            "2784/4708 - The training loss at 26th epoch : 0.08176289015405527  Training Accuracy:0.8875\n",
            "2800/4708 - The training loss at 26th epoch : 0.081533468340646  Training Accuracy:0.8877840909090909\n",
            "2816/4708 - The training loss at 26th epoch : 0.081107640291713  Training Accuracy:0.8884180790960452\n",
            "2832/4708 - The training loss at 26th epoch : 0.08087443246149512  Training Accuracy:0.8886938202247191\n",
            "2848/4708 - The training loss at 26th epoch : 0.08052161265550603  Training Accuracy:0.8893156424581006\n",
            "2864/4708 - The training loss at 26th epoch : 0.08046041855794543  Training Accuracy:0.8895833333333333\n",
            "2880/4708 - The training loss at 26th epoch : 0.08024135422733134  Training Accuracy:0.8898480662983426\n",
            "2896/4708 - The training loss at 26th epoch : 0.08048984721205568  Training Accuracy:0.8897664835164835\n",
            "2912/4708 - The training loss at 26th epoch : 0.08056823175631457  Training Accuracy:0.8896857923497268\n",
            "2928/4708 - The training loss at 26th epoch : 0.08028851803145172  Training Accuracy:0.8902853260869565\n",
            "2944/4708 - The training loss at 26th epoch : 0.08039936139446292  Training Accuracy:0.8898648648648648\n",
            "2960/4708 - The training loss at 26th epoch : 0.08022222259100756  Training Accuracy:0.8901209677419355\n",
            "2976/4708 - The training loss at 26th epoch : 0.07996093970849856  Training Accuracy:0.8907085561497327\n",
            "2992/4708 - The training loss at 26th epoch : 0.07973665376201602  Training Accuracy:0.8909574468085106\n",
            "3008/4708 - The training loss at 26th epoch : 0.07975614328687593  Training Accuracy:0.8908730158730159\n",
            "3024/4708 - The training loss at 26th epoch : 0.07955426193831024  Training Accuracy:0.8911184210526316\n",
            "3040/4708 - The training loss at 26th epoch : 0.07969400472997631  Training Accuracy:0.8907068062827225\n",
            "3056/4708 - The training loss at 26th epoch : 0.07946773549725394  Training Accuracy:0.8909505208333334\n",
            "3072/4708 - The training loss at 26th epoch : 0.07910250343665937  Training Accuracy:0.8915155440414507\n",
            "3088/4708 - The training loss at 26th epoch : 0.07897934795681283  Training Accuracy:0.8914304123711341\n",
            "3104/4708 - The training loss at 26th epoch : 0.07945014976648886  Training Accuracy:0.8907051282051283\n",
            "3120/4708 - The training loss at 26th epoch : 0.07954327014487306  Training Accuracy:0.890625\n",
            "3136/4708 - The training loss at 26th epoch : 0.07965346438225016  Training Accuracy:0.8902284263959391\n",
            "3152/4708 - The training loss at 26th epoch : 0.07933818133180234  Training Accuracy:0.8907828282828283\n",
            "3168/4708 - The training loss at 26th epoch : 0.07908529923273638  Training Accuracy:0.8913316582914573\n",
            "3184/4708 - The training loss at 26th epoch : 0.0790578242213955  Training Accuracy:0.89125\n",
            "3200/4708 - The training loss at 26th epoch : 0.07951656214748175  Training Accuracy:0.8908582089552238\n",
            "3216/4708 - The training loss at 26th epoch : 0.07943108697415653  Training Accuracy:0.8907797029702971\n",
            "3232/4708 - The training loss at 26th epoch : 0.07909814780203565  Training Accuracy:0.8913177339901478\n",
            "3248/4708 - The training loss at 26th epoch : 0.07900366484913254  Training Accuracy:0.8915441176470589\n",
            "3264/4708 - The training loss at 26th epoch : 0.07884314410553196  Training Accuracy:0.8917682926829268\n",
            "3280/4708 - The training loss at 26th epoch : 0.0788266477705472  Training Accuracy:0.8913834951456311\n",
            "3296/4708 - The training loss at 26th epoch : 0.07864021922456953  Training Accuracy:0.8916062801932367\n",
            "3312/4708 - The training loss at 26th epoch : 0.07865015899303847  Training Accuracy:0.8915264423076923\n",
            "3328/4708 - The training loss at 26th epoch : 0.07831001413174477  Training Accuracy:0.8920454545454546\n",
            "3344/4708 - The training loss at 26th epoch : 0.07836027287846549  Training Accuracy:0.8922619047619048\n",
            "3360/4708 - The training loss at 26th epoch : 0.07840833887705115  Training Accuracy:0.8921800947867299\n",
            "3376/4708 - The training loss at 26th epoch : 0.07820094169273428  Training Accuracy:0.8923938679245284\n",
            "3392/4708 - The training loss at 26th epoch : 0.07799555401629012  Training Accuracy:0.8926056338028169\n",
            "3408/4708 - The training loss at 26th epoch : 0.07763776785753711  Training Accuracy:0.893107476635514\n",
            "3424/4708 - The training loss at 26th epoch : 0.0773923659888881  Training Accuracy:0.8933139534883721\n",
            "3440/4708 - The training loss at 26th epoch : 0.07715948947602334  Training Accuracy:0.8938078703703703\n",
            "3456/4708 - The training loss at 26th epoch : 0.07707804921581374  Training Accuracy:0.8940092165898618\n",
            "3472/4708 - The training loss at 26th epoch : 0.07702994199594773  Training Accuracy:0.8942087155963303\n",
            "3488/4708 - The training loss at 26th epoch : 0.07698366469489425  Training Accuracy:0.894406392694064\n",
            "3504/4708 - The training loss at 26th epoch : 0.07698914941379426  Training Accuracy:0.8943181818181818\n",
            "3520/4708 - The training loss at 26th epoch : 0.07674366168125514  Training Accuracy:0.8945135746606335\n",
            "3536/4708 - The training loss at 26th epoch : 0.07671924644138461  Training Accuracy:0.8944256756756757\n",
            "3552/4708 - The training loss at 26th epoch : 0.07718161773279615  Training Accuracy:0.8937780269058296\n",
            "3568/4708 - The training loss at 26th epoch : 0.07703444604580835  Training Accuracy:0.8939732142857143\n",
            "3584/4708 - The training loss at 26th epoch : 0.0768254491952665  Training Accuracy:0.8941666666666667\n",
            "3600/4708 - The training loss at 26th epoch : 0.07695728886908451  Training Accuracy:0.8938053097345132\n",
            "3616/4708 - The training loss at 26th epoch : 0.07674260593325252  Training Accuracy:0.8939977973568282\n",
            "3632/4708 - The training loss at 26th epoch : 0.07676495220769008  Training Accuracy:0.8939144736842105\n",
            "3648/4708 - The training loss at 26th epoch : 0.07705712288044105  Training Accuracy:0.8935589519650655\n",
            "3664/4708 - The training loss at 26th epoch : 0.07676692002306766  Training Accuracy:0.8940217391304348\n",
            "3680/4708 - The training loss at 26th epoch : 0.07706658489434123  Training Accuracy:0.8936688311688312\n",
            "3696/4708 - The training loss at 26th epoch : 0.07674475265506012  Training Accuracy:0.8941271551724138\n",
            "3712/4708 - The training loss at 26th epoch : 0.07658830120070305  Training Accuracy:0.89431330472103\n",
            "3728/4708 - The training loss at 26th epoch : 0.07646553069225238  Training Accuracy:0.8944978632478633\n",
            "3744/4708 - The training loss at 26th epoch : 0.07627323562660322  Training Accuracy:0.8949468085106383\n",
            "3760/4708 - The training loss at 26th epoch : 0.07634064420216917  Training Accuracy:0.8948622881355932\n",
            "3776/4708 - The training loss at 26th epoch : 0.07640401532646755  Training Accuracy:0.895042194092827\n",
            "3792/4708 - The training loss at 26th epoch : 0.07669932986840829  Training Accuracy:0.8944327731092437\n",
            "3808/4708 - The training loss at 26th epoch : 0.07667147784029611  Training Accuracy:0.8943514644351465\n",
            "3824/4708 - The training loss at 26th epoch : 0.0770708789388683  Training Accuracy:0.8934895833333333\n",
            "3840/4708 - The training loss at 26th epoch : 0.07709789117680974  Training Accuracy:0.8931535269709544\n",
            "3856/4708 - The training loss at 26th epoch : 0.07749635491635079  Training Accuracy:0.8925619834710744\n",
            "3872/4708 - The training loss at 26th epoch : 0.0775770962798779  Training Accuracy:0.8924897119341564\n",
            "3888/4708 - The training loss at 26th epoch : 0.07744266733591669  Training Accuracy:0.8926741803278688\n",
            "3904/4708 - The training loss at 26th epoch : 0.07723852729837441  Training Accuracy:0.8931122448979592\n",
            "3920/4708 - The training loss at 26th epoch : 0.0771281663153259  Training Accuracy:0.8932926829268293\n",
            "3936/4708 - The training loss at 26th epoch : 0.07712103498703349  Training Accuracy:0.8932186234817814\n",
            "3952/4708 - The training loss at 26th epoch : 0.07720392077862212  Training Accuracy:0.8931451612903226\n",
            "3968/4708 - The training loss at 26th epoch : 0.0770433432186027  Training Accuracy:0.8933232931726908\n",
            "3984/4708 - The training loss at 26th epoch : 0.07734685992233194  Training Accuracy:0.893\n",
            "4000/4708 - The training loss at 26th epoch : 0.07717850449716633  Training Accuracy:0.8931772908366534\n",
            "4016/4708 - The training loss at 26th epoch : 0.07714778484272357  Training Accuracy:0.8933531746031746\n",
            "4032/4708 - The training loss at 26th epoch : 0.07712463077468859  Training Accuracy:0.8935276679841897\n",
            "4048/4708 - The training loss at 26th epoch : 0.0773180237352816  Training Accuracy:0.8929625984251969\n",
            "4064/4708 - The training loss at 26th epoch : 0.07704476628865747  Training Accuracy:0.8933823529411765\n",
            "4080/4708 - The training loss at 26th epoch : 0.0772526017371617  Training Accuracy:0.893310546875\n",
            "4096/4708 - The training loss at 26th epoch : 0.07715778930692477  Training Accuracy:0.893239299610895\n",
            "4112/4708 - The training loss at 26th epoch : 0.07706948749201335  Training Accuracy:0.8934108527131783\n",
            "4128/4708 - The training loss at 26th epoch : 0.07720850416765347  Training Accuracy:0.8933397683397684\n",
            "4144/4708 - The training loss at 26th epoch : 0.07727240137486342  Training Accuracy:0.8930288461538461\n",
            "4160/4708 - The training loss at 26th epoch : 0.07747317272959679  Training Accuracy:0.89272030651341\n",
            "4176/4708 - The training loss at 26th epoch : 0.07752149521302118  Training Accuracy:0.8928912213740458\n",
            "4192/4708 - The training loss at 26th epoch : 0.07732763513655436  Training Accuracy:0.8930608365019012\n",
            "4208/4708 - The training loss at 26th epoch : 0.07707253902888878  Training Accuracy:0.8934659090909091\n",
            "4224/4708 - The training loss at 26th epoch : 0.07731312083681383  Training Accuracy:0.8933962264150943\n",
            "4240/4708 - The training loss at 26th epoch : 0.07739485210459437  Training Accuracy:0.8933270676691729\n",
            "4256/4708 - The training loss at 26th epoch : 0.07718736138166016  Training Accuracy:0.8934925093632958\n",
            "4272/4708 - The training loss at 26th epoch : 0.0775338284890006  Training Accuracy:0.8929570895522388\n",
            "4288/4708 - The training loss at 26th epoch : 0.07733641608645161  Training Accuracy:0.8933550185873605\n",
            "4304/4708 - The training loss at 26th epoch : 0.07714388649407232  Training Accuracy:0.89375\n",
            "4320/4708 - The training loss at 26th epoch : 0.07748303635493071  Training Accuracy:0.8929889298892989\n",
            "4336/4708 - The training loss at 26th epoch : 0.07725978821010528  Training Accuracy:0.8933823529411765\n",
            "4352/4708 - The training loss at 26th epoch : 0.07712428981564119  Training Accuracy:0.8935439560439561\n",
            "4368/4708 - The training loss at 26th epoch : 0.07711124725407538  Training Accuracy:0.8937043795620438\n",
            "4384/4708 - The training loss at 26th epoch : 0.07703111956739242  Training Accuracy:0.8938636363636364\n",
            "4400/4708 - The training loss at 26th epoch : 0.07701463791695984  Training Accuracy:0.8940217391304348\n",
            "4416/4708 - The training loss at 26th epoch : 0.07702995901788828  Training Accuracy:0.8937274368231047\n",
            "4432/4708 - The training loss at 26th epoch : 0.07704189713761775  Training Accuracy:0.893660071942446\n",
            "4448/4708 - The training loss at 26th epoch : 0.07717335040808354  Training Accuracy:0.8933691756272402\n",
            "4464/4708 - The training loss at 26th epoch : 0.07701063250188148  Training Accuracy:0.8935267857142857\n",
            "4480/4708 - The training loss at 26th epoch : 0.07674859817349576  Training Accuracy:0.8939056939501779\n",
            "4496/4708 - The training loss at 26th epoch : 0.07657961396240415  Training Accuracy:0.8940602836879432\n",
            "4512/4708 - The training loss at 26th epoch : 0.07645639117807884  Training Accuracy:0.8942137809187279\n",
            "4528/4708 - The training loss at 26th epoch : 0.0763444062746904  Training Accuracy:0.8943661971830986\n",
            "4544/4708 - The training loss at 26th epoch : 0.07622217893984636  Training Accuracy:0.8945175438596491\n",
            "4560/4708 - The training loss at 26th epoch : 0.07609728188821635  Training Accuracy:0.8946678321678322\n",
            "4576/4708 - The training loss at 26th epoch : 0.07595371114872762  Training Accuracy:0.8948170731707317\n",
            "4592/4708 - The training loss at 26th epoch : 0.07610860778059009  Training Accuracy:0.8947482638888888\n",
            "4608/4708 - The training loss at 26th epoch : 0.0762819331894374  Training Accuracy:0.8942474048442907\n",
            "4624/4708 - The training loss at 26th epoch : 0.07619811939110964  Training Accuracy:0.8943965517241379\n",
            "4640/4708 - The training loss at 26th epoch : 0.07600728730998954  Training Accuracy:0.8947594501718213\n",
            "4656/4708 - The training loss at 26th epoch : 0.07593043131328166  Training Accuracy:0.8949058219178082\n",
            "4672/4708 - The training loss at 26th epoch : 0.0762019933448633  Training Accuracy:0.8946245733788396\n",
            "4688/4708 - The training loss at 26th epoch : 0.07616707208330073  Training Accuracy:0.8945578231292517\n",
            "4704/4708 - The training loss at 26th epoch : 0.07615082321769912  Training Accuracy:0.8947033898305085\n",
            "4720/4708 - The training loss at 26th epoch : 0.07602469026427897  Training Accuracy:0.894847972972973\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 27th epoch : 0.0018024209974324052  Training Accuracy:1.0\n",
            "16/4708 - The training loss at 27th epoch : 0.009417946244286836  Training Accuracy:1.0\n",
            "32/4708 - The training loss at 27th epoch : 0.059509154666859514  Training Accuracy:0.9166666666666666\n",
            "48/4708 - The training loss at 27th epoch : 0.04982269582689154  Training Accuracy:0.921875\n",
            "64/4708 - The training loss at 27th epoch : 0.04460867316035436  Training Accuracy:0.9375\n",
            "80/4708 - The training loss at 27th epoch : 0.05089062368007146  Training Accuracy:0.9375\n",
            "96/4708 - The training loss at 27th epoch : 0.062422211361028414  Training Accuracy:0.9196428571428571\n",
            "112/4708 - The training loss at 27th epoch : 0.06843815972375017  Training Accuracy:0.890625\n",
            "128/4708 - The training loss at 27th epoch : 0.07564971717660819  Training Accuracy:0.875\n",
            "144/4708 - The training loss at 27th epoch : 0.0720486396061857  Training Accuracy:0.88125\n",
            "160/4708 - The training loss at 27th epoch : 0.08329561654295602  Training Accuracy:0.8579545454545454\n",
            "176/4708 - The training loss at 27th epoch : 0.08674479159399333  Training Accuracy:0.859375\n",
            "192/4708 - The training loss at 27th epoch : 0.08250687945810246  Training Accuracy:0.8653846153846154\n",
            "208/4708 - The training loss at 27th epoch : 0.08307859453807077  Training Accuracy:0.8705357142857143\n",
            "224/4708 - The training loss at 27th epoch : 0.08979939213233834  Training Accuracy:0.8583333333333333\n",
            "240/4708 - The training loss at 27th epoch : 0.09177944687592737  Training Accuracy:0.85546875\n",
            "256/4708 - The training loss at 27th epoch : 0.09121820714056988  Training Accuracy:0.8566176470588235\n",
            "272/4708 - The training loss at 27th epoch : 0.08971680893529549  Training Accuracy:0.8576388888888888\n",
            "288/4708 - The training loss at 27th epoch : 0.08933580906204787  Training Accuracy:0.8618421052631579\n",
            "304/4708 - The training loss at 27th epoch : 0.08874912946914647  Training Accuracy:0.8625\n",
            "320/4708 - The training loss at 27th epoch : 0.08525257261296723  Training Accuracy:0.8690476190476191\n",
            "336/4708 - The training loss at 27th epoch : 0.08508445619807035  Training Accuracy:0.8721590909090909\n",
            "352/4708 - The training loss at 27th epoch : 0.08441744962772697  Training Accuracy:0.8722826086956522\n",
            "368/4708 - The training loss at 27th epoch : 0.08278709208073724  Training Accuracy:0.875\n",
            "384/4708 - The training loss at 27th epoch : 0.08125788856825411  Training Accuracy:0.8775\n",
            "400/4708 - The training loss at 27th epoch : 0.08191482116047043  Training Accuracy:0.8774038461538461\n",
            "416/4708 - The training loss at 27th epoch : 0.08106692494717772  Training Accuracy:0.8796296296296297\n",
            "432/4708 - The training loss at 27th epoch : 0.0802783409947032  Training Accuracy:0.8794642857142857\n",
            "448/4708 - The training loss at 27th epoch : 0.081253684144596  Training Accuracy:0.8771551724137931\n",
            "464/4708 - The training loss at 27th epoch : 0.08477313016211326  Training Accuracy:0.8708333333333333\n",
            "480/4708 - The training loss at 27th epoch : 0.08534768818812989  Training Accuracy:0.8709677419354839\n",
            "496/4708 - The training loss at 27th epoch : 0.08351641852755218  Training Accuracy:0.875\n",
            "512/4708 - The training loss at 27th epoch : 0.08369521688736806  Training Accuracy:0.875\n",
            "528/4708 - The training loss at 27th epoch : 0.08286041184450774  Training Accuracy:0.8731617647058824\n",
            "544/4708 - The training loss at 27th epoch : 0.08359042073923445  Training Accuracy:0.8714285714285714\n",
            "560/4708 - The training loss at 27th epoch : 0.08810458260044915  Training Accuracy:0.8645833333333334\n",
            "576/4708 - The training loss at 27th epoch : 0.08719911196141995  Training Accuracy:0.8665540540540541\n",
            "592/4708 - The training loss at 27th epoch : 0.08780283194107151  Training Accuracy:0.8667763157894737\n",
            "608/4708 - The training loss at 27th epoch : 0.08737087180770357  Training Accuracy:0.8685897435897436\n",
            "624/4708 - The training loss at 27th epoch : 0.0879421168029347  Training Accuracy:0.8671875\n",
            "640/4708 - The training loss at 27th epoch : 0.0881742705450066  Training Accuracy:0.8673780487804879\n",
            "656/4708 - The training loss at 27th epoch : 0.08693466272937793  Training Accuracy:0.8690476190476191\n",
            "672/4708 - The training loss at 27th epoch : 0.0876350938123945  Training Accuracy:0.8677325581395349\n",
            "688/4708 - The training loss at 27th epoch : 0.08580655349313111  Training Accuracy:0.8707386363636364\n",
            "704/4708 - The training loss at 27th epoch : 0.0877932855517601  Training Accuracy:0.8680555555555556\n",
            "720/4708 - The training loss at 27th epoch : 0.08742454293487016  Training Accuracy:0.8695652173913043\n",
            "736/4708 - The training loss at 27th epoch : 0.08766518082202004  Training Accuracy:0.8696808510638298\n",
            "752/4708 - The training loss at 27th epoch : 0.08791371066894305  Training Accuracy:0.8697916666666666\n",
            "768/4708 - The training loss at 27th epoch : 0.08933683365077842  Training Accuracy:0.8673469387755102\n",
            "784/4708 - The training loss at 27th epoch : 0.08924903772854322  Training Accuracy:0.8675\n",
            "800/4708 - The training loss at 27th epoch : 0.08890661900569544  Training Accuracy:0.8688725490196079\n",
            "816/4708 - The training loss at 27th epoch : 0.08873005061013534  Training Accuracy:0.8701923076923077\n",
            "832/4708 - The training loss at 27th epoch : 0.08773319348711157  Training Accuracy:0.8714622641509434\n",
            "848/4708 - The training loss at 27th epoch : 0.0870794104240631  Training Accuracy:0.8726851851851852\n",
            "864/4708 - The training loss at 27th epoch : 0.08637126952495609  Training Accuracy:0.8738636363636364\n",
            "880/4708 - The training loss at 27th epoch : 0.08594182285249365  Training Accuracy:0.875\n",
            "896/4708 - The training loss at 27th epoch : 0.08576433281673891  Training Accuracy:0.8760964912280702\n",
            "912/4708 - The training loss at 27th epoch : 0.08531456081363784  Training Accuracy:0.8771551724137931\n",
            "928/4708 - The training loss at 27th epoch : 0.0848433992956355  Training Accuracy:0.878177966101695\n",
            "944/4708 - The training loss at 27th epoch : 0.08446631113134924  Training Accuracy:0.878125\n",
            "960/4708 - The training loss at 27th epoch : 0.08500956038273248  Training Accuracy:0.8770491803278688\n",
            "976/4708 - The training loss at 27th epoch : 0.08449027907288177  Training Accuracy:0.8780241935483871\n",
            "992/4708 - The training loss at 27th epoch : 0.08341353031130086  Training Accuracy:0.8799603174603174\n",
            "1008/4708 - The training loss at 27th epoch : 0.08319111782570573  Training Accuracy:0.880859375\n",
            "1024/4708 - The training loss at 27th epoch : 0.08310781174656207  Training Accuracy:0.8817307692307692\n",
            "1040/4708 - The training loss at 27th epoch : 0.08282337041766942  Training Accuracy:0.8816287878787878\n",
            "1056/4708 - The training loss at 27th epoch : 0.08294420420196584  Training Accuracy:0.8805970149253731\n",
            "1072/4708 - The training loss at 27th epoch : 0.08263589690796055  Training Accuracy:0.8814338235294118\n",
            "1088/4708 - The training loss at 27th epoch : 0.08213916372933008  Training Accuracy:0.8822463768115942\n",
            "1104/4708 - The training loss at 27th epoch : 0.0827023127835981  Training Accuracy:0.88125\n",
            "1120/4708 - The training loss at 27th epoch : 0.08218511157889909  Training Accuracy:0.8820422535211268\n",
            "1136/4708 - The training loss at 27th epoch : 0.08238728921727367  Training Accuracy:0.8819444444444444\n",
            "1152/4708 - The training loss at 27th epoch : 0.08208473692210562  Training Accuracy:0.8827054794520548\n",
            "1168/4708 - The training loss at 27th epoch : 0.0811770417675087  Training Accuracy:0.8842905405405406\n",
            "1184/4708 - The training loss at 27th epoch : 0.08153665303576688  Training Accuracy:0.8833333333333333\n",
            "1200/4708 - The training loss at 27th epoch : 0.08079537639429897  Training Accuracy:0.8848684210526315\n",
            "1216/4708 - The training loss at 27th epoch : 0.08148921030906027  Training Accuracy:0.8847402597402597\n",
            "1232/4708 - The training loss at 27th epoch : 0.08184285562820716  Training Accuracy:0.8846153846153846\n",
            "1248/4708 - The training loss at 27th epoch : 0.08087246949825361  Training Accuracy:0.8860759493670886\n",
            "1264/4708 - The training loss at 27th epoch : 0.0810011937471699  Training Accuracy:0.8859375\n",
            "1280/4708 - The training loss at 27th epoch : 0.08098836380379155  Training Accuracy:0.8865740740740741\n",
            "1296/4708 - The training loss at 27th epoch : 0.08042727466777642  Training Accuracy:0.8871951219512195\n",
            "1312/4708 - The training loss at 27th epoch : 0.08071737442182614  Training Accuracy:0.8862951807228916\n",
            "1328/4708 - The training loss at 27th epoch : 0.08080254478296205  Training Accuracy:0.8861607142857143\n",
            "1344/4708 - The training loss at 27th epoch : 0.080916664159867  Training Accuracy:0.8860294117647058\n",
            "1360/4708 - The training loss at 27th epoch : 0.08089665324821749  Training Accuracy:0.8859011627906976\n",
            "1376/4708 - The training loss at 27th epoch : 0.08014045299745372  Training Accuracy:0.8872126436781609\n",
            "1392/4708 - The training loss at 27th epoch : 0.08059281698643916  Training Accuracy:0.8863636363636364\n",
            "1408/4708 - The training loss at 27th epoch : 0.08094926923000029  Training Accuracy:0.8855337078651685\n",
            "1424/4708 - The training loss at 27th epoch : 0.08161146222438859  Training Accuracy:0.8840277777777777\n",
            "1440/4708 - The training loss at 27th epoch : 0.0808069706786853  Training Accuracy:0.8853021978021978\n",
            "1456/4708 - The training loss at 27th epoch : 0.08098720277467264  Training Accuracy:0.8851902173913043\n",
            "1472/4708 - The training loss at 27th epoch : 0.08122831392241311  Training Accuracy:0.8850806451612904\n",
            "1488/4708 - The training loss at 27th epoch : 0.08104939610794856  Training Accuracy:0.8849734042553191\n",
            "1504/4708 - The training loss at 27th epoch : 0.080903028434269  Training Accuracy:0.8855263157894737\n",
            "1520/4708 - The training loss at 27th epoch : 0.08017037040632792  Training Accuracy:0.88671875\n",
            "1536/4708 - The training loss at 27th epoch : 0.08096820827684141  Training Accuracy:0.8846649484536082\n",
            "1552/4708 - The training loss at 27th epoch : 0.08029264737491766  Training Accuracy:0.8858418367346939\n",
            "1568/4708 - The training loss at 27th epoch : 0.08010382025298111  Training Accuracy:0.8863636363636364\n",
            "1584/4708 - The training loss at 27th epoch : 0.08012453060486996  Training Accuracy:0.88625\n",
            "1600/4708 - The training loss at 27th epoch : 0.0803855114566822  Training Accuracy:0.8861386138613861\n",
            "1616/4708 - The training loss at 27th epoch : 0.08124847811315074  Training Accuracy:0.8854166666666666\n",
            "1632/4708 - The training loss at 27th epoch : 0.08099297995453152  Training Accuracy:0.8859223300970874\n",
            "1648/4708 - The training loss at 27th epoch : 0.08097508238319984  Training Accuracy:0.8864182692307693\n",
            "1664/4708 - The training loss at 27th epoch : 0.08070674716102012  Training Accuracy:0.8869047619047619\n",
            "1680/4708 - The training loss at 27th epoch : 0.0809494747151166  Training Accuracy:0.8862028301886793\n",
            "1696/4708 - The training loss at 27th epoch : 0.08045973976104973  Training Accuracy:0.8872663551401869\n",
            "1712/4708 - The training loss at 27th epoch : 0.08024910923843188  Training Accuracy:0.8877314814814815\n",
            "1728/4708 - The training loss at 27th epoch : 0.07979721711593672  Training Accuracy:0.8881880733944955\n",
            "1744/4708 - The training loss at 27th epoch : 0.08041103676175759  Training Accuracy:0.8869318181818182\n",
            "1760/4708 - The training loss at 27th epoch : 0.08090814416708424  Training Accuracy:0.8862612612612613\n",
            "1776/4708 - The training loss at 27th epoch : 0.08041668034295661  Training Accuracy:0.88671875\n",
            "1792/4708 - The training loss at 27th epoch : 0.08002642521812939  Training Accuracy:0.8877212389380531\n",
            "1808/4708 - The training loss at 27th epoch : 0.07960082027309073  Training Accuracy:0.8881578947368421\n",
            "1824/4708 - The training loss at 27th epoch : 0.07901135713461423  Training Accuracy:0.8891304347826087\n",
            "1840/4708 - The training loss at 27th epoch : 0.07860661357940446  Training Accuracy:0.8895474137931034\n",
            "1856/4708 - The training loss at 27th epoch : 0.07863178375433028  Training Accuracy:0.8899572649572649\n",
            "1872/4708 - The training loss at 27th epoch : 0.07912786951008059  Training Accuracy:0.8893008474576272\n",
            "1888/4708 - The training loss at 27th epoch : 0.0788659996335481  Training Accuracy:0.8897058823529411\n",
            "1904/4708 - The training loss at 27th epoch : 0.07838870163409645  Training Accuracy:0.890625\n",
            "1920/4708 - The training loss at 27th epoch : 0.07821934490377955  Training Accuracy:0.890495867768595\n",
            "1936/4708 - The training loss at 27th epoch : 0.0779797429612973  Training Accuracy:0.8908811475409836\n",
            "1952/4708 - The training loss at 27th epoch : 0.07780465689031357  Training Accuracy:0.891260162601626\n",
            "1968/4708 - The training loss at 27th epoch : 0.07796279097795411  Training Accuracy:0.891633064516129\n",
            "1984/4708 - The training loss at 27th epoch : 0.07817493659645355  Training Accuracy:0.891\n",
            "2000/4708 - The training loss at 27th epoch : 0.07825776557746884  Training Accuracy:0.8908730158730159\n",
            "2016/4708 - The training loss at 27th epoch : 0.07919987552279079  Training Accuracy:0.889763779527559\n",
            "2032/4708 - The training loss at 27th epoch : 0.07954149787442454  Training Accuracy:0.8896484375\n",
            "2048/4708 - The training loss at 27th epoch : 0.08042591991482059  Training Accuracy:0.8875968992248062\n",
            "2064/4708 - The training loss at 27th epoch : 0.08005292660427424  Training Accuracy:0.8879807692307692\n",
            "2080/4708 - The training loss at 27th epoch : 0.07956032354553773  Training Accuracy:0.8888358778625954\n",
            "2096/4708 - The training loss at 27th epoch : 0.07941755644381043  Training Accuracy:0.8887310606060606\n",
            "2112/4708 - The training loss at 27th epoch : 0.07975416784410302  Training Accuracy:0.8881578947368421\n",
            "2128/4708 - The training loss at 27th epoch : 0.08002927187329135  Training Accuracy:0.8880597014925373\n",
            "2144/4708 - The training loss at 27th epoch : 0.0807770608310377  Training Accuracy:0.8870370370370371\n",
            "2160/4708 - The training loss at 27th epoch : 0.08073879849436998  Training Accuracy:0.8874080882352942\n",
            "2176/4708 - The training loss at 27th epoch : 0.08070265907971398  Training Accuracy:0.8877737226277372\n",
            "2192/4708 - The training loss at 27th epoch : 0.0813704757128073  Training Accuracy:0.8867753623188406\n",
            "2208/4708 - The training loss at 27th epoch : 0.08106616915650224  Training Accuracy:0.887589928057554\n",
            "2224/4708 - The training loss at 27th epoch : 0.08126045304564225  Training Accuracy:0.8870535714285714\n",
            "2240/4708 - The training loss at 27th epoch : 0.08162269534267952  Training Accuracy:0.8865248226950354\n",
            "2256/4708 - The training loss at 27th epoch : 0.08113359634193154  Training Accuracy:0.8873239436619719\n",
            "2272/4708 - The training loss at 27th epoch : 0.08072517134334815  Training Accuracy:0.8881118881118881\n",
            "2288/4708 - The training loss at 27th epoch : 0.08020464886825046  Training Accuracy:0.8888888888888888\n",
            "2304/4708 - The training loss at 27th epoch : 0.08015915452512341  Training Accuracy:0.8892241379310345\n",
            "2320/4708 - The training loss at 27th epoch : 0.07993845038319268  Training Accuracy:0.889554794520548\n",
            "2336/4708 - The training loss at 27th epoch : 0.08009284448950375  Training Accuracy:0.8894557823129252\n",
            "2352/4708 - The training loss at 27th epoch : 0.0798279579254952  Training Accuracy:0.8897804054054054\n",
            "2368/4708 - The training loss at 27th epoch : 0.07942300643574653  Training Accuracy:0.8905201342281879\n",
            "2384/4708 - The training loss at 27th epoch : 0.07908660619934463  Training Accuracy:0.89125\n",
            "2400/4708 - The training loss at 27th epoch : 0.0791698002749364  Training Accuracy:0.890728476821192\n",
            "2416/4708 - The training loss at 27th epoch : 0.07884870816821575  Training Accuracy:0.8910361842105263\n",
            "2432/4708 - The training loss at 27th epoch : 0.0791742865244295  Training Accuracy:0.8901143790849673\n",
            "2448/4708 - The training loss at 27th epoch : 0.07877855854299005  Training Accuracy:0.890827922077922\n",
            "2464/4708 - The training loss at 27th epoch : 0.07906030293223058  Training Accuracy:0.8899193548387097\n",
            "2480/4708 - The training loss at 27th epoch : 0.07957371213298503  Training Accuracy:0.8890224358974359\n",
            "2496/4708 - The training loss at 27th epoch : 0.07924611084459227  Training Accuracy:0.8897292993630573\n",
            "2512/4708 - The training loss at 27th epoch : 0.07916514060851791  Training Accuracy:0.8896360759493671\n",
            "2528/4708 - The training loss at 27th epoch : 0.07940596447582221  Training Accuracy:0.8895440251572327\n",
            "2544/4708 - The training loss at 27th epoch : 0.07915877830071431  Training Accuracy:0.88984375\n",
            "2560/4708 - The training loss at 27th epoch : 0.07911760493820486  Training Accuracy:0.889751552795031\n",
            "2576/4708 - The training loss at 27th epoch : 0.0793711412086535  Training Accuracy:0.8896604938271605\n",
            "2592/4708 - The training loss at 27th epoch : 0.0791496904461037  Training Accuracy:0.8899539877300614\n",
            "2608/4708 - The training loss at 27th epoch : 0.0793254706226244  Training Accuracy:0.8894817073170732\n",
            "2624/4708 - The training loss at 27th epoch : 0.07987345462534454  Training Accuracy:0.8890151515151515\n",
            "2640/4708 - The training loss at 27th epoch : 0.07957168420411738  Training Accuracy:0.889683734939759\n",
            "2656/4708 - The training loss at 27th epoch : 0.07922460638984814  Training Accuracy:0.8903443113772455\n",
            "2672/4708 - The training loss at 27th epoch : 0.07913675244223245  Training Accuracy:0.890625\n",
            "2688/4708 - The training loss at 27th epoch : 0.07916548186981402  Training Accuracy:0.8905325443786982\n",
            "2704/4708 - The training loss at 27th epoch : 0.07970689602554526  Training Accuracy:0.8900735294117647\n",
            "2720/4708 - The training loss at 27th epoch : 0.07936623249595806  Training Accuracy:0.8907163742690059\n",
            "2736/4708 - The training loss at 27th epoch : 0.07903130744247583  Training Accuracy:0.8913517441860465\n",
            "2752/4708 - The training loss at 27th epoch : 0.07895333211508093  Training Accuracy:0.8916184971098265\n",
            "2768/4708 - The training loss at 27th epoch : 0.0789273117866937  Training Accuracy:0.891882183908046\n",
            "2784/4708 - The training loss at 27th epoch : 0.07895770597947957  Training Accuracy:0.8917857142857143\n",
            "2800/4708 - The training loss at 27th epoch : 0.07859680492960805  Training Accuracy:0.8924005681818182\n",
            "2816/4708 - The training loss at 27th epoch : 0.07899695247617426  Training Accuracy:0.8923022598870056\n",
            "2832/4708 - The training loss at 27th epoch : 0.07858220086850591  Training Accuracy:0.8929073033707865\n",
            "2848/4708 - The training loss at 27th epoch : 0.07851063124828557  Training Accuracy:0.8931564245810056\n",
            "2864/4708 - The training loss at 27th epoch : 0.07867523473235923  Training Accuracy:0.8934027777777778\n",
            "2880/4708 - The training loss at 27th epoch : 0.07864803589198399  Training Accuracy:0.8933011049723757\n",
            "2896/4708 - The training loss at 27th epoch : 0.07863385248814724  Training Accuracy:0.8932005494505495\n",
            "2912/4708 - The training loss at 27th epoch : 0.07863587592654163  Training Accuracy:0.8931010928961749\n",
            "2928/4708 - The training loss at 27th epoch : 0.07866789054536658  Training Accuracy:0.8930027173913043\n",
            "2944/4708 - The training loss at 27th epoch : 0.07876709269631761  Training Accuracy:0.8929054054054054\n",
            "2960/4708 - The training loss at 27th epoch : 0.07869336924036131  Training Accuracy:0.8931451612903226\n",
            "2976/4708 - The training loss at 27th epoch : 0.0792083073052064  Training Accuracy:0.8927139037433155\n",
            "2992/4708 - The training loss at 27th epoch : 0.07897451218769101  Training Accuracy:0.8929521276595744\n",
            "3008/4708 - The training loss at 27th epoch : 0.07899092756976163  Training Accuracy:0.8931878306878307\n",
            "3024/4708 - The training loss at 27th epoch : 0.0787359380124775  Training Accuracy:0.89375\n",
            "3040/4708 - The training loss at 27th epoch : 0.078408764112091  Training Accuracy:0.8943062827225131\n",
            "3056/4708 - The training loss at 27th epoch : 0.07850814834557289  Training Accuracy:0.8942057291666666\n",
            "3072/4708 - The training loss at 27th epoch : 0.07829510618406182  Training Accuracy:0.8944300518134715\n",
            "3088/4708 - The training loss at 27th epoch : 0.07797196511406031  Training Accuracy:0.8949742268041238\n",
            "3104/4708 - The training loss at 27th epoch : 0.07776848544635012  Training Accuracy:0.8951923076923077\n",
            "3120/4708 - The training loss at 27th epoch : 0.07775800991770282  Training Accuracy:0.8954081632653061\n",
            "3136/4708 - The training loss at 27th epoch : 0.07741087523514376  Training Accuracy:0.8959390862944162\n",
            "3152/4708 - The training loss at 27th epoch : 0.0774533281156375  Training Accuracy:0.8958333333333334\n",
            "3168/4708 - The training loss at 27th epoch : 0.07711042734014684  Training Accuracy:0.8963567839195979\n",
            "3184/4708 - The training loss at 27th epoch : 0.07688635975813815  Training Accuracy:0.8965625\n",
            "3200/4708 - The training loss at 27th epoch : 0.07705574746546069  Training Accuracy:0.8964552238805971\n",
            "3216/4708 - The training loss at 27th epoch : 0.07696709955672376  Training Accuracy:0.8966584158415841\n",
            "3232/4708 - The training loss at 27th epoch : 0.07701338404644525  Training Accuracy:0.896551724137931\n",
            "3248/4708 - The training loss at 27th epoch : 0.07670202166386565  Training Accuracy:0.8970588235294118\n",
            "3264/4708 - The training loss at 27th epoch : 0.07639838187627071  Training Accuracy:0.8975609756097561\n",
            "3280/4708 - The training loss at 27th epoch : 0.07634874154505178  Training Accuracy:0.897754854368932\n",
            "3296/4708 - The training loss at 27th epoch : 0.07609894817049527  Training Accuracy:0.8982487922705314\n",
            "3312/4708 - The training loss at 27th epoch : 0.0763224589855522  Training Accuracy:0.8981370192307693\n",
            "3328/4708 - The training loss at 27th epoch : 0.07653799027917454  Training Accuracy:0.8974282296650717\n",
            "3344/4708 - The training loss at 27th epoch : 0.0766394635722306  Training Accuracy:0.8973214285714286\n",
            "3360/4708 - The training loss at 27th epoch : 0.07647218670480165  Training Accuracy:0.8975118483412322\n",
            "3376/4708 - The training loss at 27th epoch : 0.07671020340679865  Training Accuracy:0.8974056603773585\n",
            "3392/4708 - The training loss at 27th epoch : 0.0764960340138303  Training Accuracy:0.897593896713615\n",
            "3408/4708 - The training loss at 27th epoch : 0.07625169575131027  Training Accuracy:0.8977803738317757\n",
            "3424/4708 - The training loss at 27th epoch : 0.07614041066443032  Training Accuracy:0.8979651162790697\n",
            "3440/4708 - The training loss at 27th epoch : 0.07604943909077946  Training Accuracy:0.8978587962962963\n",
            "3456/4708 - The training loss at 27th epoch : 0.0760518584124699  Training Accuracy:0.8980414746543779\n",
            "3472/4708 - The training loss at 27th epoch : 0.07605214310411516  Training Accuracy:0.8982224770642202\n",
            "3488/4708 - The training loss at 27th epoch : 0.07609865725712169  Training Accuracy:0.8981164383561644\n",
            "3504/4708 - The training loss at 27th epoch : 0.07584326901376426  Training Accuracy:0.8985795454545454\n",
            "3520/4708 - The training loss at 27th epoch : 0.0758245839563284  Training Accuracy:0.8984728506787331\n",
            "3536/4708 - The training loss at 27th epoch : 0.07615000207088751  Training Accuracy:0.8978040540540541\n",
            "3552/4708 - The training loss at 27th epoch : 0.07626506882794079  Training Accuracy:0.8974215246636771\n",
            "3568/4708 - The training loss at 27th epoch : 0.07599214555278977  Training Accuracy:0.8978794642857143\n",
            "3584/4708 - The training loss at 27th epoch : 0.07603383554731269  Training Accuracy:0.8980555555555556\n",
            "3600/4708 - The training loss at 27th epoch : 0.07625713491524311  Training Accuracy:0.8976769911504425\n",
            "3616/4708 - The training loss at 27th epoch : 0.07622677928380918  Training Accuracy:0.897852422907489\n",
            "3632/4708 - The training loss at 27th epoch : 0.0761043020846088  Training Accuracy:0.8977521929824561\n",
            "3648/4708 - The training loss at 27th epoch : 0.07648904433632231  Training Accuracy:0.8971069868995634\n",
            "3664/4708 - The training loss at 27th epoch : 0.07624085832537063  Training Accuracy:0.897554347826087\n",
            "3680/4708 - The training loss at 27th epoch : 0.07597317394709431  Training Accuracy:0.8979978354978355\n",
            "3696/4708 - The training loss at 27th epoch : 0.07602391185348559  Training Accuracy:0.8976293103448276\n",
            "3712/4708 - The training loss at 27th epoch : 0.07644903486962257  Training Accuracy:0.8969957081545065\n",
            "3728/4708 - The training loss at 27th epoch : 0.07670671630584758  Training Accuracy:0.8966346153846154\n",
            "3744/4708 - The training loss at 27th epoch : 0.07705607672690501  Training Accuracy:0.8962765957446809\n",
            "3760/4708 - The training loss at 27th epoch : 0.07674728371783704  Training Accuracy:0.8967161016949152\n",
            "3776/4708 - The training loss at 27th epoch : 0.07667452634770341  Training Accuracy:0.8966244725738397\n",
            "3792/4708 - The training loss at 27th epoch : 0.07674154234045089  Training Accuracy:0.8965336134453782\n",
            "3808/4708 - The training loss at 27th epoch : 0.07657292932785591  Training Accuracy:0.8967050209205021\n",
            "3824/4708 - The training loss at 27th epoch : 0.0766580142855819  Training Accuracy:0.8963541666666667\n",
            "3840/4708 - The training loss at 27th epoch : 0.07674413842523227  Training Accuracy:0.8962655601659751\n",
            "3856/4708 - The training loss at 27th epoch : 0.07646490674532602  Training Accuracy:0.8966942148760331\n",
            "3872/4708 - The training loss at 27th epoch : 0.0764358378586811  Training Accuracy:0.8968621399176955\n",
            "3888/4708 - The training loss at 27th epoch : 0.07655508464572289  Training Accuracy:0.8965163934426229\n",
            "3904/4708 - The training loss at 27th epoch : 0.07705975045600884  Training Accuracy:0.8961734693877551\n",
            "3920/4708 - The training loss at 27th epoch : 0.076983809075199  Training Accuracy:0.8963414634146342\n",
            "3936/4708 - The training loss at 27th epoch : 0.07726595081817296  Training Accuracy:0.896002024291498\n",
            "3952/4708 - The training loss at 27th epoch : 0.07715959315043541  Training Accuracy:0.8961693548387096\n",
            "3968/4708 - The training loss at 27th epoch : 0.07703753844518162  Training Accuracy:0.8963353413654619\n",
            "3984/4708 - The training loss at 27th epoch : 0.07687694010052123  Training Accuracy:0.8965\n",
            "4000/4708 - The training loss at 27th epoch : 0.07671305125956603  Training Accuracy:0.8969123505976095\n",
            "4016/4708 - The training loss at 27th epoch : 0.07647922822052407  Training Accuracy:0.8973214285714286\n",
            "4032/4708 - The training loss at 27th epoch : 0.0763972626787262  Training Accuracy:0.8974802371541502\n",
            "4048/4708 - The training loss at 27th epoch : 0.07632395616525456  Training Accuracy:0.8976377952755905\n",
            "4064/4708 - The training loss at 27th epoch : 0.07638896906395902  Training Accuracy:0.8975490196078432\n",
            "4080/4708 - The training loss at 27th epoch : 0.07643297347709205  Training Accuracy:0.897216796875\n",
            "4096/4708 - The training loss at 27th epoch : 0.07650386108618328  Training Accuracy:0.8971303501945526\n",
            "4112/4708 - The training loss at 27th epoch : 0.07643389206546865  Training Accuracy:0.8972868217054264\n",
            "4128/4708 - The training loss at 27th epoch : 0.07650505897788243  Training Accuracy:0.8972007722007722\n",
            "4144/4708 - The training loss at 27th epoch : 0.07654832119776273  Training Accuracy:0.8971153846153846\n",
            "4160/4708 - The training loss at 27th epoch : 0.0766503502513337  Training Accuracy:0.8967911877394636\n",
            "4176/4708 - The training loss at 27th epoch : 0.07647592578830867  Training Accuracy:0.8969465648854962\n",
            "4192/4708 - The training loss at 27th epoch : 0.07639801528502879  Training Accuracy:0.8971007604562737\n",
            "4208/4708 - The training loss at 27th epoch : 0.0762647194609536  Training Accuracy:0.8972537878787878\n",
            "4224/4708 - The training loss at 27th epoch : 0.07604555723539728  Training Accuracy:0.8976415094339623\n",
            "4240/4708 - The training loss at 27th epoch : 0.07615736068942115  Training Accuracy:0.8973214285714286\n",
            "4256/4708 - The training loss at 27th epoch : 0.07628626482240647  Training Accuracy:0.897003745318352\n",
            "4272/4708 - The training loss at 27th epoch : 0.07623832818103703  Training Accuracy:0.8971548507462687\n",
            "4288/4708 - The training loss at 27th epoch : 0.07623012271885683  Training Accuracy:0.8973048327137546\n",
            "4304/4708 - The training loss at 27th epoch : 0.07622726021617622  Training Accuracy:0.8974537037037037\n",
            "4320/4708 - The training loss at 27th epoch : 0.0763578946196824  Training Accuracy:0.897370848708487\n",
            "4336/4708 - The training loss at 27th epoch : 0.07614727687990419  Training Accuracy:0.8977481617647058\n",
            "4352/4708 - The training loss at 27th epoch : 0.07610749282253494  Training Accuracy:0.8978937728937729\n",
            "4368/4708 - The training loss at 27th epoch : 0.07597771942481786  Training Accuracy:0.8980383211678832\n",
            "4384/4708 - The training loss at 27th epoch : 0.07572630514380697  Training Accuracy:0.8984090909090909\n",
            "4400/4708 - The training loss at 27th epoch : 0.07563787821016611  Training Accuracy:0.8985507246376812\n",
            "4416/4708 - The training loss at 27th epoch : 0.07562818169940326  Training Accuracy:0.8984657039711191\n",
            "4432/4708 - The training loss at 27th epoch : 0.07608543955915588  Training Accuracy:0.8974820143884892\n",
            "4448/4708 - The training loss at 27th epoch : 0.07618041949485437  Training Accuracy:0.8971774193548387\n",
            "4464/4708 - The training loss at 27th epoch : 0.07604713639473377  Training Accuracy:0.8973214285714286\n",
            "4480/4708 - The training loss at 27th epoch : 0.07600496041623706  Training Accuracy:0.8972419928825622\n",
            "4496/4708 - The training loss at 27th epoch : 0.0759010270599773  Training Accuracy:0.8973847517730497\n",
            "4512/4708 - The training loss at 27th epoch : 0.07581246323805553  Training Accuracy:0.8975265017667845\n",
            "4528/4708 - The training loss at 27th epoch : 0.07556778944146583  Training Accuracy:0.897887323943662\n",
            "4544/4708 - The training loss at 27th epoch : 0.07538942339066285  Training Accuracy:0.8980263157894737\n",
            "4560/4708 - The training loss at 27th epoch : 0.07555330198394591  Training Accuracy:0.8977272727272727\n",
            "4576/4708 - The training loss at 27th epoch : 0.07588959013463116  Training Accuracy:0.8972125435540069\n",
            "4592/4708 - The training loss at 27th epoch : 0.07632335053331236  Training Accuracy:0.8967013888888888\n",
            "4608/4708 - The training loss at 27th epoch : 0.0760908450560958  Training Accuracy:0.8970588235294118\n",
            "4624/4708 - The training loss at 27th epoch : 0.07591934748766607  Training Accuracy:0.8974137931034483\n",
            "4640/4708 - The training loss at 27th epoch : 0.07609595922896698  Training Accuracy:0.8973367697594502\n",
            "4656/4708 - The training loss at 27th epoch : 0.07604132622659941  Training Accuracy:0.8974743150684932\n",
            "4672/4708 - The training loss at 27th epoch : 0.07597451358698602  Training Accuracy:0.8976109215017065\n",
            "4688/4708 - The training loss at 27th epoch : 0.07640522038419457  Training Accuracy:0.8971088435374149\n",
            "4704/4708 - The training loss at 27th epoch : 0.07643979347852915  Training Accuracy:0.8972457627118644\n",
            "4720/4708 - The training loss at 27th epoch : 0.07653441042798828  Training Accuracy:0.8969594594594594\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 28th epoch : 0.1282219267775349  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 28th epoch : 0.06988371218709184  Training Accuracy:0.9375\n",
            "32/4708 - The training loss at 28th epoch : 0.05212646999594656  Training Accuracy:0.9583333333333334\n",
            "48/4708 - The training loss at 28th epoch : 0.04782359142102709  Training Accuracy:0.953125\n",
            "64/4708 - The training loss at 28th epoch : 0.06541954258884881  Training Accuracy:0.925\n",
            "80/4708 - The training loss at 28th epoch : 0.06131664099187679  Training Accuracy:0.9270833333333334\n",
            "96/4708 - The training loss at 28th epoch : 0.07095563091325656  Training Accuracy:0.9196428571428571\n",
            "112/4708 - The training loss at 28th epoch : 0.07014100788251797  Training Accuracy:0.9140625\n",
            "128/4708 - The training loss at 28th epoch : 0.06864649622240539  Training Accuracy:0.9166666666666666\n",
            "144/4708 - The training loss at 28th epoch : 0.0772999274668247  Training Accuracy:0.9\n",
            "160/4708 - The training loss at 28th epoch : 0.07572687461105561  Training Accuracy:0.9034090909090909\n",
            "176/4708 - The training loss at 28th epoch : 0.07461895710498771  Training Accuracy:0.9010416666666666\n",
            "192/4708 - The training loss at 28th epoch : 0.06960552754942391  Training Accuracy:0.9086538461538461\n",
            "208/4708 - The training loss at 28th epoch : 0.07264015484282264  Training Accuracy:0.90625\n",
            "224/4708 - The training loss at 28th epoch : 0.07554892161412521  Training Accuracy:0.9041666666666667\n",
            "240/4708 - The training loss at 28th epoch : 0.07711116106820264  Training Accuracy:0.90234375\n",
            "256/4708 - The training loss at 28th epoch : 0.07967490335168972  Training Accuracy:0.9007352941176471\n",
            "272/4708 - The training loss at 28th epoch : 0.07769798302997516  Training Accuracy:0.9027777777777778\n",
            "288/4708 - The training loss at 28th epoch : 0.07693634820593716  Training Accuracy:0.9013157894736842\n",
            "304/4708 - The training loss at 28th epoch : 0.08382546362182575  Training Accuracy:0.890625\n",
            "320/4708 - The training loss at 28th epoch : 0.08640072330803986  Training Accuracy:0.8869047619047619\n",
            "336/4708 - The training loss at 28th epoch : 0.08734485817122044  Training Accuracy:0.8835227272727273\n",
            "352/4708 - The training loss at 28th epoch : 0.09150859962040306  Training Accuracy:0.875\n",
            "368/4708 - The training loss at 28th epoch : 0.0888091065006892  Training Accuracy:0.8802083333333334\n",
            "384/4708 - The training loss at 28th epoch : 0.08773329081051298  Training Accuracy:0.8825\n",
            "400/4708 - The training loss at 28th epoch : 0.08566067491142296  Training Accuracy:0.8846153846153846\n",
            "416/4708 - The training loss at 28th epoch : 0.08613516355511851  Training Accuracy:0.8819444444444444\n",
            "432/4708 - The training loss at 28th epoch : 0.08669320737748275  Training Accuracy:0.8772321428571429\n",
            "448/4708 - The training loss at 28th epoch : 0.08863449405913802  Training Accuracy:0.875\n",
            "464/4708 - The training loss at 28th epoch : 0.08592789779530027  Training Accuracy:0.8791666666666667\n",
            "480/4708 - The training loss at 28th epoch : 0.08766795956321774  Training Accuracy:0.875\n",
            "496/4708 - The training loss at 28th epoch : 0.08636626711633452  Training Accuracy:0.876953125\n",
            "512/4708 - The training loss at 28th epoch : 0.08633343327409188  Training Accuracy:0.8787878787878788\n",
            "528/4708 - The training loss at 28th epoch : 0.08833734451841092  Training Accuracy:0.875\n",
            "544/4708 - The training loss at 28th epoch : 0.08764819270992348  Training Accuracy:0.875\n",
            "560/4708 - The training loss at 28th epoch : 0.08611540357208343  Training Accuracy:0.8767361111111112\n",
            "576/4708 - The training loss at 28th epoch : 0.0879130029405752  Training Accuracy:0.8716216216216216\n",
            "592/4708 - The training loss at 28th epoch : 0.0866420106095131  Training Accuracy:0.8733552631578947\n",
            "608/4708 - The training loss at 28th epoch : 0.08512313643464743  Training Accuracy:0.8766025641025641\n",
            "624/4708 - The training loss at 28th epoch : 0.08643338143308504  Training Accuracy:0.8765625\n",
            "640/4708 - The training loss at 28th epoch : 0.08708141104689579  Training Accuracy:0.8734756097560976\n",
            "656/4708 - The training loss at 28th epoch : 0.08713196546889232  Training Accuracy:0.8735119047619048\n",
            "672/4708 - The training loss at 28th epoch : 0.08959425018477328  Training Accuracy:0.872093023255814\n",
            "688/4708 - The training loss at 28th epoch : 0.08903304951338452  Training Accuracy:0.8735795454545454\n",
            "704/4708 - The training loss at 28th epoch : 0.08852736191773124  Training Accuracy:0.875\n",
            "720/4708 - The training loss at 28th epoch : 0.08759038995033323  Training Accuracy:0.875\n",
            "736/4708 - The training loss at 28th epoch : 0.08809972091517276  Training Accuracy:0.875\n",
            "752/4708 - The training loss at 28th epoch : 0.08850685698063766  Training Accuracy:0.875\n",
            "768/4708 - The training loss at 28th epoch : 0.08682758359048108  Training Accuracy:0.8775510204081632\n",
            "784/4708 - The training loss at 28th epoch : 0.0851157264968796  Training Accuracy:0.88\n",
            "800/4708 - The training loss at 28th epoch : 0.08506889843430038  Training Accuracy:0.8799019607843137\n",
            "816/4708 - The training loss at 28th epoch : 0.08439923317729649  Training Accuracy:0.8810096153846154\n",
            "832/4708 - The training loss at 28th epoch : 0.08436591421907338  Training Accuracy:0.8808962264150944\n",
            "848/4708 - The training loss at 28th epoch : 0.0841846572223192  Training Accuracy:0.8807870370370371\n",
            "864/4708 - The training loss at 28th epoch : 0.08385800097184813  Training Accuracy:0.8818181818181818\n",
            "880/4708 - The training loss at 28th epoch : 0.08561768791228451  Training Accuracy:0.8783482142857143\n",
            "896/4708 - The training loss at 28th epoch : 0.08495218118845994  Training Accuracy:0.8793859649122807\n",
            "912/4708 - The training loss at 28th epoch : 0.08549624836582329  Training Accuracy:0.8782327586206896\n",
            "928/4708 - The training loss at 28th epoch : 0.08504190118418253  Training Accuracy:0.8792372881355932\n",
            "944/4708 - The training loss at 28th epoch : 0.08390818535767972  Training Accuracy:0.88125\n",
            "960/4708 - The training loss at 28th epoch : 0.08318771340192489  Training Accuracy:0.8831967213114754\n",
            "976/4708 - The training loss at 28th epoch : 0.08292867860271207  Training Accuracy:0.8830645161290323\n",
            "992/4708 - The training loss at 28th epoch : 0.08247001628031418  Training Accuracy:0.8829365079365079\n",
            "1008/4708 - The training loss at 28th epoch : 0.08226342050150925  Training Accuracy:0.8818359375\n",
            "1024/4708 - The training loss at 28th epoch : 0.0824029955253646  Training Accuracy:0.8817307692307692\n",
            "1040/4708 - The training loss at 28th epoch : 0.0814561802584865  Training Accuracy:0.8835227272727273\n",
            "1056/4708 - The training loss at 28th epoch : 0.08240440311504314  Training Accuracy:0.8815298507462687\n",
            "1072/4708 - The training loss at 28th epoch : 0.08179592819256011  Training Accuracy:0.8832720588235294\n",
            "1088/4708 - The training loss at 28th epoch : 0.08102694727033173  Training Accuracy:0.8840579710144928\n",
            "1104/4708 - The training loss at 28th epoch : 0.08042357261777348  Training Accuracy:0.8848214285714285\n",
            "1120/4708 - The training loss at 28th epoch : 0.07967537007394376  Training Accuracy:0.8855633802816901\n",
            "1136/4708 - The training loss at 28th epoch : 0.08019788833496759  Training Accuracy:0.8854166666666666\n",
            "1152/4708 - The training loss at 28th epoch : 0.07951177965776338  Training Accuracy:0.8861301369863014\n",
            "1168/4708 - The training loss at 28th epoch : 0.07898436956163009  Training Accuracy:0.8868243243243243\n",
            "1184/4708 - The training loss at 28th epoch : 0.0800051126782365  Training Accuracy:0.8858333333333334\n",
            "1200/4708 - The training loss at 28th epoch : 0.07918864955505338  Training Accuracy:0.8873355263157895\n",
            "1216/4708 - The training loss at 28th epoch : 0.07857647674994983  Training Accuracy:0.8887987012987013\n",
            "1232/4708 - The training loss at 28th epoch : 0.07858182819648707  Training Accuracy:0.8894230769230769\n",
            "1248/4708 - The training loss at 28th epoch : 0.07832366407814814  Training Accuracy:0.8900316455696202\n",
            "1264/4708 - The training loss at 28th epoch : 0.07833606879971701  Training Accuracy:0.890625\n",
            "1280/4708 - The training loss at 28th epoch : 0.07859778850373009  Training Accuracy:0.8904320987654321\n",
            "1296/4708 - The training loss at 28th epoch : 0.07834609129482052  Training Accuracy:0.8910060975609756\n",
            "1312/4708 - The training loss at 28th epoch : 0.07849196289286252  Training Accuracy:0.8908132530120482\n",
            "1328/4708 - The training loss at 28th epoch : 0.078466778401283  Training Accuracy:0.8913690476190477\n",
            "1344/4708 - The training loss at 28th epoch : 0.07806611004542288  Training Accuracy:0.8926470588235295\n",
            "1360/4708 - The training loss at 28th epoch : 0.07800939088540292  Training Accuracy:0.8931686046511628\n",
            "1376/4708 - The training loss at 28th epoch : 0.07796414318991167  Training Accuracy:0.8929597701149425\n",
            "1392/4708 - The training loss at 28th epoch : 0.07791921643035593  Training Accuracy:0.8934659090909091\n",
            "1408/4708 - The training loss at 28th epoch : 0.07726769556727744  Training Accuracy:0.8946629213483146\n",
            "1424/4708 - The training loss at 28th epoch : 0.07684518599209664  Training Accuracy:0.8958333333333334\n",
            "1440/4708 - The training loss at 28th epoch : 0.07621159749353759  Training Accuracy:0.896978021978022\n",
            "1456/4708 - The training loss at 28th epoch : 0.07554190377697789  Training Accuracy:0.8980978260869565\n",
            "1472/4708 - The training loss at 28th epoch : 0.07552692441639207  Training Accuracy:0.8985215053763441\n",
            "1488/4708 - The training loss at 28th epoch : 0.07539334126514269  Training Accuracy:0.8982712765957447\n",
            "1504/4708 - The training loss at 28th epoch : 0.07487085791002857  Training Accuracy:0.8986842105263158\n",
            "1520/4708 - The training loss at 28th epoch : 0.07544331207096298  Training Accuracy:0.8977864583333334\n",
            "1536/4708 - The training loss at 28th epoch : 0.07522899309555779  Training Accuracy:0.8981958762886598\n",
            "1552/4708 - The training loss at 28th epoch : 0.07511627861683579  Training Accuracy:0.8985969387755102\n",
            "1568/4708 - The training loss at 28th epoch : 0.07507584908502729  Training Accuracy:0.898989898989899\n",
            "1584/4708 - The training loss at 28th epoch : 0.07526137518246447  Training Accuracy:0.89875\n",
            "1600/4708 - The training loss at 28th epoch : 0.07565304513196824  Training Accuracy:0.8985148514851485\n",
            "1616/4708 - The training loss at 28th epoch : 0.07573405947505757  Training Accuracy:0.8982843137254902\n",
            "1632/4708 - The training loss at 28th epoch : 0.07527456371637649  Training Accuracy:0.8986650485436893\n",
            "1648/4708 - The training loss at 28th epoch : 0.07481959387073507  Training Accuracy:0.8990384615384616\n",
            "1664/4708 - The training loss at 28th epoch : 0.0756460524853715  Training Accuracy:0.8976190476190476\n",
            "1680/4708 - The training loss at 28th epoch : 0.07560918227173483  Training Accuracy:0.8979952830188679\n",
            "1696/4708 - The training loss at 28th epoch : 0.07654205659027545  Training Accuracy:0.897196261682243\n",
            "1712/4708 - The training loss at 28th epoch : 0.07681922217203446  Training Accuracy:0.8969907407407407\n",
            "1728/4708 - The training loss at 28th epoch : 0.07773482456771674  Training Accuracy:0.8962155963302753\n",
            "1744/4708 - The training loss at 28th epoch : 0.07741374059181927  Training Accuracy:0.8960227272727272\n",
            "1760/4708 - The training loss at 28th epoch : 0.07687724188609021  Training Accuracy:0.8969594594594594\n",
            "1776/4708 - The training loss at 28th epoch : 0.0777523032784687  Training Accuracy:0.8962053571428571\n",
            "1792/4708 - The training loss at 28th epoch : 0.07713690846359536  Training Accuracy:0.8971238938053098\n",
            "1808/4708 - The training loss at 28th epoch : 0.07707871811440913  Training Accuracy:0.8969298245614035\n",
            "1824/4708 - The training loss at 28th epoch : 0.07665885996695544  Training Accuracy:0.8978260869565218\n",
            "1840/4708 - The training loss at 28th epoch : 0.07688512389821779  Training Accuracy:0.8970905172413793\n",
            "1856/4708 - The training loss at 28th epoch : 0.07704429575245621  Training Accuracy:0.8969017094017094\n",
            "1872/4708 - The training loss at 28th epoch : 0.07785023319796948  Training Accuracy:0.8951271186440678\n",
            "1888/4708 - The training loss at 28th epoch : 0.07805977534018557  Training Accuracy:0.8949579831932774\n",
            "1904/4708 - The training loss at 28th epoch : 0.07859818131675259  Training Accuracy:0.8942708333333333\n",
            "1920/4708 - The training loss at 28th epoch : 0.07857863173991737  Training Accuracy:0.8941115702479339\n",
            "1936/4708 - The training loss at 28th epoch : 0.07840154802346726  Training Accuracy:0.8939549180327869\n",
            "1952/4708 - The training loss at 28th epoch : 0.07858921488779999  Training Accuracy:0.8932926829268293\n",
            "1968/4708 - The training loss at 28th epoch : 0.07822899681652731  Training Accuracy:0.8941532258064516\n",
            "1984/4708 - The training loss at 28th epoch : 0.07851953429334164  Training Accuracy:0.894\n",
            "2000/4708 - The training loss at 28th epoch : 0.07855205414828158  Training Accuracy:0.8938492063492064\n",
            "2016/4708 - The training loss at 28th epoch : 0.07865270520072944  Training Accuracy:0.8937007874015748\n",
            "2032/4708 - The training loss at 28th epoch : 0.07817699452242102  Training Accuracy:0.89453125\n",
            "2048/4708 - The training loss at 28th epoch : 0.07790785585014091  Training Accuracy:0.8948643410852714\n",
            "2064/4708 - The training loss at 28th epoch : 0.07781420143391442  Training Accuracy:0.8947115384615385\n",
            "2080/4708 - The training loss at 28th epoch : 0.07751721733887938  Training Accuracy:0.8950381679389313\n",
            "2096/4708 - The training loss at 28th epoch : 0.07720531314628719  Training Accuracy:0.8953598484848485\n",
            "2112/4708 - The training loss at 28th epoch : 0.07698586931550928  Training Accuracy:0.8952067669172933\n",
            "2128/4708 - The training loss at 28th epoch : 0.07746314395146194  Training Accuracy:0.894589552238806\n",
            "2144/4708 - The training loss at 28th epoch : 0.07731607233471999  Training Accuracy:0.8949074074074074\n",
            "2160/4708 - The training loss at 28th epoch : 0.07719825744731815  Training Accuracy:0.8952205882352942\n",
            "2176/4708 - The training loss at 28th epoch : 0.07747089214303056  Training Accuracy:0.8950729927007299\n",
            "2192/4708 - The training loss at 28th epoch : 0.07711067336817386  Training Accuracy:0.8958333333333334\n",
            "2208/4708 - The training loss at 28th epoch : 0.07759683839925922  Training Accuracy:0.8952338129496403\n",
            "2224/4708 - The training loss at 28th epoch : 0.07722763095576932  Training Accuracy:0.8959821428571428\n",
            "2240/4708 - The training loss at 28th epoch : 0.07706604343989733  Training Accuracy:0.8967198581560284\n",
            "2256/4708 - The training loss at 28th epoch : 0.07668020388404687  Training Accuracy:0.8974471830985915\n",
            "2272/4708 - The training loss at 28th epoch : 0.07667438109049378  Training Accuracy:0.8972902097902098\n",
            "2288/4708 - The training loss at 28th epoch : 0.07750690637457788  Training Accuracy:0.8958333333333334\n",
            "2304/4708 - The training loss at 28th epoch : 0.07713178662265568  Training Accuracy:0.896551724137931\n",
            "2320/4708 - The training loss at 28th epoch : 0.07677986432465085  Training Accuracy:0.896832191780822\n",
            "2336/4708 - The training loss at 28th epoch : 0.07696949299968968  Training Accuracy:0.8966836734693877\n",
            "2352/4708 - The training loss at 28th epoch : 0.07747330486676574  Training Accuracy:0.8956925675675675\n",
            "2368/4708 - The training loss at 28th epoch : 0.07763160520912517  Training Accuracy:0.8955536912751678\n",
            "2384/4708 - The training loss at 28th epoch : 0.07728741269533954  Training Accuracy:0.89625\n",
            "2400/4708 - The training loss at 28th epoch : 0.07731706785926012  Training Accuracy:0.8956953642384106\n",
            "2416/4708 - The training loss at 28th epoch : 0.07711753968064003  Training Accuracy:0.8959703947368421\n",
            "2432/4708 - The training loss at 28th epoch : 0.0773522510659078  Training Accuracy:0.8958333333333334\n",
            "2448/4708 - The training loss at 28th epoch : 0.0778760778638557  Training Accuracy:0.8952922077922078\n",
            "2464/4708 - The training loss at 28th epoch : 0.0778941450100519  Training Accuracy:0.8951612903225806\n",
            "2480/4708 - The training loss at 28th epoch : 0.0777936508650944  Training Accuracy:0.8954326923076923\n",
            "2496/4708 - The training loss at 28th epoch : 0.07809860063816862  Training Accuracy:0.8953025477707006\n",
            "2512/4708 - The training loss at 28th epoch : 0.07804577768129209  Training Accuracy:0.8951740506329114\n",
            "2528/4708 - The training loss at 28th epoch : 0.07852975630408782  Training Accuracy:0.8942610062893082\n",
            "2544/4708 - The training loss at 28th epoch : 0.07836576768092267  Training Accuracy:0.89453125\n",
            "2560/4708 - The training loss at 28th epoch : 0.07823757750264744  Training Accuracy:0.8947981366459627\n",
            "2576/4708 - The training loss at 28th epoch : 0.07875853957120242  Training Accuracy:0.8942901234567902\n",
            "2592/4708 - The training loss at 28th epoch : 0.07883888462986842  Training Accuracy:0.8937883435582822\n",
            "2608/4708 - The training loss at 28th epoch : 0.07894878419789778  Training Accuracy:0.8929115853658537\n",
            "2624/4708 - The training loss at 28th epoch : 0.07879083985546056  Training Accuracy:0.8928030303030303\n",
            "2640/4708 - The training loss at 28th epoch : 0.07870663864754379  Training Accuracy:0.8930722891566265\n",
            "2656/4708 - The training loss at 28th epoch : 0.07882168566541724  Training Accuracy:0.8925898203592815\n",
            "2672/4708 - The training loss at 28th epoch : 0.07841840572302086  Training Accuracy:0.8932291666666666\n",
            "2688/4708 - The training loss at 28th epoch : 0.07819180641040484  Training Accuracy:0.893491124260355\n",
            "2704/4708 - The training loss at 28th epoch : 0.07776728464687341  Training Accuracy:0.8941176470588236\n",
            "2720/4708 - The training loss at 28th epoch : 0.07745237076055471  Training Accuracy:0.8947368421052632\n",
            "2736/4708 - The training loss at 28th epoch : 0.07739197139402289  Training Accuracy:0.8949854651162791\n",
            "2752/4708 - The training loss at 28th epoch : 0.07702997083841819  Training Accuracy:0.895592485549133\n",
            "2768/4708 - The training loss at 28th epoch : 0.07667812119042729  Training Accuracy:0.8961925287356322\n",
            "2784/4708 - The training loss at 28th epoch : 0.07687876695420327  Training Accuracy:0.8960714285714285\n",
            "2800/4708 - The training loss at 28th epoch : 0.07656636817471443  Training Accuracy:0.8966619318181818\n",
            "2816/4708 - The training loss at 28th epoch : 0.07651055580894171  Training Accuracy:0.8968926553672316\n",
            "2832/4708 - The training loss at 28th epoch : 0.07644756744696604  Training Accuracy:0.8971207865168539\n",
            "2848/4708 - The training loss at 28th epoch : 0.07653693273051937  Training Accuracy:0.8966480446927374\n",
            "2864/4708 - The training loss at 28th epoch : 0.07647723490013908  Training Accuracy:0.8965277777777778\n",
            "2880/4708 - The training loss at 28th epoch : 0.0764080655908821  Training Accuracy:0.8967541436464088\n",
            "2896/4708 - The training loss at 28th epoch : 0.07614595746129403  Training Accuracy:0.8973214285714286\n",
            "2912/4708 - The training loss at 28th epoch : 0.07582552144640889  Training Accuracy:0.8978825136612022\n",
            "2928/4708 - The training loss at 28th epoch : 0.07583413044116594  Training Accuracy:0.8977581521739131\n",
            "2944/4708 - The training loss at 28th epoch : 0.0755716510411841  Training Accuracy:0.897972972972973\n",
            "2960/4708 - The training loss at 28th epoch : 0.07546999023853393  Training Accuracy:0.8981854838709677\n",
            "2976/4708 - The training loss at 28th epoch : 0.07541300340554742  Training Accuracy:0.8980614973262032\n",
            "2992/4708 - The training loss at 28th epoch : 0.07534696527067578  Training Accuracy:0.8982712765957447\n",
            "3008/4708 - The training loss at 28th epoch : 0.07557130593711148  Training Accuracy:0.8978174603174603\n",
            "3024/4708 - The training loss at 28th epoch : 0.0758021522898434  Training Accuracy:0.8976973684210526\n",
            "3040/4708 - The training loss at 28th epoch : 0.07547896714082851  Training Accuracy:0.8982329842931938\n",
            "3056/4708 - The training loss at 28th epoch : 0.07592633933747005  Training Accuracy:0.8977864583333334\n",
            "3072/4708 - The training loss at 28th epoch : 0.07570624354293044  Training Accuracy:0.8979922279792746\n",
            "3088/4708 - The training loss at 28th epoch : 0.07573499118639378  Training Accuracy:0.8978737113402062\n",
            "3104/4708 - The training loss at 28th epoch : 0.07591640803411141  Training Accuracy:0.8977564102564103\n",
            "3120/4708 - The training loss at 28th epoch : 0.0760582243591946  Training Accuracy:0.8976403061224489\n",
            "3136/4708 - The training loss at 28th epoch : 0.07570803591050661  Training Accuracy:0.8981598984771574\n",
            "3152/4708 - The training loss at 28th epoch : 0.07559065168516216  Training Accuracy:0.8983585858585859\n",
            "3168/4708 - The training loss at 28th epoch : 0.07565047649037387  Training Accuracy:0.8982412060301508\n",
            "3184/4708 - The training loss at 28th epoch : 0.07553188776047401  Training Accuracy:0.8984375\n",
            "3200/4708 - The training loss at 28th epoch : 0.07552596229719404  Training Accuracy:0.8986318407960199\n",
            "3216/4708 - The training loss at 28th epoch : 0.07529379926261816  Training Accuracy:0.8988242574257426\n",
            "3232/4708 - The training loss at 28th epoch : 0.07526953114775836  Training Accuracy:0.8990147783251231\n",
            "3248/4708 - The training loss at 28th epoch : 0.07570227791242987  Training Accuracy:0.8982843137254902\n",
            "3264/4708 - The training loss at 28th epoch : 0.0755954970484997  Training Accuracy:0.8984756097560975\n",
            "3280/4708 - The training loss at 28th epoch : 0.07575211463041852  Training Accuracy:0.8980582524271845\n",
            "3296/4708 - The training loss at 28th epoch : 0.0758484574823604  Training Accuracy:0.8979468599033816\n",
            "3312/4708 - The training loss at 28th epoch : 0.07577815065973988  Training Accuracy:0.8978365384615384\n",
            "3328/4708 - The training loss at 28th epoch : 0.07627341088417194  Training Accuracy:0.8971291866028708\n",
            "3344/4708 - The training loss at 28th epoch : 0.0763356034984204  Training Accuracy:0.8967261904761905\n",
            "3360/4708 - The training loss at 28th epoch : 0.07629983093694165  Training Accuracy:0.8969194312796208\n",
            "3376/4708 - The training loss at 28th epoch : 0.0761846039524381  Training Accuracy:0.8968160377358491\n",
            "3392/4708 - The training loss at 28th epoch : 0.07599910525005413  Training Accuracy:0.8970070422535211\n",
            "3408/4708 - The training loss at 28th epoch : 0.07597218968416448  Training Accuracy:0.8969042056074766\n",
            "3424/4708 - The training loss at 28th epoch : 0.07592839840407073  Training Accuracy:0.897093023255814\n",
            "3440/4708 - The training loss at 28th epoch : 0.07599347184071456  Training Accuracy:0.8969907407407407\n",
            "3456/4708 - The training loss at 28th epoch : 0.07600149405760971  Training Accuracy:0.8971774193548387\n",
            "3472/4708 - The training loss at 28th epoch : 0.07584216530174773  Training Accuracy:0.8973623853211009\n",
            "3488/4708 - The training loss at 28th epoch : 0.07561825867903169  Training Accuracy:0.8978310502283106\n",
            "3504/4708 - The training loss at 28th epoch : 0.07561943131773374  Training Accuracy:0.8980113636363637\n",
            "3520/4708 - The training loss at 28th epoch : 0.075705778233548  Training Accuracy:0.8979072398190046\n",
            "3536/4708 - The training loss at 28th epoch : 0.07561653275367605  Training Accuracy:0.8980855855855856\n",
            "3552/4708 - The training loss at 28th epoch : 0.07598386004307257  Training Accuracy:0.8974215246636771\n",
            "3568/4708 - The training loss at 28th epoch : 0.0759326041100948  Training Accuracy:0.8976004464285714\n",
            "3584/4708 - The training loss at 28th epoch : 0.07588195322546809  Training Accuracy:0.8977777777777778\n",
            "3600/4708 - The training loss at 28th epoch : 0.07576756316747799  Training Accuracy:0.8979535398230089\n",
            "3616/4708 - The training loss at 28th epoch : 0.0757235584014523  Training Accuracy:0.8981277533039648\n",
            "3632/4708 - The training loss at 28th epoch : 0.07583019636645118  Training Accuracy:0.8980263157894737\n",
            "3648/4708 - The training loss at 28th epoch : 0.07593074210677578  Training Accuracy:0.8979257641921398\n",
            "3664/4708 - The training loss at 28th epoch : 0.07582651273886522  Training Accuracy:0.8980978260869565\n",
            "3680/4708 - The training loss at 28th epoch : 0.07565036174338621  Training Accuracy:0.898538961038961\n",
            "3696/4708 - The training loss at 28th epoch : 0.0757645612885098  Training Accuracy:0.8984375\n",
            "3712/4708 - The training loss at 28th epoch : 0.07577891738344837  Training Accuracy:0.898068669527897\n",
            "3728/4708 - The training loss at 28th epoch : 0.075640221114545  Training Accuracy:0.8982371794871795\n",
            "3744/4708 - The training loss at 28th epoch : 0.0755890192923713  Training Accuracy:0.8981382978723405\n",
            "3760/4708 - The training loss at 28th epoch : 0.07573580069966396  Training Accuracy:0.8980402542372882\n",
            "3776/4708 - The training loss at 28th epoch : 0.07569622091071032  Training Accuracy:0.8982067510548524\n",
            "3792/4708 - The training loss at 28th epoch : 0.07577753029129286  Training Accuracy:0.898109243697479\n",
            "3808/4708 - The training loss at 28th epoch : 0.0758006835138341  Training Accuracy:0.8980125523012552\n",
            "3824/4708 - The training loss at 28th epoch : 0.07560959088162054  Training Accuracy:0.8984375\n",
            "3840/4708 - The training loss at 28th epoch : 0.07568923326330054  Training Accuracy:0.8983402489626556\n",
            "3856/4708 - The training loss at 28th epoch : 0.0758829474301141  Training Accuracy:0.8979855371900827\n",
            "3872/4708 - The training loss at 28th epoch : 0.07587990603362406  Training Accuracy:0.8978909465020576\n",
            "3888/4708 - The training loss at 28th epoch : 0.07568988137186965  Training Accuracy:0.8983094262295082\n",
            "3904/4708 - The training loss at 28th epoch : 0.07581212198727291  Training Accuracy:0.8982142857142857\n",
            "3920/4708 - The training loss at 28th epoch : 0.07566738410223227  Training Accuracy:0.8983739837398373\n",
            "3936/4708 - The training loss at 28th epoch : 0.07557913152343088  Training Accuracy:0.8985323886639676\n",
            "3952/4708 - The training loss at 28th epoch : 0.07542959336486542  Training Accuracy:0.8986895161290323\n",
            "3968/4708 - The training loss at 28th epoch : 0.07523682555064641  Training Accuracy:0.8988453815261044\n",
            "3984/4708 - The training loss at 28th epoch : 0.07504389305872113  Training Accuracy:0.899\n",
            "4000/4708 - The training loss at 28th epoch : 0.07514737924871277  Training Accuracy:0.8989043824701195\n",
            "4016/4708 - The training loss at 28th epoch : 0.07518611167302505  Training Accuracy:0.8985615079365079\n",
            "4032/4708 - The training loss at 28th epoch : 0.0749077464961262  Training Accuracy:0.8989624505928854\n",
            "4048/4708 - The training loss at 28th epoch : 0.0747787533598356  Training Accuracy:0.8991141732283464\n",
            "4064/4708 - The training loss at 28th epoch : 0.07481147632641148  Training Accuracy:0.8990196078431373\n",
            "4080/4708 - The training loss at 28th epoch : 0.07474563043626495  Training Accuracy:0.899169921875\n",
            "4096/4708 - The training loss at 28th epoch : 0.07494742046468537  Training Accuracy:0.8988326848249028\n",
            "4112/4708 - The training loss at 28th epoch : 0.07483716994511874  Training Accuracy:0.8989825581395349\n",
            "4128/4708 - The training loss at 28th epoch : 0.07496912577371051  Training Accuracy:0.8986486486486487\n",
            "4144/4708 - The training loss at 28th epoch : 0.07519508475310559  Training Accuracy:0.8983173076923077\n",
            "4160/4708 - The training loss at 28th epoch : 0.07504222729749264  Training Accuracy:0.8984674329501916\n",
            "4176/4708 - The training loss at 28th epoch : 0.07543528512829027  Training Accuracy:0.8979007633587787\n",
            "4192/4708 - The training loss at 28th epoch : 0.07528610950382104  Training Accuracy:0.8980513307984791\n",
            "4208/4708 - The training loss at 28th epoch : 0.07514752381219529  Training Accuracy:0.8982007575757576\n",
            "4224/4708 - The training loss at 28th epoch : 0.07531966183697748  Training Accuracy:0.8981132075471698\n",
            "4240/4708 - The training loss at 28th epoch : 0.07531643151419888  Training Accuracy:0.8982612781954887\n",
            "4256/4708 - The training loss at 28th epoch : 0.07549384403257979  Training Accuracy:0.8979400749063671\n",
            "4272/4708 - The training loss at 28th epoch : 0.07538536017609776  Training Accuracy:0.8980876865671642\n",
            "4288/4708 - The training loss at 28th epoch : 0.0754972613095155  Training Accuracy:0.8982342007434945\n",
            "4304/4708 - The training loss at 28th epoch : 0.07551790499633551  Training Accuracy:0.8981481481481481\n",
            "4320/4708 - The training loss at 28th epoch : 0.07527148109071168  Training Accuracy:0.8985239852398524\n",
            "4336/4708 - The training loss at 28th epoch : 0.07530330761485146  Training Accuracy:0.8984375\n",
            "4352/4708 - The training loss at 28th epoch : 0.07508428793064344  Training Accuracy:0.8988095238095238\n",
            "4368/4708 - The training loss at 28th epoch : 0.07486341278422609  Training Accuracy:0.8991788321167883\n",
            "4384/4708 - The training loss at 28th epoch : 0.0747170289505644  Training Accuracy:0.8993181818181818\n",
            "4400/4708 - The training loss at 28th epoch : 0.07465065086752794  Training Accuracy:0.8992300724637681\n",
            "4416/4708 - The training loss at 28th epoch : 0.07452237910272008  Training Accuracy:0.8993682310469314\n",
            "4432/4708 - The training loss at 28th epoch : 0.07456743940829523  Training Accuracy:0.8990557553956835\n",
            "4448/4708 - The training loss at 28th epoch : 0.0745090917092676  Training Accuracy:0.8991935483870968\n",
            "4464/4708 - The training loss at 28th epoch : 0.07440142551292567  Training Accuracy:0.8993303571428571\n",
            "4480/4708 - The training loss at 28th epoch : 0.07458716080031637  Training Accuracy:0.8990213523131673\n",
            "4496/4708 - The training loss at 28th epoch : 0.07448488099433406  Training Accuracy:0.8991578014184397\n",
            "4512/4708 - The training loss at 28th epoch : 0.0745199062581317  Training Accuracy:0.8992932862190812\n",
            "4528/4708 - The training loss at 28th epoch : 0.07448808561260101  Training Accuracy:0.8992077464788732\n",
            "4544/4708 - The training loss at 28th epoch : 0.07427618094984582  Training Accuracy:0.8995614035087719\n",
            "4560/4708 - The training loss at 28th epoch : 0.07431172912150336  Training Accuracy:0.8994755244755245\n",
            "4576/4708 - The training loss at 28th epoch : 0.07431711532051072  Training Accuracy:0.8996080139372822\n",
            "4592/4708 - The training loss at 28th epoch : 0.07413898973151434  Training Accuracy:0.8997395833333334\n",
            "4608/4708 - The training loss at 28th epoch : 0.07421550439016532  Training Accuracy:0.8996539792387543\n",
            "4624/4708 - The training loss at 28th epoch : 0.0741018877714517  Training Accuracy:0.8997844827586207\n",
            "4640/4708 - The training loss at 28th epoch : 0.07420369595154797  Training Accuracy:0.8994845360824743\n",
            "4656/4708 - The training loss at 28th epoch : 0.07424460797202971  Training Accuracy:0.8994006849315068\n",
            "4672/4708 - The training loss at 28th epoch : 0.07442859503227076  Training Accuracy:0.89910409556314\n",
            "4688/4708 - The training loss at 28th epoch : 0.07434588265589995  Training Accuracy:0.8992346938775511\n",
            "4704/4708 - The training loss at 28th epoch : 0.074230901764634  Training Accuracy:0.899364406779661\n",
            "4720/4708 - The training loss at 28th epoch : 0.07403827571350638  Training Accuracy:0.8997043918918919\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 29th epoch : 0.06961053730640791  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 29th epoch : 0.10202574442089188  Training Accuracy:0.84375\n",
            "32/4708 - The training loss at 29th epoch : 0.07756358728204142  Training Accuracy:0.8958333333333334\n",
            "48/4708 - The training loss at 29th epoch : 0.06560600624669159  Training Accuracy:0.921875\n",
            "64/4708 - The training loss at 29th epoch : 0.0819900119523856  Training Accuracy:0.9\n",
            "80/4708 - The training loss at 29th epoch : 0.08194139874128918  Training Accuracy:0.90625\n",
            "96/4708 - The training loss at 29th epoch : 0.07995222819948132  Training Accuracy:0.9107142857142857\n",
            "112/4708 - The training loss at 29th epoch : 0.08632650019837118  Training Accuracy:0.8984375\n",
            "128/4708 - The training loss at 29th epoch : 0.07739917082433768  Training Accuracy:0.9097222222222222\n",
            "144/4708 - The training loss at 29th epoch : 0.07713783430237622  Training Accuracy:0.9125\n",
            "160/4708 - The training loss at 29th epoch : 0.08306981694713757  Training Accuracy:0.9034090909090909\n",
            "176/4708 - The training loss at 29th epoch : 0.08196284604692722  Training Accuracy:0.90625\n",
            "192/4708 - The training loss at 29th epoch : 0.07919481838371796  Training Accuracy:0.9086538461538461\n",
            "208/4708 - The training loss at 29th epoch : 0.07424872901631531  Training Accuracy:0.9151785714285714\n",
            "224/4708 - The training loss at 29th epoch : 0.0702806118864907  Training Accuracy:0.9208333333333333\n",
            "240/4708 - The training loss at 29th epoch : 0.06649401117662904  Training Accuracy:0.92578125\n",
            "256/4708 - The training loss at 29th epoch : 0.06719974455730189  Training Accuracy:0.9264705882352942\n",
            "272/4708 - The training loss at 29th epoch : 0.06558438364861154  Training Accuracy:0.9270833333333334\n",
            "288/4708 - The training loss at 29th epoch : 0.06712006874191993  Training Accuracy:0.9243421052631579\n",
            "304/4708 - The training loss at 29th epoch : 0.0680341460457507  Training Accuracy:0.921875\n",
            "320/4708 - The training loss at 29th epoch : 0.07143302296050741  Training Accuracy:0.9196428571428571\n",
            "336/4708 - The training loss at 29th epoch : 0.07294695121153727  Training Accuracy:0.9147727272727273\n",
            "352/4708 - The training loss at 29th epoch : 0.07374241715008165  Training Accuracy:0.9130434782608695\n",
            "368/4708 - The training loss at 29th epoch : 0.07553516635090583  Training Accuracy:0.9088541666666666\n",
            "384/4708 - The training loss at 29th epoch : 0.07501147548482376  Training Accuracy:0.9075\n",
            "400/4708 - The training loss at 29th epoch : 0.07375790178354859  Training Accuracy:0.90625\n",
            "416/4708 - The training loss at 29th epoch : 0.073076055417826  Training Accuracy:0.9074074074074074\n",
            "432/4708 - The training loss at 29th epoch : 0.07366318267182136  Training Accuracy:0.90625\n",
            "448/4708 - The training loss at 29th epoch : 0.0723596704045402  Training Accuracy:0.9073275862068966\n",
            "464/4708 - The training loss at 29th epoch : 0.07273342896358732  Training Accuracy:0.90625\n",
            "480/4708 - The training loss at 29th epoch : 0.07630545131889574  Training Accuracy:0.8991935483870968\n",
            "496/4708 - The training loss at 29th epoch : 0.07692304829727753  Training Accuracy:0.900390625\n",
            "512/4708 - The training loss at 29th epoch : 0.07795302359746838  Training Accuracy:0.8996212121212122\n",
            "528/4708 - The training loss at 29th epoch : 0.07866519858930705  Training Accuracy:0.8970588235294118\n",
            "544/4708 - The training loss at 29th epoch : 0.07981385878534106  Training Accuracy:0.8964285714285715\n",
            "560/4708 - The training loss at 29th epoch : 0.07816469443793275  Training Accuracy:0.8993055555555556\n",
            "576/4708 - The training loss at 29th epoch : 0.07647922951721679  Training Accuracy:0.902027027027027\n",
            "592/4708 - The training loss at 29th epoch : 0.07647944813759366  Training Accuracy:0.9013157894736842\n",
            "608/4708 - The training loss at 29th epoch : 0.07593013833379661  Training Accuracy:0.9022435897435898\n",
            "624/4708 - The training loss at 29th epoch : 0.07527358035594356  Training Accuracy:0.903125\n",
            "640/4708 - The training loss at 29th epoch : 0.07621396011576066  Training Accuracy:0.9024390243902439\n",
            "656/4708 - The training loss at 29th epoch : 0.07573678326850258  Training Accuracy:0.9032738095238095\n",
            "672/4708 - The training loss at 29th epoch : 0.07571113246985618  Training Accuracy:0.9040697674418605\n",
            "688/4708 - The training loss at 29th epoch : 0.07717476594350749  Training Accuracy:0.9019886363636364\n",
            "704/4708 - The training loss at 29th epoch : 0.07820982708793814  Training Accuracy:0.9\n",
            "720/4708 - The training loss at 29th epoch : 0.07822054473263583  Training Accuracy:0.8994565217391305\n",
            "736/4708 - The training loss at 29th epoch : 0.07959380390206129  Training Accuracy:0.8962765957446809\n",
            "752/4708 - The training loss at 29th epoch : 0.08014848162641337  Training Accuracy:0.8958333333333334\n",
            "768/4708 - The training loss at 29th epoch : 0.0806150602945447  Training Accuracy:0.8954081632653061\n",
            "784/4708 - The training loss at 29th epoch : 0.08063541336610017  Training Accuracy:0.895\n",
            "800/4708 - The training loss at 29th epoch : 0.07946854757403297  Training Accuracy:0.8970588235294118\n",
            "816/4708 - The training loss at 29th epoch : 0.07918440318752662  Training Accuracy:0.8978365384615384\n",
            "832/4708 - The training loss at 29th epoch : 0.07921605333560887  Training Accuracy:0.8974056603773585\n",
            "848/4708 - The training loss at 29th epoch : 0.07831069031259358  Training Accuracy:0.8993055555555556\n",
            "864/4708 - The training loss at 29th epoch : 0.07755215255054544  Training Accuracy:0.9\n",
            "880/4708 - The training loss at 29th epoch : 0.07718110186226439  Training Accuracy:0.9006696428571429\n",
            "896/4708 - The training loss at 29th epoch : 0.07662753933824616  Training Accuracy:0.9013157894736842\n",
            "912/4708 - The training loss at 29th epoch : 0.07712711259046164  Training Accuracy:0.9008620689655172\n",
            "928/4708 - The training loss at 29th epoch : 0.07683253480614927  Training Accuracy:0.9014830508474576\n",
            "944/4708 - The training loss at 29th epoch : 0.07696831506605663  Training Accuracy:0.9020833333333333\n",
            "960/4708 - The training loss at 29th epoch : 0.07674243956546958  Training Accuracy:0.9016393442622951\n",
            "976/4708 - The training loss at 29th epoch : 0.07619561602483196  Training Accuracy:0.9022177419354839\n",
            "992/4708 - The training loss at 29th epoch : 0.07709363631341784  Training Accuracy:0.9017857142857143\n",
            "1008/4708 - The training loss at 29th epoch : 0.07715958430200742  Training Accuracy:0.9013671875\n",
            "1024/4708 - The training loss at 29th epoch : 0.07739302257752036  Training Accuracy:0.9009615384615385\n",
            "1040/4708 - The training loss at 29th epoch : 0.07803513316541232  Training Accuracy:0.8996212121212122\n",
            "1056/4708 - The training loss at 29th epoch : 0.07753481895516445  Training Accuracy:0.9001865671641791\n",
            "1072/4708 - The training loss at 29th epoch : 0.07734153992937799  Training Accuracy:0.8988970588235294\n",
            "1088/4708 - The training loss at 29th epoch : 0.07822290289557048  Training Accuracy:0.8976449275362319\n",
            "1104/4708 - The training loss at 29th epoch : 0.07868808896407738  Training Accuracy:0.8964285714285715\n",
            "1120/4708 - The training loss at 29th epoch : 0.07819222320047746  Training Accuracy:0.8970070422535211\n",
            "1136/4708 - The training loss at 29th epoch : 0.07822510508252495  Training Accuracy:0.8967013888888888\n",
            "1152/4708 - The training loss at 29th epoch : 0.07983674662710957  Training Accuracy:0.8946917808219178\n",
            "1168/4708 - The training loss at 29th epoch : 0.07943091252697888  Training Accuracy:0.8952702702702703\n",
            "1184/4708 - The training loss at 29th epoch : 0.08057464821903725  Training Accuracy:0.8933333333333333\n",
            "1200/4708 - The training loss at 29th epoch : 0.08094195986657976  Training Accuracy:0.8922697368421053\n",
            "1216/4708 - The training loss at 29th epoch : 0.08089984267681229  Training Accuracy:0.8920454545454546\n",
            "1232/4708 - The training loss at 29th epoch : 0.08143357879558517  Training Accuracy:0.8918269230769231\n",
            "1248/4708 - The training loss at 29th epoch : 0.0805204170775902  Training Accuracy:0.8931962025316456\n",
            "1264/4708 - The training loss at 29th epoch : 0.08072420422637319  Training Accuracy:0.8921875\n",
            "1280/4708 - The training loss at 29th epoch : 0.08111939731388357  Training Accuracy:0.8912037037037037\n",
            "1296/4708 - The training loss at 29th epoch : 0.08049710993647274  Training Accuracy:0.8925304878048781\n",
            "1312/4708 - The training loss at 29th epoch : 0.08002940180385434  Training Accuracy:0.8930722891566265\n",
            "1328/4708 - The training loss at 29th epoch : 0.08017855268804944  Training Accuracy:0.8928571428571429\n",
            "1344/4708 - The training loss at 29th epoch : 0.08015609692429239  Training Accuracy:0.8926470588235295\n",
            "1360/4708 - The training loss at 29th epoch : 0.08132459649465101  Training Accuracy:0.8909883720930233\n",
            "1376/4708 - The training loss at 29th epoch : 0.08091420987225019  Training Accuracy:0.8915229885057471\n",
            "1392/4708 - The training loss at 29th epoch : 0.08091966137622662  Training Accuracy:0.8913352272727273\n",
            "1408/4708 - The training loss at 29th epoch : 0.08043212220579993  Training Accuracy:0.8918539325842697\n",
            "1424/4708 - The training loss at 29th epoch : 0.08055930752689552  Training Accuracy:0.8916666666666667\n",
            "1440/4708 - The training loss at 29th epoch : 0.0803098744667494  Training Accuracy:0.8914835164835165\n",
            "1456/4708 - The training loss at 29th epoch : 0.08030623262540589  Training Accuracy:0.8913043478260869\n",
            "1472/4708 - The training loss at 29th epoch : 0.07960953314781982  Training Accuracy:0.8924731182795699\n",
            "1488/4708 - The training loss at 29th epoch : 0.07985429682596264  Training Accuracy:0.8916223404255319\n",
            "1504/4708 - The training loss at 29th epoch : 0.08025116893676006  Training Accuracy:0.8907894736842106\n",
            "1520/4708 - The training loss at 29th epoch : 0.08107393509987933  Training Accuracy:0.8899739583333334\n",
            "1536/4708 - The training loss at 29th epoch : 0.08097480829510591  Training Accuracy:0.8904639175257731\n",
            "1552/4708 - The training loss at 29th epoch : 0.08094099853709812  Training Accuracy:0.8909438775510204\n",
            "1568/4708 - The training loss at 29th epoch : 0.08102582118351095  Training Accuracy:0.8907828282828283\n",
            "1584/4708 - The training loss at 29th epoch : 0.08185968319782648  Training Accuracy:0.89\n",
            "1600/4708 - The training loss at 29th epoch : 0.08130339353161453  Training Accuracy:0.8910891089108911\n",
            "1616/4708 - The training loss at 29th epoch : 0.08088525827277229  Training Accuracy:0.8915441176470589\n",
            "1632/4708 - The training loss at 29th epoch : 0.0805442092326537  Training Accuracy:0.8919902912621359\n",
            "1648/4708 - The training loss at 29th epoch : 0.07998342261572465  Training Accuracy:0.8924278846153846\n",
            "1664/4708 - The training loss at 29th epoch : 0.07979080388024777  Training Accuracy:0.8928571428571429\n",
            "1680/4708 - The training loss at 29th epoch : 0.0799848938774391  Training Accuracy:0.8926886792452831\n",
            "1696/4708 - The training loss at 29th epoch : 0.07972759944480265  Training Accuracy:0.893107476635514\n",
            "1712/4708 - The training loss at 29th epoch : 0.07934991378623571  Training Accuracy:0.8935185185185185\n",
            "1728/4708 - The training loss at 29th epoch : 0.07947785369829732  Training Accuracy:0.893348623853211\n",
            "1744/4708 - The training loss at 29th epoch : 0.07950518428206738  Training Accuracy:0.89375\n",
            "1760/4708 - The training loss at 29th epoch : 0.07899729030515511  Training Accuracy:0.8947072072072072\n",
            "1776/4708 - The training loss at 29th epoch : 0.07853358081550674  Training Accuracy:0.8950892857142857\n",
            "1792/4708 - The training loss at 29th epoch : 0.07844115363309642  Training Accuracy:0.8949115044247787\n",
            "1808/4708 - The training loss at 29th epoch : 0.07850826253652327  Training Accuracy:0.8947368421052632\n",
            "1824/4708 - The training loss at 29th epoch : 0.07861846067823798  Training Accuracy:0.8945652173913043\n",
            "1840/4708 - The training loss at 29th epoch : 0.07832164469053064  Training Accuracy:0.8949353448275862\n",
            "1856/4708 - The training loss at 29th epoch : 0.07856839724380048  Training Accuracy:0.8947649572649573\n",
            "1872/4708 - The training loss at 29th epoch : 0.07956594227602228  Training Accuracy:0.8935381355932204\n",
            "1888/4708 - The training loss at 29th epoch : 0.07897634976254336  Training Accuracy:0.8944327731092437\n",
            "1904/4708 - The training loss at 29th epoch : 0.07890650181707545  Training Accuracy:0.8942708333333333\n",
            "1920/4708 - The training loss at 29th epoch : 0.0786500043368775  Training Accuracy:0.8946280991735537\n",
            "1936/4708 - The training loss at 29th epoch : 0.078301959360006  Training Accuracy:0.8949795081967213\n",
            "1952/4708 - The training loss at 29th epoch : 0.07848586696720804  Training Accuracy:0.8948170731707317\n",
            "1968/4708 - The training loss at 29th epoch : 0.07793574391897176  Training Accuracy:0.8956653225806451\n",
            "1984/4708 - The training loss at 29th epoch : 0.0777293553124958  Training Accuracy:0.896\n",
            "2000/4708 - The training loss at 29th epoch : 0.07772900493056872  Training Accuracy:0.8958333333333334\n",
            "2016/4708 - The training loss at 29th epoch : 0.07829459615284588  Training Accuracy:0.8951771653543307\n",
            "2032/4708 - The training loss at 29th epoch : 0.07846884014684347  Training Accuracy:0.89501953125\n",
            "2048/4708 - The training loss at 29th epoch : 0.07883597477789192  Training Accuracy:0.8943798449612403\n",
            "2064/4708 - The training loss at 29th epoch : 0.0790416308796243  Training Accuracy:0.8942307692307693\n",
            "2080/4708 - The training loss at 29th epoch : 0.07955032224664788  Training Accuracy:0.8936068702290076\n",
            "2096/4708 - The training loss at 29th epoch : 0.07926649334785846  Training Accuracy:0.8939393939393939\n",
            "2112/4708 - The training loss at 29th epoch : 0.07888452985993621  Training Accuracy:0.894266917293233\n",
            "2128/4708 - The training loss at 29th epoch : 0.07858437515570842  Training Accuracy:0.894589552238806\n",
            "2144/4708 - The training loss at 29th epoch : 0.07832630102849145  Training Accuracy:0.8949074074074074\n",
            "2160/4708 - The training loss at 29th epoch : 0.07842642598737282  Training Accuracy:0.8947610294117647\n",
            "2176/4708 - The training loss at 29th epoch : 0.07832575938476988  Training Accuracy:0.8946167883211679\n",
            "2192/4708 - The training loss at 29th epoch : 0.07781642895129609  Training Accuracy:0.8953804347826086\n",
            "2208/4708 - The training loss at 29th epoch : 0.07788924758076146  Training Accuracy:0.8952338129496403\n",
            "2224/4708 - The training loss at 29th epoch : 0.07793132848112583  Training Accuracy:0.8950892857142857\n",
            "2240/4708 - The training loss at 29th epoch : 0.07757208000444452  Training Accuracy:0.8958333333333334\n",
            "2256/4708 - The training loss at 29th epoch : 0.07705850284676005  Training Accuracy:0.8965669014084507\n",
            "2272/4708 - The training loss at 29th epoch : 0.07699655903166332  Training Accuracy:0.8968531468531469\n",
            "2288/4708 - The training loss at 29th epoch : 0.07694753527465398  Training Accuracy:0.8962673611111112\n",
            "2304/4708 - The training loss at 29th epoch : 0.0768684025763664  Training Accuracy:0.896551724137931\n",
            "2320/4708 - The training loss at 29th epoch : 0.07685189210142518  Training Accuracy:0.896832191780822\n",
            "2336/4708 - The training loss at 29th epoch : 0.07793115900707172  Training Accuracy:0.8949829931972789\n",
            "2352/4708 - The training loss at 29th epoch : 0.07776090542151537  Training Accuracy:0.8952702702702703\n",
            "2368/4708 - The training loss at 29th epoch : 0.0775217435559904  Training Accuracy:0.8955536912751678\n",
            "2384/4708 - The training loss at 29th epoch : 0.07749461192575519  Training Accuracy:0.8958333333333334\n",
            "2400/4708 - The training loss at 29th epoch : 0.07713534451613659  Training Accuracy:0.8965231788079471\n",
            "2416/4708 - The training loss at 29th epoch : 0.0768447108176316  Training Accuracy:0.897203947368421\n",
            "2432/4708 - The training loss at 29th epoch : 0.07706496051473836  Training Accuracy:0.8970588235294118\n",
            "2448/4708 - The training loss at 29th epoch : 0.07733984145608151  Training Accuracy:0.8965097402597403\n",
            "2464/4708 - The training loss at 29th epoch : 0.07753707104104043  Training Accuracy:0.8963709677419355\n",
            "2480/4708 - The training loss at 29th epoch : 0.07779155079354254  Training Accuracy:0.8962339743589743\n",
            "2496/4708 - The training loss at 29th epoch : 0.07737685113295274  Training Accuracy:0.8968949044585988\n",
            "2512/4708 - The training loss at 29th epoch : 0.07752855629288233  Training Accuracy:0.8963607594936709\n",
            "2528/4708 - The training loss at 29th epoch : 0.07709617461940932  Training Accuracy:0.8970125786163522\n",
            "2544/4708 - The training loss at 29th epoch : 0.07730696520401063  Training Accuracy:0.896875\n",
            "2560/4708 - The training loss at 29th epoch : 0.07687631145682275  Training Accuracy:0.8975155279503105\n",
            "2576/4708 - The training loss at 29th epoch : 0.0768100307533244  Training Accuracy:0.8973765432098766\n",
            "2592/4708 - The training loss at 29th epoch : 0.07692487916735463  Training Accuracy:0.897239263803681\n",
            "2608/4708 - The training loss at 29th epoch : 0.07675634782055125  Training Accuracy:0.897484756097561\n",
            "2624/4708 - The training loss at 29th epoch : 0.07638434315829343  Training Accuracy:0.8981060606060606\n",
            "2640/4708 - The training loss at 29th epoch : 0.07651639493538136  Training Accuracy:0.8979668674698795\n",
            "2656/4708 - The training loss at 29th epoch : 0.0768635224108583  Training Accuracy:0.8974550898203593\n",
            "2672/4708 - The training loss at 29th epoch : 0.07677809259131575  Training Accuracy:0.8976934523809523\n",
            "2688/4708 - The training loss at 29th epoch : 0.07646680533660939  Training Accuracy:0.8979289940828402\n",
            "2704/4708 - The training loss at 29th epoch : 0.0770691629393165  Training Accuracy:0.8966911764705883\n",
            "2720/4708 - The training loss at 29th epoch : 0.07682824447765522  Training Accuracy:0.8969298245614035\n",
            "2736/4708 - The training loss at 29th epoch : 0.07639141734838202  Training Accuracy:0.8975290697674418\n",
            "2752/4708 - The training loss at 29th epoch : 0.0774678112113845  Training Accuracy:0.8963150289017341\n",
            "2768/4708 - The training loss at 29th epoch : 0.07728915441971337  Training Accuracy:0.896551724137931\n",
            "2784/4708 - The training loss at 29th epoch : 0.0770632314409132  Training Accuracy:0.8971428571428571\n",
            "2800/4708 - The training loss at 29th epoch : 0.07727524866772906  Training Accuracy:0.8966619318181818\n",
            "2816/4708 - The training loss at 29th epoch : 0.0770841495837966  Training Accuracy:0.8972457627118644\n",
            "2832/4708 - The training loss at 29th epoch : 0.07683072489947579  Training Accuracy:0.8978230337078652\n",
            "2848/4708 - The training loss at 29th epoch : 0.07663673898902035  Training Accuracy:0.8980446927374302\n",
            "2864/4708 - The training loss at 29th epoch : 0.07667608819463644  Training Accuracy:0.8982638888888889\n",
            "2880/4708 - The training loss at 29th epoch : 0.07626365439324079  Training Accuracy:0.8988259668508287\n",
            "2896/4708 - The training loss at 29th epoch : 0.07619698548891697  Training Accuracy:0.898695054945055\n",
            "2912/4708 - The training loss at 29th epoch : 0.0759678547434892  Training Accuracy:0.8992486338797814\n",
            "2928/4708 - The training loss at 29th epoch : 0.0757169409442954  Training Accuracy:0.8994565217391305\n",
            "2944/4708 - The training loss at 29th epoch : 0.07542943518439488  Training Accuracy:0.9\n",
            "2960/4708 - The training loss at 29th epoch : 0.07517659383773817  Training Accuracy:0.9002016129032258\n",
            "2976/4708 - The training loss at 29th epoch : 0.075266114416835  Training Accuracy:0.9000668449197861\n",
            "2992/4708 - The training loss at 29th epoch : 0.07572911209463426  Training Accuracy:0.8992686170212766\n",
            "3008/4708 - The training loss at 29th epoch : 0.07583353865627175  Training Accuracy:0.8988095238095238\n",
            "3024/4708 - The training loss at 29th epoch : 0.07594666774183077  Training Accuracy:0.8983552631578947\n",
            "3040/4708 - The training loss at 29th epoch : 0.07616522108042179  Training Accuracy:0.8975785340314136\n",
            "3056/4708 - The training loss at 29th epoch : 0.07701719406392168  Training Accuracy:0.8968098958333334\n",
            "3072/4708 - The training loss at 29th epoch : 0.07666287680465057  Training Accuracy:0.8973445595854922\n",
            "3088/4708 - The training loss at 29th epoch : 0.07709768781323241  Training Accuracy:0.8962628865979382\n",
            "3104/4708 - The training loss at 29th epoch : 0.07730044703787403  Training Accuracy:0.8961538461538462\n",
            "3120/4708 - The training loss at 29th epoch : 0.07731132014204364  Training Accuracy:0.8960459183673469\n",
            "3136/4708 - The training loss at 29th epoch : 0.07715970909735968  Training Accuracy:0.896256345177665\n",
            "3152/4708 - The training loss at 29th epoch : 0.07692785227131098  Training Accuracy:0.896780303030303\n",
            "3168/4708 - The training loss at 29th epoch : 0.07666684269985381  Training Accuracy:0.8972989949748744\n",
            "3184/4708 - The training loss at 29th epoch : 0.07683497011931661  Training Accuracy:0.8971875\n",
            "3200/4708 - The training loss at 29th epoch : 0.07673546878087667  Training Accuracy:0.8973880597014925\n",
            "3216/4708 - The training loss at 29th epoch : 0.07675077856063864  Training Accuracy:0.8975866336633663\n",
            "3232/4708 - The training loss at 29th epoch : 0.07661736969840229  Training Accuracy:0.8977832512315271\n",
            "3248/4708 - The training loss at 29th epoch : 0.07661086366478417  Training Accuracy:0.897671568627451\n",
            "3264/4708 - The training loss at 29th epoch : 0.07628985665331213  Training Accuracy:0.8981707317073171\n",
            "3280/4708 - The training loss at 29th epoch : 0.07611012613267684  Training Accuracy:0.8983616504854369\n",
            "3296/4708 - The training loss at 29th epoch : 0.07611317879547227  Training Accuracy:0.8982487922705314\n",
            "3312/4708 - The training loss at 29th epoch : 0.07619651517259765  Training Accuracy:0.8981370192307693\n",
            "3328/4708 - The training loss at 29th epoch : 0.07621656750087161  Training Accuracy:0.8980263157894737\n",
            "3344/4708 - The training loss at 29th epoch : 0.07649947188048441  Training Accuracy:0.8976190476190476\n",
            "3360/4708 - The training loss at 29th epoch : 0.07654191462954991  Training Accuracy:0.8975118483412322\n",
            "3376/4708 - The training loss at 29th epoch : 0.07640812836317444  Training Accuracy:0.8977004716981132\n",
            "3392/4708 - The training loss at 29th epoch : 0.07655723167310163  Training Accuracy:0.897593896713615\n",
            "3408/4708 - The training loss at 29th epoch : 0.07632804394151148  Training Accuracy:0.898072429906542\n",
            "3424/4708 - The training loss at 29th epoch : 0.07666284640762124  Training Accuracy:0.8979651162790697\n",
            "3440/4708 - The training loss at 29th epoch : 0.07654119394839709  Training Accuracy:0.8981481481481481\n",
            "3456/4708 - The training loss at 29th epoch : 0.07641765971409162  Training Accuracy:0.8983294930875576\n",
            "3472/4708 - The training loss at 29th epoch : 0.07648580452699302  Training Accuracy:0.8982224770642202\n",
            "3488/4708 - The training loss at 29th epoch : 0.07661517801748496  Training Accuracy:0.8978310502283106\n",
            "3504/4708 - The training loss at 29th epoch : 0.07658014928614947  Training Accuracy:0.8980113636363637\n",
            "3520/4708 - The training loss at 29th epoch : 0.07646634214472062  Training Accuracy:0.8981900452488688\n",
            "3536/4708 - The training loss at 29th epoch : 0.07662801746695849  Training Accuracy:0.8980855855855856\n",
            "3552/4708 - The training loss at 29th epoch : 0.07659158422038057  Training Accuracy:0.8982623318385651\n",
            "3568/4708 - The training loss at 29th epoch : 0.07650998862005268  Training Accuracy:0.8984375\n",
            "3584/4708 - The training loss at 29th epoch : 0.07664172533351218  Training Accuracy:0.8983333333333333\n",
            "3600/4708 - The training loss at 29th epoch : 0.07676031004714672  Training Accuracy:0.8982300884955752\n",
            "3616/4708 - The training loss at 29th epoch : 0.0765019975764076  Training Accuracy:0.8986784140969163\n",
            "3632/4708 - The training loss at 29th epoch : 0.07654655476547949  Training Accuracy:0.8988486842105263\n",
            "3648/4708 - The training loss at 29th epoch : 0.07640512254996928  Training Accuracy:0.8990174672489083\n",
            "3664/4708 - The training loss at 29th epoch : 0.0763786700957399  Training Accuracy:0.8989130434782608\n",
            "3680/4708 - The training loss at 29th epoch : 0.0763303390774564  Training Accuracy:0.8990800865800865\n",
            "3696/4708 - The training loss at 29th epoch : 0.07640549368924045  Training Accuracy:0.8987068965517241\n",
            "3712/4708 - The training loss at 29th epoch : 0.07641641339477802  Training Accuracy:0.8986051502145923\n",
            "3728/4708 - The training loss at 29th epoch : 0.07674728838192377  Training Accuracy:0.8979700854700855\n",
            "3744/4708 - The training loss at 29th epoch : 0.0766524281560715  Training Accuracy:0.8981382978723405\n",
            "3760/4708 - The training loss at 29th epoch : 0.07658854545187828  Training Accuracy:0.8980402542372882\n",
            "3776/4708 - The training loss at 29th epoch : 0.07658197779522263  Training Accuracy:0.8979430379746836\n",
            "3792/4708 - The training loss at 29th epoch : 0.07664322001057991  Training Accuracy:0.8975840336134454\n",
            "3808/4708 - The training loss at 29th epoch : 0.07674347408345429  Training Accuracy:0.897489539748954\n",
            "3824/4708 - The training loss at 29th epoch : 0.0765071680831802  Training Accuracy:0.8979166666666667\n",
            "3840/4708 - The training loss at 29th epoch : 0.07648455464113817  Training Accuracy:0.8978215767634855\n",
            "3856/4708 - The training loss at 29th epoch : 0.07667460631243338  Training Accuracy:0.8974690082644629\n",
            "3872/4708 - The training loss at 29th epoch : 0.07648623219938049  Training Accuracy:0.897633744855967\n",
            "3888/4708 - The training loss at 29th epoch : 0.07639658456575098  Training Accuracy:0.897797131147541\n",
            "3904/4708 - The training loss at 29th epoch : 0.07633183812059563  Training Accuracy:0.8979591836734694\n",
            "3920/4708 - The training loss at 29th epoch : 0.07648960544442392  Training Accuracy:0.8978658536585366\n",
            "3936/4708 - The training loss at 29th epoch : 0.07639964138372904  Training Accuracy:0.8980263157894737\n",
            "3952/4708 - The training loss at 29th epoch : 0.07657364884003506  Training Accuracy:0.8976814516129032\n",
            "3968/4708 - The training loss at 29th epoch : 0.07630099545712395  Training Accuracy:0.8980923694779116\n",
            "3984/4708 - The training loss at 29th epoch : 0.07621399516981066  Training Accuracy:0.89825\n",
            "4000/4708 - The training loss at 29th epoch : 0.07599015878857496  Training Accuracy:0.8986553784860558\n",
            "4016/4708 - The training loss at 29th epoch : 0.07581544165927917  Training Accuracy:0.8988095238095238\n",
            "4032/4708 - The training loss at 29th epoch : 0.07559673449189742  Training Accuracy:0.8992094861660079\n",
            "4048/4708 - The training loss at 29th epoch : 0.07546358188081904  Training Accuracy:0.8993602362204725\n",
            "4064/4708 - The training loss at 29th epoch : 0.07536169580649067  Training Accuracy:0.8995098039215687\n",
            "4080/4708 - The training loss at 29th epoch : 0.07517312216925168  Training Accuracy:0.89990234375\n",
            "4096/4708 - The training loss at 29th epoch : 0.07534214115882253  Training Accuracy:0.8995622568093385\n",
            "4112/4708 - The training loss at 29th epoch : 0.0750726107996011  Training Accuracy:0.8999515503875969\n",
            "4128/4708 - The training loss at 29th epoch : 0.07503111583455244  Training Accuracy:0.8998552123552124\n",
            "4144/4708 - The training loss at 29th epoch : 0.07494209411243251  Training Accuracy:0.9\n",
            "4160/4708 - The training loss at 29th epoch : 0.07502570106289178  Training Accuracy:0.8996647509578544\n",
            "4176/4708 - The training loss at 29th epoch : 0.07483937876766379  Training Accuracy:0.9000477099236641\n",
            "4192/4708 - The training loss at 29th epoch : 0.07474548225251466  Training Accuracy:0.9001901140684411\n",
            "4208/4708 - The training loss at 29th epoch : 0.0745207475424535  Training Accuracy:0.9005681818181818\n",
            "4224/4708 - The training loss at 29th epoch : 0.07464189718086336  Training Accuracy:0.9004716981132076\n",
            "4240/4708 - The training loss at 29th epoch : 0.0745773597300305  Training Accuracy:0.9006109022556391\n",
            "4256/4708 - The training loss at 29th epoch : 0.07529904203606286  Training Accuracy:0.8995786516853933\n",
            "4272/4708 - The training loss at 29th epoch : 0.0753722044732963  Training Accuracy:0.8992537313432836\n",
            "4288/4708 - The training loss at 29th epoch : 0.0753139446917326  Training Accuracy:0.8993959107806692\n",
            "4304/4708 - The training loss at 29th epoch : 0.07534245951837377  Training Accuracy:0.899537037037037\n",
            "4320/4708 - The training loss at 29th epoch : 0.07513253880015675  Training Accuracy:0.8999077490774908\n",
            "4336/4708 - The training loss at 29th epoch : 0.07496856326631562  Training Accuracy:0.9000459558823529\n",
            "4352/4708 - The training loss at 29th epoch : 0.07504123043099178  Training Accuracy:0.899496336996337\n",
            "4368/4708 - The training loss at 29th epoch : 0.07513036170414282  Training Accuracy:0.8994069343065694\n",
            "4384/4708 - The training loss at 29th epoch : 0.07490694662733473  Training Accuracy:0.8997727272727273\n",
            "4400/4708 - The training loss at 29th epoch : 0.0749702764543519  Training Accuracy:0.8996829710144928\n",
            "4416/4708 - The training loss at 29th epoch : 0.07485742813256756  Training Accuracy:0.9000451263537906\n",
            "4432/4708 - The training loss at 29th epoch : 0.07468639151975066  Training Accuracy:0.9004046762589928\n",
            "4448/4708 - The training loss at 29th epoch : 0.07473675752555589  Training Accuracy:0.9003136200716846\n",
            "4464/4708 - The training loss at 29th epoch : 0.07466735356786824  Training Accuracy:0.9004464285714285\n",
            "4480/4708 - The training loss at 29th epoch : 0.0746533580334304  Training Accuracy:0.9005782918149466\n",
            "4496/4708 - The training loss at 29th epoch : 0.07499546731429929  Training Accuracy:0.9002659574468085\n",
            "4512/4708 - The training loss at 29th epoch : 0.07493545497522225  Training Accuracy:0.9003975265017667\n",
            "4528/4708 - The training loss at 29th epoch : 0.07470810935874672  Training Accuracy:0.9007482394366197\n",
            "4544/4708 - The training loss at 29th epoch : 0.07468156050773904  Training Accuracy:0.9006578947368421\n",
            "4560/4708 - The training loss at 29th epoch : 0.07468609736448768  Training Accuracy:0.9005681818181818\n",
            "4576/4708 - The training loss at 29th epoch : 0.07474443342813643  Training Accuracy:0.9002613240418118\n",
            "4592/4708 - The training loss at 29th epoch : 0.0748316368952228  Training Accuracy:0.9001736111111112\n",
            "4608/4708 - The training loss at 29th epoch : 0.07490217942156085  Training Accuracy:0.9000865051903114\n",
            "4624/4708 - The training loss at 29th epoch : 0.07496062638548798  Training Accuracy:0.9\n",
            "4640/4708 - The training loss at 29th epoch : 0.07491796780833737  Training Accuracy:0.9001288659793815\n",
            "4656/4708 - The training loss at 29th epoch : 0.07508955871755206  Training Accuracy:0.8998287671232876\n",
            "4672/4708 - The training loss at 29th epoch : 0.07497242339841849  Training Accuracy:0.899957337883959\n",
            "4688/4708 - The training loss at 29th epoch : 0.07482230041464197  Training Accuracy:0.9002976190476191\n",
            "4704/4708 - The training loss at 29th epoch : 0.07475684484980133  Training Accuracy:0.9004237288135594\n",
            "4720/4708 - The training loss at 29th epoch : 0.0747523220957268  Training Accuracy:0.9005489864864865\n",
            "Training finished in 29 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**"
      ],
      "metadata": {
        "id": "FZ4aOlK2BK4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from IPython.display import display\n",
        "\n",
        "index = random.randint(0, len(test_dataset))\n",
        "\n",
        "x, y = test_dataset[index]\n",
        "display(x.resize((140, 140)))\n",
        "x = np.array(x)\n",
        "L = x.shape[0] * x.shape[1]\n",
        "x = x.reshape(1, L)/255.\n",
        "pred = model(x)\n",
        "\n",
        "pred = pred.squeeze(0)\n",
        "pred[pred>=0.5] = 1\n",
        "pred[pred<0.5] = 0\n",
        "print(\"Prediction: Pneumonia\" if pred[0] else \"Prediction: Healthy\")\n",
        "print(\"Ground Truth: Pneumonia\" if y[0] else \"Ground Truth: Healthy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "bkwd3i4_BKxB",
        "outputId": "e1d93a7a-73af-4421-8df9-232a55a273b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=140x140 at 0x7FA5EC3EDBD0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Pneumonia\n",
            "Ground Truth: Pneumonia\n"
          ]
        }
      ]
    }
  ]
}
