{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c3d743ef1c3c439f97db444c01127c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fe89ec665804812ade71109ca9f09b8",
              "IPY_MODEL_7ace22b369ce43288628f4479a630438",
              "IPY_MODEL_d521462c8d7d41b6b7b56b6a9a174e3c"
            ],
            "layout": "IPY_MODEL_2eda17160c9a4a139d256200ba585b38",
            "tabbable": null,
            "tooltip": null
          }
        },
        "7fe89ec665804812ade71109ca9f09b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e7de46244d2948fab46fa1dae07ffee3",
            "placeholder": "​",
            "style": "IPY_MODEL_868d040394f84d6baf849c878f211cdd",
            "tabbable": null,
            "tooltip": null,
            "value": "100%"
          }
        },
        "7ace22b369ce43288628f4479a630438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_428c27e3c4b04919a78bb5b4de18da4b",
            "max": 4170669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34d15d270a244267a78a33a0b42aa168",
            "tabbable": null,
            "tooltip": null,
            "value": 4170669
          }
        },
        "d521462c8d7d41b6b7b56b6a9a174e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_6c476675336b419d99ffcf038b89425f",
            "placeholder": "​",
            "style": "IPY_MODEL_4df94fd0e90b44e49592104b2a440760",
            "tabbable": null,
            "tooltip": null,
            "value": " 4170669/4170669 [00:03&lt;00:00, 1619623.47it/s]"
          }
        },
        "2eda17160c9a4a139d256200ba585b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7de46244d2948fab46fa1dae07ffee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868d040394f84d6baf849c878f211cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "428c27e3c4b04919a78bb5b4de18da4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34d15d270a244267a78a33a0b42aa168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c476675336b419d99ffcf038b89425f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df94fd0e90b44e49592104b2a440760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reshalfahsi/neuralnetwork/blob/main/notebook/NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Package**"
      ],
      "metadata": {
        "id": "UZ6VNZ_J8985"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjSHb5zz80lj"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/reshalfahsi/neuralnetwork\n",
        "%cd neuralnetwork\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hyperparameters**"
      ],
      "metadata": {
        "id": "X48H-uAIA5zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 16\n",
        "lr = 1e-4"
      ],
      "metadata": {
        "id": "_bppSEPgA5EV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Preparation**"
      ],
      "metadata": {
        "id": "lUMo0jOu-2Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neuralnetwork.ds.medmnist import PneumoniaMNIST\n",
        "from neuralnetwork import ds\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "train_dataset = PneumoniaMNIST(split='train', download=True)\n",
        "test_dataset = PneumoniaMNIST(split='test', download=True)\n",
        "\n",
        "print(\"Train Dataset:\", len(train_dataset))\n",
        "print(\"Test Dataset\", len(test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "c3d743ef1c3c439f97db444c01127c36",
            "7fe89ec665804812ade71109ca9f09b8",
            "7ace22b369ce43288628f4479a630438",
            "d521462c8d7d41b6b7b56b6a9a174e3c",
            "2eda17160c9a4a139d256200ba585b38",
            "e7de46244d2948fab46fa1dae07ffee3",
            "868d040394f84d6baf849c878f211cdd",
            "428c27e3c4b04919a78bb5b4de18da4b",
            "34d15d270a244267a78a33a0b42aa168",
            "6c476675336b419d99ffcf038b89425f",
            "4df94fd0e90b44e49592104b2a440760"
          ]
        },
        "id": "tiUOUneg--hw",
        "outputId": "b22b795b-49f1-4899-cbd4-1b79e9d0438c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1 to /root/.medmnist/pneumoniamnist.npz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4170669 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3d743ef1c3c439f97db444c01127c36"
            },
            "application/json": {
              "n": 0,
              "total": 4170669,
              "elapsed": 0.04892230033874512,
              "ncols": null,
              "nrows": null,
              "prefix": "",
              "ascii": false,
              "unit": "it",
              "unit_scale": false,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1000,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n",
            "Train Dataset: 4708\n",
            "Test Dataset 624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.montage(length=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "1iQt-dlo_077",
        "outputId": "fa7d0408-d0ee-42ee-bb6e-8f970373d610"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=560x560 at 0x7F5F5CF8B1D0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Neural Network**"
      ],
      "metadata": {
        "id": "FSEI2KQ993k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import neuralnetwork.nn as nn\n",
        "\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NeuralNetwork, self).__init__(**kwargs)\n",
        "        self.linear0 = nn.Linear(784, 200, **kwargs)\n",
        "        self.linear1 = nn.Linear(200, 200, **kwargs)\n",
        "        self.linear2 = nn.Linear(200, 1, **kwargs)\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.out0 = self.linear0(x)\n",
        "        self.out1 = self.sigmoid(self.out0)\n",
        "        self.out2 = self.linear1(self.out1)\n",
        "        self.out3 = self.sigmoid(self.out2)\n",
        "        self.out4 = self.linear2(self.out3)\n",
        "        self.out5 = self.sigmoid(self.out4)\n",
        "\n",
        "        return self.out5\n",
        "    \n",
        "    def backward(self, lr, criterion):\n",
        "                                                               # Computational Graph\n",
        "                                                               #\n",
        "        self.dx0 = criterion.grad()                            # loss_grad(pred, y)\n",
        "                                                               #        |\n",
        "        self.dx1 = self.sigmoid.grad(self.out4)                # sigmoid_grad(pred)\n",
        "                                                               #        |\n",
        "                                                               #        +\n",
        "                                                               #       / \\\n",
        "                                                               #      |   |\n",
        "                                                               #  b_grad  *\n",
        "                                                               #         / \\\n",
        "                                                               #        |   |\n",
        "        self.dx2 = self.linear2.grad(grad=self.dx1* self.dx0)  #   A_grad   x_grad\n",
        "                                                               #          .\n",
        "        self.dx3 = self.sigmoid.grad(self.out2)                #          .\n",
        "        self.dx4 = self.linear1.grad(grad=self.dx3 * self.dx2) #          .\n",
        "\n",
        "        self.dx5 = self.sigmoid.grad(self.out0)\n",
        "        self.dx6 = self.linear0.grad(grad=self.dx5 * self.dx4)\n",
        "\n",
        "        self.linear0.update(lr)\n",
        "        self.linear1.update(lr)\n",
        "        self.linear2.update(lr)"
      ],
      "metadata": {
        "id": "0VOnz0yN93uN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "yfMDdyfU_wnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, X, Y):\n",
        "    pred = model(X)\n",
        "    pred = pred > 0.5\n",
        "    acc = np.sum(pred == Y)\n",
        "    acc = acc / Y.shape[0]\n",
        "    return acc"
      ],
      "metadata": {
        "id": "_4HIPhzvAuOd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = ds.get_loader(dataset=train_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = ds.get_loader(dataset=test_dataset, batch_size=1)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "zsnJzsLK_wsL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    loss = list()\n",
        "    acc = list()\n",
        "    for idx, pack in enumerate(train_loader):\n",
        "        x, y = pack\n",
        "        bs = x.shape[0]\n",
        "        L = x.shape[1] * x.shape[2]\n",
        "        x = x.reshape(bs, L) / 255.0\n",
        "        pred = model(x)\n",
        "        loss.append(criterion(pred, y))\n",
        "        model.backward(lr, criterion)\n",
        "        acc.append(accuracy(model, x, y))\n",
        "        print(\n",
        "            \"{}/{} - The training loss at {}th epoch : {}  Training Accuracy:{}\".format(\n",
        "                idx * BATCH_SIZE,\n",
        "                len(train_dataset),\n",
        "                epoch,\n",
        "                np.array(loss).mean(),\n",
        "                np.array(acc).mean(),\n",
        "            ),\n",
        "        )\n",
        "        if idx > int(len(train_dataset) / BATCH_SIZE):\n",
        "            break\n",
        "\n",
        "    if np.array(acc).mean() > 0.9:\n",
        "        break\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "print(\"Training finished in {} epochs\".format(epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-47tVltQAzL6",
        "outputId": "9fac394f-105e-4844-a82c-fdd6fbc3c205"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "784/4708 - The training loss at 20th epoch : 0.08852974168176729  Training Accuracy:0.8875\n",
            "800/4708 - The training loss at 20th epoch : 0.08704848321059969  Training Accuracy:0.8897058823529411\n",
            "816/4708 - The training loss at 20th epoch : 0.0867527384862418  Training Accuracy:0.890625\n",
            "832/4708 - The training loss at 20th epoch : 0.08520498920727318  Training Accuracy:0.8926886792452831\n",
            "848/4708 - The training loss at 20th epoch : 0.08413767832606424  Training Accuracy:0.8935185185185185\n",
            "864/4708 - The training loss at 20th epoch : 0.08388258697997715  Training Accuracy:0.8931818181818182\n",
            "880/4708 - The training loss at 20th epoch : 0.08476137077753242  Training Accuracy:0.8917410714285714\n",
            "896/4708 - The training loss at 20th epoch : 0.08414224285438038  Training Accuracy:0.8925438596491229\n",
            "912/4708 - The training loss at 20th epoch : 0.08555352750042604  Training Accuracy:0.8900862068965517\n",
            "928/4708 - The training loss at 20th epoch : 0.08419691311500888  Training Accuracy:0.8919491525423728\n",
            "944/4708 - The training loss at 20th epoch : 0.08350780552394323  Training Accuracy:0.8927083333333333\n",
            "960/4708 - The training loss at 20th epoch : 0.08345919337737545  Training Accuracy:0.8924180327868853\n",
            "976/4708 - The training loss at 20th epoch : 0.08407516583435592  Training Accuracy:0.8921370967741935\n",
            "992/4708 - The training loss at 20th epoch : 0.08457798668386854  Training Accuracy:0.8918650793650794\n",
            "1008/4708 - The training loss at 20th epoch : 0.08551058019607298  Training Accuracy:0.890625\n",
            "1024/4708 - The training loss at 20th epoch : 0.08648823307661754  Training Accuracy:0.8903846153846153\n",
            "1040/4708 - The training loss at 20th epoch : 0.08598888829736888  Training Accuracy:0.8910984848484849\n",
            "1056/4708 - The training loss at 20th epoch : 0.08572202176134126  Training Accuracy:0.8917910447761194\n",
            "1072/4708 - The training loss at 20th epoch : 0.08630386249979678  Training Accuracy:0.8915441176470589\n",
            "1088/4708 - The training loss at 20th epoch : 0.08760397348228302  Training Accuracy:0.8894927536231884\n",
            "1104/4708 - The training loss at 20th epoch : 0.08709490741109656  Training Accuracy:0.8901785714285714\n",
            "1120/4708 - The training loss at 20th epoch : 0.08727415726132336  Training Accuracy:0.8899647887323944\n",
            "1136/4708 - The training loss at 20th epoch : 0.08766849473360777  Training Accuracy:0.8888888888888888\n",
            "1152/4708 - The training loss at 20th epoch : 0.08798771116203008  Training Accuracy:0.8878424657534246\n",
            "1168/4708 - The training loss at 20th epoch : 0.088675057296197  Training Accuracy:0.8859797297297297\n",
            "1184/4708 - The training loss at 20th epoch : 0.08914915265921962  Training Accuracy:0.8858333333333334\n",
            "1200/4708 - The training loss at 20th epoch : 0.08858382260950988  Training Accuracy:0.8865131578947368\n",
            "1216/4708 - The training loss at 20th epoch : 0.08808464150202677  Training Accuracy:0.8863636363636364\n",
            "1232/4708 - The training loss at 20th epoch : 0.08896951145934814  Training Accuracy:0.8854166666666666\n",
            "1248/4708 - The training loss at 20th epoch : 0.08898518771252238  Training Accuracy:0.8860759493670886\n",
            "1264/4708 - The training loss at 20th epoch : 0.08936779053614766  Training Accuracy:0.8859375\n",
            "1280/4708 - The training loss at 20th epoch : 0.09011201913507638  Training Accuracy:0.8834876543209876\n",
            "1296/4708 - The training loss at 20th epoch : 0.08951176236251795  Training Accuracy:0.8841463414634146\n",
            "1312/4708 - The training loss at 20th epoch : 0.08959420208431738  Training Accuracy:0.8840361445783133\n",
            "1328/4708 - The training loss at 20th epoch : 0.08911463750779325  Training Accuracy:0.8846726190476191\n",
            "1344/4708 - The training loss at 20th epoch : 0.09031444005242631  Training Accuracy:0.8830882352941176\n",
            "1360/4708 - The training loss at 20th epoch : 0.09022151177712061  Training Accuracy:0.8837209302325582\n",
            "1376/4708 - The training loss at 20th epoch : 0.08985223808374714  Training Accuracy:0.8843390804597702\n",
            "1392/4708 - The training loss at 20th epoch : 0.0895976418915719  Training Accuracy:0.8849431818181818\n",
            "1408/4708 - The training loss at 20th epoch : 0.0893596661133646  Training Accuracy:0.8855337078651685\n",
            "1424/4708 - The training loss at 20th epoch : 0.08944784262926159  Training Accuracy:0.8847222222222222\n",
            "1440/4708 - The training loss at 20th epoch : 0.09010442510723622  Training Accuracy:0.8839285714285714\n",
            "1456/4708 - The training loss at 20th epoch : 0.09022752044173278  Training Accuracy:0.8838315217391305\n",
            "1472/4708 - The training loss at 20th epoch : 0.08933691957726593  Training Accuracy:0.8850806451612904\n",
            "1488/4708 - The training loss at 20th epoch : 0.08884933556546841  Training Accuracy:0.8856382978723404\n",
            "1504/4708 - The training loss at 20th epoch : 0.08846598045287633  Training Accuracy:0.8861842105263158\n",
            "1520/4708 - The training loss at 20th epoch : 0.08826384714039642  Training Accuracy:0.8860677083333334\n",
            "1536/4708 - The training loss at 20th epoch : 0.08794905665644917  Training Accuracy:0.8859536082474226\n",
            "1552/4708 - The training loss at 20th epoch : 0.08931432372028492  Training Accuracy:0.8839285714285714\n",
            "1568/4708 - The training loss at 20th epoch : 0.0894908626160607  Training Accuracy:0.8838383838383839\n",
            "1584/4708 - The training loss at 20th epoch : 0.08937744486055665  Training Accuracy:0.884375\n",
            "1600/4708 - The training loss at 20th epoch : 0.0894283476202189  Training Accuracy:0.8842821782178217\n",
            "1616/4708 - The training loss at 20th epoch : 0.08943526895818733  Training Accuracy:0.883578431372549\n",
            "1632/4708 - The training loss at 20th epoch : 0.0889587255318137  Training Accuracy:0.8841019417475728\n",
            "1648/4708 - The training loss at 20th epoch : 0.0882141901368878  Training Accuracy:0.8852163461538461\n",
            "1664/4708 - The training loss at 20th epoch : 0.08791459900390365  Training Accuracy:0.8857142857142857\n",
            "1680/4708 - The training loss at 20th epoch : 0.08892142343851159  Training Accuracy:0.8844339622641509\n",
            "1696/4708 - The training loss at 20th epoch : 0.08947350232566026  Training Accuracy:0.8837616822429907\n",
            "1712/4708 - The training loss at 20th epoch : 0.08902681848464196  Training Accuracy:0.8842592592592593\n",
            "1728/4708 - The training loss at 20th epoch : 0.08879288385236918  Training Accuracy:0.8847477064220184\n",
            "1744/4708 - The training loss at 20th epoch : 0.08880836132490424  Training Accuracy:0.8846590909090909\n",
            "1760/4708 - The training loss at 20th epoch : 0.08947241650940954  Training Accuracy:0.884009009009009\n",
            "1776/4708 - The training loss at 20th epoch : 0.08885608759559048  Training Accuracy:0.8850446428571429\n",
            "1792/4708 - The training loss at 20th epoch : 0.08914040559177135  Training Accuracy:0.8844026548672567\n",
            "1808/4708 - The training loss at 20th epoch : 0.08905366861639245  Training Accuracy:0.8848684210526315\n",
            "1824/4708 - The training loss at 20th epoch : 0.08954386150020886  Training Accuracy:0.8842391304347826\n",
            "1840/4708 - The training loss at 20th epoch : 0.09045746415289102  Training Accuracy:0.8825431034482759\n",
            "1856/4708 - The training loss at 20th epoch : 0.09035948207459615  Training Accuracy:0.8824786324786325\n",
            "1872/4708 - The training loss at 20th epoch : 0.0906953768993378  Training Accuracy:0.8813559322033898\n",
            "1888/4708 - The training loss at 20th epoch : 0.09074304095963796  Training Accuracy:0.8813025210084033\n",
            "1904/4708 - The training loss at 20th epoch : 0.09097439901366089  Training Accuracy:0.88125\n",
            "1920/4708 - The training loss at 20th epoch : 0.09068369804638994  Training Accuracy:0.8822314049586777\n",
            "1936/4708 - The training loss at 20th epoch : 0.09134562711358629  Training Accuracy:0.8816598360655737\n",
            "1952/4708 - The training loss at 20th epoch : 0.0923161242638527  Training Accuracy:0.880589430894309\n",
            "1968/4708 - The training loss at 20th epoch : 0.0922375551166622  Training Accuracy:0.8805443548387096\n",
            "1984/4708 - The training loss at 20th epoch : 0.09210048115114433  Training Accuracy:0.881\n",
            "2000/4708 - The training loss at 20th epoch : 0.09219471057182452  Training Accuracy:0.8809523809523809\n",
            "2016/4708 - The training loss at 20th epoch : 0.09199838989686893  Training Accuracy:0.8804133858267716\n",
            "2032/4708 - The training loss at 20th epoch : 0.0923964938259196  Training Accuracy:0.87939453125\n",
            "2048/4708 - The training loss at 20th epoch : 0.09318828944044975  Training Accuracy:0.8783914728682171\n",
            "2064/4708 - The training loss at 20th epoch : 0.09310770859485988  Training Accuracy:0.8788461538461538\n",
            "2080/4708 - The training loss at 20th epoch : 0.09278088440191823  Training Accuracy:0.879293893129771\n",
            "2096/4708 - The training loss at 20th epoch : 0.09232025519480212  Training Accuracy:0.8797348484848485\n",
            "2112/4708 - The training loss at 20th epoch : 0.09258026235349773  Training Accuracy:0.8787593984962406\n",
            "2128/4708 - The training loss at 20th epoch : 0.09194002034076447  Training Accuracy:0.8796641791044776\n",
            "2144/4708 - The training loss at 20th epoch : 0.09223813506329166  Training Accuracy:0.8791666666666667\n",
            "2160/4708 - The training loss at 20th epoch : 0.09233474704800347  Training Accuracy:0.8791360294117647\n",
            "2176/4708 - The training loss at 20th epoch : 0.09266382602336169  Training Accuracy:0.8786496350364964\n",
            "2192/4708 - The training loss at 20th epoch : 0.09295189063236528  Training Accuracy:0.8786231884057971\n",
            "2208/4708 - The training loss at 20th epoch : 0.0928859415990206  Training Accuracy:0.8785971223021583\n",
            "2224/4708 - The training loss at 20th epoch : 0.09251174417381307  Training Accuracy:0.8794642857142857\n",
            "2240/4708 - The training loss at 20th epoch : 0.09268894773455336  Training Accuracy:0.8798758865248227\n",
            "2256/4708 - The training loss at 20th epoch : 0.09295070172397307  Training Accuracy:0.8798415492957746\n",
            "2272/4708 - The training loss at 20th epoch : 0.0936591500374004  Training Accuracy:0.8789335664335665\n",
            "2288/4708 - The training loss at 20th epoch : 0.09341738050745489  Training Accuracy:0.8793402777777778\n",
            "2304/4708 - The training loss at 20th epoch : 0.09292203219744116  Training Accuracy:0.8801724137931034\n",
            "2320/4708 - The training loss at 20th epoch : 0.09319240761196045  Training Accuracy:0.8801369863013698\n",
            "2336/4708 - The training loss at 20th epoch : 0.0929915948593717  Training Accuracy:0.8801020408163265\n",
            "2352/4708 - The training loss at 20th epoch : 0.092602371767759  Training Accuracy:0.8804898648648649\n",
            "2368/4708 - The training loss at 20th epoch : 0.09229326459145432  Training Accuracy:0.8808724832214765\n",
            "2384/4708 - The training loss at 20th epoch : 0.0924615891786861  Training Accuracy:0.8808333333333334\n",
            "2400/4708 - The training loss at 20th epoch : 0.09293110614137357  Training Accuracy:0.8803807947019867\n",
            "2416/4708 - The training loss at 20th epoch : 0.09262653367582974  Training Accuracy:0.8807565789473685\n",
            "2432/4708 - The training loss at 20th epoch : 0.09279534635306175  Training Accuracy:0.880718954248366\n",
            "2448/4708 - The training loss at 20th epoch : 0.0928209160422821  Training Accuracy:0.880275974025974\n",
            "2464/4708 - The training loss at 20th epoch : 0.0928138741195073  Training Accuracy:0.8798387096774194\n",
            "2480/4708 - The training loss at 20th epoch : 0.0928574488991788  Training Accuracy:0.8798076923076923\n",
            "2496/4708 - The training loss at 20th epoch : 0.0930589692294864  Training Accuracy:0.8793789808917197\n",
            "2512/4708 - The training loss at 20th epoch : 0.09275295945665922  Training Accuracy:0.879746835443038\n",
            "2528/4708 - The training loss at 20th epoch : 0.09262425296778046  Training Accuracy:0.8801100628930818\n",
            "2544/4708 - The training loss at 20th epoch : 0.09243668957508797  Training Accuracy:0.88046875\n",
            "2560/4708 - The training loss at 20th epoch : 0.09190367960813775  Training Accuracy:0.8812111801242236\n",
            "2576/4708 - The training loss at 20th epoch : 0.09183951602219435  Training Accuracy:0.8811728395061729\n",
            "2592/4708 - The training loss at 20th epoch : 0.09187857723408839  Training Accuracy:0.8811349693251533\n",
            "2608/4708 - The training loss at 20th epoch : 0.0922687336450692  Training Accuracy:0.8807164634146342\n",
            "2624/4708 - The training loss at 20th epoch : 0.09263777766271163  Training Accuracy:0.8803030303030303\n",
            "2640/4708 - The training loss at 20th epoch : 0.09210623041380657  Training Accuracy:0.8810240963855421\n",
            "2656/4708 - The training loss at 20th epoch : 0.09180894537361288  Training Accuracy:0.8813622754491018\n",
            "2672/4708 - The training loss at 20th epoch : 0.09208870055726995  Training Accuracy:0.8809523809523809\n",
            "2688/4708 - The training loss at 20th epoch : 0.09253793168828872  Training Accuracy:0.8801775147928994\n",
            "2704/4708 - The training loss at 20th epoch : 0.09206784343084878  Training Accuracy:0.8808823529411764\n",
            "2720/4708 - The training loss at 20th epoch : 0.09204206200048734  Training Accuracy:0.8808479532163743\n",
            "2736/4708 - The training loss at 20th epoch : 0.09207677273009271  Training Accuracy:0.8808139534883721\n",
            "2752/4708 - The training loss at 20th epoch : 0.09213340513636477  Training Accuracy:0.8804190751445087\n",
            "2768/4708 - The training loss at 20th epoch : 0.09263679871080546  Training Accuracy:0.8796695402298851\n",
            "2784/4708 - The training loss at 20th epoch : 0.09248348424565482  Training Accuracy:0.88\n",
            "2800/4708 - The training loss at 20th epoch : 0.09218300572445096  Training Accuracy:0.8803267045454546\n",
            "2816/4708 - The training loss at 20th epoch : 0.09220372190082882  Training Accuracy:0.8799435028248588\n",
            "2832/4708 - The training loss at 20th epoch : 0.09202042907342892  Training Accuracy:0.8802668539325843\n",
            "2848/4708 - The training loss at 20th epoch : 0.09261700335244634  Training Accuracy:0.8795391061452514\n",
            "2864/4708 - The training loss at 20th epoch : 0.092159911568022  Training Accuracy:0.8802083333333334\n",
            "2880/4708 - The training loss at 20th epoch : 0.09216528967103141  Training Accuracy:0.8801795580110497\n",
            "2896/4708 - The training loss at 20th epoch : 0.09211691973194991  Training Accuracy:0.8804945054945055\n",
            "2912/4708 - The training loss at 20th epoch : 0.09175928539592461  Training Accuracy:0.8811475409836066\n",
            "2928/4708 - The training loss at 20th epoch : 0.09195672033560295  Training Accuracy:0.8807744565217391\n",
            "2944/4708 - The training loss at 20th epoch : 0.09218675647323134  Training Accuracy:0.8807432432432433\n",
            "2960/4708 - The training loss at 20th epoch : 0.09210130176657988  Training Accuracy:0.8810483870967742\n",
            "2976/4708 - The training loss at 20th epoch : 0.09176095505587314  Training Accuracy:0.8816844919786097\n",
            "2992/4708 - The training loss at 20th epoch : 0.09238616448916455  Training Accuracy:0.8809840425531915\n",
            "3008/4708 - The training loss at 20th epoch : 0.09198771025447929  Training Accuracy:0.8816137566137566\n",
            "3024/4708 - The training loss at 20th epoch : 0.0917085891154193  Training Accuracy:0.8819078947368421\n",
            "3040/4708 - The training loss at 20th epoch : 0.09151160818946871  Training Accuracy:0.881871727748691\n",
            "3056/4708 - The training loss at 20th epoch : 0.09147080149352797  Training Accuracy:0.8815104166666666\n",
            "3072/4708 - The training loss at 20th epoch : 0.09156225749684452  Training Accuracy:0.8814766839378239\n",
            "3088/4708 - The training loss at 20th epoch : 0.09134963462663456  Training Accuracy:0.8817654639175257\n",
            "3104/4708 - The training loss at 20th epoch : 0.09151531277000967  Training Accuracy:0.8814102564102564\n",
            "3120/4708 - The training loss at 20th epoch : 0.09168414189923053  Training Accuracy:0.8810586734693877\n",
            "3136/4708 - The training loss at 20th epoch : 0.09226151770149214  Training Accuracy:0.8800761421319797\n",
            "3152/4708 - The training loss at 20th epoch : 0.09270993511542655  Training Accuracy:0.8791035353535354\n",
            "3168/4708 - The training loss at 20th epoch : 0.09263469784793094  Training Accuracy:0.8790829145728644\n",
            "3184/4708 - The training loss at 20th epoch : 0.0927613370305912  Training Accuracy:0.8790625\n",
            "3200/4708 - The training loss at 20th epoch : 0.09260831584848431  Training Accuracy:0.8793532338308457\n",
            "3216/4708 - The training loss at 20th epoch : 0.0923912558213875  Training Accuracy:0.8796410891089109\n",
            "3232/4708 - The training loss at 20th epoch : 0.09205008296302954  Training Accuracy:0.8802339901477833\n",
            "3248/4708 - The training loss at 20th epoch : 0.0921030366839222  Training Accuracy:0.8802083333333334\n",
            "3264/4708 - The training loss at 20th epoch : 0.09211532916377088  Training Accuracy:0.8801829268292682\n",
            "3280/4708 - The training loss at 20th epoch : 0.09212898773383212  Training Accuracy:0.8801577669902912\n",
            "3296/4708 - The training loss at 20th epoch : 0.0920948908008337  Training Accuracy:0.8798309178743962\n",
            "3312/4708 - The training loss at 20th epoch : 0.09203875750651758  Training Accuracy:0.8798076923076923\n",
            "3328/4708 - The training loss at 20th epoch : 0.09213027746510255  Training Accuracy:0.8794856459330144\n",
            "3344/4708 - The training loss at 20th epoch : 0.0926291581515586  Training Accuracy:0.8788690476190476\n",
            "3360/4708 - The training loss at 20th epoch : 0.09238212605715809  Training Accuracy:0.8791469194312796\n",
            "3376/4708 - The training loss at 20th epoch : 0.09202135628241623  Training Accuracy:0.8797169811320755\n",
            "3392/4708 - The training loss at 20th epoch : 0.09205299196796456  Training Accuracy:0.8796948356807511\n",
            "3408/4708 - The training loss at 20th epoch : 0.09213721279787244  Training Accuracy:0.8796728971962616\n",
            "3424/4708 - The training loss at 20th epoch : 0.09221718079246  Training Accuracy:0.8796511627906977\n",
            "3440/4708 - The training loss at 20th epoch : 0.09260222009794893  Training Accuracy:0.8793402777777778\n",
            "3456/4708 - The training loss at 20th epoch : 0.09238380235619333  Training Accuracy:0.8798963133640553\n",
            "3472/4708 - The training loss at 20th epoch : 0.09228466474626164  Training Accuracy:0.8798738532110092\n",
            "3488/4708 - The training loss at 20th epoch : 0.09255095310950819  Training Accuracy:0.8792808219178082\n",
            "3504/4708 - The training loss at 20th epoch : 0.09292879709494013  Training Accuracy:0.8786931818181818\n",
            "3520/4708 - The training loss at 20th epoch : 0.09298652304534268  Training Accuracy:0.8786764705882353\n",
            "3536/4708 - The training loss at 20th epoch : 0.0932575785647093  Training Accuracy:0.8780968468468469\n",
            "3552/4708 - The training loss at 20th epoch : 0.09349189546680674  Training Accuracy:0.8778026905829597\n",
            "3568/4708 - The training loss at 20th epoch : 0.09352602379660725  Training Accuracy:0.8775111607142857\n",
            "3584/4708 - The training loss at 20th epoch : 0.0934668798827013  Training Accuracy:0.8777777777777778\n",
            "3600/4708 - The training loss at 20th epoch : 0.09359942264942171  Training Accuracy:0.8777654867256637\n",
            "3616/4708 - The training loss at 20th epoch : 0.09353682439528321  Training Accuracy:0.8780286343612335\n",
            "3632/4708 - The training loss at 20th epoch : 0.09353793813116523  Training Accuracy:0.878015350877193\n",
            "3648/4708 - The training loss at 20th epoch : 0.09343931005297247  Training Accuracy:0.8780021834061136\n",
            "3664/4708 - The training loss at 20th epoch : 0.09321128310503944  Training Accuracy:0.8782608695652174\n",
            "3680/4708 - The training loss at 20th epoch : 0.09299919978126531  Training Accuracy:0.878517316017316\n",
            "3696/4708 - The training loss at 20th epoch : 0.09285992701444329  Training Accuracy:0.8785021551724138\n",
            "3712/4708 - The training loss at 20th epoch : 0.09261945671589526  Training Accuracy:0.878755364806867\n",
            "3728/4708 - The training loss at 20th epoch : 0.0927424501216953  Training Accuracy:0.8782051282051282\n",
            "3744/4708 - The training loss at 20th epoch : 0.09287516708836167  Training Accuracy:0.8781914893617021\n",
            "3760/4708 - The training loss at 20th epoch : 0.09300138077180957  Training Accuracy:0.878177966101695\n",
            "3776/4708 - The training loss at 20th epoch : 0.09336786864962764  Training Accuracy:0.8776371308016878\n",
            "3792/4708 - The training loss at 20th epoch : 0.09317015328099895  Training Accuracy:0.8778886554621849\n",
            "3808/4708 - The training loss at 20th epoch : 0.09299107057770642  Training Accuracy:0.8783995815899581\n",
            "3824/4708 - The training loss at 20th epoch : 0.09301048782309947  Training Accuracy:0.8783854166666667\n",
            "3840/4708 - The training loss at 20th epoch : 0.09278642129831527  Training Accuracy:0.8786307053941909\n",
            "3856/4708 - The training loss at 20th epoch : 0.09277726844175216  Training Accuracy:0.878099173553719\n",
            "3872/4708 - The training loss at 20th epoch : 0.09264559763173809  Training Accuracy:0.878343621399177\n",
            "3888/4708 - The training loss at 20th epoch : 0.09267498088609637  Training Accuracy:0.8783299180327869\n",
            "3904/4708 - The training loss at 20th epoch : 0.09255797691865733  Training Accuracy:0.8785714285714286\n",
            "3920/4708 - The training loss at 20th epoch : 0.09259122364752319  Training Accuracy:0.8785569105691057\n",
            "3936/4708 - The training loss at 20th epoch : 0.09357947051740631  Training Accuracy:0.8772773279352226\n",
            "3952/4708 - The training loss at 20th epoch : 0.09359760683244286  Training Accuracy:0.8770161290322581\n",
            "3968/4708 - The training loss at 20th epoch : 0.0938711739967454  Training Accuracy:0.8767570281124498\n",
            "3984/4708 - The training loss at 20th epoch : 0.0938454836777064  Training Accuracy:0.877\n",
            "4000/4708 - The training loss at 20th epoch : 0.09377837715154702  Training Accuracy:0.87699203187251\n",
            "4016/4708 - The training loss at 20th epoch : 0.09360904367528014  Training Accuracy:0.8774801587301587\n",
            "4032/4708 - The training loss at 20th epoch : 0.09379620875159864  Training Accuracy:0.8774703557312253\n",
            "4048/4708 - The training loss at 20th epoch : 0.09359291794218368  Training Accuracy:0.8777066929133859\n",
            "4064/4708 - The training loss at 20th epoch : 0.09337564045586787  Training Accuracy:0.8779411764705882\n",
            "4080/4708 - The training loss at 20th epoch : 0.09329083139102788  Training Accuracy:0.877685546875\n",
            "4096/4708 - The training loss at 20th epoch : 0.09339043770937407  Training Accuracy:0.877431906614786\n",
            "4112/4708 - The training loss at 20th epoch : 0.09332683643415737  Training Accuracy:0.8776647286821705\n",
            "4128/4708 - The training loss at 20th epoch : 0.09307656620848237  Training Accuracy:0.877895752895753\n",
            "4144/4708 - The training loss at 20th epoch : 0.09297208036081318  Training Accuracy:0.8778846153846154\n",
            "4160/4708 - The training loss at 20th epoch : 0.09286196955918856  Training Accuracy:0.8781130268199234\n",
            "4176/4708 - The training loss at 20th epoch : 0.0927180194034413  Training Accuracy:0.8781011450381679\n",
            "4192/4708 - The training loss at 20th epoch : 0.09268925420682513  Training Accuracy:0.8783269961977186\n",
            "4208/4708 - The training loss at 20th epoch : 0.09254837027164317  Training Accuracy:0.8783143939393939\n",
            "4224/4708 - The training loss at 20th epoch : 0.09240054834750294  Training Accuracy:0.8783018867924528\n",
            "4240/4708 - The training loss at 20th epoch : 0.09223878604610372  Training Accuracy:0.8785244360902256\n",
            "4256/4708 - The training loss at 20th epoch : 0.0922578211677796  Training Accuracy:0.8785112359550562\n",
            "4272/4708 - The training loss at 20th epoch : 0.09222126700710406  Training Accuracy:0.878731343283582\n",
            "4288/4708 - The training loss at 20th epoch : 0.09195872554626416  Training Accuracy:0.879182156133829\n",
            "4304/4708 - The training loss at 20th epoch : 0.09175943958197079  Training Accuracy:0.8793981481481481\n",
            "4320/4708 - The training loss at 20th epoch : 0.09222751825621459  Training Accuracy:0.878920664206642\n",
            "4336/4708 - The training loss at 20th epoch : 0.09211790855186086  Training Accuracy:0.8791360294117647\n",
            "4352/4708 - The training loss at 20th epoch : 0.09211217150429235  Training Accuracy:0.8791208791208791\n",
            "4368/4708 - The training loss at 20th epoch : 0.09239330221647771  Training Accuracy:0.8786496350364964\n",
            "4384/4708 - The training loss at 20th epoch : 0.09249264388777997  Training Accuracy:0.8786363636363637\n",
            "4400/4708 - The training loss at 20th epoch : 0.09289159823563732  Training Accuracy:0.8781702898550725\n",
            "4416/4708 - The training loss at 20th epoch : 0.0928498441306634  Training Accuracy:0.878158844765343\n",
            "4432/4708 - The training loss at 20th epoch : 0.09279856032028  Training Accuracy:0.8781474820143885\n",
            "4448/4708 - The training loss at 20th epoch : 0.09249936857792895  Training Accuracy:0.878584229390681\n",
            "4464/4708 - The training loss at 20th epoch : 0.09259077429806578  Training Accuracy:0.8783482142857143\n",
            "4480/4708 - The training loss at 20th epoch : 0.09246285403723765  Training Accuracy:0.87855871886121\n",
            "4496/4708 - The training loss at 20th epoch : 0.09220167256747103  Training Accuracy:0.8789893617021277\n",
            "4512/4708 - The training loss at 20th epoch : 0.09194129323997506  Training Accuracy:0.8794169611307421\n",
            "4528/4708 - The training loss at 20th epoch : 0.0918948972398768  Training Accuracy:0.8794014084507042\n",
            "4544/4708 - The training loss at 20th epoch : 0.09208734129680204  Training Accuracy:0.8791666666666667\n",
            "4560/4708 - The training loss at 20th epoch : 0.0923692548254725  Training Accuracy:0.8784965034965035\n",
            "4576/4708 - The training loss at 20th epoch : 0.09232377047486275  Training Accuracy:0.8784843205574913\n",
            "4592/4708 - The training loss at 20th epoch : 0.09230431250401112  Training Accuracy:0.8786892361111112\n",
            "4608/4708 - The training loss at 20th epoch : 0.09214036710373873  Training Accuracy:0.8788927335640139\n",
            "4624/4708 - The training loss at 20th epoch : 0.09193628285480746  Training Accuracy:0.8793103448275862\n",
            "4640/4708 - The training loss at 20th epoch : 0.09221252010873592  Training Accuracy:0.8786512027491409\n",
            "4656/4708 - The training loss at 20th epoch : 0.09231034247845565  Training Accuracy:0.878638698630137\n",
            "4672/4708 - The training loss at 20th epoch : 0.0921989150506315  Training Accuracy:0.8786262798634812\n",
            "4688/4708 - The training loss at 20th epoch : 0.09227677443514125  Training Accuracy:0.8784013605442177\n",
            "4704/4708 - The training loss at 20th epoch : 0.09220450549434302  Training Accuracy:0.8783898305084745\n",
            "4720/4708 - The training loss at 20th epoch : 0.09218574073269185  Training Accuracy:0.8783783783783784\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 21th epoch : 0.10160441905499853  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 21th epoch : 0.08583501714515461  Training Accuracy:0.90625\n",
            "32/4708 - The training loss at 21th epoch : 0.06509415181753758  Training Accuracy:0.9166666666666666\n",
            "48/4708 - The training loss at 21th epoch : 0.08012671861371774  Training Accuracy:0.890625\n",
            "64/4708 - The training loss at 21th epoch : 0.11368495284324553  Training Accuracy:0.85\n",
            "80/4708 - The training loss at 21th epoch : 0.09840502288041847  Training Accuracy:0.8645833333333334\n",
            "96/4708 - The training loss at 21th epoch : 0.10677668996866065  Training Accuracy:0.8482142857142857\n",
            "112/4708 - The training loss at 21th epoch : 0.11267235956883323  Training Accuracy:0.8359375\n",
            "128/4708 - The training loss at 21th epoch : 0.10591191177415542  Training Accuracy:0.8472222222222222\n",
            "144/4708 - The training loss at 21th epoch : 0.1029075647893561  Training Accuracy:0.85625\n",
            "160/4708 - The training loss at 21th epoch : 0.10768343317857208  Training Accuracy:0.8465909090909091\n",
            "176/4708 - The training loss at 21th epoch : 0.1058820049076666  Training Accuracy:0.8489583333333334\n",
            "192/4708 - The training loss at 21th epoch : 0.10180938612141235  Training Accuracy:0.8509615384615384\n",
            "208/4708 - The training loss at 21th epoch : 0.10421681555971388  Training Accuracy:0.84375\n",
            "224/4708 - The training loss at 21th epoch : 0.10426194669100688  Training Accuracy:0.8458333333333333\n",
            "240/4708 - The training loss at 21th epoch : 0.10472603817708917  Training Accuracy:0.84765625\n",
            "256/4708 - The training loss at 21th epoch : 0.10388462126503048  Training Accuracy:0.8492647058823529\n",
            "272/4708 - The training loss at 21th epoch : 0.10464643981497093  Training Accuracy:0.8506944444444444\n",
            "288/4708 - The training loss at 21th epoch : 0.1046480715255082  Training Accuracy:0.8486842105263158\n",
            "304/4708 - The training loss at 21th epoch : 0.10342891651881772  Training Accuracy:0.85\n",
            "320/4708 - The training loss at 21th epoch : 0.10120447159264594  Training Accuracy:0.8541666666666666\n",
            "336/4708 - The training loss at 21th epoch : 0.101634009487628  Training Accuracy:0.8551136363636364\n",
            "352/4708 - The training loss at 21th epoch : 0.09807754313962977  Training Accuracy:0.8614130434782609\n",
            "368/4708 - The training loss at 21th epoch : 0.09590503203390077  Training Accuracy:0.8645833333333334\n",
            "384/4708 - The training loss at 21th epoch : 0.09636337052563318  Training Accuracy:0.865\n",
            "400/4708 - The training loss at 21th epoch : 0.09380005642787254  Training Accuracy:0.8701923076923077\n",
            "416/4708 - The training loss at 21th epoch : 0.09828586131313709  Training Accuracy:0.8680555555555556\n",
            "432/4708 - The training loss at 21th epoch : 0.10115697636299215  Training Accuracy:0.8660714285714286\n",
            "448/4708 - The training loss at 21th epoch : 0.10040280992959977  Training Accuracy:0.8685344827586207\n",
            "464/4708 - The training loss at 21th epoch : 0.09825404580508225  Training Accuracy:0.8708333333333333\n",
            "480/4708 - The training loss at 21th epoch : 0.10407562380352386  Training Accuracy:0.8629032258064516\n",
            "496/4708 - The training loss at 21th epoch : 0.10606306046657278  Training Accuracy:0.859375\n",
            "512/4708 - The training loss at 21th epoch : 0.10643182309096326  Training Accuracy:0.8598484848484849\n",
            "528/4708 - The training loss at 21th epoch : 0.10559165940861766  Training Accuracy:0.8602941176470589\n",
            "544/4708 - The training loss at 21th epoch : 0.10503988556447554  Training Accuracy:0.8625\n",
            "560/4708 - The training loss at 21th epoch : 0.1033557085601435  Training Accuracy:0.8663194444444444\n",
            "576/4708 - The training loss at 21th epoch : 0.10365477311353617  Training Accuracy:0.8648648648648649\n",
            "592/4708 - The training loss at 21th epoch : 0.1028190620371078  Training Accuracy:0.8667763157894737\n",
            "608/4708 - The training loss at 21th epoch : 0.10406791501462252  Training Accuracy:0.8653846153846154\n",
            "624/4708 - The training loss at 21th epoch : 0.10365869366783127  Training Accuracy:0.865625\n",
            "640/4708 - The training loss at 21th epoch : 0.10311317632933563  Training Accuracy:0.8658536585365854\n",
            "656/4708 - The training loss at 21th epoch : 0.10274324093521783  Training Accuracy:0.8660714285714286\n",
            "672/4708 - The training loss at 21th epoch : 0.1007667996964304  Training Accuracy:0.8691860465116279\n",
            "688/4708 - The training loss at 21th epoch : 0.10066133286409201  Training Accuracy:0.8693181818181818\n",
            "704/4708 - The training loss at 21th epoch : 0.10184057042004395  Training Accuracy:0.8680555555555556\n",
            "720/4708 - The training loss at 21th epoch : 0.10187582178791539  Training Accuracy:0.8682065217391305\n",
            "736/4708 - The training loss at 21th epoch : 0.10259282814179363  Training Accuracy:0.8670212765957447\n",
            "752/4708 - The training loss at 21th epoch : 0.10180776331064466  Training Accuracy:0.8684895833333334\n",
            "768/4708 - The training loss at 21th epoch : 0.10072622652430942  Training Accuracy:0.8698979591836735\n",
            "784/4708 - The training loss at 21th epoch : 0.10293375339439294  Training Accuracy:0.865\n",
            "800/4708 - The training loss at 21th epoch : 0.10254573417985806  Training Accuracy:0.866421568627451\n",
            "816/4708 - The training loss at 21th epoch : 0.10220857331397712  Training Accuracy:0.8665865384615384\n",
            "832/4708 - The training loss at 21th epoch : 0.10201091699034445  Training Accuracy:0.8679245283018868\n",
            "848/4708 - The training loss at 21th epoch : 0.10184591886906752  Training Accuracy:0.8680555555555556\n",
            "864/4708 - The training loss at 21th epoch : 0.10207960660311069  Training Accuracy:0.8670454545454546\n",
            "880/4708 - The training loss at 21th epoch : 0.10210525117551092  Training Accuracy:0.8671875\n",
            "896/4708 - The training loss at 21th epoch : 0.10358578326875066  Training Accuracy:0.8640350877192983\n",
            "912/4708 - The training loss at 21th epoch : 0.10358696199770571  Training Accuracy:0.8642241379310345\n",
            "928/4708 - The training loss at 21th epoch : 0.10392121814162611  Training Accuracy:0.8633474576271186\n",
            "944/4708 - The training loss at 21th epoch : 0.10431352457589581  Training Accuracy:0.8635416666666667\n",
            "960/4708 - The training loss at 21th epoch : 0.10323104974237769  Training Accuracy:0.8647540983606558\n",
            "976/4708 - The training loss at 21th epoch : 0.10313263820980109  Training Accuracy:0.8639112903225806\n",
            "992/4708 - The training loss at 21th epoch : 0.10295376636918666  Training Accuracy:0.8640873015873016\n",
            "1008/4708 - The training loss at 21th epoch : 0.10379356296570132  Training Accuracy:0.86328125\n",
            "1024/4708 - The training loss at 21th epoch : 0.10333892037159795  Training Accuracy:0.864423076923077\n",
            "1040/4708 - The training loss at 21th epoch : 0.10369275511875284  Training Accuracy:0.8645833333333334\n",
            "1056/4708 - The training loss at 21th epoch : 0.10362807304971573  Training Accuracy:0.8647388059701493\n",
            "1072/4708 - The training loss at 21th epoch : 0.10361153334600356  Training Accuracy:0.8639705882352942\n",
            "1088/4708 - The training loss at 21th epoch : 0.10339725829786346  Training Accuracy:0.8632246376811594\n",
            "1104/4708 - The training loss at 21th epoch : 0.10221414721411284  Training Accuracy:0.8651785714285715\n",
            "1120/4708 - The training loss at 21th epoch : 0.10138750397299862  Training Accuracy:0.8661971830985915\n",
            "1136/4708 - The training loss at 21th epoch : 0.10168007616122415  Training Accuracy:0.8663194444444444\n",
            "1152/4708 - The training loss at 21th epoch : 0.10212889983050141  Training Accuracy:0.8647260273972602\n",
            "1168/4708 - The training loss at 21th epoch : 0.10242947418988782  Training Accuracy:0.8640202702702703\n",
            "1184/4708 - The training loss at 21th epoch : 0.10195759231566365  Training Accuracy:0.865\n",
            "1200/4708 - The training loss at 21th epoch : 0.10187058853784618  Training Accuracy:0.8651315789473685\n",
            "1216/4708 - The training loss at 21th epoch : 0.10146130947944648  Training Accuracy:0.8660714285714286\n",
            "1232/4708 - The training loss at 21th epoch : 0.10227790751850731  Training Accuracy:0.8653846153846154\n",
            "1248/4708 - The training loss at 21th epoch : 0.10186239488884784  Training Accuracy:0.8670886075949367\n",
            "1264/4708 - The training loss at 21th epoch : 0.101661717556216  Training Accuracy:0.8671875\n",
            "1280/4708 - The training loss at 21th epoch : 0.10186848681825743  Training Accuracy:0.8672839506172839\n",
            "1296/4708 - The training loss at 21th epoch : 0.1019389028780595  Training Accuracy:0.8666158536585366\n",
            "1312/4708 - The training loss at 21th epoch : 0.10181833201328652  Training Accuracy:0.8667168674698795\n",
            "1328/4708 - The training loss at 21th epoch : 0.10172279211304612  Training Accuracy:0.8660714285714286\n",
            "1344/4708 - The training loss at 21th epoch : 0.10139623823542815  Training Accuracy:0.8669117647058824\n",
            "1360/4708 - The training loss at 21th epoch : 0.1008762406134407  Training Accuracy:0.8670058139534884\n",
            "1376/4708 - The training loss at 21th epoch : 0.09980933967217709  Training Accuracy:0.8685344827586207\n",
            "1392/4708 - The training loss at 21th epoch : 0.09966958336572515  Training Accuracy:0.8693181818181818\n",
            "1408/4708 - The training loss at 21th epoch : 0.09887200876796952  Training Accuracy:0.8700842696629213\n",
            "1424/4708 - The training loss at 21th epoch : 0.09871249193627367  Training Accuracy:0.8701388888888889\n",
            "1440/4708 - The training loss at 21th epoch : 0.09776592572197096  Training Accuracy:0.8715659340659341\n",
            "1456/4708 - The training loss at 21th epoch : 0.09732413839470679  Training Accuracy:0.8722826086956522\n",
            "1472/4708 - The training loss at 21th epoch : 0.09745093783436741  Training Accuracy:0.8716397849462365\n",
            "1488/4708 - The training loss at 21th epoch : 0.09722951592121987  Training Accuracy:0.8723404255319149\n",
            "1504/4708 - The training loss at 21th epoch : 0.09736097221488815  Training Accuracy:0.8723684210526316\n",
            "1520/4708 - The training loss at 21th epoch : 0.09797557032112403  Training Accuracy:0.8717447916666666\n",
            "1536/4708 - The training loss at 21th epoch : 0.09733120016246585  Training Accuracy:0.8724226804123711\n",
            "1552/4708 - The training loss at 21th epoch : 0.09761674670348029  Training Accuracy:0.8718112244897959\n",
            "1568/4708 - The training loss at 21th epoch : 0.09776391518686717  Training Accuracy:0.8718434343434344\n",
            "1584/4708 - The training loss at 21th epoch : 0.0979602187424123  Training Accuracy:0.871875\n",
            "1600/4708 - The training loss at 21th epoch : 0.09736390515519507  Training Accuracy:0.8725247524752475\n",
            "1616/4708 - The training loss at 21th epoch : 0.09728894688600605  Training Accuracy:0.8725490196078431\n",
            "1632/4708 - The training loss at 21th epoch : 0.0973173960158448  Training Accuracy:0.8719660194174758\n",
            "1648/4708 - The training loss at 21th epoch : 0.0967318946585597  Training Accuracy:0.8725961538461539\n",
            "1664/4708 - The training loss at 21th epoch : 0.09650492403009017  Training Accuracy:0.8732142857142857\n",
            "1680/4708 - The training loss at 21th epoch : 0.09580707435779191  Training Accuracy:0.8738207547169812\n",
            "1696/4708 - The training loss at 21th epoch : 0.09615443945034029  Training Accuracy:0.8738317757009346\n",
            "1712/4708 - The training loss at 21th epoch : 0.0973601112565845  Training Accuracy:0.8721064814814815\n",
            "1728/4708 - The training loss at 21th epoch : 0.09694310121097588  Training Accuracy:0.8721330275229358\n",
            "1744/4708 - The training loss at 21th epoch : 0.09618410038860672  Training Accuracy:0.8732954545454545\n",
            "1760/4708 - The training loss at 21th epoch : 0.09588958335131857  Training Accuracy:0.8733108108108109\n",
            "1776/4708 - The training loss at 21th epoch : 0.09612571545414972  Training Accuracy:0.8727678571428571\n",
            "1792/4708 - The training loss at 21th epoch : 0.09558421385157259  Training Accuracy:0.8733407079646017\n",
            "1808/4708 - The training loss at 21th epoch : 0.09599663567941642  Training Accuracy:0.8722587719298246\n",
            "1824/4708 - The training loss at 21th epoch : 0.09636209918855784  Training Accuracy:0.8717391304347826\n",
            "1840/4708 - The training loss at 21th epoch : 0.096094366826434  Training Accuracy:0.8723060344827587\n",
            "1856/4708 - The training loss at 21th epoch : 0.09691525203777654  Training Accuracy:0.8701923076923077\n",
            "1872/4708 - The training loss at 21th epoch : 0.0962457615943161  Training Accuracy:0.871292372881356\n",
            "1888/4708 - The training loss at 21th epoch : 0.09550075056353914  Training Accuracy:0.8723739495798319\n",
            "1904/4708 - The training loss at 21th epoch : 0.09562252830310063  Training Accuracy:0.871875\n",
            "1920/4708 - The training loss at 21th epoch : 0.09617920847820545  Training Accuracy:0.8708677685950413\n",
            "1936/4708 - The training loss at 21th epoch : 0.09573420125902417  Training Accuracy:0.8714139344262295\n",
            "1952/4708 - The training loss at 21th epoch : 0.09537135136960573  Training Accuracy:0.8719512195121951\n",
            "1968/4708 - The training loss at 21th epoch : 0.09673766932603821  Training Accuracy:0.8699596774193549\n",
            "1984/4708 - The training loss at 21th epoch : 0.09700094253619367  Training Accuracy:0.8695\n",
            "2000/4708 - The training loss at 21th epoch : 0.0964549555479119  Training Accuracy:0.8705357142857143\n",
            "2016/4708 - The training loss at 21th epoch : 0.09583198462581896  Training Accuracy:0.8715551181102362\n",
            "2032/4708 - The training loss at 21th epoch : 0.09549111365709834  Training Accuracy:0.87255859375\n",
            "2048/4708 - The training loss at 21th epoch : 0.09511221976912354  Training Accuracy:0.873062015503876\n",
            "2064/4708 - The training loss at 21th epoch : 0.09512978590705293  Training Accuracy:0.8730769230769231\n",
            "2080/4708 - The training loss at 21th epoch : 0.09531665193214929  Training Accuracy:0.8730916030534351\n",
            "2096/4708 - The training loss at 21th epoch : 0.09510207992539549  Training Accuracy:0.8735795454545454\n",
            "2112/4708 - The training loss at 21th epoch : 0.09497571975436686  Training Accuracy:0.8731203007518797\n",
            "2128/4708 - The training loss at 21th epoch : 0.09554282605872154  Training Accuracy:0.8726679104477612\n",
            "2144/4708 - The training loss at 21th epoch : 0.09537486259370327  Training Accuracy:0.8726851851851852\n",
            "2160/4708 - The training loss at 21th epoch : 0.09493742793241153  Training Accuracy:0.8731617647058824\n",
            "2176/4708 - The training loss at 21th epoch : 0.0946942011298781  Training Accuracy:0.8736313868613139\n",
            "2192/4708 - The training loss at 21th epoch : 0.09498111237914612  Training Accuracy:0.8731884057971014\n",
            "2208/4708 - The training loss at 21th epoch : 0.09486309701968752  Training Accuracy:0.8736510791366906\n",
            "2224/4708 - The training loss at 21th epoch : 0.09477947747952886  Training Accuracy:0.8741071428571429\n",
            "2240/4708 - The training loss at 21th epoch : 0.09462532930944902  Training Accuracy:0.8745567375886525\n",
            "2256/4708 - The training loss at 21th epoch : 0.09441343339419998  Training Accuracy:0.875\n",
            "2272/4708 - The training loss at 21th epoch : 0.09483028224181558  Training Accuracy:0.8745629370629371\n",
            "2288/4708 - The training loss at 21th epoch : 0.09434908928828573  Training Accuracy:0.8754340277777778\n",
            "2304/4708 - The training loss at 21th epoch : 0.09450595817340769  Training Accuracy:0.8754310344827586\n",
            "2320/4708 - The training loss at 21th epoch : 0.09465149860679638  Training Accuracy:0.8754280821917808\n",
            "2336/4708 - The training loss at 21th epoch : 0.09495071839953155  Training Accuracy:0.8745748299319728\n",
            "2352/4708 - The training loss at 21th epoch : 0.09503650916659016  Training Accuracy:0.8745777027027027\n",
            "2368/4708 - The training loss at 21th epoch : 0.09538142081391797  Training Accuracy:0.8745805369127517\n",
            "2384/4708 - The training loss at 21th epoch : 0.09553911767624397  Training Accuracy:0.8745833333333334\n",
            "2400/4708 - The training loss at 21th epoch : 0.09521272172015578  Training Accuracy:0.875\n",
            "2416/4708 - The training loss at 21th epoch : 0.09519498075035364  Training Accuracy:0.8745888157894737\n",
            "2432/4708 - The training loss at 21th epoch : 0.09499557138484716  Training Accuracy:0.875\n",
            "2448/4708 - The training loss at 21th epoch : 0.0951496432001428  Training Accuracy:0.8745941558441559\n",
            "2464/4708 - The training loss at 21th epoch : 0.09464511677310856  Training Accuracy:0.8754032258064516\n",
            "2480/4708 - The training loss at 21th epoch : 0.09412748175320813  Training Accuracy:0.8762019230769231\n",
            "2496/4708 - The training loss at 21th epoch : 0.09392597619026362  Training Accuracy:0.8765923566878981\n",
            "2512/4708 - The training loss at 21th epoch : 0.0941975235925915  Training Accuracy:0.8765822784810127\n",
            "2528/4708 - The training loss at 21th epoch : 0.09391326387213587  Training Accuracy:0.8765723270440252\n",
            "2544/4708 - The training loss at 21th epoch : 0.09420085898920445  Training Accuracy:0.876171875\n",
            "2560/4708 - The training loss at 21th epoch : 0.09434995272039173  Training Accuracy:0.8761645962732919\n",
            "2576/4708 - The training loss at 21th epoch : 0.09399922728787029  Training Accuracy:0.8765432098765432\n",
            "2592/4708 - The training loss at 21th epoch : 0.09425695559795068  Training Accuracy:0.8757668711656442\n",
            "2608/4708 - The training loss at 21th epoch : 0.09406448936270755  Training Accuracy:0.8761432926829268\n",
            "2624/4708 - The training loss at 21th epoch : 0.09399052964326446  Training Accuracy:0.8765151515151515\n",
            "2640/4708 - The training loss at 21th epoch : 0.09442681644728776  Training Accuracy:0.8757530120481928\n",
            "2656/4708 - The training loss at 21th epoch : 0.0948098585429783  Training Accuracy:0.875\n",
            "2672/4708 - The training loss at 21th epoch : 0.09492691853723427  Training Accuracy:0.8746279761904762\n",
            "2688/4708 - The training loss at 21th epoch : 0.09446879934478544  Training Accuracy:0.8753698224852071\n",
            "2704/4708 - The training loss at 21th epoch : 0.0941260544341394  Training Accuracy:0.8757352941176471\n",
            "2720/4708 - The training loss at 21th epoch : 0.09503429543286898  Training Accuracy:0.8742690058479532\n",
            "2736/4708 - The training loss at 21th epoch : 0.09539005678445724  Training Accuracy:0.8739098837209303\n",
            "2752/4708 - The training loss at 21th epoch : 0.0953633711904847  Training Accuracy:0.8739161849710982\n",
            "2768/4708 - The training loss at 21th epoch : 0.0948568071502197  Training Accuracy:0.8746408045977011\n",
            "2784/4708 - The training loss at 21th epoch : 0.09445609945258988  Training Accuracy:0.8753571428571428\n",
            "2800/4708 - The training loss at 21th epoch : 0.09425203562610975  Training Accuracy:0.8757102272727273\n",
            "2816/4708 - The training loss at 21th epoch : 0.09404040246778728  Training Accuracy:0.8760593220338984\n",
            "2832/4708 - The training loss at 21th epoch : 0.09417155124776368  Training Accuracy:0.8760533707865169\n",
            "2848/4708 - The training loss at 21th epoch : 0.09448562317727614  Training Accuracy:0.8753491620111732\n",
            "2864/4708 - The training loss at 21th epoch : 0.0942740102344399  Training Accuracy:0.8756944444444444\n",
            "2880/4708 - The training loss at 21th epoch : 0.0942298564286104  Training Accuracy:0.8756906077348067\n",
            "2896/4708 - The training loss at 21th epoch : 0.09443594351561692  Training Accuracy:0.8753434065934066\n",
            "2912/4708 - The training loss at 21th epoch : 0.09428356714624501  Training Accuracy:0.8756830601092896\n",
            "2928/4708 - The training loss at 21th epoch : 0.094538935362661  Training Accuracy:0.8756793478260869\n",
            "2944/4708 - The training loss at 21th epoch : 0.09421484430139206  Training Accuracy:0.8760135135135135\n",
            "2960/4708 - The training loss at 21th epoch : 0.09385386284297802  Training Accuracy:0.8766801075268817\n",
            "2976/4708 - The training loss at 21th epoch : 0.09380839931516113  Training Accuracy:0.8766711229946524\n",
            "2992/4708 - The training loss at 21th epoch : 0.09391508395800313  Training Accuracy:0.8766622340425532\n",
            "3008/4708 - The training loss at 21th epoch : 0.09373493254553249  Training Accuracy:0.876984126984127\n",
            "3024/4708 - The training loss at 21th epoch : 0.09355235222440197  Training Accuracy:0.8773026315789474\n",
            "3040/4708 - The training loss at 21th epoch : 0.09329345900623084  Training Accuracy:0.8776178010471204\n",
            "3056/4708 - The training loss at 21th epoch : 0.09301368450385604  Training Accuracy:0.8782552083333334\n",
            "3072/4708 - The training loss at 21th epoch : 0.09338298086814405  Training Accuracy:0.8772668393782384\n",
            "3088/4708 - The training loss at 21th epoch : 0.0939507869376598  Training Accuracy:0.8762886597938144\n",
            "3104/4708 - The training loss at 21th epoch : 0.09363923060501786  Training Accuracy:0.8766025641025641\n",
            "3120/4708 - The training loss at 21th epoch : 0.09407672681270736  Training Accuracy:0.8759566326530612\n",
            "3136/4708 - The training loss at 21th epoch : 0.09367536451179985  Training Accuracy:0.8765862944162437\n",
            "3152/4708 - The training loss at 21th epoch : 0.09353823733375681  Training Accuracy:0.8768939393939394\n",
            "3168/4708 - The training loss at 21th epoch : 0.09339738241760681  Training Accuracy:0.8771984924623115\n",
            "3184/4708 - The training loss at 21th epoch : 0.09298912199418155  Training Accuracy:0.8778125\n",
            "3200/4708 - The training loss at 21th epoch : 0.09262303421216979  Training Accuracy:0.8784203980099502\n",
            "3216/4708 - The training loss at 21th epoch : 0.09228053078615538  Training Accuracy:0.8790222772277227\n",
            "3232/4708 - The training loss at 21th epoch : 0.09272288369083638  Training Accuracy:0.8783866995073891\n",
            "3248/4708 - The training loss at 21th epoch : 0.09238795155269304  Training Accuracy:0.8789828431372549\n",
            "3264/4708 - The training loss at 21th epoch : 0.09240528079606225  Training Accuracy:0.8789634146341463\n",
            "3280/4708 - The training loss at 21th epoch : 0.09261386681281598  Training Accuracy:0.8786407766990292\n",
            "3296/4708 - The training loss at 21th epoch : 0.09258505007917917  Training Accuracy:0.8786231884057971\n",
            "3312/4708 - The training loss at 21th epoch : 0.09291162747766825  Training Accuracy:0.8780048076923077\n",
            "3328/4708 - The training loss at 21th epoch : 0.09262151370508848  Training Accuracy:0.8782894736842105\n",
            "3344/4708 - The training loss at 21th epoch : 0.0924989017244851  Training Accuracy:0.8782738095238095\n",
            "3360/4708 - The training loss at 21th epoch : 0.09233939551667045  Training Accuracy:0.8785545023696683\n",
            "3376/4708 - The training loss at 21th epoch : 0.09217108999980174  Training Accuracy:0.8785377358490566\n",
            "3392/4708 - The training loss at 21th epoch : 0.09225527478174624  Training Accuracy:0.8782276995305164\n",
            "3408/4708 - The training loss at 21th epoch : 0.09258658794899947  Training Accuracy:0.8776285046728972\n",
            "3424/4708 - The training loss at 21th epoch : 0.09227149801234627  Training Accuracy:0.8781976744186046\n",
            "3440/4708 - The training loss at 21th epoch : 0.09263490778640206  Training Accuracy:0.8778935185185185\n",
            "3456/4708 - The training loss at 21th epoch : 0.09256787946030279  Training Accuracy:0.878168202764977\n",
            "3472/4708 - The training loss at 21th epoch : 0.09215136599604874  Training Accuracy:0.8787270642201835\n",
            "3488/4708 - The training loss at 21th epoch : 0.09206864053371616  Training Accuracy:0.8787100456621004\n",
            "3504/4708 - The training loss at 21th epoch : 0.09206239054895998  Training Accuracy:0.8786931818181818\n",
            "3520/4708 - The training loss at 21th epoch : 0.09226445484984366  Training Accuracy:0.8786764705882353\n",
            "3536/4708 - The training loss at 21th epoch : 0.09249942659514356  Training Accuracy:0.8783783783783784\n",
            "3552/4708 - The training loss at 21th epoch : 0.09241010025280687  Training Accuracy:0.8786434977578476\n",
            "3568/4708 - The training loss at 21th epoch : 0.09252654886908347  Training Accuracy:0.8786272321428571\n",
            "3584/4708 - The training loss at 21th epoch : 0.09229817171017313  Training Accuracy:0.8788888888888889\n",
            "3600/4708 - The training loss at 21th epoch : 0.09213028772980596  Training Accuracy:0.8791482300884956\n",
            "3616/4708 - The training loss at 21th epoch : 0.09200771178047074  Training Accuracy:0.8794052863436124\n",
            "3632/4708 - The training loss at 21th epoch : 0.0921170935668797  Training Accuracy:0.8793859649122807\n",
            "3648/4708 - The training loss at 21th epoch : 0.09214627774051795  Training Accuracy:0.8793668122270742\n",
            "3664/4708 - The training loss at 21th epoch : 0.09208880147263022  Training Accuracy:0.8793478260869565\n",
            "3680/4708 - The training loss at 21th epoch : 0.09204525390473277  Training Accuracy:0.8793290043290043\n",
            "3696/4708 - The training loss at 21th epoch : 0.09234870557558171  Training Accuracy:0.8790409482758621\n",
            "3712/4708 - The training loss at 21th epoch : 0.09207091355110461  Training Accuracy:0.8792918454935622\n",
            "3728/4708 - The training loss at 21th epoch : 0.09241179899282174  Training Accuracy:0.8790064102564102\n",
            "3744/4708 - The training loss at 21th epoch : 0.09230087459852657  Training Accuracy:0.8792553191489362\n",
            "3760/4708 - The training loss at 21th epoch : 0.09241912819513215  Training Accuracy:0.8792372881355932\n",
            "3776/4708 - The training loss at 21th epoch : 0.09222662408559305  Training Accuracy:0.8794831223628692\n",
            "3792/4708 - The training loss at 21th epoch : 0.09215894924049436  Training Accuracy:0.8794642857142857\n",
            "3808/4708 - The training loss at 21th epoch : 0.09186727794727602  Training Accuracy:0.8799686192468619\n",
            "3824/4708 - The training loss at 21th epoch : 0.09187803594770806  Training Accuracy:0.8796875\n",
            "3840/4708 - The training loss at 21th epoch : 0.09159986426820038  Training Accuracy:0.8799273858921162\n",
            "3856/4708 - The training loss at 21th epoch : 0.09151620783710608  Training Accuracy:0.8801652892561983\n",
            "3872/4708 - The training loss at 21th epoch : 0.09178072310011892  Training Accuracy:0.8796296296296297\n",
            "3888/4708 - The training loss at 21th epoch : 0.0918535889275273  Training Accuracy:0.8796106557377049\n",
            "3904/4708 - The training loss at 21th epoch : 0.09190932593211262  Training Accuracy:0.8795918367346939\n",
            "3920/4708 - The training loss at 21th epoch : 0.09168721902613468  Training Accuracy:0.8798272357723578\n",
            "3936/4708 - The training loss at 21th epoch : 0.09154747882712609  Training Accuracy:0.8800607287449392\n",
            "3952/4708 - The training loss at 21th epoch : 0.09158509044300002  Training Accuracy:0.8800403225806451\n",
            "3968/4708 - The training loss at 21th epoch : 0.09157524428284498  Training Accuracy:0.8800200803212851\n",
            "3984/4708 - The training loss at 21th epoch : 0.09166267430074618  Training Accuracy:0.87975\n",
            "4000/4708 - The training loss at 21th epoch : 0.0914166971488825  Training Accuracy:0.8802290836653387\n",
            "4016/4708 - The training loss at 21th epoch : 0.09115697271287616  Training Accuracy:0.8807043650793651\n",
            "4032/4708 - The training loss at 21th epoch : 0.09150759107728246  Training Accuracy:0.8801877470355731\n",
            "4048/4708 - The training loss at 21th epoch : 0.09147457412205524  Training Accuracy:0.8801673228346457\n",
            "4064/4708 - The training loss at 21th epoch : 0.0912636189085857  Training Accuracy:0.8806372549019608\n",
            "4080/4708 - The training loss at 21th epoch : 0.09121388910629243  Training Accuracy:0.880859375\n",
            "4096/4708 - The training loss at 21th epoch : 0.09120897171750483  Training Accuracy:0.881079766536965\n",
            "4112/4708 - The training loss at 21th epoch : 0.09103211969218175  Training Accuracy:0.8812984496124031\n",
            "4128/4708 - The training loss at 21th epoch : 0.09125185086887169  Training Accuracy:0.8810328185328186\n",
            "4144/4708 - The training loss at 21th epoch : 0.09126261339465158  Training Accuracy:0.8810096153846154\n",
            "4160/4708 - The training loss at 21th epoch : 0.09120235764470695  Training Accuracy:0.8812260536398467\n",
            "4176/4708 - The training loss at 21th epoch : 0.09104608509650292  Training Accuracy:0.8814408396946565\n",
            "4192/4708 - The training loss at 21th epoch : 0.09145714947006699  Training Accuracy:0.8804657794676806\n",
            "4208/4708 - The training loss at 21th epoch : 0.09119106050999437  Training Accuracy:0.8809185606060606\n",
            "4224/4708 - The training loss at 21th epoch : 0.09136699048337303  Training Accuracy:0.8808962264150944\n",
            "4240/4708 - The training loss at 21th epoch : 0.09143324941261692  Training Accuracy:0.880874060150376\n",
            "4256/4708 - The training loss at 21th epoch : 0.09119077209042452  Training Accuracy:0.8813202247191011\n",
            "4272/4708 - The training loss at 21th epoch : 0.09115235561402821  Training Accuracy:0.8812966417910447\n",
            "4288/4708 - The training loss at 21th epoch : 0.0912045417160923  Training Accuracy:0.8812732342007435\n",
            "4304/4708 - The training loss at 21th epoch : 0.09105294284676832  Training Accuracy:0.8814814814814815\n",
            "4320/4708 - The training loss at 21th epoch : 0.09113175923952964  Training Accuracy:0.8812269372693727\n",
            "4336/4708 - The training loss at 21th epoch : 0.09108972043073325  Training Accuracy:0.8812040441176471\n",
            "4352/4708 - The training loss at 21th epoch : 0.09113130921652433  Training Accuracy:0.8811813186813187\n",
            "4368/4708 - The training loss at 21th epoch : 0.09114892066182571  Training Accuracy:0.8811587591240876\n",
            "4384/4708 - The training loss at 21th epoch : 0.09124351636596999  Training Accuracy:0.8811363636363636\n",
            "4400/4708 - The training loss at 21th epoch : 0.09157076801428711  Training Accuracy:0.880661231884058\n",
            "4416/4708 - The training loss at 21th epoch : 0.09190464901664382  Training Accuracy:0.8804151624548736\n",
            "4432/4708 - The training loss at 21th epoch : 0.0920210044450546  Training Accuracy:0.8803956834532374\n",
            "4448/4708 - The training loss at 21th epoch : 0.0918215408081337  Training Accuracy:0.8808243727598566\n",
            "4464/4708 - The training loss at 21th epoch : 0.09216988068852638  Training Accuracy:0.8803571428571428\n",
            "4480/4708 - The training loss at 21th epoch : 0.09209842108121329  Training Accuracy:0.880338078291815\n",
            "4496/4708 - The training loss at 21th epoch : 0.09207918690106094  Training Accuracy:0.8800975177304965\n",
            "4512/4708 - The training loss at 21th epoch : 0.0920018413062636  Training Accuracy:0.8803003533568905\n",
            "4528/4708 - The training loss at 21th epoch : 0.09198141692066804  Training Accuracy:0.8805017605633803\n",
            "4544/4708 - The training loss at 21th epoch : 0.09210897420241906  Training Accuracy:0.8804824561403509\n",
            "4560/4708 - The training loss at 21th epoch : 0.09215601479672812  Training Accuracy:0.8804632867132867\n",
            "4576/4708 - The training loss at 21th epoch : 0.09199556854089719  Training Accuracy:0.8806620209059234\n",
            "4592/4708 - The training loss at 21th epoch : 0.09245168679451218  Training Accuracy:0.8799913194444444\n",
            "4608/4708 - The training loss at 21th epoch : 0.09225101722849836  Training Accuracy:0.8801903114186851\n",
            "4624/4708 - The training loss at 21th epoch : 0.09201026899324627  Training Accuracy:0.8806034482758621\n",
            "4640/4708 - The training loss at 21th epoch : 0.0923143194047841  Training Accuracy:0.8801546391752577\n",
            "4656/4708 - The training loss at 21th epoch : 0.09217595806482835  Training Accuracy:0.8803510273972602\n",
            "4672/4708 - The training loss at 21th epoch : 0.09243310431413002  Training Accuracy:0.8801194539249146\n",
            "4688/4708 - The training loss at 21th epoch : 0.09238878238264936  Training Accuracy:0.8803146258503401\n",
            "4704/4708 - The training loss at 21th epoch : 0.09230118027456663  Training Accuracy:0.8805084745762712\n",
            "4720/4708 - The training loss at 21th epoch : 0.09225176269706309  Training Accuracy:0.8804898648648649\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 22th epoch : 0.11722615433011481  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 22th epoch : 0.12096698884600043  Training Accuracy:0.84375\n",
            "32/4708 - The training loss at 22th epoch : 0.09594934076202322  Training Accuracy:0.875\n",
            "48/4708 - The training loss at 22th epoch : 0.11643224571140415  Training Accuracy:0.84375\n",
            "64/4708 - The training loss at 22th epoch : 0.111541392917616  Training Accuracy:0.8625\n",
            "80/4708 - The training loss at 22th epoch : 0.09872080253159184  Training Accuracy:0.8854166666666666\n",
            "96/4708 - The training loss at 22th epoch : 0.08723250669351733  Training Accuracy:0.8928571428571429\n",
            "112/4708 - The training loss at 22th epoch : 0.10696452906932132  Training Accuracy:0.8671875\n",
            "128/4708 - The training loss at 22th epoch : 0.1086422249059536  Training Accuracy:0.8680555555555556\n",
            "144/4708 - The training loss at 22th epoch : 0.10408973652568139  Training Accuracy:0.875\n",
            "160/4708 - The training loss at 22th epoch : 0.09635037231087348  Training Accuracy:0.8863636363636364\n",
            "176/4708 - The training loss at 22th epoch : 0.0921308478937131  Training Accuracy:0.8854166666666666\n",
            "192/4708 - The training loss at 22th epoch : 0.0872454146072214  Training Accuracy:0.8894230769230769\n",
            "208/4708 - The training loss at 22th epoch : 0.09293202317902369  Training Accuracy:0.8794642857142857\n",
            "224/4708 - The training loss at 22th epoch : 0.0887291003899816  Training Accuracy:0.8875\n",
            "240/4708 - The training loss at 22th epoch : 0.08739801101565675  Training Accuracy:0.88671875\n",
            "256/4708 - The training loss at 22th epoch : 0.08289667854446148  Training Accuracy:0.8933823529411765\n",
            "272/4708 - The training loss at 22th epoch : 0.08748472520438916  Training Accuracy:0.8888888888888888\n",
            "288/4708 - The training loss at 22th epoch : 0.08760872516955454  Training Accuracy:0.8881578947368421\n",
            "304/4708 - The training loss at 22th epoch : 0.0835463528785704  Training Accuracy:0.89375\n",
            "320/4708 - The training loss at 22th epoch : 0.08448217066766356  Training Accuracy:0.8928571428571429\n",
            "336/4708 - The training loss at 22th epoch : 0.08460459458895632  Training Accuracy:0.8920454545454546\n",
            "352/4708 - The training loss at 22th epoch : 0.08929069963514977  Training Accuracy:0.8831521739130435\n",
            "368/4708 - The training loss at 22th epoch : 0.09018305051161422  Training Accuracy:0.8802083333333334\n",
            "384/4708 - The training loss at 22th epoch : 0.09072041386628032  Training Accuracy:0.88\n",
            "400/4708 - The training loss at 22th epoch : 0.09153370941963948  Training Accuracy:0.8798076923076923\n",
            "416/4708 - The training loss at 22th epoch : 0.09060794884561643  Training Accuracy:0.8796296296296297\n",
            "432/4708 - The training loss at 22th epoch : 0.09238773787497305  Training Accuracy:0.875\n",
            "448/4708 - The training loss at 22th epoch : 0.09502275982854198  Training Accuracy:0.8706896551724138\n",
            "464/4708 - The training loss at 22th epoch : 0.09391334917313782  Training Accuracy:0.8708333333333333\n",
            "480/4708 - The training loss at 22th epoch : 0.09710010370083827  Training Accuracy:0.8669354838709677\n",
            "496/4708 - The training loss at 22th epoch : 0.09642115147615872  Training Accuracy:0.8671875\n",
            "512/4708 - The training loss at 22th epoch : 0.0949326770074674  Training Accuracy:0.8674242424242424\n",
            "528/4708 - The training loss at 22th epoch : 0.09402695863849982  Training Accuracy:0.8676470588235294\n",
            "544/4708 - The training loss at 22th epoch : 0.09506074981722626  Training Accuracy:0.8678571428571429\n",
            "560/4708 - The training loss at 22th epoch : 0.09304081623439353  Training Accuracy:0.8715277777777778\n",
            "576/4708 - The training loss at 22th epoch : 0.0954288973269803  Training Accuracy:0.8682432432432432\n",
            "592/4708 - The training loss at 22th epoch : 0.09449182907352095  Training Accuracy:0.8700657894736842\n",
            "608/4708 - The training loss at 22th epoch : 0.09619447819436974  Training Accuracy:0.8685897435897436\n",
            "624/4708 - The training loss at 22th epoch : 0.0969857736738161  Training Accuracy:0.86875\n",
            "640/4708 - The training loss at 22th epoch : 0.09778619714869169  Training Accuracy:0.8673780487804879\n",
            "656/4708 - The training loss at 22th epoch : 0.09908089849100878  Training Accuracy:0.8660714285714286\n",
            "672/4708 - The training loss at 22th epoch : 0.10027530966977789  Training Accuracy:0.8648255813953488\n",
            "688/4708 - The training loss at 22th epoch : 0.09952105301635804  Training Accuracy:0.8664772727272727\n",
            "704/4708 - The training loss at 22th epoch : 0.09888361324726185  Training Accuracy:0.8680555555555556\n",
            "720/4708 - The training loss at 22th epoch : 0.09761741693283439  Training Accuracy:0.8695652173913043\n",
            "736/4708 - The training loss at 22th epoch : 0.09687842743415115  Training Accuracy:0.8696808510638298\n",
            "752/4708 - The training loss at 22th epoch : 0.09692802558427453  Training Accuracy:0.8697916666666666\n",
            "768/4708 - The training loss at 22th epoch : 0.09682374703878682  Training Accuracy:0.8686224489795918\n",
            "784/4708 - The training loss at 22th epoch : 0.09531497712433575  Training Accuracy:0.87\n",
            "800/4708 - The training loss at 22th epoch : 0.0954910443841186  Training Accuracy:0.8700980392156863\n",
            "816/4708 - The training loss at 22th epoch : 0.09466067122590888  Training Accuracy:0.8713942307692307\n",
            "832/4708 - The training loss at 22th epoch : 0.09407741679523017  Training Accuracy:0.8714622641509434\n",
            "848/4708 - The training loss at 22th epoch : 0.09422890373965212  Training Accuracy:0.8715277777777778\n",
            "864/4708 - The training loss at 22th epoch : 0.09366768676299347  Training Accuracy:0.8727272727272727\n",
            "880/4708 - The training loss at 22th epoch : 0.09298116258485098  Training Accuracy:0.8738839285714286\n",
            "896/4708 - The training loss at 22th epoch : 0.09371106804696702  Training Accuracy:0.8728070175438597\n",
            "912/4708 - The training loss at 22th epoch : 0.09387812248530913  Training Accuracy:0.8728448275862069\n",
            "928/4708 - The training loss at 22th epoch : 0.09544400271331402  Training Accuracy:0.8707627118644068\n",
            "944/4708 - The training loss at 22th epoch : 0.09526293367421669  Training Accuracy:0.8708333333333333\n",
            "960/4708 - The training loss at 22th epoch : 0.09697627849521046  Training Accuracy:0.8688524590163934\n",
            "976/4708 - The training loss at 22th epoch : 0.09574730993535965  Training Accuracy:0.8709677419354839\n",
            "992/4708 - The training loss at 22th epoch : 0.09490943084264666  Training Accuracy:0.8720238095238095\n",
            "1008/4708 - The training loss at 22th epoch : 0.09605701019995462  Training Accuracy:0.8701171875\n",
            "1024/4708 - The training loss at 22th epoch : 0.09667277954333807  Training Accuracy:0.8701923076923077\n",
            "1040/4708 - The training loss at 22th epoch : 0.09703778188754016  Training Accuracy:0.8693181818181818\n",
            "1056/4708 - The training loss at 22th epoch : 0.0968563404601595  Training Accuracy:0.8694029850746269\n",
            "1072/4708 - The training loss at 22th epoch : 0.0967151482735672  Training Accuracy:0.8694852941176471\n",
            "1088/4708 - The training loss at 22th epoch : 0.09592879785843467  Training Accuracy:0.8704710144927537\n",
            "1104/4708 - The training loss at 22th epoch : 0.09548775203370558  Training Accuracy:0.8714285714285714\n",
            "1120/4708 - The training loss at 22th epoch : 0.09593265159311609  Training Accuracy:0.8705985915492958\n",
            "1136/4708 - The training loss at 22th epoch : 0.09549715177137293  Training Accuracy:0.8706597222222222\n",
            "1152/4708 - The training loss at 22th epoch : 0.0951783852639003  Training Accuracy:0.8715753424657534\n",
            "1168/4708 - The training loss at 22th epoch : 0.09459377622365363  Training Accuracy:0.8724662162162162\n",
            "1184/4708 - The training loss at 22th epoch : 0.09577578395187056  Training Accuracy:0.87\n",
            "1200/4708 - The training loss at 22th epoch : 0.0962406143117594  Training Accuracy:0.8692434210526315\n",
            "1216/4708 - The training loss at 22th epoch : 0.09630466715147565  Training Accuracy:0.8685064935064936\n",
            "1232/4708 - The training loss at 22th epoch : 0.0961775870891411  Training Accuracy:0.8685897435897436\n",
            "1248/4708 - The training loss at 22th epoch : 0.09575622499846094  Training Accuracy:0.8686708860759493\n",
            "1264/4708 - The training loss at 22th epoch : 0.09602352574545588  Training Accuracy:0.86796875\n",
            "1280/4708 - The training loss at 22th epoch : 0.09536880317146453  Training Accuracy:0.8688271604938271\n",
            "1296/4708 - The training loss at 22th epoch : 0.09571938848045024  Training Accuracy:0.8689024390243902\n",
            "1312/4708 - The training loss at 22th epoch : 0.09523188826393342  Training Accuracy:0.8697289156626506\n",
            "1328/4708 - The training loss at 22th epoch : 0.09452996462119392  Training Accuracy:0.8712797619047619\n",
            "1344/4708 - The training loss at 22th epoch : 0.09497096923177846  Training Accuracy:0.8698529411764706\n",
            "1360/4708 - The training loss at 22th epoch : 0.0943515877830391  Training Accuracy:0.8706395348837209\n",
            "1376/4708 - The training loss at 22th epoch : 0.0941501908412288  Training Accuracy:0.8714080459770115\n",
            "1392/4708 - The training loss at 22th epoch : 0.09362294078419926  Training Accuracy:0.8721590909090909\n",
            "1408/4708 - The training loss at 22th epoch : 0.0927668260357497  Training Accuracy:0.8735955056179775\n",
            "1424/4708 - The training loss at 22th epoch : 0.09234640797157315  Training Accuracy:0.8743055555555556\n",
            "1440/4708 - The training loss at 22th epoch : 0.09138241666887562  Training Accuracy:0.8756868131868132\n",
            "1456/4708 - The training loss at 22th epoch : 0.09066508579138584  Training Accuracy:0.876358695652174\n",
            "1472/4708 - The training loss at 22th epoch : 0.09007210590713584  Training Accuracy:0.8770161290322581\n",
            "1488/4708 - The training loss at 22th epoch : 0.09091578623422901  Training Accuracy:0.8763297872340425\n",
            "1504/4708 - The training loss at 22th epoch : 0.09018637412944484  Training Accuracy:0.8776315789473684\n",
            "1520/4708 - The training loss at 22th epoch : 0.08992597187519173  Training Accuracy:0.8776041666666666\n",
            "1536/4708 - The training loss at 22th epoch : 0.089880550616969  Training Accuracy:0.8782216494845361\n",
            "1552/4708 - The training loss at 22th epoch : 0.08936964616247231  Training Accuracy:0.8794642857142857\n",
            "1568/4708 - The training loss at 22th epoch : 0.08972246769596672  Training Accuracy:0.8794191919191919\n",
            "1584/4708 - The training loss at 22th epoch : 0.0896626187827052  Training Accuracy:0.879375\n",
            "1600/4708 - The training loss at 22th epoch : 0.08969792741404671  Training Accuracy:0.8793316831683168\n",
            "1616/4708 - The training loss at 22th epoch : 0.0896992849234302  Training Accuracy:0.8792892156862745\n",
            "1632/4708 - The training loss at 22th epoch : 0.09007821844668676  Training Accuracy:0.8786407766990292\n",
            "1648/4708 - The training loss at 22th epoch : 0.08947815927305985  Training Accuracy:0.8792067307692307\n",
            "1664/4708 - The training loss at 22th epoch : 0.09072095776404109  Training Accuracy:0.8773809523809524\n",
            "1680/4708 - The training loss at 22th epoch : 0.09034715128650889  Training Accuracy:0.8779481132075472\n",
            "1696/4708 - The training loss at 22th epoch : 0.0903384845703158  Training Accuracy:0.8773364485981309\n",
            "1712/4708 - The training loss at 22th epoch : 0.09060468292209477  Training Accuracy:0.8773148148148148\n",
            "1728/4708 - The training loss at 22th epoch : 0.09001596056222112  Training Accuracy:0.8784403669724771\n",
            "1744/4708 - The training loss at 22th epoch : 0.08984692158734528  Training Accuracy:0.8784090909090909\n",
            "1760/4708 - The training loss at 22th epoch : 0.09172927627923332  Training Accuracy:0.8761261261261262\n",
            "1776/4708 - The training loss at 22th epoch : 0.09179446445986618  Training Accuracy:0.8761160714285714\n",
            "1792/4708 - The training loss at 22th epoch : 0.09178535580792414  Training Accuracy:0.8766592920353983\n",
            "1808/4708 - The training loss at 22th epoch : 0.09280074527165931  Training Accuracy:0.8755482456140351\n",
            "1824/4708 - The training loss at 22th epoch : 0.09279074179436325  Training Accuracy:0.8755434782608695\n",
            "1840/4708 - The training loss at 22th epoch : 0.0925370898305101  Training Accuracy:0.8755387931034483\n",
            "1856/4708 - The training loss at 22th epoch : 0.09276566636045151  Training Accuracy:0.875\n",
            "1872/4708 - The training loss at 22th epoch : 0.09245289885052081  Training Accuracy:0.875\n",
            "1888/4708 - The training loss at 22th epoch : 0.0926345909376179  Training Accuracy:0.8744747899159664\n",
            "1904/4708 - The training loss at 22th epoch : 0.092426322738085  Training Accuracy:0.875\n",
            "1920/4708 - The training loss at 22th epoch : 0.09257446592599598  Training Accuracy:0.875\n",
            "1936/4708 - The training loss at 22th epoch : 0.0923350533412106  Training Accuracy:0.8755122950819673\n",
            "1952/4708 - The training loss at 22th epoch : 0.09264373973504952  Training Accuracy:0.8755081300813008\n",
            "1968/4708 - The training loss at 22th epoch : 0.09302895909175135  Training Accuracy:0.875\n",
            "1984/4708 - The training loss at 22th epoch : 0.09345762962266026  Training Accuracy:0.874\n",
            "2000/4708 - The training loss at 22th epoch : 0.09295420627754304  Training Accuracy:0.875\n",
            "2016/4708 - The training loss at 22th epoch : 0.09237834722102284  Training Accuracy:0.8759842519685039\n",
            "2032/4708 - The training loss at 22th epoch : 0.09271600726918793  Training Accuracy:0.87548828125\n",
            "2048/4708 - The training loss at 22th epoch : 0.09241100094132959  Training Accuracy:0.875968992248062\n",
            "2064/4708 - The training loss at 22th epoch : 0.09207600372917187  Training Accuracy:0.8764423076923077\n",
            "2080/4708 - The training loss at 22th epoch : 0.09226896139763019  Training Accuracy:0.8759541984732825\n",
            "2096/4708 - The training loss at 22th epoch : 0.09238282101159824  Training Accuracy:0.8759469696969697\n",
            "2112/4708 - The training loss at 22th epoch : 0.09227411513776716  Training Accuracy:0.8764097744360902\n",
            "2128/4708 - The training loss at 22th epoch : 0.09219557445494993  Training Accuracy:0.8759328358208955\n",
            "2144/4708 - The training loss at 22th epoch : 0.092438391671663  Training Accuracy:0.8759259259259259\n",
            "2160/4708 - The training loss at 22th epoch : 0.09211592755184086  Training Accuracy:0.8763786764705882\n",
            "2176/4708 - The training loss at 22th epoch : 0.09236098505294078  Training Accuracy:0.8763686131386861\n",
            "2192/4708 - The training loss at 22th epoch : 0.09267033044468567  Training Accuracy:0.8759057971014492\n",
            "2208/4708 - The training loss at 22th epoch : 0.09229748276057678  Training Accuracy:0.8763489208633094\n",
            "2224/4708 - The training loss at 22th epoch : 0.09194161995849254  Training Accuracy:0.8767857142857143\n",
            "2240/4708 - The training loss at 22th epoch : 0.09216795888522414  Training Accuracy:0.87677304964539\n",
            "2256/4708 - The training loss at 22th epoch : 0.09201218248137802  Training Accuracy:0.8767605633802817\n",
            "2272/4708 - The training loss at 22th epoch : 0.0918185572508639  Training Accuracy:0.8776223776223776\n",
            "2288/4708 - The training loss at 22th epoch : 0.09174170806881661  Training Accuracy:0.8776041666666666\n",
            "2304/4708 - The training loss at 22th epoch : 0.09134784734106659  Training Accuracy:0.8780172413793104\n",
            "2320/4708 - The training loss at 22th epoch : 0.09144807499810548  Training Accuracy:0.8779965753424658\n",
            "2336/4708 - The training loss at 22th epoch : 0.09144521693039942  Training Accuracy:0.8779761904761905\n",
            "2352/4708 - The training loss at 22th epoch : 0.09106989006119455  Training Accuracy:0.8788006756756757\n",
            "2368/4708 - The training loss at 22th epoch : 0.09139733309900196  Training Accuracy:0.8783557046979866\n",
            "2384/4708 - The training loss at 22th epoch : 0.09134042080701835  Training Accuracy:0.8783333333333333\n",
            "2400/4708 - The training loss at 22th epoch : 0.09108226527771428  Training Accuracy:0.8787251655629139\n",
            "2416/4708 - The training loss at 22th epoch : 0.09100192964859026  Training Accuracy:0.8787006578947368\n",
            "2432/4708 - The training loss at 22th epoch : 0.09121719668850997  Training Accuracy:0.8782679738562091\n",
            "2448/4708 - The training loss at 22th epoch : 0.09144027826656484  Training Accuracy:0.8782467532467533\n",
            "2464/4708 - The training loss at 22th epoch : 0.09119669612386128  Training Accuracy:0.8782258064516129\n",
            "2480/4708 - The training loss at 22th epoch : 0.09088882615147065  Training Accuracy:0.8782051282051282\n",
            "2496/4708 - The training loss at 22th epoch : 0.09097180995739296  Training Accuracy:0.8781847133757962\n",
            "2512/4708 - The training loss at 22th epoch : 0.09109443990919476  Training Accuracy:0.8777689873417721\n",
            "2528/4708 - The training loss at 22th epoch : 0.0907996262782666  Training Accuracy:0.8781446540880503\n",
            "2544/4708 - The training loss at 22th epoch : 0.09135886023499852  Training Accuracy:0.87734375\n",
            "2560/4708 - The training loss at 22th epoch : 0.09139295627869097  Training Accuracy:0.8773291925465838\n",
            "2576/4708 - The training loss at 22th epoch : 0.09163372078094195  Training Accuracy:0.876929012345679\n",
            "2592/4708 - The training loss at 22th epoch : 0.09139809970373479  Training Accuracy:0.8773006134969326\n",
            "2608/4708 - The training loss at 22th epoch : 0.09139628578960966  Training Accuracy:0.8772865853658537\n",
            "2624/4708 - The training loss at 22th epoch : 0.0916695766822366  Training Accuracy:0.8765151515151515\n",
            "2640/4708 - The training loss at 22th epoch : 0.0914754985238728  Training Accuracy:0.8768825301204819\n",
            "2656/4708 - The training loss at 22th epoch : 0.0913292495211638  Training Accuracy:0.8768712574850299\n",
            "2672/4708 - The training loss at 22th epoch : 0.09148569801684553  Training Accuracy:0.8761160714285714\n",
            "2688/4708 - The training loss at 22th epoch : 0.09115792088208817  Training Accuracy:0.8764792899408284\n",
            "2704/4708 - The training loss at 22th epoch : 0.09113364818768031  Training Accuracy:0.8764705882352941\n",
            "2720/4708 - The training loss at 22th epoch : 0.09128592662014919  Training Accuracy:0.8764619883040936\n",
            "2736/4708 - The training loss at 22th epoch : 0.09168396764372339  Training Accuracy:0.8760901162790697\n",
            "2752/4708 - The training loss at 22th epoch : 0.0914498502248554  Training Accuracy:0.8764450867052023\n",
            "2768/4708 - The training loss at 22th epoch : 0.09190856732558984  Training Accuracy:0.8757183908045977\n",
            "2784/4708 - The training loss at 22th epoch : 0.09157937704197877  Training Accuracy:0.8760714285714286\n",
            "2800/4708 - The training loss at 22th epoch : 0.09114495594000002  Training Accuracy:0.8767755681818182\n",
            "2816/4708 - The training loss at 22th epoch : 0.0909678590534273  Training Accuracy:0.8771186440677966\n",
            "2832/4708 - The training loss at 22th epoch : 0.09061063635828744  Training Accuracy:0.8778089887640449\n",
            "2848/4708 - The training loss at 22th epoch : 0.0902728268249024  Training Accuracy:0.8784916201117319\n",
            "2864/4708 - The training loss at 22th epoch : 0.09020291003657657  Training Accuracy:0.8784722222222222\n",
            "2880/4708 - The training loss at 22th epoch : 0.0898351459584218  Training Accuracy:0.8791436464088398\n",
            "2896/4708 - The training loss at 22th epoch : 0.09012034365044272  Training Accuracy:0.8787774725274725\n",
            "2912/4708 - The training loss at 22th epoch : 0.09033957100176314  Training Accuracy:0.8787568306010929\n",
            "2928/4708 - The training loss at 22th epoch : 0.0901787513273415  Training Accuracy:0.8790760869565217\n",
            "2944/4708 - The training loss at 22th epoch : 0.08990194033881393  Training Accuracy:0.8793918918918919\n",
            "2960/4708 - The training loss at 22th epoch : 0.08982108379401293  Training Accuracy:0.8793682795698925\n",
            "2976/4708 - The training loss at 22th epoch : 0.08961137007932526  Training Accuracy:0.8796791443850267\n",
            "2992/4708 - The training loss at 22th epoch : 0.08960219584671626  Training Accuracy:0.8793218085106383\n",
            "3008/4708 - The training loss at 22th epoch : 0.08920148197528806  Training Accuracy:0.8799603174603174\n",
            "3024/4708 - The training loss at 22th epoch : 0.08930784967751204  Training Accuracy:0.8796052631578948\n",
            "3040/4708 - The training loss at 22th epoch : 0.08902047498855399  Training Accuracy:0.8799083769633508\n",
            "3056/4708 - The training loss at 22th epoch : 0.08893025984091733  Training Accuracy:0.8798828125\n",
            "3072/4708 - The training loss at 22th epoch : 0.0889457971161798  Training Accuracy:0.8798575129533679\n",
            "3088/4708 - The training loss at 22th epoch : 0.08884453006317969  Training Accuracy:0.8801546391752577\n",
            "3104/4708 - The training loss at 22th epoch : 0.08874857509439366  Training Accuracy:0.8804487179487179\n",
            "3120/4708 - The training loss at 22th epoch : 0.08866568085831562  Training Accuracy:0.8807397959183674\n",
            "3136/4708 - The training loss at 22th epoch : 0.08838221175289578  Training Accuracy:0.8810279187817259\n",
            "3152/4708 - The training loss at 22th epoch : 0.08832455059541766  Training Accuracy:0.8809974747474747\n",
            "3168/4708 - The training loss at 22th epoch : 0.08830911540928868  Training Accuracy:0.8812814070351759\n",
            "3184/4708 - The training loss at 22th epoch : 0.08791820846893389  Training Accuracy:0.881875\n",
            "3200/4708 - The training loss at 22th epoch : 0.0884691923261806  Training Accuracy:0.8812189054726368\n",
            "3216/4708 - The training loss at 22th epoch : 0.08842411801801688  Training Accuracy:0.8811881188118812\n",
            "3232/4708 - The training loss at 22th epoch : 0.08806559240625175  Training Accuracy:0.8817733990147784\n",
            "3248/4708 - The training loss at 22th epoch : 0.0882160936481603  Training Accuracy:0.8814338235294118\n",
            "3264/4708 - The training loss at 22th epoch : 0.08789800824941481  Training Accuracy:0.8820121951219512\n",
            "3280/4708 - The training loss at 22th epoch : 0.08762591934682655  Training Accuracy:0.8825849514563107\n",
            "3296/4708 - The training loss at 22th epoch : 0.087772983533392  Training Accuracy:0.8822463768115942\n",
            "3312/4708 - The training loss at 22th epoch : 0.08742246372470387  Training Accuracy:0.8828125\n",
            "3328/4708 - The training loss at 22th epoch : 0.08759074652104602  Training Accuracy:0.8827751196172249\n",
            "3344/4708 - The training loss at 22th epoch : 0.08791765938650949  Training Accuracy:0.8824404761904762\n",
            "3360/4708 - The training loss at 22th epoch : 0.0880532908515574  Training Accuracy:0.8824052132701422\n",
            "3376/4708 - The training loss at 22th epoch : 0.08791278394290371  Training Accuracy:0.8826650943396226\n",
            "3392/4708 - The training loss at 22th epoch : 0.08782219879123998  Training Accuracy:0.8829225352112676\n",
            "3408/4708 - The training loss at 22th epoch : 0.08803744234817115  Training Accuracy:0.8828855140186916\n",
            "3424/4708 - The training loss at 22th epoch : 0.08804611777342929  Training Accuracy:0.8825581395348837\n",
            "3440/4708 - The training loss at 22th epoch : 0.08809441051038812  Training Accuracy:0.8822337962962963\n",
            "3456/4708 - The training loss at 22th epoch : 0.08788805673405899  Training Accuracy:0.8824884792626728\n",
            "3472/4708 - The training loss at 22th epoch : 0.08763389428792946  Training Accuracy:0.8830275229357798\n",
            "3488/4708 - The training loss at 22th epoch : 0.08761213661324938  Training Accuracy:0.8829908675799086\n",
            "3504/4708 - The training loss at 22th epoch : 0.08766078948626108  Training Accuracy:0.8829545454545454\n",
            "3520/4708 - The training loss at 22th epoch : 0.08758805354888483  Training Accuracy:0.8832013574660633\n",
            "3536/4708 - The training loss at 22th epoch : 0.08722802661719672  Training Accuracy:0.8837274774774775\n",
            "3552/4708 - The training loss at 22th epoch : 0.08746252218826732  Training Accuracy:0.883127802690583\n",
            "3568/4708 - The training loss at 22th epoch : 0.08753668505050709  Training Accuracy:0.8830915178571429\n",
            "3584/4708 - The training loss at 22th epoch : 0.08740129996440552  Training Accuracy:0.8833333333333333\n",
            "3600/4708 - The training loss at 22th epoch : 0.0874045360435905  Training Accuracy:0.8830199115044248\n",
            "3616/4708 - The training loss at 22th epoch : 0.08723416908866968  Training Accuracy:0.8832599118942731\n",
            "3632/4708 - The training loss at 22th epoch : 0.08755679871472556  Training Accuracy:0.8826754385964912\n",
            "3648/4708 - The training loss at 22th epoch : 0.08757511541384055  Training Accuracy:0.88264192139738\n",
            "3664/4708 - The training loss at 22th epoch : 0.08744633621393184  Training Accuracy:0.8828804347826087\n",
            "3680/4708 - The training loss at 22th epoch : 0.08749965165231918  Training Accuracy:0.8825757575757576\n",
            "3696/4708 - The training loss at 22th epoch : 0.08804014770438676  Training Accuracy:0.8820043103448276\n",
            "3712/4708 - The training loss at 22th epoch : 0.08803953171702715  Training Accuracy:0.8822424892703863\n",
            "3728/4708 - The training loss at 22th epoch : 0.08787512034426315  Training Accuracy:0.8824786324786325\n",
            "3744/4708 - The training loss at 22th epoch : 0.08813178710540455  Training Accuracy:0.8824468085106383\n",
            "3760/4708 - The training loss at 22th epoch : 0.08791082435100694  Training Accuracy:0.8826800847457628\n",
            "3776/4708 - The training loss at 22th epoch : 0.08787327391254257  Training Accuracy:0.8826476793248945\n",
            "3792/4708 - The training loss at 22th epoch : 0.08787575257649598  Training Accuracy:0.8828781512605042\n",
            "3808/4708 - The training loss at 22th epoch : 0.08781644732496481  Training Accuracy:0.8828451882845189\n",
            "3824/4708 - The training loss at 22th epoch : 0.08753035283235884  Training Accuracy:0.8833333333333333\n",
            "3840/4708 - The training loss at 22th epoch : 0.08736084477640049  Training Accuracy:0.883558091286307\n",
            "3856/4708 - The training loss at 22th epoch : 0.08731761050524416  Training Accuracy:0.8835227272727273\n",
            "3872/4708 - The training loss at 22th epoch : 0.08729037696830853  Training Accuracy:0.8834876543209876\n",
            "3888/4708 - The training loss at 22th epoch : 0.0874661658174922  Training Accuracy:0.8831967213114754\n",
            "3904/4708 - The training loss at 22th epoch : 0.08726123812883607  Training Accuracy:0.8834183673469388\n",
            "3920/4708 - The training loss at 22th epoch : 0.08725580385817022  Training Accuracy:0.8836382113821138\n",
            "3936/4708 - The training loss at 22th epoch : 0.08721565908277285  Training Accuracy:0.8836032388663968\n",
            "3952/4708 - The training loss at 22th epoch : 0.08750048129400827  Training Accuracy:0.8833165322580645\n",
            "3968/4708 - The training loss at 22th epoch : 0.08721914745200705  Training Accuracy:0.883785140562249\n",
            "3984/4708 - The training loss at 22th epoch : 0.08737665965513479  Training Accuracy:0.8835\n",
            "4000/4708 - The training loss at 22th epoch : 0.08734678836756149  Training Accuracy:0.8834661354581673\n",
            "4016/4708 - The training loss at 22th epoch : 0.08728793197038677  Training Accuracy:0.8834325396825397\n",
            "4032/4708 - The training loss at 22th epoch : 0.08701324336913391  Training Accuracy:0.883893280632411\n",
            "4048/4708 - The training loss at 22th epoch : 0.08685189530404507  Training Accuracy:0.8841043307086615\n",
            "4064/4708 - The training loss at 22th epoch : 0.08738589179601901  Training Accuracy:0.8833333333333333\n",
            "4080/4708 - The training loss at 22th epoch : 0.08752913501375681  Training Accuracy:0.883056640625\n",
            "4096/4708 - The training loss at 22th epoch : 0.08735320114892309  Training Accuracy:0.8830252918287937\n",
            "4112/4708 - The training loss at 22th epoch : 0.08738081656983544  Training Accuracy:0.8832364341085271\n",
            "4128/4708 - The training loss at 22th epoch : 0.08758622373974351  Training Accuracy:0.8829633204633205\n",
            "4144/4708 - The training loss at 22th epoch : 0.08755897583028915  Training Accuracy:0.8829326923076923\n",
            "4160/4708 - The training loss at 22th epoch : 0.08767027025823108  Training Accuracy:0.8826628352490421\n",
            "4176/4708 - The training loss at 22th epoch : 0.08756536629522517  Training Accuracy:0.8828721374045801\n",
            "4192/4708 - The training loss at 22th epoch : 0.08776619712257622  Training Accuracy:0.8826045627376425\n",
            "4208/4708 - The training loss at 22th epoch : 0.08790253829371594  Training Accuracy:0.8825757575757576\n",
            "4224/4708 - The training loss at 22th epoch : 0.08815675440382031  Training Accuracy:0.882311320754717\n",
            "4240/4708 - The training loss at 22th epoch : 0.08826757876232627  Training Accuracy:0.8822838345864662\n",
            "4256/4708 - The training loss at 22th epoch : 0.08812502580494314  Training Accuracy:0.8824906367041199\n",
            "4272/4708 - The training loss at 22th epoch : 0.0883455387770243  Training Accuracy:0.8819962686567164\n",
            "4288/4708 - The training loss at 22th epoch : 0.08811118726956008  Training Accuracy:0.8824349442379182\n",
            "4304/4708 - The training loss at 22th epoch : 0.08803293573280865  Training Accuracy:0.8826388888888889\n",
            "4320/4708 - The training loss at 22th epoch : 0.08786815060690316  Training Accuracy:0.8828413284132841\n",
            "4336/4708 - The training loss at 22th epoch : 0.08780696156503334  Training Accuracy:0.8828125\n",
            "4352/4708 - The training loss at 22th epoch : 0.08767708969602583  Training Accuracy:0.8827838827838828\n",
            "4368/4708 - The training loss at 22th epoch : 0.08782352943183093  Training Accuracy:0.8825273722627737\n",
            "4384/4708 - The training loss at 22th epoch : 0.08766155921133417  Training Accuracy:0.8827272727272727\n",
            "4400/4708 - The training loss at 22th epoch : 0.08776380208937558  Training Accuracy:0.8826992753623188\n",
            "4416/4708 - The training loss at 22th epoch : 0.0876931744805299  Training Accuracy:0.8826714801444043\n",
            "4432/4708 - The training loss at 22th epoch : 0.08782564597355644  Training Accuracy:0.8826438848920863\n",
            "4448/4708 - The training loss at 22th epoch : 0.08783442421672827  Training Accuracy:0.8826164874551972\n",
            "4464/4708 - The training loss at 22th epoch : 0.08794091581997364  Training Accuracy:0.8823660714285714\n",
            "4480/4708 - The training loss at 22th epoch : 0.08796997793786142  Training Accuracy:0.8823398576512456\n",
            "4496/4708 - The training loss at 22th epoch : 0.08799573987945611  Training Accuracy:0.882313829787234\n",
            "4512/4708 - The training loss at 22th epoch : 0.0882806270195483  Training Accuracy:0.8820671378091873\n",
            "4528/4708 - The training loss at 22th epoch : 0.08862127555074072  Training Accuracy:0.8816021126760564\n",
            "4544/4708 - The training loss at 22th epoch : 0.08866403982529196  Training Accuracy:0.881578947368421\n",
            "4560/4708 - The training loss at 22th epoch : 0.08900513597927477  Training Accuracy:0.8811188811188811\n",
            "4576/4708 - The training loss at 22th epoch : 0.08924342888573338  Training Accuracy:0.8808797909407665\n",
            "4592/4708 - The training loss at 22th epoch : 0.08966787374663457  Training Accuracy:0.8804253472222222\n",
            "4608/4708 - The training loss at 22th epoch : 0.08957682532590243  Training Accuracy:0.8806228373702422\n",
            "4624/4708 - The training loss at 22th epoch : 0.08953109292559058  Training Accuracy:0.8808189655172414\n",
            "4640/4708 - The training loss at 22th epoch : 0.08986828638357003  Training Accuracy:0.8805841924398625\n",
            "4656/4708 - The training loss at 22th epoch : 0.09014828563558477  Training Accuracy:0.8801369863013698\n",
            "4672/4708 - The training loss at 22th epoch : 0.09011341155596261  Training Accuracy:0.8803327645051194\n",
            "4688/4708 - The training loss at 22th epoch : 0.09009839537611426  Training Accuracy:0.8803146258503401\n",
            "4704/4708 - The training loss at 22th epoch : 0.08985840267518717  Training Accuracy:0.8807203389830508\n",
            "4720/4708 - The training loss at 22th epoch : 0.08969877666379031  Training Accuracy:0.8809121621621622\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 23th epoch : 0.013919945939658096  Training Accuracy:1.0\n",
            "16/4708 - The training loss at 23th epoch : 0.08314732090567702  Training Accuracy:0.875\n",
            "32/4708 - The training loss at 23th epoch : 0.09636640168731254  Training Accuracy:0.8541666666666666\n",
            "48/4708 - The training loss at 23th epoch : 0.09889033678152265  Training Accuracy:0.84375\n",
            "64/4708 - The training loss at 23th epoch : 0.09531098868687239  Training Accuracy:0.85\n",
            "80/4708 - The training loss at 23th epoch : 0.08460015742283879  Training Accuracy:0.875\n",
            "96/4708 - The training loss at 23th epoch : 0.07955904918770172  Training Accuracy:0.8839285714285714\n",
            "112/4708 - The training loss at 23th epoch : 0.07747415803928848  Training Accuracy:0.890625\n",
            "128/4708 - The training loss at 23th epoch : 0.08169380348008451  Training Accuracy:0.8888888888888888\n",
            "144/4708 - The training loss at 23th epoch : 0.07769571881529308  Training Accuracy:0.89375\n",
            "160/4708 - The training loss at 23th epoch : 0.07486079767389697  Training Accuracy:0.8977272727272727\n",
            "176/4708 - The training loss at 23th epoch : 0.07908750080057318  Training Accuracy:0.890625\n",
            "192/4708 - The training loss at 23th epoch : 0.08939036763549775  Training Accuracy:0.8701923076923077\n",
            "208/4708 - The training loss at 23th epoch : 0.09255875837265204  Training Accuracy:0.8660714285714286\n",
            "224/4708 - The training loss at 23th epoch : 0.08698081005160606  Training Accuracy:0.875\n",
            "240/4708 - The training loss at 23th epoch : 0.08641987533920178  Training Accuracy:0.875\n",
            "256/4708 - The training loss at 23th epoch : 0.08726026239277311  Training Accuracy:0.8786764705882353\n",
            "272/4708 - The training loss at 23th epoch : 0.08792174989316408  Training Accuracy:0.8784722222222222\n",
            "288/4708 - The training loss at 23th epoch : 0.08421431076373827  Training Accuracy:0.8848684210526315\n",
            "304/4708 - The training loss at 23th epoch : 0.08037154092739804  Training Accuracy:0.890625\n",
            "320/4708 - The training loss at 23th epoch : 0.07896946439078568  Training Accuracy:0.8958333333333334\n",
            "336/4708 - The training loss at 23th epoch : 0.07618537842812147  Training Accuracy:0.9005681818181818\n",
            "352/4708 - The training loss at 23th epoch : 0.07674030901988207  Training Accuracy:0.8940217391304348\n",
            "368/4708 - The training loss at 23th epoch : 0.0746274493283058  Training Accuracy:0.8984375\n",
            "384/4708 - The training loss at 23th epoch : 0.0758532354191777  Training Accuracy:0.8975\n",
            "400/4708 - The training loss at 23th epoch : 0.07464931858011375  Training Accuracy:0.8990384615384616\n",
            "416/4708 - The training loss at 23th epoch : 0.07463837956048905  Training Accuracy:0.9004629629629629\n",
            "432/4708 - The training loss at 23th epoch : 0.07367451981062426  Training Accuracy:0.8995535714285714\n",
            "448/4708 - The training loss at 23th epoch : 0.07543174818435437  Training Accuracy:0.8987068965517241\n",
            "464/4708 - The training loss at 23th epoch : 0.07657824943193249  Training Accuracy:0.8958333333333334\n",
            "480/4708 - The training loss at 23th epoch : 0.07720116547027121  Training Accuracy:0.8971774193548387\n",
            "496/4708 - The training loss at 23th epoch : 0.07652546602814994  Training Accuracy:0.8984375\n",
            "512/4708 - The training loss at 23th epoch : 0.07721026984006144  Training Accuracy:0.8958333333333334\n",
            "528/4708 - The training loss at 23th epoch : 0.08244960521696013  Training Accuracy:0.8897058823529411\n",
            "544/4708 - The training loss at 23th epoch : 0.08122621252893136  Training Accuracy:0.8928571428571429\n",
            "560/4708 - The training loss at 23th epoch : 0.08004634320560747  Training Accuracy:0.8958333333333334\n",
            "576/4708 - The training loss at 23th epoch : 0.07976628671219693  Training Accuracy:0.8969594594594594\n",
            "592/4708 - The training loss at 23th epoch : 0.07865670669589608  Training Accuracy:0.8980263157894737\n",
            "608/4708 - The training loss at 23th epoch : 0.07987473134091552  Training Accuracy:0.8958333333333334\n",
            "624/4708 - The training loss at 23th epoch : 0.07896231768208659  Training Accuracy:0.896875\n",
            "640/4708 - The training loss at 23th epoch : 0.08057383848603926  Training Accuracy:0.8932926829268293\n",
            "656/4708 - The training loss at 23th epoch : 0.07960726557699506  Training Accuracy:0.8958333333333334\n",
            "672/4708 - The training loss at 23th epoch : 0.07945370694539312  Training Accuracy:0.8968023255813954\n",
            "688/4708 - The training loss at 23th epoch : 0.07934871686465678  Training Accuracy:0.8963068181818182\n",
            "704/4708 - The training loss at 23th epoch : 0.07943048012897387  Training Accuracy:0.8958333333333334\n",
            "720/4708 - The training loss at 23th epoch : 0.07915880617887337  Training Accuracy:0.8967391304347826\n",
            "736/4708 - The training loss at 23th epoch : 0.07862947971472896  Training Accuracy:0.8976063829787234\n",
            "752/4708 - The training loss at 23th epoch : 0.08136178148449993  Training Accuracy:0.8932291666666666\n",
            "768/4708 - The training loss at 23th epoch : 0.08240009560115436  Training Accuracy:0.8915816326530612\n",
            "784/4708 - The training loss at 23th epoch : 0.08103518509807105  Training Accuracy:0.89375\n",
            "800/4708 - The training loss at 23th epoch : 0.08094315488752643  Training Accuracy:0.8946078431372549\n",
            "816/4708 - The training loss at 23th epoch : 0.08132862613816959  Training Accuracy:0.8930288461538461\n",
            "832/4708 - The training loss at 23th epoch : 0.08209959261057491  Training Accuracy:0.8915094339622641\n",
            "848/4708 - The training loss at 23th epoch : 0.08269550229675199  Training Accuracy:0.8900462962962963\n",
            "864/4708 - The training loss at 23th epoch : 0.08151415534836991  Training Accuracy:0.8920454545454546\n",
            "880/4708 - The training loss at 23th epoch : 0.08196372741186254  Training Accuracy:0.890625\n",
            "896/4708 - The training loss at 23th epoch : 0.08382511460503762  Training Accuracy:0.8881578947368421\n",
            "912/4708 - The training loss at 23th epoch : 0.08351426558008997  Training Accuracy:0.8890086206896551\n",
            "928/4708 - The training loss at 23th epoch : 0.08401189635173445  Training Accuracy:0.8877118644067796\n",
            "944/4708 - The training loss at 23th epoch : 0.08419701167942809  Training Accuracy:0.8875\n",
            "960/4708 - The training loss at 23th epoch : 0.08432948379071994  Training Accuracy:0.8872950819672131\n",
            "976/4708 - The training loss at 23th epoch : 0.08375637464565128  Training Accuracy:0.8870967741935484\n",
            "992/4708 - The training loss at 23th epoch : 0.08373970698359526  Training Accuracy:0.8859126984126984\n",
            "1008/4708 - The training loss at 23th epoch : 0.08431749131671473  Training Accuracy:0.8857421875\n",
            "1024/4708 - The training loss at 23th epoch : 0.08607151544847293  Training Accuracy:0.8836538461538461\n",
            "1040/4708 - The training loss at 23th epoch : 0.08594690349970581  Training Accuracy:0.884469696969697\n",
            "1056/4708 - The training loss at 23th epoch : 0.08620787517543044  Training Accuracy:0.8843283582089553\n",
            "1072/4708 - The training loss at 23th epoch : 0.08507729734271552  Training Accuracy:0.8860294117647058\n",
            "1088/4708 - The training loss at 23th epoch : 0.08425266256546496  Training Accuracy:0.8876811594202898\n",
            "1104/4708 - The training loss at 23th epoch : 0.08360907774481138  Training Accuracy:0.8875\n",
            "1120/4708 - The training loss at 23th epoch : 0.0828302093837439  Training Accuracy:0.8882042253521126\n",
            "1136/4708 - The training loss at 23th epoch : 0.08308529039345926  Training Accuracy:0.8871527777777778\n",
            "1152/4708 - The training loss at 23th epoch : 0.0826273371293948  Training Accuracy:0.8878424657534246\n",
            "1168/4708 - The training loss at 23th epoch : 0.08259510236414648  Training Accuracy:0.8885135135135135\n",
            "1184/4708 - The training loss at 23th epoch : 0.0821248787615696  Training Accuracy:0.8891666666666667\n",
            "1200/4708 - The training loss at 23th epoch : 0.08302729775916176  Training Accuracy:0.8873355263157895\n",
            "1216/4708 - The training loss at 23th epoch : 0.08365414648594059  Training Accuracy:0.8871753246753247\n",
            "1232/4708 - The training loss at 23th epoch : 0.08422669549022155  Training Accuracy:0.8870192307692307\n",
            "1248/4708 - The training loss at 23th epoch : 0.08422292283018602  Training Accuracy:0.8860759493670886\n",
            "1264/4708 - The training loss at 23th epoch : 0.08346184063241799  Training Accuracy:0.8875\n",
            "1280/4708 - The training loss at 23th epoch : 0.08316154086716156  Training Accuracy:0.8881172839506173\n",
            "1296/4708 - The training loss at 23th epoch : 0.08260547875436623  Training Accuracy:0.8887195121951219\n",
            "1312/4708 - The training loss at 23th epoch : 0.0827966371669075  Training Accuracy:0.8885542168674698\n",
            "1328/4708 - The training loss at 23th epoch : 0.08247213059354257  Training Accuracy:0.8883928571428571\n",
            "1344/4708 - The training loss at 23th epoch : 0.08189950683953243  Training Accuracy:0.8889705882352941\n",
            "1360/4708 - The training loss at 23th epoch : 0.08141393024633574  Training Accuracy:0.8895348837209303\n",
            "1376/4708 - The training loss at 23th epoch : 0.08092582965266595  Training Accuracy:0.8900862068965517\n",
            "1392/4708 - The training loss at 23th epoch : 0.08049355027318433  Training Accuracy:0.890625\n",
            "1408/4708 - The training loss at 23th epoch : 0.07969984256930428  Training Accuracy:0.8918539325842697\n",
            "1424/4708 - The training loss at 23th epoch : 0.08007937442832189  Training Accuracy:0.8909722222222223\n",
            "1440/4708 - The training loss at 23th epoch : 0.07993735238569279  Training Accuracy:0.8914835164835165\n",
            "1456/4708 - The training loss at 23th epoch : 0.07922598888589419  Training Accuracy:0.8926630434782609\n",
            "1472/4708 - The training loss at 23th epoch : 0.07959308211792027  Training Accuracy:0.8918010752688172\n",
            "1488/4708 - The training loss at 23th epoch : 0.07988746850226372  Training Accuracy:0.8922872340425532\n",
            "1504/4708 - The training loss at 23th epoch : 0.07936319949691982  Training Accuracy:0.8934210526315789\n",
            "1520/4708 - The training loss at 23th epoch : 0.08077149674059865  Training Accuracy:0.8919270833333334\n",
            "1536/4708 - The training loss at 23th epoch : 0.08128061826748526  Training Accuracy:0.8917525773195877\n",
            "1552/4708 - The training loss at 23th epoch : 0.08095426213388283  Training Accuracy:0.892219387755102\n",
            "1568/4708 - The training loss at 23th epoch : 0.08059870881988059  Training Accuracy:0.8933080808080808\n",
            "1584/4708 - The training loss at 23th epoch : 0.08283800183195916  Training Accuracy:0.89125\n",
            "1600/4708 - The training loss at 23th epoch : 0.08430219890748669  Training Accuracy:0.8892326732673267\n",
            "1616/4708 - The training loss at 23th epoch : 0.08423741991019572  Training Accuracy:0.8897058823529411\n",
            "1632/4708 - The training loss at 23th epoch : 0.08409705620115403  Training Accuracy:0.8895631067961165\n",
            "1648/4708 - The training loss at 23th epoch : 0.08407134387136456  Training Accuracy:0.8900240384615384\n",
            "1664/4708 - The training loss at 23th epoch : 0.08385893220978614  Training Accuracy:0.8898809523809523\n",
            "1680/4708 - The training loss at 23th epoch : 0.08383000550512149  Training Accuracy:0.8903301886792453\n",
            "1696/4708 - The training loss at 23th epoch : 0.08320848462648361  Training Accuracy:0.8913551401869159\n",
            "1712/4708 - The training loss at 23th epoch : 0.08329037424786936  Training Accuracy:0.890625\n",
            "1728/4708 - The training loss at 23th epoch : 0.08382185679926078  Training Accuracy:0.8893348623853211\n",
            "1744/4708 - The training loss at 23th epoch : 0.08434048315894624  Training Accuracy:0.8880681818181818\n",
            "1760/4708 - The training loss at 23th epoch : 0.0840496753944482  Training Accuracy:0.8885135135135135\n",
            "1776/4708 - The training loss at 23th epoch : 0.08355519592679206  Training Accuracy:0.8889508928571429\n",
            "1792/4708 - The training loss at 23th epoch : 0.0837407986342033  Training Accuracy:0.8888274336283186\n",
            "1808/4708 - The training loss at 23th epoch : 0.08382465184443501  Training Accuracy:0.8887061403508771\n",
            "1824/4708 - The training loss at 23th epoch : 0.0837067212152115  Training Accuracy:0.8885869565217391\n",
            "1840/4708 - The training loss at 23th epoch : 0.08431063862017427  Training Accuracy:0.8879310344827587\n",
            "1856/4708 - The training loss at 23th epoch : 0.0848093859036117  Training Accuracy:0.8872863247863247\n",
            "1872/4708 - The training loss at 23th epoch : 0.08422143018462067  Training Accuracy:0.8882415254237288\n",
            "1888/4708 - The training loss at 23th epoch : 0.08397977974057699  Training Accuracy:0.8886554621848739\n",
            "1904/4708 - The training loss at 23th epoch : 0.08353232995070116  Training Accuracy:0.8895833333333333\n",
            "1920/4708 - The training loss at 23th epoch : 0.08296630968976366  Training Accuracy:0.890495867768595\n",
            "1936/4708 - The training loss at 23th epoch : 0.08285831010972398  Training Accuracy:0.8903688524590164\n",
            "1952/4708 - The training loss at 23th epoch : 0.08302230975992951  Training Accuracy:0.8902439024390244\n",
            "1968/4708 - The training loss at 23th epoch : 0.0827269185043587  Training Accuracy:0.890625\n",
            "1984/4708 - The training loss at 23th epoch : 0.08231797776010193  Training Accuracy:0.891\n",
            "2000/4708 - The training loss at 23th epoch : 0.08213616769263646  Training Accuracy:0.8908730158730159\n",
            "2016/4708 - The training loss at 23th epoch : 0.08180129594806873  Training Accuracy:0.8912401574803149\n",
            "2032/4708 - The training loss at 23th epoch : 0.08167955760839904  Training Accuracy:0.89111328125\n",
            "2048/4708 - The training loss at 23th epoch : 0.0817946274221345  Training Accuracy:0.8905038759689923\n",
            "2064/4708 - The training loss at 23th epoch : 0.08162865001456814  Training Accuracy:0.8908653846153847\n",
            "2080/4708 - The training loss at 23th epoch : 0.08182335985873652  Training Accuracy:0.8907442748091603\n",
            "2096/4708 - The training loss at 23th epoch : 0.08167709667731127  Training Accuracy:0.890625\n",
            "2112/4708 - The training loss at 23th epoch : 0.08159429150043049  Training Accuracy:0.8909774436090225\n",
            "2128/4708 - The training loss at 23th epoch : 0.08163731501544698  Training Accuracy:0.8908582089552238\n",
            "2144/4708 - The training loss at 23th epoch : 0.08216092977752186  Training Accuracy:0.8902777777777777\n",
            "2160/4708 - The training loss at 23th epoch : 0.08243377249994362  Training Accuracy:0.8901654411764706\n",
            "2176/4708 - The training loss at 23th epoch : 0.08206983951193944  Training Accuracy:0.8909671532846716\n",
            "2192/4708 - The training loss at 23th epoch : 0.08235555311559209  Training Accuracy:0.8899456521739131\n",
            "2208/4708 - The training loss at 23th epoch : 0.08248021731501053  Training Accuracy:0.8898381294964028\n",
            "2224/4708 - The training loss at 23th epoch : 0.08360502050920361  Training Accuracy:0.8883928571428571\n",
            "2240/4708 - The training loss at 23th epoch : 0.08313697889777352  Training Accuracy:0.8891843971631206\n",
            "2256/4708 - The training loss at 23th epoch : 0.08313968288058361  Training Accuracy:0.889524647887324\n",
            "2272/4708 - The training loss at 23th epoch : 0.08361770360921654  Training Accuracy:0.888548951048951\n",
            "2288/4708 - The training loss at 23th epoch : 0.08373833932740087  Training Accuracy:0.8880208333333334\n",
            "2304/4708 - The training loss at 23th epoch : 0.08343822346894346  Training Accuracy:0.8883620689655173\n",
            "2320/4708 - The training loss at 23th epoch : 0.08319024883917565  Training Accuracy:0.8886986301369864\n",
            "2336/4708 - The training loss at 23th epoch : 0.08324849285771088  Training Accuracy:0.8886054421768708\n",
            "2352/4708 - The training loss at 23th epoch : 0.08302497608054199  Training Accuracy:0.8889358108108109\n",
            "2368/4708 - The training loss at 23th epoch : 0.08339190197558163  Training Accuracy:0.888003355704698\n",
            "2384/4708 - The training loss at 23th epoch : 0.08347118957511983  Training Accuracy:0.8879166666666667\n",
            "2400/4708 - The training loss at 23th epoch : 0.08301075257264436  Training Accuracy:0.8886589403973509\n",
            "2416/4708 - The training loss at 23th epoch : 0.08289394844627347  Training Accuracy:0.8889802631578947\n",
            "2432/4708 - The training loss at 23th epoch : 0.08314396876251662  Training Accuracy:0.8884803921568627\n",
            "2448/4708 - The training loss at 23th epoch : 0.08333219426661022  Training Accuracy:0.8883928571428571\n",
            "2464/4708 - The training loss at 23th epoch : 0.08371644744846278  Training Accuracy:0.8879032258064516\n",
            "2480/4708 - The training loss at 23th epoch : 0.08362792336799665  Training Accuracy:0.8882211538461539\n",
            "2496/4708 - The training loss at 23th epoch : 0.08346418101026745  Training Accuracy:0.8881369426751592\n",
            "2512/4708 - The training loss at 23th epoch : 0.08312779297670557  Training Accuracy:0.8888449367088608\n",
            "2528/4708 - The training loss at 23th epoch : 0.08369240164209969  Training Accuracy:0.8875786163522013\n",
            "2544/4708 - The training loss at 23th epoch : 0.08338840187554489  Training Accuracy:0.887890625\n",
            "2560/4708 - The training loss at 23th epoch : 0.08369898190065367  Training Accuracy:0.8874223602484472\n",
            "2576/4708 - The training loss at 23th epoch : 0.08378965070664905  Training Accuracy:0.8873456790123457\n",
            "2592/4708 - The training loss at 23th epoch : 0.08396734612217101  Training Accuracy:0.8872699386503068\n",
            "2608/4708 - The training loss at 23th epoch : 0.08414889830585708  Training Accuracy:0.8871951219512195\n",
            "2624/4708 - The training loss at 23th epoch : 0.08446943856888342  Training Accuracy:0.8863636363636364\n",
            "2640/4708 - The training loss at 23th epoch : 0.08475451236212608  Training Accuracy:0.8855421686746988\n",
            "2656/4708 - The training loss at 23th epoch : 0.08457559781535379  Training Accuracy:0.8858532934131736\n",
            "2672/4708 - The training loss at 23th epoch : 0.08454621313462404  Training Accuracy:0.8861607142857143\n",
            "2688/4708 - The training loss at 23th epoch : 0.08435032803520781  Training Accuracy:0.8864644970414202\n",
            "2704/4708 - The training loss at 23th epoch : 0.08434679945235551  Training Accuracy:0.8860294117647058\n",
            "2720/4708 - The training loss at 23th epoch : 0.08510574180334676  Training Accuracy:0.8848684210526315\n",
            "2736/4708 - The training loss at 23th epoch : 0.08501726841904035  Training Accuracy:0.8851744186046512\n",
            "2752/4708 - The training loss at 23th epoch : 0.0848778089925029  Training Accuracy:0.8854768786127167\n",
            "2768/4708 - The training loss at 23th epoch : 0.08479851763862847  Training Accuracy:0.8857758620689655\n",
            "2784/4708 - The training loss at 23th epoch : 0.08500109228312426  Training Accuracy:0.885\n",
            "2800/4708 - The training loss at 23th epoch : 0.084970788293462  Training Accuracy:0.8852982954545454\n",
            "2816/4708 - The training loss at 23th epoch : 0.0846690083940283  Training Accuracy:0.8859463276836158\n",
            "2832/4708 - The training loss at 23th epoch : 0.0842620056605494  Training Accuracy:0.8865870786516854\n",
            "2848/4708 - The training loss at 23th epoch : 0.08391143404610078  Training Accuracy:0.8872206703910615\n",
            "2864/4708 - The training loss at 23th epoch : 0.08350082346928307  Training Accuracy:0.8878472222222222\n",
            "2880/4708 - The training loss at 23th epoch : 0.08308297285289575  Training Accuracy:0.8884668508287292\n",
            "2896/4708 - The training loss at 23th epoch : 0.08385970118081011  Training Accuracy:0.8877060439560439\n",
            "2912/4708 - The training loss at 23th epoch : 0.0836678217743824  Training Accuracy:0.8883196721311475\n",
            "2928/4708 - The training loss at 23th epoch : 0.0832500094407309  Training Accuracy:0.8889266304347826\n",
            "2944/4708 - The training loss at 23th epoch : 0.08288957924743866  Training Accuracy:0.889527027027027\n",
            "2960/4708 - The training loss at 23th epoch : 0.08298379068202806  Training Accuracy:0.8891129032258065\n",
            "2976/4708 - The training loss at 23th epoch : 0.0833936970246649  Training Accuracy:0.8883689839572193\n",
            "2992/4708 - The training loss at 23th epoch : 0.08315811739365654  Training Accuracy:0.8886303191489362\n",
            "3008/4708 - The training loss at 23th epoch : 0.08298943833915946  Training Accuracy:0.8888888888888888\n",
            "3024/4708 - The training loss at 23th epoch : 0.08302355354878947  Training Accuracy:0.8888157894736842\n",
            "3040/4708 - The training loss at 23th epoch : 0.08272658437833091  Training Accuracy:0.8893979057591623\n",
            "3056/4708 - The training loss at 23th epoch : 0.08321247147482402  Training Accuracy:0.8889973958333334\n",
            "3072/4708 - The training loss at 23th epoch : 0.08303129910403798  Training Accuracy:0.8892487046632125\n",
            "3088/4708 - The training loss at 23th epoch : 0.08316167446975785  Training Accuracy:0.8891752577319587\n",
            "3104/4708 - The training loss at 23th epoch : 0.08302455085344118  Training Accuracy:0.8894230769230769\n",
            "3120/4708 - The training loss at 23th epoch : 0.08269801356086172  Training Accuracy:0.8899872448979592\n",
            "3136/4708 - The training loss at 23th epoch : 0.08316181861646123  Training Accuracy:0.8892766497461929\n",
            "3152/4708 - The training loss at 23th epoch : 0.08316236518474097  Training Accuracy:0.8892045454545454\n",
            "3168/4708 - The training loss at 23th epoch : 0.08318678498405242  Training Accuracy:0.8891331658291457\n",
            "3184/4708 - The training loss at 23th epoch : 0.0830193999817123  Training Accuracy:0.889375\n",
            "3200/4708 - The training loss at 23th epoch : 0.08263799057070663  Training Accuracy:0.8899253731343284\n",
            "3216/4708 - The training loss at 23th epoch : 0.08266828323778719  Training Accuracy:0.8898514851485149\n",
            "3232/4708 - The training loss at 23th epoch : 0.08335296197706157  Training Accuracy:0.8888546798029556\n",
            "3248/4708 - The training loss at 23th epoch : 0.08320417224546826  Training Accuracy:0.8890931372549019\n",
            "3264/4708 - The training loss at 23th epoch : 0.08359178176737844  Training Accuracy:0.8887195121951219\n",
            "3280/4708 - The training loss at 23th epoch : 0.08375011603610065  Training Accuracy:0.8886529126213593\n",
            "3296/4708 - The training loss at 23th epoch : 0.08356971170343318  Training Accuracy:0.8888888888888888\n",
            "3312/4708 - The training loss at 23th epoch : 0.08378147757956479  Training Accuracy:0.8885216346153846\n",
            "3328/4708 - The training loss at 23th epoch : 0.08385158570771609  Training Accuracy:0.8884569377990431\n",
            "3344/4708 - The training loss at 23th epoch : 0.08384084935141231  Training Accuracy:0.8883928571428571\n",
            "3360/4708 - The training loss at 23th epoch : 0.08396291162461425  Training Accuracy:0.8883293838862559\n",
            "3376/4708 - The training loss at 23th epoch : 0.08383987895084831  Training Accuracy:0.8882665094339622\n",
            "3392/4708 - The training loss at 23th epoch : 0.08422653024576347  Training Accuracy:0.8876173708920188\n",
            "3408/4708 - The training loss at 23th epoch : 0.08462210890559581  Training Accuracy:0.8872663551401869\n",
            "3424/4708 - The training loss at 23th epoch : 0.08473913876590541  Training Accuracy:0.8872093023255814\n",
            "3440/4708 - The training loss at 23th epoch : 0.08458183017809165  Training Accuracy:0.8874421296296297\n",
            "3456/4708 - The training loss at 23th epoch : 0.08446382521354893  Training Accuracy:0.8873847926267281\n",
            "3472/4708 - The training loss at 23th epoch : 0.08416227037437259  Training Accuracy:0.887901376146789\n",
            "3488/4708 - The training loss at 23th epoch : 0.08410376391949645  Training Accuracy:0.8881278538812786\n",
            "3504/4708 - The training loss at 23th epoch : 0.08399140122195448  Training Accuracy:0.8880681818181818\n",
            "3520/4708 - The training loss at 23th epoch : 0.08403231377699363  Training Accuracy:0.8880090497737556\n",
            "3536/4708 - The training loss at 23th epoch : 0.08420407035836365  Training Accuracy:0.887668918918919\n",
            "3552/4708 - The training loss at 23th epoch : 0.0841945902870313  Training Accuracy:0.8873318385650224\n",
            "3568/4708 - The training loss at 23th epoch : 0.08410770793899427  Training Accuracy:0.8875558035714286\n",
            "3584/4708 - The training loss at 23th epoch : 0.08418001798976406  Training Accuracy:0.8875\n",
            "3600/4708 - The training loss at 23th epoch : 0.08419869498795837  Training Accuracy:0.8874446902654868\n",
            "3616/4708 - The training loss at 23th epoch : 0.08454022718952138  Training Accuracy:0.8868392070484582\n",
            "3632/4708 - The training loss at 23th epoch : 0.08479013100061943  Training Accuracy:0.8865131578947368\n",
            "3648/4708 - The training loss at 23th epoch : 0.08473085752684638  Training Accuracy:0.8864628820960698\n",
            "3664/4708 - The training loss at 23th epoch : 0.08453427783242476  Training Accuracy:0.8866847826086957\n",
            "3680/4708 - The training loss at 23th epoch : 0.08424863842482384  Training Accuracy:0.8871753246753247\n",
            "3696/4708 - The training loss at 23th epoch : 0.08404657616011306  Training Accuracy:0.8873922413793104\n",
            "3712/4708 - The training loss at 23th epoch : 0.08380634098946706  Training Accuracy:0.887607296137339\n",
            "3728/4708 - The training loss at 23th epoch : 0.08396663471198965  Training Accuracy:0.8870192307692307\n",
            "3744/4708 - The training loss at 23th epoch : 0.08421027459853758  Training Accuracy:0.886436170212766\n",
            "3760/4708 - The training loss at 23th epoch : 0.08412098138353961  Training Accuracy:0.8863877118644068\n",
            "3776/4708 - The training loss at 23th epoch : 0.08411192778301442  Training Accuracy:0.8866033755274262\n",
            "3792/4708 - The training loss at 23th epoch : 0.08389671795266279  Training Accuracy:0.8870798319327731\n",
            "3808/4708 - The training loss at 23th epoch : 0.08392019229873723  Training Accuracy:0.8870292887029289\n",
            "3824/4708 - The training loss at 23th epoch : 0.08402375392792175  Training Accuracy:0.88671875\n",
            "3840/4708 - The training loss at 23th epoch : 0.08436357486962331  Training Accuracy:0.8864107883817427\n",
            "3856/4708 - The training loss at 23th epoch : 0.08419990652053068  Training Accuracy:0.8866219008264463\n",
            "3872/4708 - The training loss at 23th epoch : 0.0843489556834954  Training Accuracy:0.8865740740740741\n",
            "3888/4708 - The training loss at 23th epoch : 0.08415117404717942  Training Accuracy:0.8867827868852459\n",
            "3904/4708 - The training loss at 23th epoch : 0.08399831595576326  Training Accuracy:0.8869897959183674\n",
            "3920/4708 - The training loss at 23th epoch : 0.08409741504282843  Training Accuracy:0.8869410569105691\n",
            "3936/4708 - The training loss at 23th epoch : 0.08407935833517392  Training Accuracy:0.8871457489878543\n",
            "3952/4708 - The training loss at 23th epoch : 0.0842594886236771  Training Accuracy:0.8870967741935484\n",
            "3968/4708 - The training loss at 23th epoch : 0.0840174908683803  Training Accuracy:0.8875502008032129\n",
            "3984/4708 - The training loss at 23th epoch : 0.08439038834995084  Training Accuracy:0.88725\n",
            "4000/4708 - The training loss at 23th epoch : 0.08467787984268715  Training Accuracy:0.8869521912350598\n",
            "4016/4708 - The training loss at 23th epoch : 0.08473501872158226  Training Accuracy:0.8869047619047619\n",
            "4032/4708 - The training loss at 23th epoch : 0.08511914090780111  Training Accuracy:0.8863636363636364\n",
            "4048/4708 - The training loss at 23th epoch : 0.08505162217260454  Training Accuracy:0.8863188976377953\n",
            "4064/4708 - The training loss at 23th epoch : 0.08524126755360283  Training Accuracy:0.8860294117647058\n",
            "4080/4708 - The training loss at 23th epoch : 0.08495516931199537  Training Accuracy:0.886474609375\n",
            "4096/4708 - The training loss at 23th epoch : 0.0850261902982756  Training Accuracy:0.8864299610894941\n",
            "4112/4708 - The training loss at 23th epoch : 0.0851898636520874  Training Accuracy:0.8859011627906976\n",
            "4128/4708 - The training loss at 23th epoch : 0.08539147181155277  Training Accuracy:0.8856177606177607\n",
            "4144/4708 - The training loss at 23th epoch : 0.08538640297340534  Training Accuracy:0.885576923076923\n",
            "4160/4708 - The training loss at 23th epoch : 0.08561489987501515  Training Accuracy:0.8852969348659003\n",
            "4176/4708 - The training loss at 23th epoch : 0.08551685169005764  Training Accuracy:0.8854961832061069\n",
            "4192/4708 - The training loss at 23th epoch : 0.08538626889110311  Training Accuracy:0.8856939163498099\n",
            "4208/4708 - The training loss at 23th epoch : 0.0852090934092413  Training Accuracy:0.8861268939393939\n",
            "4224/4708 - The training loss at 23th epoch : 0.08506048589497167  Training Accuracy:0.8860849056603773\n",
            "4240/4708 - The training loss at 23th epoch : 0.08491090684596729  Training Accuracy:0.8862781954887218\n",
            "4256/4708 - The training loss at 23th epoch : 0.08500035837348699  Training Accuracy:0.8864700374531835\n",
            "4272/4708 - The training loss at 23th epoch : 0.08504342748664853  Training Accuracy:0.8864272388059702\n",
            "4288/4708 - The training loss at 23th epoch : 0.0849876078677358  Training Accuracy:0.8866171003717472\n",
            "4304/4708 - The training loss at 23th epoch : 0.08535496373270494  Training Accuracy:0.8863425925925926\n",
            "4320/4708 - The training loss at 23th epoch : 0.08561265298457778  Training Accuracy:0.886070110701107\n",
            "4336/4708 - The training loss at 23th epoch : 0.08537694997098824  Training Accuracy:0.8864889705882353\n",
            "4352/4708 - The training loss at 23th epoch : 0.08538168291035204  Training Accuracy:0.8864468864468864\n",
            "4368/4708 - The training loss at 23th epoch : 0.08515381179780318  Training Accuracy:0.8868613138686131\n",
            "4384/4708 - The training loss at 23th epoch : 0.08556308537041159  Training Accuracy:0.8863636363636364\n",
            "4400/4708 - The training loss at 23th epoch : 0.08557926141436074  Training Accuracy:0.886322463768116\n",
            "4416/4708 - The training loss at 23th epoch : 0.08556146245192141  Training Accuracy:0.8860559566787004\n",
            "4432/4708 - The training loss at 23th epoch : 0.08570607532512722  Training Accuracy:0.8860161870503597\n",
            "4448/4708 - The training loss at 23th epoch : 0.0855272462317412  Training Accuracy:0.8864247311827957\n",
            "4464/4708 - The training loss at 23th epoch : 0.08528920509252573  Training Accuracy:0.8868303571428572\n",
            "4480/4708 - The training loss at 23th epoch : 0.08547850263456665  Training Accuracy:0.886788256227758\n",
            "4496/4708 - The training loss at 23th epoch : 0.08567387436502688  Training Accuracy:0.8865248226950354\n",
            "4512/4708 - The training loss at 23th epoch : 0.08569912601763768  Training Accuracy:0.8864840989399293\n",
            "4528/4708 - The training loss at 23th epoch : 0.08572571494736103  Training Accuracy:0.886443661971831\n",
            "4544/4708 - The training loss at 23th epoch : 0.08548619833967706  Training Accuracy:0.8868421052631579\n",
            "4560/4708 - The training loss at 23th epoch : 0.08523982384826863  Training Accuracy:0.8872377622377622\n",
            "4576/4708 - The training loss at 23th epoch : 0.08540867082518998  Training Accuracy:0.8869773519163763\n",
            "4592/4708 - The training loss at 23th epoch : 0.0852055747873015  Training Accuracy:0.8871527777777778\n",
            "4608/4708 - The training loss at 23th epoch : 0.08512176587622658  Training Accuracy:0.8871107266435986\n",
            "4624/4708 - The training loss at 23th epoch : 0.08556080830454026  Training Accuracy:0.8862068965517241\n",
            "4640/4708 - The training loss at 23th epoch : 0.08541230561530778  Training Accuracy:0.8863831615120275\n",
            "4656/4708 - The training loss at 23th epoch : 0.08535232798403762  Training Accuracy:0.8865582191780822\n",
            "4672/4708 - The training loss at 23th epoch : 0.08557399809828094  Training Accuracy:0.8863054607508533\n",
            "4688/4708 - The training loss at 23th epoch : 0.085606741213059  Training Accuracy:0.8862670068027211\n",
            "4704/4708 - The training loss at 23th epoch : 0.08541243619825119  Training Accuracy:0.8866525423728814\n",
            "4720/4708 - The training loss at 23th epoch : 0.08533880525760223  Training Accuracy:0.8868243243243243\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 24th epoch : 0.21745111716052773  Training Accuracy:0.75\n",
            "16/4708 - The training loss at 24th epoch : 0.18655474005036024  Training Accuracy:0.8125\n",
            "32/4708 - The training loss at 24th epoch : 0.14875030149180804  Training Accuracy:0.8333333333333334\n",
            "48/4708 - The training loss at 24th epoch : 0.14432276930907428  Training Accuracy:0.828125\n",
            "64/4708 - The training loss at 24th epoch : 0.12513351577686124  Training Accuracy:0.85\n",
            "80/4708 - The training loss at 24th epoch : 0.12006792364758208  Training Accuracy:0.84375\n",
            "96/4708 - The training loss at 24th epoch : 0.1065548320988579  Training Accuracy:0.8571428571428571\n",
            "112/4708 - The training loss at 24th epoch : 0.10827343296347004  Training Accuracy:0.8515625\n",
            "128/4708 - The training loss at 24th epoch : 0.10970025675607359  Training Accuracy:0.8402777777777778\n",
            "144/4708 - The training loss at 24th epoch : 0.10744833539032325  Training Accuracy:0.84375\n",
            "160/4708 - The training loss at 24th epoch : 0.1292096897825635  Training Accuracy:0.8068181818181818\n",
            "176/4708 - The training loss at 24th epoch : 0.12708874965783587  Training Accuracy:0.8125\n",
            "192/4708 - The training loss at 24th epoch : 0.11901046989670482  Training Accuracy:0.8269230769230769\n",
            "208/4708 - The training loss at 24th epoch : 0.11592943304762816  Training Accuracy:0.8303571428571429\n",
            "224/4708 - The training loss at 24th epoch : 0.11087152492298452  Training Accuracy:0.8375\n",
            "240/4708 - The training loss at 24th epoch : 0.10567133324766118  Training Accuracy:0.84765625\n",
            "256/4708 - The training loss at 24th epoch : 0.10085535164319565  Training Accuracy:0.8566176470588235\n",
            "272/4708 - The training loss at 24th epoch : 0.10448350806099269  Training Accuracy:0.8541666666666666\n",
            "288/4708 - The training loss at 24th epoch : 0.09982246069562876  Training Accuracy:0.8618421052631579\n",
            "304/4708 - The training loss at 24th epoch : 0.09645337646524346  Training Accuracy:0.86875\n",
            "320/4708 - The training loss at 24th epoch : 0.09347373075363376  Training Accuracy:0.8720238095238095\n",
            "336/4708 - The training loss at 24th epoch : 0.0911337338390692  Training Accuracy:0.875\n",
            "352/4708 - The training loss at 24th epoch : 0.09196091744598109  Training Accuracy:0.875\n",
            "368/4708 - The training loss at 24th epoch : 0.09155963143638812  Training Accuracy:0.8776041666666666\n",
            "384/4708 - The training loss at 24th epoch : 0.09118174029483214  Training Accuracy:0.8775\n",
            "400/4708 - The training loss at 24th epoch : 0.0938411678565467  Training Accuracy:0.8725961538461539\n",
            "416/4708 - The training loss at 24th epoch : 0.09582098316986551  Training Accuracy:0.8703703703703703\n",
            "432/4708 - The training loss at 24th epoch : 0.09671995342972084  Training Accuracy:0.8683035714285714\n",
            "448/4708 - The training loss at 24th epoch : 0.09529629424938081  Training Accuracy:0.8706896551724138\n",
            "464/4708 - The training loss at 24th epoch : 0.09771399089990859  Training Accuracy:0.86875\n",
            "480/4708 - The training loss at 24th epoch : 0.09688092897895134  Training Accuracy:0.8709677419354839\n",
            "496/4708 - The training loss at 24th epoch : 0.09707062802562182  Training Accuracy:0.869140625\n",
            "512/4708 - The training loss at 24th epoch : 0.0961837370480568  Training Accuracy:0.8712121212121212\n",
            "528/4708 - The training loss at 24th epoch : 0.09927236941661015  Training Accuracy:0.8676470588235294\n",
            "544/4708 - The training loss at 24th epoch : 0.09789666077538794  Training Accuracy:0.8714285714285714\n",
            "560/4708 - The training loss at 24th epoch : 0.09948975348457915  Training Accuracy:0.8680555555555556\n",
            "576/4708 - The training loss at 24th epoch : 0.09956343143258937  Training Accuracy:0.8665540540540541\n",
            "592/4708 - The training loss at 24th epoch : 0.09793133526541804  Training Accuracy:0.8700657894736842\n",
            "608/4708 - The training loss at 24th epoch : 0.09612159913272653  Training Accuracy:0.8717948717948718\n",
            "624/4708 - The training loss at 24th epoch : 0.098172637256602  Training Accuracy:0.8703125\n",
            "640/4708 - The training loss at 24th epoch : 0.09710451089677734  Training Accuracy:0.8719512195121951\n",
            "656/4708 - The training loss at 24th epoch : 0.10030023477879692  Training Accuracy:0.8660714285714286\n",
            "672/4708 - The training loss at 24th epoch : 0.09860963030331171  Training Accuracy:0.8691860465116279\n",
            "688/4708 - The training loss at 24th epoch : 0.09712594110022987  Training Accuracy:0.8721590909090909\n",
            "704/4708 - The training loss at 24th epoch : 0.09508594743854207  Training Accuracy:0.875\n",
            "720/4708 - The training loss at 24th epoch : 0.09478815801908212  Training Accuracy:0.875\n",
            "736/4708 - The training loss at 24th epoch : 0.09489292114454721  Training Accuracy:0.875\n",
            "752/4708 - The training loss at 24th epoch : 0.0946087799508515  Training Accuracy:0.875\n",
            "768/4708 - The training loss at 24th epoch : 0.09368058910613143  Training Accuracy:0.8762755102040817\n",
            "784/4708 - The training loss at 24th epoch : 0.09398208900531145  Training Accuracy:0.875\n",
            "800/4708 - The training loss at 24th epoch : 0.09277234582630012  Training Accuracy:0.8762254901960784\n",
            "816/4708 - The training loss at 24th epoch : 0.09389237473482717  Training Accuracy:0.875\n",
            "832/4708 - The training loss at 24th epoch : 0.09339039963528903  Training Accuracy:0.875\n",
            "848/4708 - The training loss at 24th epoch : 0.09303697284812827  Training Accuracy:0.875\n",
            "864/4708 - The training loss at 24th epoch : 0.09330312479836327  Training Accuracy:0.8738636363636364\n",
            "880/4708 - The training loss at 24th epoch : 0.09324407952193872  Training Accuracy:0.8738839285714286\n",
            "896/4708 - The training loss at 24th epoch : 0.09308067252667725  Training Accuracy:0.8739035087719298\n",
            "912/4708 - The training loss at 24th epoch : 0.09440687950504392  Training Accuracy:0.8728448275862069\n",
            "928/4708 - The training loss at 24th epoch : 0.0956648270187923  Training Accuracy:0.871822033898305\n",
            "944/4708 - The training loss at 24th epoch : 0.09452835601397863  Training Accuracy:0.8729166666666667\n",
            "960/4708 - The training loss at 24th epoch : 0.09328024406473331  Training Accuracy:0.875\n",
            "976/4708 - The training loss at 24th epoch : 0.09368321286230896  Training Accuracy:0.875\n",
            "992/4708 - The training loss at 24th epoch : 0.09392400906125335  Training Accuracy:0.8740079365079365\n",
            "1008/4708 - The training loss at 24th epoch : 0.09290844746293707  Training Accuracy:0.875\n",
            "1024/4708 - The training loss at 24th epoch : 0.09239305372882962  Training Accuracy:0.8759615384615385\n",
            "1040/4708 - The training loss at 24th epoch : 0.09257067625067875  Training Accuracy:0.8759469696969697\n",
            "1056/4708 - The training loss at 24th epoch : 0.09138109118483767  Training Accuracy:0.8777985074626866\n",
            "1072/4708 - The training loss at 24th epoch : 0.09082166624952381  Training Accuracy:0.8786764705882353\n",
            "1088/4708 - The training loss at 24th epoch : 0.09155150175867435  Training Accuracy:0.8777173913043478\n",
            "1104/4708 - The training loss at 24th epoch : 0.09096743738641097  Training Accuracy:0.8785714285714286\n",
            "1120/4708 - The training loss at 24th epoch : 0.09042361073119824  Training Accuracy:0.8794014084507042\n",
            "1136/4708 - The training loss at 24th epoch : 0.09075821556108289  Training Accuracy:0.8784722222222222\n",
            "1152/4708 - The training loss at 24th epoch : 0.09021153441581559  Training Accuracy:0.8792808219178082\n",
            "1168/4708 - The training loss at 24th epoch : 0.09006532048547297  Training Accuracy:0.8800675675675675\n",
            "1184/4708 - The training loss at 24th epoch : 0.09013593344131264  Training Accuracy:0.8808333333333334\n",
            "1200/4708 - The training loss at 24th epoch : 0.0891773995250702  Training Accuracy:0.8824013157894737\n",
            "1216/4708 - The training loss at 24th epoch : 0.08944159096250623  Training Accuracy:0.8814935064935064\n",
            "1232/4708 - The training loss at 24th epoch : 0.08858001567768453  Training Accuracy:0.8830128205128205\n",
            "1248/4708 - The training loss at 24th epoch : 0.08902982355375745  Training Accuracy:0.882120253164557\n",
            "1264/4708 - The training loss at 24th epoch : 0.08900398462561346  Training Accuracy:0.88203125\n",
            "1280/4708 - The training loss at 24th epoch : 0.08898202511346168  Training Accuracy:0.8811728395061729\n",
            "1296/4708 - The training loss at 24th epoch : 0.08826553689273203  Training Accuracy:0.8826219512195121\n",
            "1312/4708 - The training loss at 24th epoch : 0.08887572105321911  Training Accuracy:0.8810240963855421\n",
            "1328/4708 - The training loss at 24th epoch : 0.08876767859634035  Training Accuracy:0.8816964285714286\n",
            "1344/4708 - The training loss at 24th epoch : 0.08901545429777442  Training Accuracy:0.8808823529411764\n",
            "1360/4708 - The training loss at 24th epoch : 0.0888126604208295  Training Accuracy:0.8815406976744186\n",
            "1376/4708 - The training loss at 24th epoch : 0.08801660681290922  Training Accuracy:0.8829022988505747\n",
            "1392/4708 - The training loss at 24th epoch : 0.0882236992671385  Training Accuracy:0.8821022727272727\n",
            "1408/4708 - The training loss at 24th epoch : 0.08792892865307836  Training Accuracy:0.8827247191011236\n",
            "1424/4708 - The training loss at 24th epoch : 0.08772130551003  Training Accuracy:0.8833333333333333\n",
            "1440/4708 - The training loss at 24th epoch : 0.08693034188027352  Training Accuracy:0.8846153846153846\n",
            "1456/4708 - The training loss at 24th epoch : 0.0872341336958483  Training Accuracy:0.8838315217391305\n",
            "1472/4708 - The training loss at 24th epoch : 0.08735196914461936  Training Accuracy:0.883736559139785\n",
            "1488/4708 - The training loss at 24th epoch : 0.08798157320964924  Training Accuracy:0.8829787234042553\n",
            "1504/4708 - The training loss at 24th epoch : 0.08808435311361185  Training Accuracy:0.8828947368421053\n",
            "1520/4708 - The training loss at 24th epoch : 0.08802470949890621  Training Accuracy:0.8834635416666666\n",
            "1536/4708 - The training loss at 24th epoch : 0.08796356240551921  Training Accuracy:0.884020618556701\n",
            "1552/4708 - The training loss at 24th epoch : 0.08749165609667746  Training Accuracy:0.8845663265306123\n",
            "1568/4708 - The training loss at 24th epoch : 0.08728264324579775  Training Accuracy:0.88510101010101\n",
            "1584/4708 - The training loss at 24th epoch : 0.08681269093209558  Training Accuracy:0.88625\n",
            "1600/4708 - The training loss at 24th epoch : 0.08726909583636097  Training Accuracy:0.8849009900990099\n",
            "1616/4708 - The training loss at 24th epoch : 0.08667850389274959  Training Accuracy:0.8860294117647058\n",
            "1632/4708 - The training loss at 24th epoch : 0.08683391778022347  Training Accuracy:0.8859223300970874\n",
            "1648/4708 - The training loss at 24th epoch : 0.08708175943964556  Training Accuracy:0.8858173076923077\n",
            "1664/4708 - The training loss at 24th epoch : 0.08633293469893984  Training Accuracy:0.8869047619047619\n",
            "1680/4708 - The training loss at 24th epoch : 0.08573154115668179  Training Accuracy:0.8879716981132075\n",
            "1696/4708 - The training loss at 24th epoch : 0.08710561149322117  Training Accuracy:0.8855140186915887\n",
            "1712/4708 - The training loss at 24th epoch : 0.08655236438730889  Training Accuracy:0.8859953703703703\n",
            "1728/4708 - The training loss at 24th epoch : 0.08672090840286449  Training Accuracy:0.8853211009174312\n",
            "1744/4708 - The training loss at 24th epoch : 0.08678605211909159  Training Accuracy:0.8852272727272728\n",
            "1760/4708 - The training loss at 24th epoch : 0.08658937498401657  Training Accuracy:0.8856981981981982\n",
            "1776/4708 - The training loss at 24th epoch : 0.08597862784889336  Training Accuracy:0.88671875\n",
            "1792/4708 - The training loss at 24th epoch : 0.08600430410735647  Training Accuracy:0.8871681415929203\n",
            "1808/4708 - The training loss at 24th epoch : 0.0856403106686573  Training Accuracy:0.887609649122807\n",
            "1824/4708 - The training loss at 24th epoch : 0.08609792532603938  Training Accuracy:0.8858695652173914\n",
            "1840/4708 - The training loss at 24th epoch : 0.08613151673227082  Training Accuracy:0.8863146551724138\n",
            "1856/4708 - The training loss at 24th epoch : 0.08592306816432978  Training Accuracy:0.8867521367521367\n",
            "1872/4708 - The training loss at 24th epoch : 0.08544988647657553  Training Accuracy:0.8871822033898306\n",
            "1888/4708 - The training loss at 24th epoch : 0.085251185152159  Training Accuracy:0.8876050420168067\n",
            "1904/4708 - The training loss at 24th epoch : 0.08532047049874535  Training Accuracy:0.8869791666666667\n",
            "1920/4708 - The training loss at 24th epoch : 0.08547016224822024  Training Accuracy:0.8868801652892562\n",
            "1936/4708 - The training loss at 24th epoch : 0.08524769981493889  Training Accuracy:0.8872950819672131\n",
            "1952/4708 - The training loss at 24th epoch : 0.08494209983500245  Training Accuracy:0.8877032520325203\n",
            "1968/4708 - The training loss at 24th epoch : 0.0844062828384042  Training Accuracy:0.8886088709677419\n",
            "1984/4708 - The training loss at 24th epoch : 0.0849957355749593  Training Accuracy:0.888\n",
            "2000/4708 - The training loss at 24th epoch : 0.08602998614425235  Training Accuracy:0.8864087301587301\n",
            "2016/4708 - The training loss at 24th epoch : 0.08605265054199375  Training Accuracy:0.8863188976377953\n",
            "2032/4708 - The training loss at 24th epoch : 0.08658001958234685  Training Accuracy:0.8857421875\n",
            "2048/4708 - The training loss at 24th epoch : 0.08640798510702949  Training Accuracy:0.8861434108527132\n",
            "2064/4708 - The training loss at 24th epoch : 0.08644516780354554  Training Accuracy:0.8860576923076923\n",
            "2080/4708 - The training loss at 24th epoch : 0.08661817080752164  Training Accuracy:0.8859732824427481\n",
            "2096/4708 - The training loss at 24th epoch : 0.08708397336081491  Training Accuracy:0.8849431818181818\n",
            "2112/4708 - The training loss at 24th epoch : 0.08705402105383955  Training Accuracy:0.8848684210526315\n",
            "2128/4708 - The training loss at 24th epoch : 0.08741674556174024  Training Accuracy:0.8847947761194029\n",
            "2144/4708 - The training loss at 24th epoch : 0.0872525130610934  Training Accuracy:0.8847222222222222\n",
            "2160/4708 - The training loss at 24th epoch : 0.08700206816558416  Training Accuracy:0.8851102941176471\n",
            "2176/4708 - The training loss at 24th epoch : 0.08739308548701576  Training Accuracy:0.8841240875912408\n",
            "2192/4708 - The training loss at 24th epoch : 0.0875428426785084  Training Accuracy:0.8840579710144928\n",
            "2208/4708 - The training loss at 24th epoch : 0.0871051358856812  Training Accuracy:0.8844424460431655\n",
            "2224/4708 - The training loss at 24th epoch : 0.08716944724991547  Training Accuracy:0.8839285714285714\n",
            "2240/4708 - The training loss at 24th epoch : 0.08751724426485737  Training Accuracy:0.8829787234042553\n",
            "2256/4708 - The training loss at 24th epoch : 0.08785867090292407  Training Accuracy:0.8824823943661971\n",
            "2272/4708 - The training loss at 24th epoch : 0.0874910902630752  Training Accuracy:0.8833041958041958\n",
            "2288/4708 - The training loss at 24th epoch : 0.08759495245976007  Training Accuracy:0.8832465277777778\n",
            "2304/4708 - The training loss at 24th epoch : 0.08710864874487174  Training Accuracy:0.884051724137931\n",
            "2320/4708 - The training loss at 24th epoch : 0.08671206071043322  Training Accuracy:0.884417808219178\n",
            "2336/4708 - The training loss at 24th epoch : 0.0867577911357815  Training Accuracy:0.8843537414965986\n",
            "2352/4708 - The training loss at 24th epoch : 0.08672141204431304  Training Accuracy:0.8842905405405406\n",
            "2368/4708 - The training loss at 24th epoch : 0.08678726192065345  Training Accuracy:0.8842281879194631\n",
            "2384/4708 - The training loss at 24th epoch : 0.08683931670514523  Training Accuracy:0.8841666666666667\n",
            "2400/4708 - The training loss at 24th epoch : 0.08654718763030371  Training Accuracy:0.8849337748344371\n",
            "2416/4708 - The training loss at 24th epoch : 0.08646015220206382  Training Accuracy:0.8852796052631579\n",
            "2432/4708 - The training loss at 24th epoch : 0.08612413076015744  Training Accuracy:0.8856209150326797\n",
            "2448/4708 - The training loss at 24th epoch : 0.08638788106366181  Training Accuracy:0.8851461038961039\n",
            "2464/4708 - The training loss at 24th epoch : 0.08683167003182629  Training Accuracy:0.8846774193548387\n",
            "2480/4708 - The training loss at 24th epoch : 0.0867291223521529  Training Accuracy:0.8850160256410257\n",
            "2496/4708 - The training loss at 24th epoch : 0.08709649605243011  Training Accuracy:0.8845541401273885\n",
            "2512/4708 - The training loss at 24th epoch : 0.08685831284995668  Training Accuracy:0.8848892405063291\n",
            "2528/4708 - The training loss at 24th epoch : 0.08701024226651555  Training Accuracy:0.8848270440251572\n",
            "2544/4708 - The training loss at 24th epoch : 0.08669705990842043  Training Accuracy:0.88515625\n",
            "2560/4708 - The training loss at 24th epoch : 0.08661237092024274  Training Accuracy:0.8850931677018633\n",
            "2576/4708 - The training loss at 24th epoch : 0.08641994266133857  Training Accuracy:0.8854166666666666\n",
            "2592/4708 - The training loss at 24th epoch : 0.0864602752226674  Training Accuracy:0.8853527607361963\n",
            "2608/4708 - The training loss at 24th epoch : 0.08640041372348835  Training Accuracy:0.885670731707317\n",
            "2624/4708 - The training loss at 24th epoch : 0.08612353235882454  Training Accuracy:0.8859848484848485\n",
            "2640/4708 - The training loss at 24th epoch : 0.08660731218917996  Training Accuracy:0.8851656626506024\n",
            "2656/4708 - The training loss at 24th epoch : 0.08651767090134571  Training Accuracy:0.8854790419161677\n",
            "2672/4708 - The training loss at 24th epoch : 0.08637341315617439  Training Accuracy:0.8854166666666666\n",
            "2688/4708 - The training loss at 24th epoch : 0.08620561673133721  Training Accuracy:0.8857248520710059\n",
            "2704/4708 - The training loss at 24th epoch : 0.08583380985276517  Training Accuracy:0.8863970588235294\n",
            "2720/4708 - The training loss at 24th epoch : 0.08539056663678606  Training Accuracy:0.8870614035087719\n",
            "2736/4708 - The training loss at 24th epoch : 0.08535525843153968  Training Accuracy:0.8869912790697675\n",
            "2752/4708 - The training loss at 24th epoch : 0.08510655442119788  Training Accuracy:0.8872832369942196\n",
            "2768/4708 - The training loss at 24th epoch : 0.08513243766696987  Training Accuracy:0.8872126436781609\n",
            "2784/4708 - The training loss at 24th epoch : 0.08506789042712304  Training Accuracy:0.8871428571428571\n",
            "2800/4708 - The training loss at 24th epoch : 0.08510428031859484  Training Accuracy:0.8874289772727273\n",
            "2816/4708 - The training loss at 24th epoch : 0.0853662106283459  Training Accuracy:0.8870056497175142\n",
            "2832/4708 - The training loss at 24th epoch : 0.08561486258828592  Training Accuracy:0.8862359550561798\n",
            "2848/4708 - The training loss at 24th epoch : 0.08586021058012962  Training Accuracy:0.8861731843575419\n",
            "2864/4708 - The training loss at 24th epoch : 0.08553318454660795  Training Accuracy:0.8864583333333333\n",
            "2880/4708 - The training loss at 24th epoch : 0.08572997864061567  Training Accuracy:0.886049723756906\n",
            "2896/4708 - The training loss at 24th epoch : 0.0857135158351722  Training Accuracy:0.8856456043956044\n",
            "2912/4708 - The training loss at 24th epoch : 0.08632339812725745  Training Accuracy:0.8838797814207651\n",
            "2928/4708 - The training loss at 24th epoch : 0.08602141781943272  Training Accuracy:0.884171195652174\n",
            "2944/4708 - The training loss at 24th epoch : 0.08579065677846144  Training Accuracy:0.8844594594594595\n",
            "2960/4708 - The training loss at 24th epoch : 0.08576408700336852  Training Accuracy:0.8844086021505376\n",
            "2976/4708 - The training loss at 24th epoch : 0.08570713189920709  Training Accuracy:0.8846925133689839\n",
            "2992/4708 - The training loss at 24th epoch : 0.08553685999686539  Training Accuracy:0.8849734042553191\n",
            "3008/4708 - The training loss at 24th epoch : 0.08587424451201693  Training Accuracy:0.8845899470899471\n",
            "3024/4708 - The training loss at 24th epoch : 0.08553050246521768  Training Accuracy:0.8851973684210527\n",
            "3040/4708 - The training loss at 24th epoch : 0.0853409298817747  Training Accuracy:0.8854712041884817\n",
            "3056/4708 - The training loss at 24th epoch : 0.08536516697257619  Training Accuracy:0.8854166666666666\n",
            "3072/4708 - The training loss at 24th epoch : 0.0852386086211023  Training Accuracy:0.8853626943005182\n",
            "3088/4708 - The training loss at 24th epoch : 0.08481907061000195  Training Accuracy:0.8859536082474226\n",
            "3104/4708 - The training loss at 24th epoch : 0.08453327825309054  Training Accuracy:0.8865384615384615\n",
            "3120/4708 - The training loss at 24th epoch : 0.08471307602252902  Training Accuracy:0.8861607142857143\n",
            "3136/4708 - The training loss at 24th epoch : 0.08440076726566866  Training Accuracy:0.886738578680203\n",
            "3152/4708 - The training loss at 24th epoch : 0.08444951351700052  Training Accuracy:0.8866792929292929\n",
            "3168/4708 - The training loss at 24th epoch : 0.08446086839017591  Training Accuracy:0.8866206030150754\n",
            "3184/4708 - The training loss at 24th epoch : 0.08571878075294881  Training Accuracy:0.885\n",
            "3200/4708 - The training loss at 24th epoch : 0.08569991552892639  Training Accuracy:0.8852611940298507\n",
            "3216/4708 - The training loss at 24th epoch : 0.08542668164060634  Training Accuracy:0.885519801980198\n",
            "3232/4708 - The training loss at 24th epoch : 0.085794253238324  Training Accuracy:0.8851600985221675\n",
            "3248/4708 - The training loss at 24th epoch : 0.08574223687300116  Training Accuracy:0.8854166666666666\n",
            "3264/4708 - The training loss at 24th epoch : 0.08575483414224407  Training Accuracy:0.8853658536585366\n",
            "3280/4708 - The training loss at 24th epoch : 0.0862031492877778  Training Accuracy:0.8844053398058253\n",
            "3296/4708 - The training loss at 24th epoch : 0.08635088787641987  Training Accuracy:0.8843599033816425\n",
            "3312/4708 - The training loss at 24th epoch : 0.08671009524607068  Training Accuracy:0.8837139423076923\n",
            "3328/4708 - The training loss at 24th epoch : 0.0867083299191881  Training Accuracy:0.8836722488038278\n",
            "3344/4708 - The training loss at 24th epoch : 0.08671716866094124  Training Accuracy:0.8839285714285714\n",
            "3360/4708 - The training loss at 24th epoch : 0.08674913194031995  Training Accuracy:0.8838862559241706\n",
            "3376/4708 - The training loss at 24th epoch : 0.08678248067341209  Training Accuracy:0.8838443396226415\n",
            "3392/4708 - The training loss at 24th epoch : 0.08666534339807398  Training Accuracy:0.8838028169014085\n",
            "3408/4708 - The training loss at 24th epoch : 0.08699618912111214  Training Accuracy:0.883177570093458\n",
            "3424/4708 - The training loss at 24th epoch : 0.08680656938954384  Training Accuracy:0.8834302325581396\n",
            "3440/4708 - The training loss at 24th epoch : 0.0868759215146613  Training Accuracy:0.8833912037037037\n",
            "3456/4708 - The training loss at 24th epoch : 0.08661060577564789  Training Accuracy:0.8836405529953917\n",
            "3472/4708 - The training loss at 24th epoch : 0.08650965481382608  Training Accuracy:0.8833142201834863\n",
            "3488/4708 - The training loss at 24th epoch : 0.08631335006653235  Training Accuracy:0.8835616438356164\n",
            "3504/4708 - The training loss at 24th epoch : 0.08672411510048991  Training Accuracy:0.8829545454545454\n",
            "3520/4708 - The training loss at 24th epoch : 0.08642382555285189  Training Accuracy:0.8834841628959276\n",
            "3536/4708 - The training loss at 24th epoch : 0.0862609112072224  Training Accuracy:0.8834459459459459\n",
            "3552/4708 - The training loss at 24th epoch : 0.08606762293002963  Training Accuracy:0.8836883408071748\n",
            "3568/4708 - The training loss at 24th epoch : 0.08620114466683233  Training Accuracy:0.8836495535714286\n",
            "3584/4708 - The training loss at 24th epoch : 0.085857502630371  Training Accuracy:0.8841666666666667\n",
            "3600/4708 - The training loss at 24th epoch : 0.08607860588769864  Training Accuracy:0.8835730088495575\n",
            "3616/4708 - The training loss at 24th epoch : 0.08617988913518752  Training Accuracy:0.8835352422907489\n",
            "3632/4708 - The training loss at 24th epoch : 0.08628782907897219  Training Accuracy:0.8834978070175439\n",
            "3648/4708 - The training loss at 24th epoch : 0.08645238469030692  Training Accuracy:0.8831877729257642\n",
            "3664/4708 - The training loss at 24th epoch : 0.08635047240442598  Training Accuracy:0.8834239130434782\n",
            "3680/4708 - The training loss at 24th epoch : 0.08616720697424123  Training Accuracy:0.8836580086580087\n",
            "3696/4708 - The training loss at 24th epoch : 0.08589002638767201  Training Accuracy:0.8841594827586207\n",
            "3712/4708 - The training loss at 24th epoch : 0.08588880874605104  Training Accuracy:0.8843884120171673\n",
            "3728/4708 - The training loss at 24th epoch : 0.08570188465344072  Training Accuracy:0.8846153846153846\n",
            "3744/4708 - The training loss at 24th epoch : 0.08569657642996784  Training Accuracy:0.8845744680851064\n",
            "3760/4708 - The training loss at 24th epoch : 0.08555668872401993  Training Accuracy:0.8847987288135594\n",
            "3776/4708 - The training loss at 24th epoch : 0.08543550473760092  Training Accuracy:0.8847573839662447\n",
            "3792/4708 - The training loss at 24th epoch : 0.08580597137646007  Training Accuracy:0.884453781512605\n",
            "3808/4708 - The training loss at 24th epoch : 0.08554206407372335  Training Accuracy:0.8849372384937239\n",
            "3824/4708 - The training loss at 24th epoch : 0.085615084570246  Training Accuracy:0.8846354166666667\n",
            "3840/4708 - The training loss at 24th epoch : 0.08530631518843597  Training Accuracy:0.8851141078838174\n",
            "3856/4708 - The training loss at 24th epoch : 0.08586519528268577  Training Accuracy:0.8842975206611571\n",
            "3872/4708 - The training loss at 24th epoch : 0.08579663162740049  Training Accuracy:0.8842592592592593\n",
            "3888/4708 - The training loss at 24th epoch : 0.08615867770294725  Training Accuracy:0.8839651639344263\n",
            "3904/4708 - The training loss at 24th epoch : 0.08601304836131363  Training Accuracy:0.8841836734693878\n",
            "3920/4708 - The training loss at 24th epoch : 0.08634400099398037  Training Accuracy:0.8833841463414634\n",
            "3936/4708 - The training loss at 24th epoch : 0.08612579104010654  Training Accuracy:0.8836032388663968\n",
            "3952/4708 - The training loss at 24th epoch : 0.08636237948211417  Training Accuracy:0.8833165322580645\n",
            "3968/4708 - The training loss at 24th epoch : 0.08614028218776137  Training Accuracy:0.883785140562249\n",
            "3984/4708 - The training loss at 24th epoch : 0.08606013199579562  Training Accuracy:0.88375\n",
            "4000/4708 - The training loss at 24th epoch : 0.08629240553895749  Training Accuracy:0.8832171314741036\n",
            "4016/4708 - The training loss at 24th epoch : 0.08610016864297644  Training Accuracy:0.8836805555555556\n",
            "4032/4708 - The training loss at 24th epoch : 0.08629943035560121  Training Accuracy:0.8836462450592886\n",
            "4048/4708 - The training loss at 24th epoch : 0.08632615601804941  Training Accuracy:0.8833661417322834\n",
            "4064/4708 - The training loss at 24th epoch : 0.08625162796838758  Training Accuracy:0.8833333333333333\n",
            "4080/4708 - The training loss at 24th epoch : 0.08623795567151528  Training Accuracy:0.88330078125\n",
            "4096/4708 - The training loss at 24th epoch : 0.08635683826986171  Training Accuracy:0.8832684824902723\n",
            "4112/4708 - The training loss at 24th epoch : 0.08636656103894223  Training Accuracy:0.8832364341085271\n",
            "4128/4708 - The training loss at 24th epoch : 0.08672022089499856  Training Accuracy:0.8829633204633205\n",
            "4144/4708 - The training loss at 24th epoch : 0.08690111365765335  Training Accuracy:0.8829326923076923\n",
            "4160/4708 - The training loss at 24th epoch : 0.08678189554356838  Training Accuracy:0.8831417624521073\n",
            "4176/4708 - The training loss at 24th epoch : 0.08680640876791891  Training Accuracy:0.8831106870229007\n",
            "4192/4708 - The training loss at 24th epoch : 0.08676140113732328  Training Accuracy:0.8830798479087453\n",
            "4208/4708 - The training loss at 24th epoch : 0.08699817971359926  Training Accuracy:0.8828125\n",
            "4224/4708 - The training loss at 24th epoch : 0.08693639400322467  Training Accuracy:0.8827830188679245\n",
            "4240/4708 - The training loss at 24th epoch : 0.08685413428138948  Training Accuracy:0.8829887218045113\n",
            "4256/4708 - The training loss at 24th epoch : 0.0866848888333523  Training Accuracy:0.8829588014981273\n",
            "4272/4708 - The training loss at 24th epoch : 0.08655540975158005  Training Accuracy:0.8831623134328358\n",
            "4288/4708 - The training loss at 24th epoch : 0.08650807516275492  Training Accuracy:0.883364312267658\n",
            "4304/4708 - The training loss at 24th epoch : 0.08667763859859254  Training Accuracy:0.8833333333333333\n",
            "4320/4708 - The training loss at 24th epoch : 0.08654893502621074  Training Accuracy:0.8835332103321033\n",
            "4336/4708 - The training loss at 24th epoch : 0.08645621845563471  Training Accuracy:0.8837316176470589\n",
            "4352/4708 - The training loss at 24th epoch : 0.08650894921836023  Training Accuracy:0.8834706959706959\n",
            "4368/4708 - The training loss at 24th epoch : 0.08646366140380667  Training Accuracy:0.8836678832116789\n",
            "4384/4708 - The training loss at 24th epoch : 0.08666771756710914  Training Accuracy:0.8836363636363637\n",
            "4400/4708 - The training loss at 24th epoch : 0.0869934550900086  Training Accuracy:0.8831521739130435\n",
            "4416/4708 - The training loss at 24th epoch : 0.08679389849725731  Training Accuracy:0.8833483754512635\n",
            "4432/4708 - The training loss at 24th epoch : 0.08676474734723669  Training Accuracy:0.883318345323741\n",
            "4448/4708 - The training loss at 24th epoch : 0.08670375733408152  Training Accuracy:0.8835125448028673\n",
            "4464/4708 - The training loss at 24th epoch : 0.0868265221365162  Training Accuracy:0.8832589285714286\n",
            "4480/4708 - The training loss at 24th epoch : 0.08675557844791547  Training Accuracy:0.8832295373665481\n",
            "4496/4708 - The training loss at 24th epoch : 0.08666751847663842  Training Accuracy:0.8834219858156028\n",
            "4512/4708 - The training loss at 24th epoch : 0.08685589944387932  Training Accuracy:0.8831713780918727\n",
            "4528/4708 - The training loss at 24th epoch : 0.0870406184585129  Training Accuracy:0.8829225352112676\n",
            "4544/4708 - The training loss at 24th epoch : 0.08688859824223676  Training Accuracy:0.8831140350877194\n",
            "4560/4708 - The training loss at 24th epoch : 0.08660239485623848  Training Accuracy:0.8835227272727273\n",
            "4576/4708 - The training loss at 24th epoch : 0.08652212055551313  Training Accuracy:0.8837108013937283\n",
            "4592/4708 - The training loss at 24th epoch : 0.08670931257399087  Training Accuracy:0.8832465277777778\n",
            "4608/4708 - The training loss at 24th epoch : 0.08683487520177613  Training Accuracy:0.8832179930795848\n",
            "4624/4708 - The training loss at 24th epoch : 0.08695747882662073  Training Accuracy:0.8831896551724138\n",
            "4640/4708 - The training loss at 24th epoch : 0.08697426033821594  Training Accuracy:0.8831615120274914\n",
            "4656/4708 - The training loss at 24th epoch : 0.08694843507824841  Training Accuracy:0.883347602739726\n",
            "4672/4708 - The training loss at 24th epoch : 0.0869311328568453  Training Accuracy:0.8835324232081911\n",
            "4688/4708 - The training loss at 24th epoch : 0.0870442853275566  Training Accuracy:0.8832908163265306\n",
            "4704/4708 - The training loss at 24th epoch : 0.0870776391446665  Training Accuracy:0.8832627118644067\n",
            "4720/4708 - The training loss at 24th epoch : 0.08717616183221884  Training Accuracy:0.8832347972972973\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 25th epoch : 0.12155960947112948  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 25th epoch : 0.13705863235794416  Training Accuracy:0.8125\n",
            "32/4708 - The training loss at 25th epoch : 0.1079097872423807  Training Accuracy:0.8541666666666666\n",
            "48/4708 - The training loss at 25th epoch : 0.09422276045459033  Training Accuracy:0.875\n",
            "64/4708 - The training loss at 25th epoch : 0.08802550932156013  Training Accuracy:0.8875\n",
            "80/4708 - The training loss at 25th epoch : 0.08731267543398023  Training Accuracy:0.8854166666666666\n",
            "96/4708 - The training loss at 25th epoch : 0.09158845645302549  Training Accuracy:0.875\n",
            "112/4708 - The training loss at 25th epoch : 0.09301532653397256  Training Accuracy:0.875\n",
            "128/4708 - The training loss at 25th epoch : 0.10374790103546738  Training Accuracy:0.8541666666666666\n",
            "144/4708 - The training loss at 25th epoch : 0.10004651095051711  Training Accuracy:0.8625\n",
            "160/4708 - The training loss at 25th epoch : 0.09702921105997779  Training Accuracy:0.8693181818181818\n",
            "176/4708 - The training loss at 25th epoch : 0.09186155803291807  Training Accuracy:0.8802083333333334\n",
            "192/4708 - The training loss at 25th epoch : 0.0985040675795957  Training Accuracy:0.8653846153846154\n",
            "208/4708 - The training loss at 25th epoch : 0.09555826816662963  Training Accuracy:0.8705357142857143\n",
            "224/4708 - The training loss at 25th epoch : 0.09751905711448439  Training Accuracy:0.8666666666666667\n",
            "240/4708 - The training loss at 25th epoch : 0.09498755896507079  Training Accuracy:0.87109375\n",
            "256/4708 - The training loss at 25th epoch : 0.09855024387607363  Training Accuracy:0.8676470588235294\n",
            "272/4708 - The training loss at 25th epoch : 0.09661564253671381  Training Accuracy:0.8715277777777778\n",
            "288/4708 - The training loss at 25th epoch : 0.09433269601603292  Training Accuracy:0.875\n",
            "304/4708 - The training loss at 25th epoch : 0.09165622248090922  Training Accuracy:0.878125\n",
            "320/4708 - The training loss at 25th epoch : 0.08802142892788985  Training Accuracy:0.8839285714285714\n",
            "336/4708 - The training loss at 25th epoch : 0.08803989944087257  Training Accuracy:0.8835227272727273\n",
            "352/4708 - The training loss at 25th epoch : 0.0887864617445516  Training Accuracy:0.8831521739130435\n",
            "368/4708 - The training loss at 25th epoch : 0.09031050186542895  Training Accuracy:0.8828125\n",
            "384/4708 - The training loss at 25th epoch : 0.08732394304645358  Training Accuracy:0.8875\n",
            "400/4708 - The training loss at 25th epoch : 0.08556490773818567  Training Accuracy:0.8894230769230769\n",
            "416/4708 - The training loss at 25th epoch : 0.08458849690168783  Training Accuracy:0.8888888888888888\n",
            "432/4708 - The training loss at 25th epoch : 0.08381541651123382  Training Accuracy:0.890625\n",
            "448/4708 - The training loss at 25th epoch : 0.0813342050794177  Training Accuracy:0.8943965517241379\n",
            "464/4708 - The training loss at 25th epoch : 0.07987915905842632  Training Accuracy:0.8958333333333334\n",
            "480/4708 - The training loss at 25th epoch : 0.08285749630941071  Training Accuracy:0.8931451612903226\n",
            "496/4708 - The training loss at 25th epoch : 0.08398944993067224  Training Accuracy:0.892578125\n",
            "512/4708 - The training loss at 25th epoch : 0.08597284618764181  Training Accuracy:0.8882575757575758\n",
            "528/4708 - The training loss at 25th epoch : 0.08468733703747452  Training Accuracy:0.8897058823529411\n",
            "544/4708 - The training loss at 25th epoch : 0.08318525880474785  Training Accuracy:0.8928571428571429\n",
            "560/4708 - The training loss at 25th epoch : 0.08164705516820253  Training Accuracy:0.8940972222222222\n",
            "576/4708 - The training loss at 25th epoch : 0.08429911309935356  Training Accuracy:0.8902027027027027\n",
            "592/4708 - The training loss at 25th epoch : 0.0837095215428962  Training Accuracy:0.8914473684210527\n",
            "608/4708 - The training loss at 25th epoch : 0.08538002963554259  Training Accuracy:0.8878205128205128\n",
            "624/4708 - The training loss at 25th epoch : 0.08636882339443494  Training Accuracy:0.8875\n",
            "640/4708 - The training loss at 25th epoch : 0.08498392041003444  Training Accuracy:0.8902439024390244\n",
            "656/4708 - The training loss at 25th epoch : 0.0844721250004792  Training Accuracy:0.8898809523809523\n",
            "672/4708 - The training loss at 25th epoch : 0.08380021806553847  Training Accuracy:0.8909883720930233\n",
            "688/4708 - The training loss at 25th epoch : 0.08302489024276528  Training Accuracy:0.890625\n",
            "704/4708 - The training loss at 25th epoch : 0.08314837031089804  Training Accuracy:0.8902777777777777\n",
            "720/4708 - The training loss at 25th epoch : 0.08353196948363019  Training Accuracy:0.8885869565217391\n",
            "736/4708 - The training loss at 25th epoch : 0.08373004440191928  Training Accuracy:0.8882978723404256\n",
            "752/4708 - The training loss at 25th epoch : 0.08286064916934567  Training Accuracy:0.8893229166666666\n",
            "768/4708 - The training loss at 25th epoch : 0.08169043093491683  Training Accuracy:0.8915816326530612\n",
            "784/4708 - The training loss at 25th epoch : 0.08176875449284518  Training Accuracy:0.89125\n",
            "800/4708 - The training loss at 25th epoch : 0.08129950863147961  Training Accuracy:0.8909313725490197\n",
            "816/4708 - The training loss at 25th epoch : 0.0803698810990748  Training Accuracy:0.8918269230769231\n",
            "832/4708 - The training loss at 25th epoch : 0.08070054471322316  Training Accuracy:0.8915094339622641\n",
            "848/4708 - The training loss at 25th epoch : 0.08109395824010654  Training Accuracy:0.8900462962962963\n",
            "864/4708 - The training loss at 25th epoch : 0.07965977117370837  Training Accuracy:0.8920454545454546\n",
            "880/4708 - The training loss at 25th epoch : 0.08013350819242678  Training Accuracy:0.890625\n",
            "896/4708 - The training loss at 25th epoch : 0.07899863129873376  Training Accuracy:0.8925438596491229\n",
            "912/4708 - The training loss at 25th epoch : 0.07959100919910808  Training Accuracy:0.8911637931034483\n",
            "928/4708 - The training loss at 25th epoch : 0.0802565426848979  Training Accuracy:0.8898305084745762\n",
            "944/4708 - The training loss at 25th epoch : 0.08140731651649817  Training Accuracy:0.8885416666666667\n",
            "960/4708 - The training loss at 25th epoch : 0.08066522187665277  Training Accuracy:0.8903688524590164\n",
            "976/4708 - The training loss at 25th epoch : 0.08123749228801405  Training Accuracy:0.8901209677419355\n",
            "992/4708 - The training loss at 25th epoch : 0.08122978171092715  Training Accuracy:0.8898809523809523\n",
            "1008/4708 - The training loss at 25th epoch : 0.08121505384749517  Training Accuracy:0.8896484375\n",
            "1024/4708 - The training loss at 25th epoch : 0.08137194282171556  Training Accuracy:0.8903846153846153\n",
            "1040/4708 - The training loss at 25th epoch : 0.08112218719326716  Training Accuracy:0.8910984848484849\n",
            "1056/4708 - The training loss at 25th epoch : 0.08165032048741681  Training Accuracy:0.8908582089552238\n",
            "1072/4708 - The training loss at 25th epoch : 0.0819810224297971  Training Accuracy:0.890625\n",
            "1088/4708 - The training loss at 25th epoch : 0.08180911743671286  Training Accuracy:0.8913043478260869\n",
            "1104/4708 - The training loss at 25th epoch : 0.08219830353254994  Training Accuracy:0.8910714285714286\n",
            "1120/4708 - The training loss at 25th epoch : 0.08169812237332558  Training Accuracy:0.891725352112676\n",
            "1136/4708 - The training loss at 25th epoch : 0.0843937215957476  Training Accuracy:0.8880208333333334\n",
            "1152/4708 - The training loss at 25th epoch : 0.0841140912699794  Training Accuracy:0.8878424657534246\n",
            "1168/4708 - The training loss at 25th epoch : 0.08314911260535195  Training Accuracy:0.8893581081081081\n",
            "1184/4708 - The training loss at 25th epoch : 0.08351699685751934  Training Accuracy:0.8883333333333333\n",
            "1200/4708 - The training loss at 25th epoch : 0.08355797222962692  Training Accuracy:0.8881578947368421\n",
            "1216/4708 - The training loss at 25th epoch : 0.08256336143391707  Training Accuracy:0.8896103896103896\n",
            "1232/4708 - The training loss at 25th epoch : 0.08202110032371591  Training Accuracy:0.8902243589743589\n",
            "1248/4708 - The training loss at 25th epoch : 0.0813731902075123  Training Accuracy:0.8908227848101266\n",
            "1264/4708 - The training loss at 25th epoch : 0.08118137141987983  Training Accuracy:0.89140625\n",
            "1280/4708 - The training loss at 25th epoch : 0.08105665718694911  Training Accuracy:0.8919753086419753\n",
            "1296/4708 - The training loss at 25th epoch : 0.0801633467530109  Training Accuracy:0.8932926829268293\n",
            "1312/4708 - The training loss at 25th epoch : 0.08020426337479239  Training Accuracy:0.8930722891566265\n",
            "1328/4708 - The training loss at 25th epoch : 0.08039685746527823  Training Accuracy:0.8928571428571429\n",
            "1344/4708 - The training loss at 25th epoch : 0.08065640024792377  Training Accuracy:0.8919117647058824\n",
            "1360/4708 - The training loss at 25th epoch : 0.08024433674238961  Training Accuracy:0.8924418604651163\n",
            "1376/4708 - The training loss at 25th epoch : 0.07968050911567345  Training Accuracy:0.8936781609195402\n",
            "1392/4708 - The training loss at 25th epoch : 0.07981283508568561  Training Accuracy:0.8934659090909091\n",
            "1408/4708 - The training loss at 25th epoch : 0.07908818502962991  Training Accuracy:0.8946629213483146\n",
            "1424/4708 - The training loss at 25th epoch : 0.08022620428556872  Training Accuracy:0.8923611111111112\n",
            "1440/4708 - The training loss at 25th epoch : 0.08071645224445315  Training Accuracy:0.8914835164835165\n",
            "1456/4708 - The training loss at 25th epoch : 0.08094630936164166  Training Accuracy:0.891983695652174\n",
            "1472/4708 - The training loss at 25th epoch : 0.08118162540912502  Training Accuracy:0.8911290322580645\n",
            "1488/4708 - The training loss at 25th epoch : 0.08092284844466487  Training Accuracy:0.8916223404255319\n",
            "1504/4708 - The training loss at 25th epoch : 0.08177421631913874  Training Accuracy:0.8907894736842106\n",
            "1520/4708 - The training loss at 25th epoch : 0.08137217625759068  Training Accuracy:0.8912760416666666\n",
            "1536/4708 - The training loss at 25th epoch : 0.08111967849730325  Training Accuracy:0.8917525773195877\n",
            "1552/4708 - The training loss at 25th epoch : 0.08141624437058777  Training Accuracy:0.8909438775510204\n",
            "1568/4708 - The training loss at 25th epoch : 0.08096881045022783  Training Accuracy:0.8914141414141414\n",
            "1584/4708 - The training loss at 25th epoch : 0.0804973141168574  Training Accuracy:0.8925\n",
            "1600/4708 - The training loss at 25th epoch : 0.08117868623212396  Training Accuracy:0.8910891089108911\n",
            "1616/4708 - The training loss at 25th epoch : 0.08075274580053225  Training Accuracy:0.8915441176470589\n",
            "1632/4708 - The training loss at 25th epoch : 0.08098666600464882  Training Accuracy:0.8913834951456311\n",
            "1648/4708 - The training loss at 25th epoch : 0.0806191849013278  Training Accuracy:0.8912259615384616\n",
            "1664/4708 - The training loss at 25th epoch : 0.08023575846261227  Training Accuracy:0.8916666666666667\n",
            "1680/4708 - The training loss at 25th epoch : 0.08030358429451784  Training Accuracy:0.8915094339622641\n",
            "1696/4708 - The training loss at 25th epoch : 0.08052113761001303  Training Accuracy:0.8913551401869159\n",
            "1712/4708 - The training loss at 25th epoch : 0.0802984420978785  Training Accuracy:0.8912037037037037\n",
            "1728/4708 - The training loss at 25th epoch : 0.08034340154278938  Training Accuracy:0.8910550458715596\n",
            "1744/4708 - The training loss at 25th epoch : 0.08021422757924508  Training Accuracy:0.8914772727272727\n",
            "1760/4708 - The training loss at 25th epoch : 0.08063198269871844  Training Accuracy:0.8907657657657657\n",
            "1776/4708 - The training loss at 25th epoch : 0.08062818056054807  Training Accuracy:0.8911830357142857\n",
            "1792/4708 - The training loss at 25th epoch : 0.08028034189808754  Training Accuracy:0.8915929203539823\n",
            "1808/4708 - The training loss at 25th epoch : 0.08077183711268207  Training Accuracy:0.8914473684210527\n",
            "1824/4708 - The training loss at 25th epoch : 0.08064800793248698  Training Accuracy:0.8918478260869566\n",
            "1840/4708 - The training loss at 25th epoch : 0.08003474762542918  Training Accuracy:0.8927801724137931\n",
            "1856/4708 - The training loss at 25th epoch : 0.0794191764404893  Training Accuracy:0.8936965811965812\n",
            "1872/4708 - The training loss at 25th epoch : 0.07990934055643152  Training Accuracy:0.8930084745762712\n",
            "1888/4708 - The training loss at 25th epoch : 0.08078442819770355  Training Accuracy:0.8912815126050421\n",
            "1904/4708 - The training loss at 25th epoch : 0.08073657703961093  Training Accuracy:0.8916666666666667\n",
            "1920/4708 - The training loss at 25th epoch : 0.08016047320041797  Training Accuracy:0.8925619834710744\n",
            "1936/4708 - The training loss at 25th epoch : 0.08060050745648445  Training Accuracy:0.8924180327868853\n",
            "1952/4708 - The training loss at 25th epoch : 0.08041530341274429  Training Accuracy:0.8922764227642277\n",
            "1968/4708 - The training loss at 25th epoch : 0.08004103299223374  Training Accuracy:0.8926411290322581\n",
            "1984/4708 - The training loss at 25th epoch : 0.07980747422269868  Training Accuracy:0.893\n",
            "2000/4708 - The training loss at 25th epoch : 0.07978228108176004  Training Accuracy:0.8933531746031746\n",
            "2016/4708 - The training loss at 25th epoch : 0.07975459522320207  Training Accuracy:0.8932086614173228\n",
            "2032/4708 - The training loss at 25th epoch : 0.08093979604923901  Training Accuracy:0.8916015625\n",
            "2048/4708 - The training loss at 25th epoch : 0.08055592554169219  Training Accuracy:0.8919573643410853\n",
            "2064/4708 - The training loss at 25th epoch : 0.08075259180844796  Training Accuracy:0.8923076923076924\n",
            "2080/4708 - The training loss at 25th epoch : 0.08036228093711925  Training Accuracy:0.8931297709923665\n",
            "2096/4708 - The training loss at 25th epoch : 0.0807312849267489  Training Accuracy:0.8929924242424242\n",
            "2112/4708 - The training loss at 25th epoch : 0.08090665457333765  Training Accuracy:0.8928571428571429\n",
            "2128/4708 - The training loss at 25th epoch : 0.08114864101236903  Training Accuracy:0.8927238805970149\n",
            "2144/4708 - The training loss at 25th epoch : 0.08209850582434239  Training Accuracy:0.8912037037037037\n",
            "2160/4708 - The training loss at 25th epoch : 0.08245882114824059  Training Accuracy:0.890625\n",
            "2176/4708 - The training loss at 25th epoch : 0.08309219993218271  Training Accuracy:0.8900547445255474\n",
            "2192/4708 - The training loss at 25th epoch : 0.08388950876149791  Training Accuracy:0.8885869565217391\n",
            "2208/4708 - The training loss at 25th epoch : 0.08407318458170598  Training Accuracy:0.8884892086330936\n",
            "2224/4708 - The training loss at 25th epoch : 0.08474413690152272  Training Accuracy:0.8875\n",
            "2240/4708 - The training loss at 25th epoch : 0.08456565003186448  Training Accuracy:0.887854609929078\n",
            "2256/4708 - The training loss at 25th epoch : 0.08431097733816924  Training Accuracy:0.8882042253521126\n",
            "2272/4708 - The training loss at 25th epoch : 0.08449182896241317  Training Accuracy:0.8881118881118881\n",
            "2288/4708 - The training loss at 25th epoch : 0.08413481623553193  Training Accuracy:0.8884548611111112\n",
            "2304/4708 - The training loss at 25th epoch : 0.08410744935837657  Training Accuracy:0.8883620689655173\n",
            "2320/4708 - The training loss at 25th epoch : 0.08416325921905461  Training Accuracy:0.8882705479452054\n",
            "2336/4708 - The training loss at 25th epoch : 0.08410626557342224  Training Accuracy:0.8881802721088435\n",
            "2352/4708 - The training loss at 25th epoch : 0.0839907730949053  Training Accuracy:0.8880912162162162\n",
            "2368/4708 - The training loss at 25th epoch : 0.08437079490476534  Training Accuracy:0.8871644295302014\n",
            "2384/4708 - The training loss at 25th epoch : 0.08450361112090729  Training Accuracy:0.8866666666666667\n",
            "2400/4708 - The training loss at 25th epoch : 0.08422325059820455  Training Accuracy:0.8870033112582781\n",
            "2416/4708 - The training loss at 25th epoch : 0.0841690287276375  Training Accuracy:0.8869243421052632\n",
            "2432/4708 - The training loss at 25th epoch : 0.08385134667618409  Training Accuracy:0.8872549019607843\n",
            "2448/4708 - The training loss at 25th epoch : 0.08342823706118371  Training Accuracy:0.887987012987013\n",
            "2464/4708 - The training loss at 25th epoch : 0.08303116852271003  Training Accuracy:0.8887096774193548\n",
            "2480/4708 - The training loss at 25th epoch : 0.08260720340058748  Training Accuracy:0.8894230769230769\n",
            "2496/4708 - The training loss at 25th epoch : 0.08227307696594162  Training Accuracy:0.8897292993630573\n",
            "2512/4708 - The training loss at 25th epoch : 0.082322582126945  Training Accuracy:0.8896360759493671\n",
            "2528/4708 - The training loss at 25th epoch : 0.082532327692371  Training Accuracy:0.8895440251572327\n",
            "2544/4708 - The training loss at 25th epoch : 0.08221857275532754  Training Accuracy:0.88984375\n",
            "2560/4708 - The training loss at 25th epoch : 0.0832190531749705  Training Accuracy:0.8878105590062112\n",
            "2576/4708 - The training loss at 25th epoch : 0.08309346317924476  Training Accuracy:0.8881172839506173\n",
            "2592/4708 - The training loss at 25th epoch : 0.0830826072301659  Training Accuracy:0.888420245398773\n",
            "2608/4708 - The training loss at 25th epoch : 0.08355084067094322  Training Accuracy:0.8875762195121951\n",
            "2624/4708 - The training loss at 25th epoch : 0.08425750768461682  Training Accuracy:0.8871212121212121\n",
            "2640/4708 - The training loss at 25th epoch : 0.08402950136891137  Training Accuracy:0.8874246987951807\n",
            "2656/4708 - The training loss at 25th epoch : 0.08381762300196335  Training Accuracy:0.8877245508982036\n",
            "2672/4708 - The training loss at 25th epoch : 0.08359833391815955  Training Accuracy:0.8880208333333334\n",
            "2688/4708 - The training loss at 25th epoch : 0.083814586929879  Training Accuracy:0.8872041420118343\n",
            "2704/4708 - The training loss at 25th epoch : 0.0841093948094738  Training Accuracy:0.8867647058823529\n",
            "2720/4708 - The training loss at 25th epoch : 0.08390308151944176  Training Accuracy:0.8870614035087719\n",
            "2736/4708 - The training loss at 25th epoch : 0.08449651572136423  Training Accuracy:0.8862645348837209\n",
            "2752/4708 - The training loss at 25th epoch : 0.08409799082168788  Training Accuracy:0.8869219653179191\n",
            "2768/4708 - The training loss at 25th epoch : 0.08379415776347357  Training Accuracy:0.8872126436781609\n",
            "2784/4708 - The training loss at 25th epoch : 0.08396362313524926  Training Accuracy:0.8867857142857143\n",
            "2800/4708 - The training loss at 25th epoch : 0.08381338731620054  Training Accuracy:0.8870738636363636\n",
            "2816/4708 - The training loss at 25th epoch : 0.08336759932556491  Training Accuracy:0.8877118644067796\n",
            "2832/4708 - The training loss at 25th epoch : 0.08337672050610287  Training Accuracy:0.8876404494382022\n",
            "2848/4708 - The training loss at 25th epoch : 0.0835310296537863  Training Accuracy:0.8875698324022346\n",
            "2864/4708 - The training loss at 25th epoch : 0.08327447745002997  Training Accuracy:0.8878472222222222\n",
            "2880/4708 - The training loss at 25th epoch : 0.08334443731345709  Training Accuracy:0.8877762430939227\n",
            "2896/4708 - The training loss at 25th epoch : 0.08317247028456079  Training Accuracy:0.8880494505494505\n",
            "2912/4708 - The training loss at 25th epoch : 0.08326031074844087  Training Accuracy:0.8883196721311475\n",
            "2928/4708 - The training loss at 25th epoch : 0.0829461660566569  Training Accuracy:0.8889266304347826\n",
            "2944/4708 - The training loss at 25th epoch : 0.08268343552650638  Training Accuracy:0.8891891891891892\n",
            "2960/4708 - The training loss at 25th epoch : 0.08246422691561164  Training Accuracy:0.8894489247311828\n",
            "2976/4708 - The training loss at 25th epoch : 0.08244635612467044  Training Accuracy:0.8897058823529411\n",
            "2992/4708 - The training loss at 25th epoch : 0.08223558333001629  Training Accuracy:0.8899601063829787\n",
            "3008/4708 - The training loss at 25th epoch : 0.0824339712866177  Training Accuracy:0.8898809523809523\n",
            "3024/4708 - The training loss at 25th epoch : 0.08260284704505619  Training Accuracy:0.8898026315789473\n",
            "3040/4708 - The training loss at 25th epoch : 0.08259628894532446  Training Accuracy:0.8897251308900523\n",
            "3056/4708 - The training loss at 25th epoch : 0.08273847919988182  Training Accuracy:0.8893229166666666\n",
            "3072/4708 - The training loss at 25th epoch : 0.0827027204351871  Training Accuracy:0.8889248704663213\n",
            "3088/4708 - The training loss at 25th epoch : 0.0827892417301646  Training Accuracy:0.8888530927835051\n",
            "3104/4708 - The training loss at 25th epoch : 0.08274627911579513  Training Accuracy:0.889102564102564\n",
            "3120/4708 - The training loss at 25th epoch : 0.0830422543235229  Training Accuracy:0.8887117346938775\n",
            "3136/4708 - The training loss at 25th epoch : 0.08268561356763533  Training Accuracy:0.8892766497461929\n",
            "3152/4708 - The training loss at 25th epoch : 0.08319262889867364  Training Accuracy:0.8888888888888888\n",
            "3168/4708 - The training loss at 25th epoch : 0.0832925848110433  Training Accuracy:0.8888190954773869\n",
            "3184/4708 - The training loss at 25th epoch : 0.08351257521522157  Training Accuracy:0.8884375\n",
            "3200/4708 - The training loss at 25th epoch : 0.08366982118291182  Training Accuracy:0.8883706467661692\n",
            "3216/4708 - The training loss at 25th epoch : 0.08340724146665185  Training Accuracy:0.8889232673267327\n",
            "3232/4708 - The training loss at 25th epoch : 0.08320259365631513  Training Accuracy:0.8891625615763546\n",
            "3248/4708 - The training loss at 25th epoch : 0.08290806950356465  Training Accuracy:0.8897058823529411\n",
            "3264/4708 - The training loss at 25th epoch : 0.08267863435460023  Training Accuracy:0.8899390243902439\n",
            "3280/4708 - The training loss at 25th epoch : 0.08293919372096543  Training Accuracy:0.8892597087378641\n",
            "3296/4708 - The training loss at 25th epoch : 0.08273638663339537  Training Accuracy:0.8897946859903382\n",
            "3312/4708 - The training loss at 25th epoch : 0.08241939039914857  Training Accuracy:0.8903245192307693\n",
            "3328/4708 - The training loss at 25th epoch : 0.08224437734990349  Training Accuracy:0.8905502392344498\n",
            "3344/4708 - The training loss at 25th epoch : 0.08231356901636774  Training Accuracy:0.8907738095238096\n",
            "3360/4708 - The training loss at 25th epoch : 0.08218720699226637  Training Accuracy:0.8912914691943128\n",
            "3376/4708 - The training loss at 25th epoch : 0.08216371527980909  Training Accuracy:0.8909198113207547\n",
            "3392/4708 - The training loss at 25th epoch : 0.08206971351291488  Training Accuracy:0.8908450704225352\n",
            "3408/4708 - The training loss at 25th epoch : 0.08241031402971513  Training Accuracy:0.8898948598130841\n",
            "3424/4708 - The training loss at 25th epoch : 0.08243232174241241  Training Accuracy:0.8898255813953488\n",
            "3440/4708 - The training loss at 25th epoch : 0.08239583709113238  Training Accuracy:0.8897569444444444\n",
            "3456/4708 - The training loss at 25th epoch : 0.0828352558730567  Training Accuracy:0.8894009216589862\n",
            "3472/4708 - The training loss at 25th epoch : 0.08252359774810746  Training Accuracy:0.8899082568807339\n",
            "3488/4708 - The training loss at 25th epoch : 0.08247771093454931  Training Accuracy:0.8898401826484018\n",
            "3504/4708 - The training loss at 25th epoch : 0.08238188959883141  Training Accuracy:0.8897727272727273\n",
            "3520/4708 - The training loss at 25th epoch : 0.08250436883289129  Training Accuracy:0.8897058823529411\n",
            "3536/4708 - The training loss at 25th epoch : 0.0825086468200317  Training Accuracy:0.8896396396396397\n",
            "3552/4708 - The training loss at 25th epoch : 0.0827140489147614  Training Accuracy:0.8890134529147982\n",
            "3568/4708 - The training loss at 25th epoch : 0.08282243926425739  Training Accuracy:0.888671875\n",
            "3584/4708 - The training loss at 25th epoch : 0.08252968147761891  Training Accuracy:0.8891666666666667\n",
            "3600/4708 - The training loss at 25th epoch : 0.08286170045980663  Training Accuracy:0.8885508849557522\n",
            "3616/4708 - The training loss at 25th epoch : 0.08301271040691352  Training Accuracy:0.8884911894273128\n",
            "3632/4708 - The training loss at 25th epoch : 0.08305624848271592  Training Accuracy:0.8884320175438597\n",
            "3648/4708 - The training loss at 25th epoch : 0.0832003208352739  Training Accuracy:0.8881004366812227\n",
            "3664/4708 - The training loss at 25th epoch : 0.08297243006441697  Training Accuracy:0.8885869565217391\n",
            "3680/4708 - The training loss at 25th epoch : 0.08285507384644095  Training Accuracy:0.8887987012987013\n",
            "3696/4708 - The training loss at 25th epoch : 0.08285196947973683  Training Accuracy:0.888739224137931\n",
            "3712/4708 - The training loss at 25th epoch : 0.08288416019063355  Training Accuracy:0.8889484978540773\n",
            "3728/4708 - The training loss at 25th epoch : 0.08275841437258677  Training Accuracy:0.8891559829059829\n",
            "3744/4708 - The training loss at 25th epoch : 0.08299513802879374  Training Accuracy:0.8888297872340426\n",
            "3760/4708 - The training loss at 25th epoch : 0.08299531217949672  Training Accuracy:0.888771186440678\n",
            "3776/4708 - The training loss at 25th epoch : 0.08302780407227642  Training Accuracy:0.8887130801687764\n",
            "3792/4708 - The training loss at 25th epoch : 0.08303912104744317  Training Accuracy:0.8886554621848739\n",
            "3808/4708 - The training loss at 25th epoch : 0.08337867093245609  Training Accuracy:0.888336820083682\n",
            "3824/4708 - The training loss at 25th epoch : 0.08357924722491025  Training Accuracy:0.8880208333333334\n",
            "3840/4708 - The training loss at 25th epoch : 0.08361608665349994  Training Accuracy:0.8879668049792531\n",
            "3856/4708 - The training loss at 25th epoch : 0.08395110060148238  Training Accuracy:0.887396694214876\n",
            "3872/4708 - The training loss at 25th epoch : 0.08458707987408133  Training Accuracy:0.8865740740740741\n",
            "3888/4708 - The training loss at 25th epoch : 0.0845778190515439  Training Accuracy:0.8865266393442623\n",
            "3904/4708 - The training loss at 25th epoch : 0.08452601896568929  Training Accuracy:0.886734693877551\n",
            "3920/4708 - The training loss at 25th epoch : 0.084784080370811  Training Accuracy:0.8861788617886179\n",
            "3936/4708 - The training loss at 25th epoch : 0.08489208009451805  Training Accuracy:0.8861336032388664\n",
            "3952/4708 - The training loss at 25th epoch : 0.08456771157800319  Training Accuracy:0.8865927419354839\n",
            "3968/4708 - The training loss at 25th epoch : 0.08443754777291994  Training Accuracy:0.8865461847389559\n",
            "3984/4708 - The training loss at 25th epoch : 0.08413867515305697  Training Accuracy:0.887\n",
            "4000/4708 - The training loss at 25th epoch : 0.08417294941019214  Training Accuracy:0.8869521912350598\n",
            "4016/4708 - The training loss at 25th epoch : 0.0839559481195248  Training Accuracy:0.8874007936507936\n",
            "4032/4708 - The training loss at 25th epoch : 0.08374064479215673  Training Accuracy:0.887598814229249\n",
            "4048/4708 - The training loss at 25th epoch : 0.08394290845025454  Training Accuracy:0.8875492125984252\n",
            "4064/4708 - The training loss at 25th epoch : 0.0838696684823719  Training Accuracy:0.8875\n",
            "4080/4708 - The training loss at 25th epoch : 0.08394773605359065  Training Accuracy:0.887451171875\n",
            "4096/4708 - The training loss at 25th epoch : 0.08371745912162559  Training Accuracy:0.8878891050583657\n",
            "4112/4708 - The training loss at 25th epoch : 0.08374636779461694  Training Accuracy:0.8878391472868217\n",
            "4128/4708 - The training loss at 25th epoch : 0.08397440328909925  Training Accuracy:0.8875482625482626\n",
            "4144/4708 - The training loss at 25th epoch : 0.0840607983729091  Training Accuracy:0.8875\n",
            "4160/4708 - The training loss at 25th epoch : 0.08441900261568741  Training Accuracy:0.8872126436781609\n",
            "4176/4708 - The training loss at 25th epoch : 0.0845278441287504  Training Accuracy:0.8871660305343512\n",
            "4192/4708 - The training loss at 25th epoch : 0.08469634641230256  Training Accuracy:0.8871197718631179\n",
            "4208/4708 - The training loss at 25th epoch : 0.08476394125347465  Training Accuracy:0.8870738636363636\n",
            "4224/4708 - The training loss at 25th epoch : 0.08478135594193155  Training Accuracy:0.8870283018867925\n",
            "4240/4708 - The training loss at 25th epoch : 0.08502971177844557  Training Accuracy:0.8867481203007519\n",
            "4256/4708 - The training loss at 25th epoch : 0.084967234627007  Training Accuracy:0.8867041198501873\n",
            "4272/4708 - The training loss at 25th epoch : 0.08507875917467575  Training Accuracy:0.8861940298507462\n",
            "4288/4708 - The training loss at 25th epoch : 0.08499575113684768  Training Accuracy:0.8861524163568774\n",
            "4304/4708 - The training loss at 25th epoch : 0.08501140410422132  Training Accuracy:0.8861111111111111\n",
            "4320/4708 - The training loss at 25th epoch : 0.08506959618107861  Training Accuracy:0.886070110701107\n",
            "4336/4708 - The training loss at 25th epoch : 0.08491666611261536  Training Accuracy:0.8862591911764706\n",
            "4352/4708 - The training loss at 25th epoch : 0.08506290276974016  Training Accuracy:0.885989010989011\n",
            "4368/4708 - The training loss at 25th epoch : 0.08479405363160404  Training Accuracy:0.886405109489051\n",
            "4384/4708 - The training loss at 25th epoch : 0.08478826445887307  Training Accuracy:0.8865909090909091\n",
            "4400/4708 - The training loss at 25th epoch : 0.08489750062220174  Training Accuracy:0.8865489130434783\n",
            "4416/4708 - The training loss at 25th epoch : 0.08498292797961132  Training Accuracy:0.8865072202166066\n",
            "4432/4708 - The training loss at 25th epoch : 0.08484075033276293  Training Accuracy:0.8864658273381295\n",
            "4448/4708 - The training loss at 25th epoch : 0.08470560401863197  Training Accuracy:0.8866487455197133\n",
            "4464/4708 - The training loss at 25th epoch : 0.08474812100227079  Training Accuracy:0.8863839285714286\n",
            "4480/4708 - The training loss at 25th epoch : 0.08448433656195051  Training Accuracy:0.886788256227758\n",
            "4496/4708 - The training loss at 25th epoch : 0.08453258644805903  Training Accuracy:0.8865248226950354\n",
            "4512/4708 - The training loss at 25th epoch : 0.08498140311265735  Training Accuracy:0.885821554770318\n",
            "4528/4708 - The training loss at 25th epoch : 0.0849097030862607  Training Accuracy:0.8860035211267606\n",
            "4544/4708 - The training loss at 25th epoch : 0.08504107527836512  Training Accuracy:0.8855263157894737\n",
            "4560/4708 - The training loss at 25th epoch : 0.08498153199836242  Training Accuracy:0.8854895104895105\n",
            "4576/4708 - The training loss at 25th epoch : 0.08543016574495732  Training Accuracy:0.8850174216027874\n",
            "4592/4708 - The training loss at 25th epoch : 0.08545367902895525  Training Accuracy:0.8849826388888888\n",
            "4608/4708 - The training loss at 25th epoch : 0.0852073111623062  Training Accuracy:0.8853806228373703\n",
            "4624/4708 - The training loss at 25th epoch : 0.08511482846401124  Training Accuracy:0.8855603448275862\n",
            "4640/4708 - The training loss at 25th epoch : 0.08524626689772062  Training Accuracy:0.8857388316151202\n",
            "4656/4708 - The training loss at 25th epoch : 0.0851607355337614  Training Accuracy:0.885916095890411\n",
            "4672/4708 - The training loss at 25th epoch : 0.08494810672425723  Training Accuracy:0.8863054607508533\n",
            "4688/4708 - The training loss at 25th epoch : 0.08495100783318736  Training Accuracy:0.8862670068027211\n",
            "4704/4708 - The training loss at 25th epoch : 0.0852235498749953  Training Accuracy:0.8860169491525424\n",
            "4720/4708 - The training loss at 25th epoch : 0.0852906380568323  Training Accuracy:0.8859797297297297\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 26th epoch : 0.09612841129492526  Training Accuracy:0.8125\n",
            "16/4708 - The training loss at 26th epoch : 0.0810092410251121  Training Accuracy:0.84375\n",
            "32/4708 - The training loss at 26th epoch : 0.0921223578049256  Training Accuracy:0.8333333333333334\n",
            "48/4708 - The training loss at 26th epoch : 0.08136718372114428  Training Accuracy:0.84375\n",
            "64/4708 - The training loss at 26th epoch : 0.07480375501350936  Training Accuracy:0.8625\n",
            "80/4708 - The training loss at 26th epoch : 0.0663163721822974  Training Accuracy:0.8854166666666666\n",
            "96/4708 - The training loss at 26th epoch : 0.06808595114275963  Training Accuracy:0.8839285714285714\n",
            "112/4708 - The training loss at 26th epoch : 0.08356375426947635  Training Accuracy:0.8671875\n",
            "128/4708 - The training loss at 26th epoch : 0.08203156800108159  Training Accuracy:0.8680555555555556\n",
            "144/4708 - The training loss at 26th epoch : 0.08293029888084533  Training Accuracy:0.86875\n",
            "160/4708 - The training loss at 26th epoch : 0.08069195999056467  Training Accuracy:0.8693181818181818\n",
            "176/4708 - The training loss at 26th epoch : 0.07921704912218218  Training Accuracy:0.8697916666666666\n",
            "192/4708 - The training loss at 26th epoch : 0.07745214695872008  Training Accuracy:0.8701923076923077\n",
            "208/4708 - The training loss at 26th epoch : 0.0824859669463885  Training Accuracy:0.8616071428571429\n",
            "224/4708 - The training loss at 26th epoch : 0.0798332453118354  Training Accuracy:0.8666666666666667\n",
            "240/4708 - The training loss at 26th epoch : 0.08199502533408552  Training Accuracy:0.8671875\n",
            "256/4708 - The training loss at 26th epoch : 0.07746828448550419  Training Accuracy:0.875\n",
            "272/4708 - The training loss at 26th epoch : 0.07666294570729161  Training Accuracy:0.8784722222222222\n",
            "288/4708 - The training loss at 26th epoch : 0.0780570022043816  Training Accuracy:0.8782894736842105\n",
            "304/4708 - The training loss at 26th epoch : 0.07628350057152028  Training Accuracy:0.88125\n",
            "320/4708 - The training loss at 26th epoch : 0.07626684992496446  Training Accuracy:0.8839285714285714\n",
            "336/4708 - The training loss at 26th epoch : 0.07920223221869557  Training Accuracy:0.8806818181818182\n",
            "352/4708 - The training loss at 26th epoch : 0.08206841442027073  Training Accuracy:0.8777173913043478\n",
            "368/4708 - The training loss at 26th epoch : 0.08165705754351842  Training Accuracy:0.8776041666666666\n",
            "384/4708 - The training loss at 26th epoch : 0.08048490020727536  Training Accuracy:0.88\n",
            "400/4708 - The training loss at 26th epoch : 0.08015970557645707  Training Accuracy:0.8822115384615384\n",
            "416/4708 - The training loss at 26th epoch : 0.07724119574579573  Training Accuracy:0.8865740740740741\n",
            "432/4708 - The training loss at 26th epoch : 0.07966222894091277  Training Accuracy:0.8839285714285714\n",
            "448/4708 - The training loss at 26th epoch : 0.08056459030792486  Training Accuracy:0.8836206896551724\n",
            "464/4708 - The training loss at 26th epoch : 0.08127491423060527  Training Accuracy:0.8833333333333333\n",
            "480/4708 - The training loss at 26th epoch : 0.08345561545126347  Training Accuracy:0.8810483870967742\n",
            "496/4708 - The training loss at 26th epoch : 0.08310903720564608  Training Accuracy:0.880859375\n",
            "512/4708 - The training loss at 26th epoch : 0.0823042573300497  Training Accuracy:0.8825757575757576\n",
            "528/4708 - The training loss at 26th epoch : 0.08276735703494598  Training Accuracy:0.8841911764705882\n",
            "544/4708 - The training loss at 26th epoch : 0.08390000724122514  Training Accuracy:0.8821428571428571\n",
            "560/4708 - The training loss at 26th epoch : 0.08334462948618311  Training Accuracy:0.8819444444444444\n",
            "576/4708 - The training loss at 26th epoch : 0.08380995544266248  Training Accuracy:0.8817567567567568\n",
            "592/4708 - The training loss at 26th epoch : 0.08371452407129587  Training Accuracy:0.881578947368421\n",
            "608/4708 - The training loss at 26th epoch : 0.08219755936911843  Training Accuracy:0.8846153846153846\n",
            "624/4708 - The training loss at 26th epoch : 0.08208302358789331  Training Accuracy:0.884375\n",
            "640/4708 - The training loss at 26th epoch : 0.08325434886624196  Training Accuracy:0.8841463414634146\n",
            "656/4708 - The training loss at 26th epoch : 0.08258990525091123  Training Accuracy:0.8854166666666666\n",
            "672/4708 - The training loss at 26th epoch : 0.08125349180589374  Training Accuracy:0.8880813953488372\n",
            "688/4708 - The training loss at 26th epoch : 0.08093958027341944  Training Accuracy:0.8892045454545454\n",
            "704/4708 - The training loss at 26th epoch : 0.07967027804976688  Training Accuracy:0.8916666666666667\n",
            "720/4708 - The training loss at 26th epoch : 0.07859065339242234  Training Accuracy:0.8926630434782609\n",
            "736/4708 - The training loss at 26th epoch : 0.0786329635788923  Training Accuracy:0.8909574468085106\n",
            "752/4708 - The training loss at 26th epoch : 0.07867484966191367  Training Accuracy:0.8919270833333334\n",
            "768/4708 - The training loss at 26th epoch : 0.07713684591722497  Training Accuracy:0.8941326530612245\n",
            "784/4708 - The training loss at 26th epoch : 0.07681871522038679  Training Accuracy:0.895\n",
            "800/4708 - The training loss at 26th epoch : 0.07733143466354354  Training Accuracy:0.8946078431372549\n",
            "816/4708 - The training loss at 26th epoch : 0.07760408318398236  Training Accuracy:0.8942307692307693\n",
            "832/4708 - The training loss at 26th epoch : 0.07649119462035762  Training Accuracy:0.8962264150943396\n",
            "848/4708 - The training loss at 26th epoch : 0.07585917483933857  Training Accuracy:0.8969907407407407\n",
            "864/4708 - The training loss at 26th epoch : 0.07668315306215391  Training Accuracy:0.8954545454545455\n",
            "880/4708 - The training loss at 26th epoch : 0.07658280041437493  Training Accuracy:0.8950892857142857\n",
            "896/4708 - The training loss at 26th epoch : 0.07848148018582599  Training Accuracy:0.893640350877193\n",
            "912/4708 - The training loss at 26th epoch : 0.08031100309709259  Training Accuracy:0.8911637931034483\n",
            "928/4708 - The training loss at 26th epoch : 0.08003512020060463  Training Accuracy:0.8908898305084746\n",
            "944/4708 - The training loss at 26th epoch : 0.07891287023610652  Training Accuracy:0.8927083333333333\n",
            "960/4708 - The training loss at 26th epoch : 0.08049175584319701  Training Accuracy:0.8913934426229508\n",
            "976/4708 - The training loss at 26th epoch : 0.08095434889190488  Training Accuracy:0.8911290322580645\n",
            "992/4708 - The training loss at 26th epoch : 0.08098207713784637  Training Accuracy:0.8918650793650794\n",
            "1008/4708 - The training loss at 26th epoch : 0.08106451484562102  Training Accuracy:0.8916015625\n",
            "1024/4708 - The training loss at 26th epoch : 0.08038234490872188  Training Accuracy:0.8923076923076924\n",
            "1040/4708 - The training loss at 26th epoch : 0.08110284466428698  Training Accuracy:0.8910984848484849\n",
            "1056/4708 - The training loss at 26th epoch : 0.08078312248816227  Training Accuracy:0.8917910447761194\n",
            "1072/4708 - The training loss at 26th epoch : 0.07967721324811898  Training Accuracy:0.8933823529411765\n",
            "1088/4708 - The training loss at 26th epoch : 0.07987374138378761  Training Accuracy:0.8931159420289855\n",
            "1104/4708 - The training loss at 26th epoch : 0.07999917937538574  Training Accuracy:0.8928571428571429\n",
            "1120/4708 - The training loss at 26th epoch : 0.08037778028201628  Training Accuracy:0.8926056338028169\n",
            "1136/4708 - The training loss at 26th epoch : 0.08066467534329708  Training Accuracy:0.8923611111111112\n",
            "1152/4708 - The training loss at 26th epoch : 0.08162026375326978  Training Accuracy:0.8912671232876712\n",
            "1168/4708 - The training loss at 26th epoch : 0.0809407805299785  Training Accuracy:0.8918918918918919\n",
            "1184/4708 - The training loss at 26th epoch : 0.080583490072548  Training Accuracy:0.8925\n",
            "1200/4708 - The training loss at 26th epoch : 0.0809397502304755  Training Accuracy:0.8922697368421053\n",
            "1216/4708 - The training loss at 26th epoch : 0.08054955781896972  Training Accuracy:0.8928571428571429\n",
            "1232/4708 - The training loss at 26th epoch : 0.08186787033289553  Training Accuracy:0.8910256410256411\n",
            "1248/4708 - The training loss at 26th epoch : 0.08246331478674387  Training Accuracy:0.8900316455696202\n",
            "1264/4708 - The training loss at 26th epoch : 0.08222591425605852  Training Accuracy:0.890625\n",
            "1280/4708 - The training loss at 26th epoch : 0.08314074186523625  Training Accuracy:0.8896604938271605\n",
            "1296/4708 - The training loss at 26th epoch : 0.08327142961021639  Training Accuracy:0.8887195121951219\n",
            "1312/4708 - The training loss at 26th epoch : 0.08260907549186945  Training Accuracy:0.8893072289156626\n",
            "1328/4708 - The training loss at 26th epoch : 0.08303863862113797  Training Accuracy:0.8891369047619048\n",
            "1344/4708 - The training loss at 26th epoch : 0.08252308135806483  Training Accuracy:0.8897058823529411\n",
            "1360/4708 - The training loss at 26th epoch : 0.08252235638794812  Training Accuracy:0.8895348837209303\n",
            "1376/4708 - The training loss at 26th epoch : 0.08323917152473777  Training Accuracy:0.8886494252873564\n",
            "1392/4708 - The training loss at 26th epoch : 0.08257212200726655  Training Accuracy:0.8899147727272727\n",
            "1408/4708 - The training loss at 26th epoch : 0.08267179406919246  Training Accuracy:0.889747191011236\n",
            "1424/4708 - The training loss at 26th epoch : 0.08181776149862335  Training Accuracy:0.8909722222222223\n",
            "1440/4708 - The training loss at 26th epoch : 0.08154605533416509  Training Accuracy:0.8907967032967034\n",
            "1456/4708 - The training loss at 26th epoch : 0.08303599481446881  Training Accuracy:0.8879076086956522\n",
            "1472/4708 - The training loss at 26th epoch : 0.08326653545185621  Training Accuracy:0.8877688172043011\n",
            "1488/4708 - The training loss at 26th epoch : 0.08307647653843665  Training Accuracy:0.8882978723404256\n",
            "1504/4708 - The training loss at 26th epoch : 0.08228815929079757  Training Accuracy:0.8894736842105263\n",
            "1520/4708 - The training loss at 26th epoch : 0.08212049389576345  Training Accuracy:0.8899739583333334\n",
            "1536/4708 - The training loss at 26th epoch : 0.08251631049332192  Training Accuracy:0.8885309278350515\n",
            "1552/4708 - The training loss at 26th epoch : 0.08191936215600225  Training Accuracy:0.8896683673469388\n",
            "1568/4708 - The training loss at 26th epoch : 0.08157791547109473  Training Accuracy:0.8901515151515151\n",
            "1584/4708 - The training loss at 26th epoch : 0.08086548970206076  Training Accuracy:0.89125\n",
            "1600/4708 - The training loss at 26th epoch : 0.08151907734272125  Training Accuracy:0.8898514851485149\n",
            "1616/4708 - The training loss at 26th epoch : 0.08110642085938494  Training Accuracy:0.8909313725490197\n",
            "1632/4708 - The training loss at 26th epoch : 0.08040163092411942  Training Accuracy:0.8919902912621359\n",
            "1648/4708 - The training loss at 26th epoch : 0.08049801381601991  Training Accuracy:0.8918269230769231\n",
            "1664/4708 - The training loss at 26th epoch : 0.08134696828640245  Training Accuracy:0.8904761904761904\n",
            "1680/4708 - The training loss at 26th epoch : 0.08071474625590563  Training Accuracy:0.8915094339622641\n",
            "1696/4708 - The training loss at 26th epoch : 0.08130836633110507  Training Accuracy:0.8901869158878505\n",
            "1712/4708 - The training loss at 26th epoch : 0.0812650613515339  Training Accuracy:0.8900462962962963\n",
            "1728/4708 - The training loss at 26th epoch : 0.0814600477164433  Training Accuracy:0.8899082568807339\n",
            "1744/4708 - The training loss at 26th epoch : 0.08091628923843966  Training Accuracy:0.8903409090909091\n",
            "1760/4708 - The training loss at 26th epoch : 0.08052498833015229  Training Accuracy:0.8907657657657657\n",
            "1776/4708 - The training loss at 26th epoch : 0.08103451075064738  Training Accuracy:0.890625\n",
            "1792/4708 - The training loss at 26th epoch : 0.08109798263015514  Training Accuracy:0.889933628318584\n",
            "1808/4708 - The training loss at 26th epoch : 0.08062559115934728  Training Accuracy:0.8903508771929824\n",
            "1824/4708 - The training loss at 26th epoch : 0.08064283261957869  Training Accuracy:0.8896739130434783\n",
            "1840/4708 - The training loss at 26th epoch : 0.08081803424073328  Training Accuracy:0.8900862068965517\n",
            "1856/4708 - The training loss at 26th epoch : 0.0810637848912286  Training Accuracy:0.8894230769230769\n",
            "1872/4708 - The training loss at 26th epoch : 0.08108724209689515  Training Accuracy:0.8898305084745762\n",
            "1888/4708 - The training loss at 26th epoch : 0.08109409513393658  Training Accuracy:0.8897058823529411\n",
            "1904/4708 - The training loss at 26th epoch : 0.08194503211273897  Training Accuracy:0.8890625\n",
            "1920/4708 - The training loss at 26th epoch : 0.08188938333229849  Training Accuracy:0.8894628099173554\n",
            "1936/4708 - The training loss at 26th epoch : 0.08190401509371832  Training Accuracy:0.889344262295082\n",
            "1952/4708 - The training loss at 26th epoch : 0.08197430659627979  Training Accuracy:0.8892276422764228\n",
            "1968/4708 - The training loss at 26th epoch : 0.08176675892246715  Training Accuracy:0.889616935483871\n",
            "1984/4708 - The training loss at 26th epoch : 0.0818278264610444  Training Accuracy:0.8895\n",
            "2000/4708 - The training loss at 26th epoch : 0.08188721595530722  Training Accuracy:0.8898809523809523\n",
            "2016/4708 - The training loss at 26th epoch : 0.08137338221788336  Training Accuracy:0.890748031496063\n",
            "2032/4708 - The training loss at 26th epoch : 0.08169944049552674  Training Accuracy:0.89013671875\n",
            "2048/4708 - The training loss at 26th epoch : 0.08204721643460162  Training Accuracy:0.8900193798449613\n",
            "2064/4708 - The training loss at 26th epoch : 0.08260715233517764  Training Accuracy:0.8889423076923076\n",
            "2080/4708 - The training loss at 26th epoch : 0.08258244460965307  Training Accuracy:0.8883587786259542\n",
            "2096/4708 - The training loss at 26th epoch : 0.08290870536608523  Training Accuracy:0.8882575757575758\n",
            "2112/4708 - The training loss at 26th epoch : 0.08287030219699279  Training Accuracy:0.8881578947368421\n",
            "2128/4708 - The training loss at 26th epoch : 0.08252967401808395  Training Accuracy:0.8885261194029851\n",
            "2144/4708 - The training loss at 26th epoch : 0.08245346320571213  Training Accuracy:0.888425925925926\n",
            "2160/4708 - The training loss at 26th epoch : 0.08244216041898322  Training Accuracy:0.8883272058823529\n",
            "2176/4708 - The training loss at 26th epoch : 0.08201230283575846  Training Accuracy:0.8886861313868614\n",
            "2192/4708 - The training loss at 26th epoch : 0.0817527939835411  Training Accuracy:0.8890398550724637\n",
            "2208/4708 - The training loss at 26th epoch : 0.08184177489520195  Training Accuracy:0.8889388489208633\n",
            "2224/4708 - The training loss at 26th epoch : 0.08183596275187213  Training Accuracy:0.8892857142857142\n",
            "2240/4708 - The training loss at 26th epoch : 0.08213205365266923  Training Accuracy:0.8891843971631206\n",
            "2256/4708 - The training loss at 26th epoch : 0.08208244765950395  Training Accuracy:0.8890845070422535\n",
            "2272/4708 - The training loss at 26th epoch : 0.0820088866960595  Training Accuracy:0.888986013986014\n",
            "2288/4708 - The training loss at 26th epoch : 0.081631450969865  Training Accuracy:0.8897569444444444\n",
            "2304/4708 - The training loss at 26th epoch : 0.08118757071280155  Training Accuracy:0.8905172413793103\n",
            "2320/4708 - The training loss at 26th epoch : 0.0818912721887609  Training Accuracy:0.889554794520548\n",
            "2336/4708 - The training loss at 26th epoch : 0.08200674926392386  Training Accuracy:0.8894557823129252\n",
            "2352/4708 - The training loss at 26th epoch : 0.08232485403156535  Training Accuracy:0.8893581081081081\n",
            "2368/4708 - The training loss at 26th epoch : 0.08251560666122394  Training Accuracy:0.8888422818791947\n",
            "2384/4708 - The training loss at 26th epoch : 0.08237418114070284  Training Accuracy:0.8891666666666667\n",
            "2400/4708 - The training loss at 26th epoch : 0.08258119606399492  Training Accuracy:0.8890728476821192\n",
            "2416/4708 - The training loss at 26th epoch : 0.08254995117437587  Training Accuracy:0.8889802631578947\n",
            "2432/4708 - The training loss at 26th epoch : 0.08252731425883432  Training Accuracy:0.8888888888888888\n",
            "2448/4708 - The training loss at 26th epoch : 0.08225236341674846  Training Accuracy:0.8892045454545454\n",
            "2464/4708 - The training loss at 26th epoch : 0.0822903228625472  Training Accuracy:0.8895161290322581\n",
            "2480/4708 - The training loss at 26th epoch : 0.08212918587134932  Training Accuracy:0.889823717948718\n",
            "2496/4708 - The training loss at 26th epoch : 0.08200435520309701  Training Accuracy:0.8897292993630573\n",
            "2512/4708 - The training loss at 26th epoch : 0.08173548185329205  Training Accuracy:0.8900316455696202\n",
            "2528/4708 - The training loss at 26th epoch : 0.08128877913393494  Training Accuracy:0.8907232704402516\n",
            "2544/4708 - The training loss at 26th epoch : 0.08114108707275859  Training Accuracy:0.891015625\n",
            "2560/4708 - The training loss at 26th epoch : 0.08109062292298093  Training Accuracy:0.890916149068323\n",
            "2576/4708 - The training loss at 26th epoch : 0.08145131263710872  Training Accuracy:0.8904320987654321\n",
            "2592/4708 - The training loss at 26th epoch : 0.08142878853094707  Training Accuracy:0.8903374233128835\n",
            "2608/4708 - The training loss at 26th epoch : 0.08146800281979133  Training Accuracy:0.8898628048780488\n",
            "2624/4708 - The training loss at 26th epoch : 0.08110197707535369  Training Accuracy:0.890530303030303\n",
            "2640/4708 - The training loss at 26th epoch : 0.08074683371608166  Training Accuracy:0.8911897590361446\n",
            "2656/4708 - The training loss at 26th epoch : 0.08113127870483285  Training Accuracy:0.8907185628742516\n",
            "2672/4708 - The training loss at 26th epoch : 0.08141497068299722  Training Accuracy:0.8902529761904762\n",
            "2688/4708 - The training loss at 26th epoch : 0.08159140149297925  Training Accuracy:0.8901627218934911\n",
            "2704/4708 - The training loss at 26th epoch : 0.08147397508780246  Training Accuracy:0.8904411764705882\n",
            "2720/4708 - The training loss at 26th epoch : 0.0814903956018082  Training Accuracy:0.8903508771929824\n",
            "2736/4708 - The training loss at 26th epoch : 0.08126427365395895  Training Accuracy:0.890625\n",
            "2752/4708 - The training loss at 26th epoch : 0.08110855918766581  Training Accuracy:0.8908959537572254\n",
            "2768/4708 - The training loss at 26th epoch : 0.08110827285733649  Training Accuracy:0.8908045977011494\n",
            "2784/4708 - The training loss at 26th epoch : 0.08145234919581995  Training Accuracy:0.89\n",
            "2800/4708 - The training loss at 26th epoch : 0.08131162068563222  Training Accuracy:0.8899147727272727\n",
            "2816/4708 - The training loss at 26th epoch : 0.0814748774240965  Training Accuracy:0.8894774011299436\n",
            "2832/4708 - The training loss at 26th epoch : 0.08120217045492423  Training Accuracy:0.889747191011236\n",
            "2848/4708 - The training loss at 26th epoch : 0.08097402444502912  Training Accuracy:0.890013966480447\n",
            "2864/4708 - The training loss at 26th epoch : 0.08073041735029096  Training Accuracy:0.890625\n",
            "2880/4708 - The training loss at 26th epoch : 0.0807432937671832  Training Accuracy:0.8901933701657458\n",
            "2896/4708 - The training loss at 26th epoch : 0.08046417276560205  Training Accuracy:0.8907967032967034\n",
            "2912/4708 - The training loss at 26th epoch : 0.0807657532350941  Training Accuracy:0.8903688524590164\n",
            "2928/4708 - The training loss at 26th epoch : 0.08119846406439689  Training Accuracy:0.889266304347826\n",
            "2944/4708 - The training loss at 26th epoch : 0.0810534466874363  Training Accuracy:0.889527027027027\n",
            "2960/4708 - The training loss at 26th epoch : 0.08136024932521245  Training Accuracy:0.8891129032258065\n",
            "2976/4708 - The training loss at 26th epoch : 0.08097782627744192  Training Accuracy:0.8897058823529411\n",
            "2992/4708 - The training loss at 26th epoch : 0.08082140505793352  Training Accuracy:0.8899601063829787\n",
            "3008/4708 - The training loss at 26th epoch : 0.08111609522619516  Training Accuracy:0.8895502645502645\n",
            "3024/4708 - The training loss at 26th epoch : 0.08112134635876125  Training Accuracy:0.8894736842105263\n",
            "3040/4708 - The training loss at 26th epoch : 0.08154114281045624  Training Accuracy:0.8887434554973822\n",
            "3056/4708 - The training loss at 26th epoch : 0.08207306602338282  Training Accuracy:0.8880208333333334\n",
            "3072/4708 - The training loss at 26th epoch : 0.08234748985419765  Training Accuracy:0.8873056994818653\n",
            "3088/4708 - The training loss at 26th epoch : 0.08219126915580979  Training Accuracy:0.8875644329896907\n",
            "3104/4708 - The training loss at 26th epoch : 0.08225638498596231  Training Accuracy:0.8875\n",
            "3120/4708 - The training loss at 26th epoch : 0.08271901962240644  Training Accuracy:0.8864795918367347\n",
            "3136/4708 - The training loss at 26th epoch : 0.08285832707210736  Training Accuracy:0.8861040609137056\n",
            "3152/4708 - The training loss at 26th epoch : 0.08254589521472053  Training Accuracy:0.8866792929292929\n",
            "3168/4708 - The training loss at 26th epoch : 0.08274246955097835  Training Accuracy:0.8863065326633166\n",
            "3184/4708 - The training loss at 26th epoch : 0.08293174248376005  Training Accuracy:0.8859375\n",
            "3200/4708 - The training loss at 26th epoch : 0.08272843683482088  Training Accuracy:0.8865049751243781\n",
            "3216/4708 - The training loss at 26th epoch : 0.0828137060849165  Training Accuracy:0.8864480198019802\n",
            "3232/4708 - The training loss at 26th epoch : 0.08265262133524615  Training Accuracy:0.8866995073891626\n",
            "3248/4708 - The training loss at 26th epoch : 0.08248363564028781  Training Accuracy:0.8869485294117647\n",
            "3264/4708 - The training loss at 26th epoch : 0.08278181369058088  Training Accuracy:0.886280487804878\n",
            "3280/4708 - The training loss at 26th epoch : 0.08253915498529067  Training Accuracy:0.8865291262135923\n",
            "3296/4708 - The training loss at 26th epoch : 0.0825487166040793  Training Accuracy:0.8867753623188406\n",
            "3312/4708 - The training loss at 26th epoch : 0.08258675759995734  Training Accuracy:0.8864182692307693\n",
            "3328/4708 - The training loss at 26th epoch : 0.08242602238649127  Training Accuracy:0.8863636363636364\n",
            "3344/4708 - The training loss at 26th epoch : 0.08260309818996922  Training Accuracy:0.8860119047619047\n",
            "3360/4708 - The training loss at 26th epoch : 0.08272682241050568  Training Accuracy:0.8859597156398105\n",
            "3376/4708 - The training loss at 26th epoch : 0.0825398317028372  Training Accuracy:0.8862028301886793\n",
            "3392/4708 - The training loss at 26th epoch : 0.08252901301740782  Training Accuracy:0.886443661971831\n",
            "3408/4708 - The training loss at 26th epoch : 0.08256256846359557  Training Accuracy:0.8863901869158879\n",
            "3424/4708 - The training loss at 26th epoch : 0.0822433438327634  Training Accuracy:0.8869186046511628\n",
            "3440/4708 - The training loss at 26th epoch : 0.08243606633155688  Training Accuracy:0.8868634259259259\n",
            "3456/4708 - The training loss at 26th epoch : 0.08238590944820356  Training Accuracy:0.8868087557603687\n",
            "3472/4708 - The training loss at 26th epoch : 0.0824008543733902  Training Accuracy:0.8867545871559633\n",
            "3488/4708 - The training loss at 26th epoch : 0.08222142289054386  Training Accuracy:0.886986301369863\n",
            "3504/4708 - The training loss at 26th epoch : 0.08202197266839305  Training Accuracy:0.8872159090909091\n",
            "3520/4708 - The training loss at 26th epoch : 0.0817418881055951  Training Accuracy:0.8877262443438914\n",
            "3536/4708 - The training loss at 26th epoch : 0.0818591592152474  Training Accuracy:0.8873873873873874\n",
            "3552/4708 - The training loss at 26th epoch : 0.08154246469230171  Training Accuracy:0.8878923766816144\n",
            "3568/4708 - The training loss at 26th epoch : 0.08154818706081877  Training Accuracy:0.8875558035714286\n",
            "3584/4708 - The training loss at 26th epoch : 0.08187689469292912  Training Accuracy:0.8872222222222222\n",
            "3600/4708 - The training loss at 26th epoch : 0.08186296851850287  Training Accuracy:0.8874446902654868\n",
            "3616/4708 - The training loss at 26th epoch : 0.08184048725033566  Training Accuracy:0.8873898678414097\n",
            "3632/4708 - The training loss at 26th epoch : 0.08208435282231002  Training Accuracy:0.8867872807017544\n",
            "3648/4708 - The training loss at 26th epoch : 0.08204395404898875  Training Accuracy:0.886735807860262\n",
            "3664/4708 - The training loss at 26th epoch : 0.08229820276972485  Training Accuracy:0.8864130434782609\n",
            "3680/4708 - The training loss at 26th epoch : 0.08282012969007509  Training Accuracy:0.885551948051948\n",
            "3696/4708 - The training loss at 26th epoch : 0.0829574729081853  Training Accuracy:0.8855064655172413\n",
            "3712/4708 - The training loss at 26th epoch : 0.08301414168078276  Training Accuracy:0.8851931330472103\n",
            "3728/4708 - The training loss at 26th epoch : 0.08302544747984593  Training Accuracy:0.8854166666666666\n",
            "3744/4708 - The training loss at 26th epoch : 0.08293231706107422  Training Accuracy:0.8856382978723404\n",
            "3760/4708 - The training loss at 26th epoch : 0.08303255536247835  Training Accuracy:0.885593220338983\n",
            "3776/4708 - The training loss at 26th epoch : 0.08323203944248397  Training Accuracy:0.8852848101265823\n",
            "3792/4708 - The training loss at 26th epoch : 0.08321228550364451  Training Accuracy:0.8855042016806722\n",
            "3808/4708 - The training loss at 26th epoch : 0.08313904004280018  Training Accuracy:0.8854602510460251\n",
            "3824/4708 - The training loss at 26th epoch : 0.0831490236550842  Training Accuracy:0.8854166666666666\n",
            "3840/4708 - The training loss at 26th epoch : 0.08290557678631147  Training Accuracy:0.8858921161825726\n",
            "3856/4708 - The training loss at 26th epoch : 0.08286158916963657  Training Accuracy:0.8861053719008265\n",
            "3872/4708 - The training loss at 26th epoch : 0.08273109936231063  Training Accuracy:0.886059670781893\n",
            "3888/4708 - The training loss at 26th epoch : 0.08273587303954394  Training Accuracy:0.8860143442622951\n",
            "3904/4708 - The training loss at 26th epoch : 0.08286609632625791  Training Accuracy:0.885969387755102\n",
            "3920/4708 - The training loss at 26th epoch : 0.08265353653481382  Training Accuracy:0.8864329268292683\n",
            "3936/4708 - The training loss at 26th epoch : 0.08249957327592468  Training Accuracy:0.8866396761133604\n",
            "3952/4708 - The training loss at 26th epoch : 0.0827983567143206  Training Accuracy:0.8863407258064516\n",
            "3968/4708 - The training loss at 26th epoch : 0.08255032279107391  Training Accuracy:0.8865461847389559\n",
            "3984/4708 - The training loss at 26th epoch : 0.08256093984165533  Training Accuracy:0.8865\n",
            "4000/4708 - The training loss at 26th epoch : 0.08247509245334594  Training Accuracy:0.8867031872509961\n",
            "4016/4708 - The training loss at 26th epoch : 0.08225839189604102  Training Accuracy:0.8871527777777778\n",
            "4032/4708 - The training loss at 26th epoch : 0.08201015120719281  Training Accuracy:0.887598814229249\n",
            "4048/4708 - The training loss at 26th epoch : 0.08186401585629889  Training Accuracy:0.8877952755905512\n",
            "4064/4708 - The training loss at 26th epoch : 0.08179704181418021  Training Accuracy:0.8879901960784313\n",
            "4080/4708 - The training loss at 26th epoch : 0.08156638962159957  Training Accuracy:0.888427734375\n",
            "4096/4708 - The training loss at 26th epoch : 0.08135736712020865  Training Accuracy:0.8886186770428015\n",
            "4112/4708 - The training loss at 26th epoch : 0.08120118130744003  Training Accuracy:0.8888081395348837\n",
            "4128/4708 - The training loss at 26th epoch : 0.08092289109127954  Training Accuracy:0.8892374517374517\n",
            "4144/4708 - The training loss at 26th epoch : 0.08091370906486195  Training Accuracy:0.8891826923076923\n",
            "4160/4708 - The training loss at 26th epoch : 0.08129716763898175  Training Accuracy:0.8886494252873564\n",
            "4176/4708 - The training loss at 26th epoch : 0.08148537959857928  Training Accuracy:0.8883587786259542\n",
            "4192/4708 - The training loss at 26th epoch : 0.08130590908417662  Training Accuracy:0.8887832699619772\n",
            "4208/4708 - The training loss at 26th epoch : 0.08117246372985236  Training Accuracy:0.888967803030303\n",
            "4224/4708 - The training loss at 26th epoch : 0.08183799255004404  Training Accuracy:0.8879716981132075\n",
            "4240/4708 - The training loss at 26th epoch : 0.08192260127383488  Training Accuracy:0.887453007518797\n",
            "4256/4708 - The training loss at 26th epoch : 0.08232892849677424  Training Accuracy:0.8867041198501873\n",
            "4272/4708 - The training loss at 26th epoch : 0.08234027124552931  Training Accuracy:0.886660447761194\n",
            "4288/4708 - The training loss at 26th epoch : 0.0824719536985822  Training Accuracy:0.8866171003717472\n",
            "4304/4708 - The training loss at 26th epoch : 0.0827938494545423  Training Accuracy:0.8863425925925926\n",
            "4320/4708 - The training loss at 26th epoch : 0.08268730023691588  Training Accuracy:0.8865313653136532\n",
            "4336/4708 - The training loss at 26th epoch : 0.08265505725487952  Training Accuracy:0.8864889705882353\n",
            "4352/4708 - The training loss at 26th epoch : 0.08305879465454798  Training Accuracy:0.8857600732600732\n",
            "4368/4708 - The training loss at 26th epoch : 0.08297014353816927  Training Accuracy:0.8859489051094891\n",
            "4384/4708 - The training loss at 26th epoch : 0.08330830875105916  Training Accuracy:0.8854545454545455\n",
            "4400/4708 - The training loss at 26th epoch : 0.08370870185065435  Training Accuracy:0.884963768115942\n",
            "4416/4708 - The training loss at 26th epoch : 0.08357221491765686  Training Accuracy:0.8851534296028881\n",
            "4432/4708 - The training loss at 26th epoch : 0.0837041653116697  Training Accuracy:0.8851169064748201\n",
            "4448/4708 - The training loss at 26th epoch : 0.0835509420748566  Training Accuracy:0.8853046594982079\n",
            "4464/4708 - The training loss at 26th epoch : 0.08381232821661388  Training Accuracy:0.8848214285714285\n",
            "4480/4708 - The training loss at 26th epoch : 0.08387213777528049  Training Accuracy:0.8847864768683275\n",
            "4496/4708 - The training loss at 26th epoch : 0.08384492695923412  Training Accuracy:0.8847517730496454\n",
            "4512/4708 - The training loss at 26th epoch : 0.08394354711809657  Training Accuracy:0.8847173144876325\n",
            "4528/4708 - The training loss at 26th epoch : 0.08378788722090529  Training Accuracy:0.8849031690140845\n",
            "4544/4708 - The training loss at 26th epoch : 0.08395325399122142  Training Accuracy:0.8846491228070176\n",
            "4560/4708 - The training loss at 26th epoch : 0.0839378604389643  Training Accuracy:0.8846153846153846\n",
            "4576/4708 - The training loss at 26th epoch : 0.08369687651633982  Training Accuracy:0.8850174216027874\n",
            "4592/4708 - The training loss at 26th epoch : 0.08363139277076824  Training Accuracy:0.8851996527777778\n",
            "4608/4708 - The training loss at 26th epoch : 0.08342066784185609  Training Accuracy:0.8853806228373703\n",
            "4624/4708 - The training loss at 26th epoch : 0.0834230028667418  Training Accuracy:0.8853448275862069\n",
            "4640/4708 - The training loss at 26th epoch : 0.08376914103204089  Training Accuracy:0.8846649484536082\n",
            "4656/4708 - The training loss at 26th epoch : 0.08385256036038333  Training Accuracy:0.8846318493150684\n",
            "4672/4708 - The training loss at 26th epoch : 0.08381360910977774  Training Accuracy:0.8848122866894198\n",
            "4688/4708 - The training loss at 26th epoch : 0.08374002672370544  Training Accuracy:0.8849914965986394\n",
            "4704/4708 - The training loss at 26th epoch : 0.0837549327624436  Training Accuracy:0.8849576271186441\n",
            "4720/4708 - The training loss at 26th epoch : 0.08364752430651425  Training Accuracy:0.8851351351351351\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 27th epoch : 0.13197232294894495  Training Accuracy:0.8125\n",
            "16/4708 - The training loss at 27th epoch : 0.11418092999931181  Training Accuracy:0.84375\n",
            "32/4708 - The training loss at 27th epoch : 0.1066357059097094  Training Accuracy:0.8541666666666666\n",
            "48/4708 - The training loss at 27th epoch : 0.12182124859751636  Training Accuracy:0.84375\n",
            "64/4708 - The training loss at 27th epoch : 0.12926756419649726  Training Accuracy:0.8375\n",
            "80/4708 - The training loss at 27th epoch : 0.11948351305825726  Training Accuracy:0.84375\n",
            "96/4708 - The training loss at 27th epoch : 0.11728173238708763  Training Accuracy:0.8482142857142857\n",
            "112/4708 - The training loss at 27th epoch : 0.11400811833243171  Training Accuracy:0.8515625\n",
            "128/4708 - The training loss at 27th epoch : 0.1234214654089611  Training Accuracy:0.8402777777777778\n",
            "144/4708 - The training loss at 27th epoch : 0.1314327511427355  Training Accuracy:0.83125\n",
            "160/4708 - The training loss at 27th epoch : 0.1269173693807179  Training Accuracy:0.8352272727272727\n",
            "176/4708 - The training loss at 27th epoch : 0.1234963262930579  Training Accuracy:0.8333333333333334\n",
            "192/4708 - The training loss at 27th epoch : 0.12296820569491743  Training Accuracy:0.8365384615384616\n",
            "208/4708 - The training loss at 27th epoch : 0.1214571489071012  Training Accuracy:0.8392857142857143\n",
            "224/4708 - The training loss at 27th epoch : 0.11910540536786618  Training Accuracy:0.8416666666666667\n",
            "240/4708 - The training loss at 27th epoch : 0.11556446423767738  Training Accuracy:0.84375\n",
            "256/4708 - The training loss at 27th epoch : 0.11239441049885392  Training Accuracy:0.8419117647058824\n",
            "272/4708 - The training loss at 27th epoch : 0.10921200469840212  Training Accuracy:0.8472222222222222\n",
            "288/4708 - The training loss at 27th epoch : 0.10817353568325262  Training Accuracy:0.8519736842105263\n",
            "304/4708 - The training loss at 27th epoch : 0.11239982156390808  Training Accuracy:0.846875\n",
            "320/4708 - The training loss at 27th epoch : 0.11468750492795789  Training Accuracy:0.8452380952380952\n",
            "336/4708 - The training loss at 27th epoch : 0.11193591690881521  Training Accuracy:0.8494318181818182\n",
            "352/4708 - The training loss at 27th epoch : 0.10797134422240609  Training Accuracy:0.8559782608695652\n",
            "368/4708 - The training loss at 27th epoch : 0.1074113149324208  Training Accuracy:0.8567708333333334\n",
            "384/4708 - The training loss at 27th epoch : 0.10888905603491633  Training Accuracy:0.8525\n",
            "400/4708 - The training loss at 27th epoch : 0.10756672269427027  Training Accuracy:0.8533653846153846\n",
            "416/4708 - The training loss at 27th epoch : 0.10761001439069727  Training Accuracy:0.8541666666666666\n",
            "432/4708 - The training loss at 27th epoch : 0.10708526666885512  Training Accuracy:0.8526785714285714\n",
            "448/4708 - The training loss at 27th epoch : 0.10443017348452374  Training Accuracy:0.8556034482758621\n",
            "464/4708 - The training loss at 27th epoch : 0.1033897645192989  Training Accuracy:0.85625\n",
            "480/4708 - The training loss at 27th epoch : 0.10124016404308095  Training Accuracy:0.8588709677419355\n",
            "496/4708 - The training loss at 27th epoch : 0.10111688875037436  Training Accuracy:0.859375\n",
            "512/4708 - The training loss at 27th epoch : 0.1007160804396437  Training Accuracy:0.8598484848484849\n",
            "528/4708 - The training loss at 27th epoch : 0.101809024091083  Training Accuracy:0.8566176470588235\n",
            "544/4708 - The training loss at 27th epoch : 0.10577270279128162  Training Accuracy:0.8517857142857143\n",
            "560/4708 - The training loss at 27th epoch : 0.10465278908850767  Training Accuracy:0.8524305555555556\n",
            "576/4708 - The training loss at 27th epoch : 0.1039068703462871  Training Accuracy:0.8530405405405406\n",
            "592/4708 - The training loss at 27th epoch : 0.1023915522381184  Training Accuracy:0.8552631578947368\n",
            "608/4708 - The training loss at 27th epoch : 0.10163655911410832  Training Accuracy:0.8573717948717948\n",
            "624/4708 - The training loss at 27th epoch : 0.102337334519137  Training Accuracy:0.85625\n",
            "640/4708 - The training loss at 27th epoch : 0.10265024288840639  Training Accuracy:0.8567073170731707\n",
            "656/4708 - The training loss at 27th epoch : 0.10226344989474923  Training Accuracy:0.8586309523809523\n",
            "672/4708 - The training loss at 27th epoch : 0.10163943235909478  Training Accuracy:0.8590116279069767\n",
            "688/4708 - The training loss at 27th epoch : 0.10272590488781451  Training Accuracy:0.8579545454545454\n",
            "704/4708 - The training loss at 27th epoch : 0.10231531439349223  Training Accuracy:0.8583333333333333\n",
            "720/4708 - The training loss at 27th epoch : 0.10140380355282598  Training Accuracy:0.8586956521739131\n",
            "736/4708 - The training loss at 27th epoch : 0.09962885808332692  Training Accuracy:0.8617021276595744\n",
            "752/4708 - The training loss at 27th epoch : 0.09887507869820789  Training Accuracy:0.8619791666666666\n",
            "768/4708 - The training loss at 27th epoch : 0.09731248005072958  Training Accuracy:0.8647959183673469\n",
            "784/4708 - The training loss at 27th epoch : 0.09807386204278559  Training Accuracy:0.865\n",
            "800/4708 - The training loss at 27th epoch : 0.09878921681937496  Training Accuracy:0.8639705882352942\n",
            "816/4708 - The training loss at 27th epoch : 0.09930711364930749  Training Accuracy:0.8641826923076923\n",
            "832/4708 - The training loss at 27th epoch : 0.09807897145306749  Training Accuracy:0.8667452830188679\n",
            "848/4708 - The training loss at 27th epoch : 0.09636135566569924  Training Accuracy:0.8692129629629629\n",
            "864/4708 - The training loss at 27th epoch : 0.09552227093867384  Training Accuracy:0.8693181818181818\n",
            "880/4708 - The training loss at 27th epoch : 0.09470564332765953  Training Accuracy:0.8705357142857143\n",
            "896/4708 - The training loss at 27th epoch : 0.09335269055532779  Training Accuracy:0.8728070175438597\n",
            "912/4708 - The training loss at 27th epoch : 0.092874662731171  Training Accuracy:0.8739224137931034\n",
            "928/4708 - The training loss at 27th epoch : 0.09242818065283172  Training Accuracy:0.8728813559322034\n",
            "944/4708 - The training loss at 27th epoch : 0.09113580542937104  Training Accuracy:0.875\n",
            "960/4708 - The training loss at 27th epoch : 0.09137538927136842  Training Accuracy:0.875\n",
            "976/4708 - The training loss at 27th epoch : 0.09086136829999819  Training Accuracy:0.876008064516129\n",
            "992/4708 - The training loss at 27th epoch : 0.08996945276917999  Training Accuracy:0.876984126984127\n",
            "1008/4708 - The training loss at 27th epoch : 0.0888062308240426  Training Accuracy:0.87890625\n",
            "1024/4708 - The training loss at 27th epoch : 0.08902845454096717  Training Accuracy:0.8788461538461538\n",
            "1040/4708 - The training loss at 27th epoch : 0.0887763043001915  Training Accuracy:0.8797348484848485\n",
            "1056/4708 - The training loss at 27th epoch : 0.08837206824133992  Training Accuracy:0.8805970149253731\n",
            "1072/4708 - The training loss at 27th epoch : 0.08779576758160233  Training Accuracy:0.8814338235294118\n",
            "1088/4708 - The training loss at 27th epoch : 0.08785505375955377  Training Accuracy:0.8813405797101449\n",
            "1104/4708 - The training loss at 27th epoch : 0.0878583161958206  Training Accuracy:0.88125\n",
            "1120/4708 - The training loss at 27th epoch : 0.08699180088905481  Training Accuracy:0.8829225352112676\n",
            "1136/4708 - The training loss at 27th epoch : 0.08725805941083059  Training Accuracy:0.8828125\n",
            "1152/4708 - The training loss at 27th epoch : 0.08677720597666594  Training Accuracy:0.8835616438356164\n",
            "1168/4708 - The training loss at 27th epoch : 0.08745158019313984  Training Accuracy:0.8834459459459459\n",
            "1184/4708 - The training loss at 27th epoch : 0.08734615766097932  Training Accuracy:0.8841666666666667\n",
            "1200/4708 - The training loss at 27th epoch : 0.08660866808744334  Training Accuracy:0.8856907894736842\n",
            "1216/4708 - The training loss at 27th epoch : 0.08733692804936277  Training Accuracy:0.8839285714285714\n",
            "1232/4708 - The training loss at 27th epoch : 0.08628202841267481  Training Accuracy:0.8854166666666666\n",
            "1248/4708 - The training loss at 27th epoch : 0.08684519685885321  Training Accuracy:0.884493670886076\n",
            "1264/4708 - The training loss at 27th epoch : 0.08625812480767  Training Accuracy:0.8859375\n",
            "1280/4708 - The training loss at 27th epoch : 0.08600832748589303  Training Accuracy:0.8865740740740741\n",
            "1296/4708 - The training loss at 27th epoch : 0.08515479728447953  Training Accuracy:0.8879573170731707\n",
            "1312/4708 - The training loss at 27th epoch : 0.08557915492102369  Training Accuracy:0.8878012048192772\n",
            "1328/4708 - The training loss at 27th epoch : 0.08548121229004904  Training Accuracy:0.8883928571428571\n",
            "1344/4708 - The training loss at 27th epoch : 0.08528014701208989  Training Accuracy:0.8889705882352941\n",
            "1360/4708 - The training loss at 27th epoch : 0.0851764912972409  Training Accuracy:0.8888081395348837\n",
            "1376/4708 - The training loss at 27th epoch : 0.08569665437990093  Training Accuracy:0.8879310344827587\n",
            "1392/4708 - The training loss at 27th epoch : 0.08494881756804226  Training Accuracy:0.8884943181818182\n",
            "1408/4708 - The training loss at 27th epoch : 0.08515486276243196  Training Accuracy:0.8883426966292135\n",
            "1424/4708 - The training loss at 27th epoch : 0.08478908232975703  Training Accuracy:0.8888888888888888\n",
            "1440/4708 - The training loss at 27th epoch : 0.08545432900442052  Training Accuracy:0.8887362637362637\n",
            "1456/4708 - The training loss at 27th epoch : 0.08508677405659748  Training Accuracy:0.8885869565217391\n",
            "1472/4708 - The training loss at 27th epoch : 0.08459792479818079  Training Accuracy:0.8891129032258065\n",
            "1488/4708 - The training loss at 27th epoch : 0.0848477150115372  Training Accuracy:0.8882978723404256\n",
            "1504/4708 - The training loss at 27th epoch : 0.0847107630123152  Training Accuracy:0.8881578947368421\n",
            "1520/4708 - The training loss at 27th epoch : 0.0856901485172799  Training Accuracy:0.88671875\n",
            "1536/4708 - The training loss at 27th epoch : 0.08522758168197042  Training Accuracy:0.8872422680412371\n",
            "1552/4708 - The training loss at 27th epoch : 0.08444516238198291  Training Accuracy:0.8883928571428571\n",
            "1568/4708 - The training loss at 27th epoch : 0.08423959308911769  Training Accuracy:0.8888888888888888\n",
            "1584/4708 - The training loss at 27th epoch : 0.08388499071809435  Training Accuracy:0.889375\n",
            "1600/4708 - The training loss at 27th epoch : 0.08405740928844538  Training Accuracy:0.8886138613861386\n",
            "1616/4708 - The training loss at 27th epoch : 0.08392728958171794  Training Accuracy:0.8890931372549019\n",
            "1632/4708 - The training loss at 27th epoch : 0.08352980621633313  Training Accuracy:0.8895631067961165\n",
            "1648/4708 - The training loss at 27th epoch : 0.08331079602122769  Training Accuracy:0.8900240384615384\n",
            "1664/4708 - The training loss at 27th epoch : 0.08373096085265821  Training Accuracy:0.8886904761904761\n",
            "1680/4708 - The training loss at 27th epoch : 0.08346330770454531  Training Accuracy:0.8891509433962265\n",
            "1696/4708 - The training loss at 27th epoch : 0.08332305291564898  Training Accuracy:0.889018691588785\n",
            "1712/4708 - The training loss at 27th epoch : 0.08360086888221262  Training Accuracy:0.8877314814814815\n",
            "1728/4708 - The training loss at 27th epoch : 0.08326557962205876  Training Accuracy:0.8881880733944955\n",
            "1744/4708 - The training loss at 27th epoch : 0.08349408236937098  Training Accuracy:0.8875\n",
            "1760/4708 - The training loss at 27th epoch : 0.08316029232849721  Training Accuracy:0.8879504504504504\n",
            "1776/4708 - The training loss at 27th epoch : 0.08303507572034767  Training Accuracy:0.8878348214285714\n",
            "1792/4708 - The training loss at 27th epoch : 0.08249222096100757  Training Accuracy:0.8888274336283186\n",
            "1808/4708 - The training loss at 27th epoch : 0.08288042622591762  Training Accuracy:0.8881578947368421\n",
            "1824/4708 - The training loss at 27th epoch : 0.0836643089723968  Training Accuracy:0.8875\n",
            "1840/4708 - The training loss at 27th epoch : 0.08401555036408406  Training Accuracy:0.8868534482758621\n",
            "1856/4708 - The training loss at 27th epoch : 0.08493366525947456  Training Accuracy:0.8856837606837606\n",
            "1872/4708 - The training loss at 27th epoch : 0.08505549120337055  Training Accuracy:0.8850635593220338\n",
            "1888/4708 - The training loss at 27th epoch : 0.08507096013493051  Training Accuracy:0.8849789915966386\n",
            "1904/4708 - The training loss at 27th epoch : 0.08515380738689181  Training Accuracy:0.8848958333333333\n",
            "1920/4708 - The training loss at 27th epoch : 0.08459540018335582  Training Accuracy:0.8858471074380165\n",
            "1936/4708 - The training loss at 27th epoch : 0.08432082434783256  Training Accuracy:0.8862704918032787\n",
            "1952/4708 - The training loss at 27th epoch : 0.0844182625680007  Training Accuracy:0.885670731707317\n",
            "1968/4708 - The training loss at 27th epoch : 0.0840115758629382  Training Accuracy:0.8860887096774194\n",
            "1984/4708 - The training loss at 27th epoch : 0.08354550479958656  Training Accuracy:0.8865\n",
            "2000/4708 - The training loss at 27th epoch : 0.08358225110954359  Training Accuracy:0.8864087301587301\n",
            "2016/4708 - The training loss at 27th epoch : 0.08367059371472631  Training Accuracy:0.8858267716535433\n",
            "2032/4708 - The training loss at 27th epoch : 0.08405465310307511  Training Accuracy:0.88525390625\n",
            "2048/4708 - The training loss at 27th epoch : 0.08422559534701374  Training Accuracy:0.8851744186046512\n",
            "2064/4708 - The training loss at 27th epoch : 0.08372723071913339  Training Accuracy:0.8860576923076923\n",
            "2080/4708 - The training loss at 27th epoch : 0.08350948263611517  Training Accuracy:0.8864503816793893\n",
            "2096/4708 - The training loss at 27th epoch : 0.0830838122859238  Training Accuracy:0.8868371212121212\n",
            "2112/4708 - The training loss at 27th epoch : 0.0825985675460938  Training Accuracy:0.887687969924812\n",
            "2128/4708 - The training loss at 27th epoch : 0.08248245284581103  Training Accuracy:0.8875932835820896\n",
            "2144/4708 - The training loss at 27th epoch : 0.08195978255095342  Training Accuracy:0.888425925925926\n",
            "2160/4708 - The training loss at 27th epoch : 0.08191730511372063  Training Accuracy:0.8883272058823529\n",
            "2176/4708 - The training loss at 27th epoch : 0.08147688930858281  Training Accuracy:0.8891423357664233\n",
            "2192/4708 - The training loss at 27th epoch : 0.08162626955805137  Training Accuracy:0.8885869565217391\n",
            "2208/4708 - The training loss at 27th epoch : 0.08128345506203133  Training Accuracy:0.8893884892086331\n",
            "2224/4708 - The training loss at 27th epoch : 0.08103341922167172  Training Accuracy:0.8897321428571429\n",
            "2240/4708 - The training loss at 27th epoch : 0.08094475697653687  Training Accuracy:0.8896276595744681\n",
            "2256/4708 - The training loss at 27th epoch : 0.08145434945222556  Training Accuracy:0.8890845070422535\n",
            "2272/4708 - The training loss at 27th epoch : 0.08124468334369964  Training Accuracy:0.8894230769230769\n",
            "2288/4708 - The training loss at 27th epoch : 0.08090723868378356  Training Accuracy:0.8901909722222222\n",
            "2304/4708 - The training loss at 27th epoch : 0.08048257937593556  Training Accuracy:0.8909482758620689\n",
            "2320/4708 - The training loss at 27th epoch : 0.08029446409321633  Training Accuracy:0.8908390410958904\n",
            "2336/4708 - The training loss at 27th epoch : 0.08015727709735404  Training Accuracy:0.8907312925170068\n",
            "2352/4708 - The training loss at 27th epoch : 0.08060459738886643  Training Accuracy:0.8902027027027027\n",
            "2368/4708 - The training loss at 27th epoch : 0.08012685648477251  Training Accuracy:0.8909395973154363\n",
            "2384/4708 - The training loss at 27th epoch : 0.07995506054325878  Training Accuracy:0.89125\n",
            "2400/4708 - The training loss at 27th epoch : 0.08018985928187107  Training Accuracy:0.8911423841059603\n",
            "2416/4708 - The training loss at 27th epoch : 0.08028264623032665  Training Accuracy:0.890625\n",
            "2432/4708 - The training loss at 27th epoch : 0.07998201194571286  Training Accuracy:0.8909313725490197\n",
            "2448/4708 - The training loss at 27th epoch : 0.08011358751522316  Training Accuracy:0.890827922077922\n",
            "2464/4708 - The training loss at 27th epoch : 0.08065288387566844  Training Accuracy:0.8899193548387097\n",
            "2480/4708 - The training loss at 27th epoch : 0.0806569605398636  Training Accuracy:0.889823717948718\n",
            "2496/4708 - The training loss at 27th epoch : 0.08046515099960137  Training Accuracy:0.8901273885350318\n",
            "2512/4708 - The training loss at 27th epoch : 0.08041545842641776  Training Accuracy:0.8900316455696202\n",
            "2528/4708 - The training loss at 27th epoch : 0.08003089776234164  Training Accuracy:0.8907232704402516\n",
            "2544/4708 - The training loss at 27th epoch : 0.07981984177739362  Training Accuracy:0.891015625\n",
            "2560/4708 - The training loss at 27th epoch : 0.07975729068760763  Training Accuracy:0.890916149068323\n",
            "2576/4708 - The training loss at 27th epoch : 0.0797123537998797  Training Accuracy:0.8908179012345679\n",
            "2592/4708 - The training loss at 27th epoch : 0.07934730149320353  Training Accuracy:0.8914877300613497\n",
            "2608/4708 - The training loss at 27th epoch : 0.07941478003207071  Training Accuracy:0.8917682926829268\n",
            "2624/4708 - The training loss at 27th epoch : 0.07937759521355156  Training Accuracy:0.8920454545454546\n",
            "2640/4708 - The training loss at 27th epoch : 0.07963343018994215  Training Accuracy:0.8919427710843374\n",
            "2656/4708 - The training loss at 27th epoch : 0.07974786274781216  Training Accuracy:0.8918413173652695\n",
            "2672/4708 - The training loss at 27th epoch : 0.07948986375577156  Training Accuracy:0.8921130952380952\n",
            "2688/4708 - The training loss at 27th epoch : 0.07965922154221042  Training Accuracy:0.8920118343195266\n",
            "2704/4708 - The training loss at 27th epoch : 0.07975232526484438  Training Accuracy:0.8919117647058824\n",
            "2720/4708 - The training loss at 27th epoch : 0.07964451847183529  Training Accuracy:0.8921783625730995\n",
            "2736/4708 - The training loss at 27th epoch : 0.07979952271786309  Training Accuracy:0.8917151162790697\n",
            "2752/4708 - The training loss at 27th epoch : 0.07998102343704719  Training Accuracy:0.8916184971098265\n",
            "2768/4708 - The training loss at 27th epoch : 0.07967374224378723  Training Accuracy:0.891882183908046\n",
            "2784/4708 - The training loss at 27th epoch : 0.0796575061652115  Training Accuracy:0.8921428571428571\n",
            "2800/4708 - The training loss at 27th epoch : 0.07965462650663324  Training Accuracy:0.8920454545454546\n",
            "2816/4708 - The training loss at 27th epoch : 0.07962914564994727  Training Accuracy:0.8919491525423728\n",
            "2832/4708 - The training loss at 27th epoch : 0.08020613057214245  Training Accuracy:0.8908005617977528\n",
            "2848/4708 - The training loss at 27th epoch : 0.08008704596024363  Training Accuracy:0.8907122905027933\n",
            "2864/4708 - The training loss at 27th epoch : 0.07988008542382304  Training Accuracy:0.8909722222222223\n",
            "2880/4708 - The training loss at 27th epoch : 0.08020842330257606  Training Accuracy:0.8905386740331491\n",
            "2896/4708 - The training loss at 27th epoch : 0.08030759562976303  Training Accuracy:0.8901098901098901\n",
            "2912/4708 - The training loss at 27th epoch : 0.08051456913347894  Training Accuracy:0.8896857923497268\n",
            "2928/4708 - The training loss at 27th epoch : 0.08034391531514881  Training Accuracy:0.8899456521739131\n",
            "2944/4708 - The training loss at 27th epoch : 0.08085523567651892  Training Accuracy:0.889527027027027\n",
            "2960/4708 - The training loss at 27th epoch : 0.08069509010419175  Training Accuracy:0.8897849462365591\n",
            "2976/4708 - The training loss at 27th epoch : 0.08068872529451918  Training Accuracy:0.8897058823529411\n",
            "2992/4708 - The training loss at 27th epoch : 0.0805271524639023  Training Accuracy:0.8899601063829787\n",
            "3008/4708 - The training loss at 27th epoch : 0.08040785248341457  Training Accuracy:0.8902116402116402\n",
            "3024/4708 - The training loss at 27th epoch : 0.08059297905166364  Training Accuracy:0.8898026315789473\n",
            "3040/4708 - The training loss at 27th epoch : 0.08067088023841025  Training Accuracy:0.8897251308900523\n",
            "3056/4708 - The training loss at 27th epoch : 0.08041962618234752  Training Accuracy:0.8902994791666666\n",
            "3072/4708 - The training loss at 27th epoch : 0.08072739417281219  Training Accuracy:0.8895725388601037\n",
            "3088/4708 - The training loss at 27th epoch : 0.08068496830205069  Training Accuracy:0.8898195876288659\n",
            "3104/4708 - The training loss at 27th epoch : 0.08095176971112662  Training Accuracy:0.8897435897435897\n",
            "3120/4708 - The training loss at 27th epoch : 0.0808218608264222  Training Accuracy:0.8899872448979592\n",
            "3136/4708 - The training loss at 27th epoch : 0.08089457202919995  Training Accuracy:0.8899111675126904\n",
            "3152/4708 - The training loss at 27th epoch : 0.08114307786845497  Training Accuracy:0.889520202020202\n",
            "3168/4708 - The training loss at 27th epoch : 0.08155081017348352  Training Accuracy:0.8888190954773869\n",
            "3184/4708 - The training loss at 27th epoch : 0.08174509719098896  Training Accuracy:0.8884375\n",
            "3200/4708 - The training loss at 27th epoch : 0.08142511157568866  Training Accuracy:0.8889925373134329\n",
            "3216/4708 - The training loss at 27th epoch : 0.0816286389857447  Training Accuracy:0.8889232673267327\n",
            "3232/4708 - The training loss at 27th epoch : 0.081463688941085  Training Accuracy:0.8891625615763546\n",
            "3248/4708 - The training loss at 27th epoch : 0.08114275914173748  Training Accuracy:0.8897058823529411\n",
            "3264/4708 - The training loss at 27th epoch : 0.08080186200030899  Training Accuracy:0.8902439024390244\n",
            "3280/4708 - The training loss at 27th epoch : 0.08067781120183733  Training Accuracy:0.8904733009708737\n",
            "3296/4708 - The training loss at 27th epoch : 0.08042304693750293  Training Accuracy:0.8910024154589372\n",
            "3312/4708 - The training loss at 27th epoch : 0.08023092571330322  Training Accuracy:0.8909254807692307\n",
            "3328/4708 - The training loss at 27th epoch : 0.08033174384621934  Training Accuracy:0.8908492822966507\n",
            "3344/4708 - The training loss at 27th epoch : 0.08030772120988952  Training Accuracy:0.8910714285714286\n",
            "3360/4708 - The training loss at 27th epoch : 0.0799985589594712  Training Accuracy:0.8915876777251185\n",
            "3376/4708 - The training loss at 27th epoch : 0.08016330809907124  Training Accuracy:0.8909198113207547\n",
            "3392/4708 - The training loss at 27th epoch : 0.08038089606949275  Training Accuracy:0.8905516431924883\n",
            "3408/4708 - The training loss at 27th epoch : 0.08008029711764282  Training Accuracy:0.8910630841121495\n",
            "3424/4708 - The training loss at 27th epoch : 0.08003631150889272  Training Accuracy:0.8912790697674419\n",
            "3440/4708 - The training loss at 27th epoch : 0.08006382832277154  Training Accuracy:0.8914930555555556\n",
            "3456/4708 - The training loss at 27th epoch : 0.08027561586463222  Training Accuracy:0.8911290322580645\n",
            "3472/4708 - The training loss at 27th epoch : 0.08026403346169475  Training Accuracy:0.8910550458715596\n",
            "3488/4708 - The training loss at 27th epoch : 0.08027894790301059  Training Accuracy:0.8912671232876712\n",
            "3504/4708 - The training loss at 27th epoch : 0.08035640341722992  Training Accuracy:0.8911931818181819\n",
            "3520/4708 - The training loss at 27th epoch : 0.08054819427795165  Training Accuracy:0.8911199095022625\n",
            "3536/4708 - The training loss at 27th epoch : 0.08020118755873662  Training Accuracy:0.8916103603603603\n",
            "3552/4708 - The training loss at 27th epoch : 0.08021475689400114  Training Accuracy:0.8918161434977578\n",
            "3568/4708 - The training loss at 27th epoch : 0.08008477974825999  Training Accuracy:0.8920200892857143\n",
            "3584/4708 - The training loss at 27th epoch : 0.0802745027673886  Training Accuracy:0.8919444444444444\n",
            "3600/4708 - The training loss at 27th epoch : 0.08015663236670172  Training Accuracy:0.8921460176991151\n",
            "3616/4708 - The training loss at 27th epoch : 0.0799554562563688  Training Accuracy:0.8923458149779736\n",
            "3632/4708 - The training loss at 27th epoch : 0.08015721863882194  Training Accuracy:0.8917214912280702\n",
            "3648/4708 - The training loss at 27th epoch : 0.0803802679656942  Training Accuracy:0.8916484716157205\n",
            "3664/4708 - The training loss at 27th epoch : 0.0802496830727828  Training Accuracy:0.8918478260869566\n",
            "3680/4708 - The training loss at 27th epoch : 0.08045989863632354  Training Accuracy:0.8912337662337663\n",
            "3696/4708 - The training loss at 27th epoch : 0.08050388741601842  Training Accuracy:0.8908943965517241\n",
            "3712/4708 - The training loss at 27th epoch : 0.08109328300204142  Training Accuracy:0.8902896995708155\n",
            "3728/4708 - The training loss at 27th epoch : 0.08103001830609192  Training Accuracy:0.8904914529914529\n",
            "3744/4708 - The training loss at 27th epoch : 0.08139483646115235  Training Accuracy:0.8901595744680851\n",
            "3760/4708 - The training loss at 27th epoch : 0.0815901962734283  Training Accuracy:0.8898305084745762\n",
            "3776/4708 - The training loss at 27th epoch : 0.08167132402477677  Training Accuracy:0.8897679324894515\n",
            "3792/4708 - The training loss at 27th epoch : 0.08186978263857146  Training Accuracy:0.8897058823529411\n",
            "3808/4708 - The training loss at 27th epoch : 0.08186739780345743  Training Accuracy:0.8896443514644351\n",
            "3824/4708 - The training loss at 27th epoch : 0.08180470354046383  Training Accuracy:0.88984375\n",
            "3840/4708 - The training loss at 27th epoch : 0.0818075463263986  Training Accuracy:0.8897821576763485\n",
            "3856/4708 - The training loss at 27th epoch : 0.08153884054999914  Training Accuracy:0.8902376033057852\n",
            "3872/4708 - The training loss at 27th epoch : 0.08161148736348492  Training Accuracy:0.8899176954732511\n",
            "3888/4708 - The training loss at 27th epoch : 0.08179586264095416  Training Accuracy:0.8896004098360656\n",
            "3904/4708 - The training loss at 27th epoch : 0.08174709607227813  Training Accuracy:0.889795918367347\n",
            "3920/4708 - The training loss at 27th epoch : 0.08168547047976413  Training Accuracy:0.889989837398374\n",
            "3936/4708 - The training loss at 27th epoch : 0.08195183420129624  Training Accuracy:0.8896761133603239\n",
            "3952/4708 - The training loss at 27th epoch : 0.08183121581854137  Training Accuracy:0.8898689516129032\n",
            "3968/4708 - The training loss at 27th epoch : 0.08213274005678967  Training Accuracy:0.8895582329317269\n",
            "3984/4708 - The training loss at 27th epoch : 0.08217090315793388  Training Accuracy:0.88975\n",
            "4000/4708 - The training loss at 27th epoch : 0.08193478282323824  Training Accuracy:0.8901892430278885\n",
            "4016/4708 - The training loss at 27th epoch : 0.08187083876232593  Training Accuracy:0.8901289682539683\n",
            "4032/4708 - The training loss at 27th epoch : 0.08216474301264752  Training Accuracy:0.8895750988142292\n",
            "4048/4708 - The training loss at 27th epoch : 0.08250240131131453  Training Accuracy:0.8892716535433071\n",
            "4064/4708 - The training loss at 27th epoch : 0.08249810136450855  Training Accuracy:0.8894607843137254\n",
            "4080/4708 - The training loss at 27th epoch : 0.08244161888411457  Training Accuracy:0.8896484375\n",
            "4096/4708 - The training loss at 27th epoch : 0.08234943333861809  Training Accuracy:0.8895914396887159\n",
            "4112/4708 - The training loss at 27th epoch : 0.08220323671951195  Training Accuracy:0.8897771317829457\n",
            "4128/4708 - The training loss at 27th epoch : 0.0821176458320729  Training Accuracy:0.88996138996139\n",
            "4144/4708 - The training loss at 27th epoch : 0.08208706794793594  Training Accuracy:0.8899038461538461\n",
            "4160/4708 - The training loss at 27th epoch : 0.081786701655905  Training Accuracy:0.8903256704980843\n",
            "4176/4708 - The training loss at 27th epoch : 0.08170205674045916  Training Accuracy:0.8905057251908397\n",
            "4192/4708 - The training loss at 27th epoch : 0.08175346019980079  Training Accuracy:0.8904467680608364\n",
            "4208/4708 - The training loss at 27th epoch : 0.08177135805152567  Training Accuracy:0.8903882575757576\n",
            "4224/4708 - The training loss at 27th epoch : 0.08154028225175436  Training Accuracy:0.8908018867924529\n",
            "4240/4708 - The training loss at 27th epoch : 0.08166561317001868  Training Accuracy:0.8905075187969925\n",
            "4256/4708 - The training loss at 27th epoch : 0.08196134070174771  Training Accuracy:0.8902153558052435\n",
            "4272/4708 - The training loss at 27th epoch : 0.08184648579630968  Training Accuracy:0.8903917910447762\n",
            "4288/4708 - The training loss at 27th epoch : 0.08175794735798553  Training Accuracy:0.8905669144981413\n",
            "4304/4708 - The training loss at 27th epoch : 0.08156632311277853  Training Accuracy:0.8909722222222223\n",
            "4320/4708 - The training loss at 27th epoch : 0.08154486126469586  Training Accuracy:0.8911439114391144\n",
            "4336/4708 - The training loss at 27th epoch : 0.08163989361264949  Training Accuracy:0.890625\n",
            "4352/4708 - The training loss at 27th epoch : 0.08236292435369154  Training Accuracy:0.8894230769230769\n",
            "4368/4708 - The training loss at 27th epoch : 0.08264794266583193  Training Accuracy:0.8893704379562044\n",
            "4384/4708 - The training loss at 27th epoch : 0.08287121888111788  Training Accuracy:0.8888636363636364\n",
            "4400/4708 - The training loss at 27th epoch : 0.08282226212148129  Training Accuracy:0.8890398550724637\n",
            "4416/4708 - The training loss at 27th epoch : 0.08276683695610672  Training Accuracy:0.8892148014440433\n",
            "4432/4708 - The training loss at 27th epoch : 0.08278777402543779  Training Accuracy:0.8891636690647482\n",
            "4448/4708 - The training loss at 27th epoch : 0.08257192064554598  Training Accuracy:0.8895609318996416\n",
            "4464/4708 - The training loss at 27th epoch : 0.0823811742953989  Training Accuracy:0.8897321428571429\n",
            "4480/4708 - The training loss at 27th epoch : 0.08227043199373643  Training Accuracy:0.8899021352313167\n",
            "4496/4708 - The training loss at 27th epoch : 0.08225068731165897  Training Accuracy:0.8898492907801419\n",
            "4512/4708 - The training loss at 27th epoch : 0.08248900726208437  Training Accuracy:0.8895759717314488\n",
            "4528/4708 - The training loss at 27th epoch : 0.08227639169491677  Training Accuracy:0.8899647887323944\n",
            "4544/4708 - The training loss at 27th epoch : 0.08228945998055104  Training Accuracy:0.8896929824561404\n",
            "4560/4708 - The training loss at 27th epoch : 0.08276207276418283  Training Accuracy:0.888986013986014\n",
            "4576/4708 - The training loss at 27th epoch : 0.0831542435070438  Training Accuracy:0.8885017421602788\n",
            "4592/4708 - The training loss at 27th epoch : 0.08309406767251722  Training Accuracy:0.8882378472222222\n",
            "4608/4708 - The training loss at 27th epoch : 0.08307968155192465  Training Accuracy:0.8881920415224913\n",
            "4624/4708 - The training loss at 27th epoch : 0.08306199009159781  Training Accuracy:0.8881465517241379\n",
            "4640/4708 - The training loss at 27th epoch : 0.0829966490255147  Training Accuracy:0.8881013745704467\n",
            "4656/4708 - The training loss at 27th epoch : 0.08305432921709706  Training Accuracy:0.888056506849315\n",
            "4672/4708 - The training loss at 27th epoch : 0.08315037096816487  Training Accuracy:0.8880119453924915\n",
            "4688/4708 - The training loss at 27th epoch : 0.08302820713628885  Training Accuracy:0.8881802721088435\n",
            "4704/4708 - The training loss at 27th epoch : 0.08308732779031812  Training Accuracy:0.888135593220339\n",
            "4720/4708 - The training loss at 27th epoch : 0.08301693386090483  Training Accuracy:0.8883023648648649\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 28th epoch : 0.019082365663460776  Training Accuracy:1.0\n",
            "16/4708 - The training loss at 28th epoch : 0.02890819041691785  Training Accuracy:0.96875\n",
            "32/4708 - The training loss at 28th epoch : 0.05253693680207141  Training Accuracy:0.9375\n",
            "48/4708 - The training loss at 28th epoch : 0.06144875831928206  Training Accuracy:0.90625\n",
            "64/4708 - The training loss at 28th epoch : 0.10139704972769122  Training Accuracy:0.8625\n",
            "80/4708 - The training loss at 28th epoch : 0.09450351416623735  Training Accuracy:0.8645833333333334\n",
            "96/4708 - The training loss at 28th epoch : 0.0911423519946348  Training Accuracy:0.875\n",
            "112/4708 - The training loss at 28th epoch : 0.10442448839911687  Training Accuracy:0.859375\n",
            "128/4708 - The training loss at 28th epoch : 0.10335072938016462  Training Accuracy:0.8611111111111112\n",
            "144/4708 - The training loss at 28th epoch : 0.09835599836806104  Training Accuracy:0.8625\n",
            "160/4708 - The training loss at 28th epoch : 0.09268901241961024  Training Accuracy:0.875\n",
            "176/4708 - The training loss at 28th epoch : 0.09257877635789989  Training Accuracy:0.875\n",
            "192/4708 - The training loss at 28th epoch : 0.0943739507513195  Training Accuracy:0.875\n",
            "208/4708 - The training loss at 28th epoch : 0.0898352815358014  Training Accuracy:0.8794642857142857\n",
            "224/4708 - The training loss at 28th epoch : 0.08868630839413254  Training Accuracy:0.8833333333333333\n",
            "240/4708 - The training loss at 28th epoch : 0.08505085748066878  Training Accuracy:0.88671875\n",
            "256/4708 - The training loss at 28th epoch : 0.08544988588042016  Training Accuracy:0.8823529411764706\n",
            "272/4708 - The training loss at 28th epoch : 0.0830933354480778  Training Accuracy:0.8854166666666666\n",
            "288/4708 - The training loss at 28th epoch : 0.08188594722930147  Training Accuracy:0.8848684210526315\n",
            "304/4708 - The training loss at 28th epoch : 0.08123834680773312  Training Accuracy:0.884375\n",
            "320/4708 - The training loss at 28th epoch : 0.07771941342117959  Training Accuracy:0.8898809523809523\n",
            "336/4708 - The training loss at 28th epoch : 0.0771215765881177  Training Accuracy:0.8920454545454546\n",
            "352/4708 - The training loss at 28th epoch : 0.07496405980406004  Training Accuracy:0.8967391304347826\n",
            "368/4708 - The training loss at 28th epoch : 0.07459689161907972  Training Accuracy:0.8984375\n",
            "384/4708 - The training loss at 28th epoch : 0.07448353831431664  Training Accuracy:0.8975\n",
            "400/4708 - The training loss at 28th epoch : 0.0743384545070157  Training Accuracy:0.8990384615384616\n",
            "416/4708 - The training loss at 28th epoch : 0.07372097705460044  Training Accuracy:0.9004629629629629\n",
            "432/4708 - The training loss at 28th epoch : 0.07480997425470139  Training Accuracy:0.8973214285714286\n",
            "448/4708 - The training loss at 28th epoch : 0.0765688833753566  Training Accuracy:0.8943965517241379\n",
            "464/4708 - The training loss at 28th epoch : 0.07448773419317524  Training Accuracy:0.8979166666666667\n",
            "480/4708 - The training loss at 28th epoch : 0.07393210398357003  Training Accuracy:0.8991935483870968\n",
            "496/4708 - The training loss at 28th epoch : 0.07506826205496006  Training Accuracy:0.8984375\n",
            "512/4708 - The training loss at 28th epoch : 0.07562352209599499  Training Accuracy:0.8958333333333334\n",
            "528/4708 - The training loss at 28th epoch : 0.07511467157704461  Training Accuracy:0.8952205882352942\n",
            "544/4708 - The training loss at 28th epoch : 0.07604566467085552  Training Accuracy:0.8946428571428572\n",
            "560/4708 - The training loss at 28th epoch : 0.0805386165263738  Training Accuracy:0.8888888888888888\n",
            "576/4708 - The training loss at 28th epoch : 0.08124276075746698  Training Accuracy:0.8885135135135135\n",
            "592/4708 - The training loss at 28th epoch : 0.08059269776749627  Training Accuracy:0.8898026315789473\n",
            "608/4708 - The training loss at 28th epoch : 0.07986002091248416  Training Accuracy:0.8926282051282052\n",
            "624/4708 - The training loss at 28th epoch : 0.08159353811961755  Training Accuracy:0.8890625\n",
            "640/4708 - The training loss at 28th epoch : 0.08297476823323573  Training Accuracy:0.8871951219512195\n",
            "656/4708 - The training loss at 28th epoch : 0.08374415074157031  Training Accuracy:0.8854166666666666\n",
            "672/4708 - The training loss at 28th epoch : 0.08375835251947952  Training Accuracy:0.8866279069767442\n",
            "688/4708 - The training loss at 28th epoch : 0.08327108379096784  Training Accuracy:0.8877840909090909\n",
            "704/4708 - The training loss at 28th epoch : 0.08259251321389004  Training Accuracy:0.8888888888888888\n",
            "720/4708 - The training loss at 28th epoch : 0.08117324756193127  Training Accuracy:0.8913043478260869\n",
            "736/4708 - The training loss at 28th epoch : 0.08295507494201103  Training Accuracy:0.8882978723404256\n",
            "752/4708 - The training loss at 28th epoch : 0.08184354802569678  Training Accuracy:0.8893229166666666\n",
            "768/4708 - The training loss at 28th epoch : 0.0807403220688159  Training Accuracy:0.8915816326530612\n",
            "784/4708 - The training loss at 28th epoch : 0.0793186873223567  Training Accuracy:0.89375\n",
            "800/4708 - The training loss at 28th epoch : 0.07890621826605905  Training Accuracy:0.8946078431372549\n",
            "816/4708 - The training loss at 28th epoch : 0.07966133033297249  Training Accuracy:0.8942307692307693\n",
            "832/4708 - The training loss at 28th epoch : 0.07872213737491414  Training Accuracy:0.8950471698113207\n",
            "848/4708 - The training loss at 28th epoch : 0.07938346067829244  Training Accuracy:0.8946759259259259\n",
            "864/4708 - The training loss at 28th epoch : 0.07846695131285567  Training Accuracy:0.8965909090909091\n",
            "880/4708 - The training loss at 28th epoch : 0.08016919555215543  Training Accuracy:0.8950892857142857\n",
            "896/4708 - The training loss at 28th epoch : 0.08140831705178009  Training Accuracy:0.8925438596491229\n",
            "912/4708 - The training loss at 28th epoch : 0.08109799155339414  Training Accuracy:0.8933189655172413\n",
            "928/4708 - The training loss at 28th epoch : 0.08167424252576283  Training Accuracy:0.8930084745762712\n",
            "944/4708 - The training loss at 28th epoch : 0.08095021913019752  Training Accuracy:0.89375\n",
            "960/4708 - The training loss at 28th epoch : 0.08065820806318151  Training Accuracy:0.8944672131147541\n",
            "976/4708 - The training loss at 28th epoch : 0.07961570508359912  Training Accuracy:0.8961693548387096\n",
            "992/4708 - The training loss at 28th epoch : 0.07968796347267391  Training Accuracy:0.8958333333333334\n",
            "1008/4708 - The training loss at 28th epoch : 0.0794762285327927  Training Accuracy:0.8955078125\n",
            "1024/4708 - The training loss at 28th epoch : 0.07854689510502215  Training Accuracy:0.8971153846153846\n",
            "1040/4708 - The training loss at 28th epoch : 0.07893459317874571  Training Accuracy:0.8977272727272727\n",
            "1056/4708 - The training loss at 28th epoch : 0.07834902722745604  Training Accuracy:0.898320895522388\n",
            "1072/4708 - The training loss at 28th epoch : 0.07769955756016836  Training Accuracy:0.8988970588235294\n",
            "1088/4708 - The training loss at 28th epoch : 0.07867049701590922  Training Accuracy:0.8976449275362319\n",
            "1104/4708 - The training loss at 28th epoch : 0.07782943616866408  Training Accuracy:0.8991071428571429\n",
            "1120/4708 - The training loss at 28th epoch : 0.0785570524209909  Training Accuracy:0.8987676056338029\n",
            "1136/4708 - The training loss at 28th epoch : 0.07892557054365139  Training Accuracy:0.8975694444444444\n",
            "1152/4708 - The training loss at 28th epoch : 0.07917209994119236  Training Accuracy:0.896404109589041\n",
            "1168/4708 - The training loss at 28th epoch : 0.0801022422697097  Training Accuracy:0.8952702702702703\n",
            "1184/4708 - The training loss at 28th epoch : 0.07946142478798801  Training Accuracy:0.8958333333333334\n",
            "1200/4708 - The training loss at 28th epoch : 0.07919687525025267  Training Accuracy:0.8963815789473685\n",
            "1216/4708 - The training loss at 28th epoch : 0.08050803803756798  Training Accuracy:0.8944805194805194\n",
            "1232/4708 - The training loss at 28th epoch : 0.0818015430940677  Training Accuracy:0.8934294871794872\n",
            "1248/4708 - The training loss at 28th epoch : 0.0818376488434864  Training Accuracy:0.8931962025316456\n",
            "1264/4708 - The training loss at 28th epoch : 0.08092261016197266  Training Accuracy:0.89453125\n",
            "1280/4708 - The training loss at 28th epoch : 0.08135750486422202  Training Accuracy:0.8935185185185185\n",
            "1296/4708 - The training loss at 28th epoch : 0.0809235701061343  Training Accuracy:0.8940548780487805\n",
            "1312/4708 - The training loss at 28th epoch : 0.08142388918779002  Training Accuracy:0.8938253012048193\n",
            "1328/4708 - The training loss at 28th epoch : 0.08144356116054799  Training Accuracy:0.8936011904761905\n",
            "1344/4708 - The training loss at 28th epoch : 0.08139492907424391  Training Accuracy:0.8926470588235295\n",
            "1360/4708 - The training loss at 28th epoch : 0.08160865879909551  Training Accuracy:0.8924418604651163\n",
            "1376/4708 - The training loss at 28th epoch : 0.08112906805266715  Training Accuracy:0.8929597701149425\n",
            "1392/4708 - The training loss at 28th epoch : 0.0805960741144816  Training Accuracy:0.8934659090909091\n",
            "1408/4708 - The training loss at 28th epoch : 0.08040040834442957  Training Accuracy:0.8939606741573034\n",
            "1424/4708 - The training loss at 28th epoch : 0.08000332472886365  Training Accuracy:0.8944444444444445\n",
            "1440/4708 - The training loss at 28th epoch : 0.07988715659751068  Training Accuracy:0.8942307692307693\n",
            "1456/4708 - The training loss at 28th epoch : 0.07945795595951381  Training Accuracy:0.8947010869565217\n",
            "1472/4708 - The training loss at 28th epoch : 0.07965880141893905  Training Accuracy:0.8951612903225806\n",
            "1488/4708 - The training loss at 28th epoch : 0.08023870422071071  Training Accuracy:0.894281914893617\n",
            "1504/4708 - The training loss at 28th epoch : 0.08046977905501397  Training Accuracy:0.8934210526315789\n",
            "1520/4708 - The training loss at 28th epoch : 0.08106291654743734  Training Accuracy:0.8919270833333334\n",
            "1536/4708 - The training loss at 28th epoch : 0.08034149920278841  Training Accuracy:0.8930412371134021\n",
            "1552/4708 - The training loss at 28th epoch : 0.08011717199272986  Training Accuracy:0.8928571428571429\n",
            "1568/4708 - The training loss at 28th epoch : 0.0802798767907381  Training Accuracy:0.8926767676767676\n",
            "1584/4708 - The training loss at 28th epoch : 0.08034200769033575  Training Accuracy:0.8925\n",
            "1600/4708 - The training loss at 28th epoch : 0.07979640636923485  Training Accuracy:0.8935643564356436\n",
            "1616/4708 - The training loss at 28th epoch : 0.0808951468244339  Training Accuracy:0.8921568627450981\n",
            "1632/4708 - The training loss at 28th epoch : 0.08027513891673675  Training Accuracy:0.8932038834951457\n",
            "1648/4708 - The training loss at 28th epoch : 0.08057540323234641  Training Accuracy:0.8924278846153846\n",
            "1664/4708 - The training loss at 28th epoch : 0.08025052556816595  Training Accuracy:0.8928571428571429\n",
            "1680/4708 - The training loss at 28th epoch : 0.08033205710547209  Training Accuracy:0.8926886792452831\n",
            "1696/4708 - The training loss at 28th epoch : 0.08008462999258635  Training Accuracy:0.893107476635514\n",
            "1712/4708 - The training loss at 28th epoch : 0.07988370828820021  Training Accuracy:0.8929398148148148\n",
            "1728/4708 - The training loss at 28th epoch : 0.07924765080780626  Training Accuracy:0.8939220183486238\n",
            "1744/4708 - The training loss at 28th epoch : 0.07928790354019463  Training Accuracy:0.8943181818181818\n",
            "1760/4708 - The training loss at 28th epoch : 0.08002003201092597  Training Accuracy:0.893581081081081\n",
            "1776/4708 - The training loss at 28th epoch : 0.0806119420408682  Training Accuracy:0.8928571428571429\n",
            "1792/4708 - The training loss at 28th epoch : 0.08042387662517328  Training Accuracy:0.8932522123893806\n",
            "1808/4708 - The training loss at 28th epoch : 0.08051771952245304  Training Accuracy:0.8930921052631579\n",
            "1824/4708 - The training loss at 28th epoch : 0.08067618265478657  Training Accuracy:0.8929347826086956\n",
            "1840/4708 - The training loss at 28th epoch : 0.08070842543736613  Training Accuracy:0.8927801724137931\n",
            "1856/4708 - The training loss at 28th epoch : 0.08072220948171863  Training Accuracy:0.8926282051282052\n",
            "1872/4708 - The training loss at 28th epoch : 0.08058423245725277  Training Accuracy:0.8930084745762712\n",
            "1888/4708 - The training loss at 28th epoch : 0.08097433577585864  Training Accuracy:0.8928571428571429\n",
            "1904/4708 - The training loss at 28th epoch : 0.08079334373415671  Training Accuracy:0.8932291666666666\n",
            "1920/4708 - The training loss at 28th epoch : 0.08036735593606055  Training Accuracy:0.893595041322314\n",
            "1936/4708 - The training loss at 28th epoch : 0.08016943339518924  Training Accuracy:0.8939549180327869\n",
            "1952/4708 - The training loss at 28th epoch : 0.08059772852521012  Training Accuracy:0.8938008130081301\n",
            "1968/4708 - The training loss at 28th epoch : 0.08091420899347639  Training Accuracy:0.8936491935483871\n",
            "1984/4708 - The training loss at 28th epoch : 0.08049707909311937  Training Accuracy:0.8945\n",
            "2000/4708 - The training loss at 28th epoch : 0.0805228378366577  Training Accuracy:0.8943452380952381\n",
            "2016/4708 - The training loss at 28th epoch : 0.0807394998593512  Training Accuracy:0.8941929133858267\n",
            "2032/4708 - The training loss at 28th epoch : 0.08050253456856762  Training Accuracy:0.89453125\n",
            "2048/4708 - The training loss at 28th epoch : 0.08007999192118487  Training Accuracy:0.8948643410852714\n",
            "2064/4708 - The training loss at 28th epoch : 0.08013621139299797  Training Accuracy:0.8947115384615385\n",
            "2080/4708 - The training loss at 28th epoch : 0.08013083167759392  Training Accuracy:0.8945610687022901\n",
            "2096/4708 - The training loss at 28th epoch : 0.0805316659081033  Training Accuracy:0.8944128787878788\n",
            "2112/4708 - The training loss at 28th epoch : 0.08044631373333745  Training Accuracy:0.894266917293233\n",
            "2128/4708 - The training loss at 28th epoch : 0.08014295940242196  Training Accuracy:0.8950559701492538\n",
            "2144/4708 - The training loss at 28th epoch : 0.07999069134874609  Training Accuracy:0.8953703703703704\n",
            "2160/4708 - The training loss at 28th epoch : 0.07987804408731826  Training Accuracy:0.8956801470588235\n",
            "2176/4708 - The training loss at 28th epoch : 0.07960635351171237  Training Accuracy:0.8959854014598541\n",
            "2192/4708 - The training loss at 28th epoch : 0.07971366005515972  Training Accuracy:0.8958333333333334\n",
            "2208/4708 - The training loss at 28th epoch : 0.07976384464335817  Training Accuracy:0.89568345323741\n",
            "2224/4708 - The training loss at 28th epoch : 0.07930526596528467  Training Accuracy:0.8964285714285715\n",
            "2240/4708 - The training loss at 28th epoch : 0.079389371305977  Training Accuracy:0.8958333333333334\n",
            "2256/4708 - The training loss at 28th epoch : 0.07944133820122325  Training Accuracy:0.8956866197183099\n",
            "2272/4708 - The training loss at 28th epoch : 0.07902260343817451  Training Accuracy:0.896416083916084\n",
            "2288/4708 - The training loss at 28th epoch : 0.07952577612629019  Training Accuracy:0.8953993055555556\n",
            "2304/4708 - The training loss at 28th epoch : 0.0796784552187408  Training Accuracy:0.8952586206896552\n",
            "2320/4708 - The training loss at 28th epoch : 0.07944530867117182  Training Accuracy:0.8955479452054794\n",
            "2336/4708 - The training loss at 28th epoch : 0.07953588847612046  Training Accuracy:0.8949829931972789\n",
            "2352/4708 - The training loss at 28th epoch : 0.07992669564526378  Training Accuracy:0.8944256756756757\n",
            "2368/4708 - The training loss at 28th epoch : 0.08006818675867937  Training Accuracy:0.8938758389261745\n",
            "2384/4708 - The training loss at 28th epoch : 0.079832188300345  Training Accuracy:0.8941666666666667\n",
            "2400/4708 - The training loss at 28th epoch : 0.08052406073895985  Training Accuracy:0.8932119205298014\n",
            "2416/4708 - The training loss at 28th epoch : 0.08049137220598805  Training Accuracy:0.8935032894736842\n",
            "2432/4708 - The training loss at 28th epoch : 0.08078262498262977  Training Accuracy:0.8929738562091504\n",
            "2448/4708 - The training loss at 28th epoch : 0.08063901707200712  Training Accuracy:0.893262987012987\n",
            "2464/4708 - The training loss at 28th epoch : 0.08055379144251967  Training Accuracy:0.8935483870967742\n",
            "2480/4708 - The training loss at 28th epoch : 0.08092007254999  Training Accuracy:0.8930288461538461\n",
            "2496/4708 - The training loss at 28th epoch : 0.08092346684528781  Training Accuracy:0.8929140127388535\n",
            "2512/4708 - The training loss at 28th epoch : 0.08053191651889421  Training Accuracy:0.8935917721518988\n",
            "2528/4708 - The training loss at 28th epoch : 0.0811809973684136  Training Accuracy:0.8930817610062893\n",
            "2544/4708 - The training loss at 28th epoch : 0.08206693850930172  Training Accuracy:0.891796875\n",
            "2560/4708 - The training loss at 28th epoch : 0.08183763857266553  Training Accuracy:0.8920807453416149\n",
            "2576/4708 - The training loss at 28th epoch : 0.08307199910323128  Training Accuracy:0.8900462962962963\n",
            "2592/4708 - The training loss at 28th epoch : 0.08271664961287864  Training Accuracy:0.8907208588957055\n",
            "2608/4708 - The training loss at 28th epoch : 0.08248699652536648  Training Accuracy:0.8910060975609756\n",
            "2624/4708 - The training loss at 28th epoch : 0.08268745126613486  Training Accuracy:0.8909090909090909\n",
            "2640/4708 - The training loss at 28th epoch : 0.08236328660375676  Training Accuracy:0.8911897590361446\n",
            "2656/4708 - The training loss at 28th epoch : 0.08204386368106925  Training Accuracy:0.8918413173652695\n",
            "2672/4708 - The training loss at 28th epoch : 0.08266060717164495  Training Accuracy:0.8909970238095238\n",
            "2688/4708 - The training loss at 28th epoch : 0.08281074790119432  Training Accuracy:0.8909023668639053\n",
            "2704/4708 - The training loss at 28th epoch : 0.08251515477740747  Training Accuracy:0.8911764705882353\n",
            "2720/4708 - The training loss at 28th epoch : 0.08257207299534065  Training Accuracy:0.8910818713450293\n",
            "2736/4708 - The training loss at 28th epoch : 0.08285839265784858  Training Accuracy:0.890625\n",
            "2752/4708 - The training loss at 28th epoch : 0.08295546202646721  Training Accuracy:0.8901734104046243\n",
            "2768/4708 - The training loss at 28th epoch : 0.08288670230714983  Training Accuracy:0.8900862068965517\n",
            "2784/4708 - The training loss at 28th epoch : 0.0828144441288208  Training Accuracy:0.8903571428571428\n",
            "2800/4708 - The training loss at 28th epoch : 0.0824107497649413  Training Accuracy:0.8909801136363636\n",
            "2816/4708 - The training loss at 28th epoch : 0.08245643747596407  Training Accuracy:0.8905367231638418\n",
            "2832/4708 - The training loss at 28th epoch : 0.0830222718649201  Training Accuracy:0.8893960674157303\n",
            "2848/4708 - The training loss at 28th epoch : 0.08338848737147996  Training Accuracy:0.8886173184357542\n",
            "2864/4708 - The training loss at 28th epoch : 0.08380667668565002  Training Accuracy:0.8878472222222222\n",
            "2880/4708 - The training loss at 28th epoch : 0.08371367102164641  Training Accuracy:0.888121546961326\n",
            "2896/4708 - The training loss at 28th epoch : 0.08361430325074774  Training Accuracy:0.8880494505494505\n",
            "2912/4708 - The training loss at 28th epoch : 0.08322209159957705  Training Accuracy:0.8886612021857924\n",
            "2928/4708 - The training loss at 28th epoch : 0.08308669261002338  Training Accuracy:0.8889266304347826\n",
            "2944/4708 - The training loss at 28th epoch : 0.0828417847655581  Training Accuracy:0.8891891891891892\n",
            "2960/4708 - The training loss at 28th epoch : 0.08275942934015708  Training Accuracy:0.8894489247311828\n",
            "2976/4708 - The training loss at 28th epoch : 0.08244846144077449  Training Accuracy:0.8900401069518716\n",
            "2992/4708 - The training loss at 28th epoch : 0.08229616161475885  Training Accuracy:0.8902925531914894\n",
            "3008/4708 - The training loss at 28th epoch : 0.08219768031658933  Training Accuracy:0.8902116402116402\n",
            "3024/4708 - The training loss at 28th epoch : 0.08232107350822167  Training Accuracy:0.8901315789473684\n",
            "3040/4708 - The training loss at 28th epoch : 0.08195537301445215  Training Accuracy:0.8907068062827225\n",
            "3056/4708 - The training loss at 28th epoch : 0.08208665129006233  Training Accuracy:0.890625\n",
            "3072/4708 - The training loss at 28th epoch : 0.08268505122117312  Training Accuracy:0.8898963730569949\n",
            "3088/4708 - The training loss at 28th epoch : 0.0827759280663338  Training Accuracy:0.8894974226804123\n",
            "3104/4708 - The training loss at 28th epoch : 0.0824095357851233  Training Accuracy:0.8900641025641025\n",
            "3120/4708 - The training loss at 28th epoch : 0.08228637192334264  Training Accuracy:0.8899872448979592\n",
            "3136/4708 - The training loss at 28th epoch : 0.08190006670502668  Training Accuracy:0.8905456852791879\n",
            "3152/4708 - The training loss at 28th epoch : 0.08178619100732006  Training Accuracy:0.8907828282828283\n",
            "3168/4708 - The training loss at 28th epoch : 0.08155975167871506  Training Accuracy:0.8910175879396985\n",
            "3184/4708 - The training loss at 28th epoch : 0.08134211768775909  Training Accuracy:0.89125\n",
            "3200/4708 - The training loss at 28th epoch : 0.08131699509901986  Training Accuracy:0.8911691542288557\n",
            "3216/4708 - The training loss at 28th epoch : 0.081208739969724  Training Accuracy:0.8913985148514851\n",
            "3232/4708 - The training loss at 28th epoch : 0.08094685997725709  Training Accuracy:0.8916256157635468\n",
            "3248/4708 - The training loss at 28th epoch : 0.08149313272216062  Training Accuracy:0.8912377450980392\n",
            "3264/4708 - The training loss at 28th epoch : 0.08141000325091496  Training Accuracy:0.8914634146341464\n",
            "3280/4708 - The training loss at 28th epoch : 0.08157142190994596  Training Accuracy:0.8910800970873787\n",
            "3296/4708 - The training loss at 28th epoch : 0.08133549365973433  Training Accuracy:0.8913043478260869\n",
            "3312/4708 - The training loss at 28th epoch : 0.08113291550628365  Training Accuracy:0.8915264423076923\n",
            "3328/4708 - The training loss at 28th epoch : 0.0812248401058491  Training Accuracy:0.8914473684210527\n",
            "3344/4708 - The training loss at 28th epoch : 0.08090994109885159  Training Accuracy:0.8919642857142858\n",
            "3360/4708 - The training loss at 28th epoch : 0.0807841363624299  Training Accuracy:0.8921800947867299\n",
            "3376/4708 - The training loss at 28th epoch : 0.08093715794102849  Training Accuracy:0.8920990566037735\n",
            "3392/4708 - The training loss at 28th epoch : 0.08125975480790203  Training Accuracy:0.891725352112676\n",
            "3408/4708 - The training loss at 28th epoch : 0.08103339935619784  Training Accuracy:0.892231308411215\n",
            "3424/4708 - The training loss at 28th epoch : 0.0810013232812783  Training Accuracy:0.8924418604651163\n",
            "3440/4708 - The training loss at 28th epoch : 0.08108731036914668  Training Accuracy:0.8917824074074074\n",
            "3456/4708 - The training loss at 28th epoch : 0.08094546557400735  Training Accuracy:0.8919930875576036\n",
            "3472/4708 - The training loss at 28th epoch : 0.08128922282461505  Training Accuracy:0.8916284403669725\n",
            "3488/4708 - The training loss at 28th epoch : 0.08129267656421389  Training Accuracy:0.891837899543379\n",
            "3504/4708 - The training loss at 28th epoch : 0.08153524946256234  Training Accuracy:0.8917613636363636\n",
            "3520/4708 - The training loss at 28th epoch : 0.08133344091036919  Training Accuracy:0.8919683257918553\n",
            "3536/4708 - The training loss at 28th epoch : 0.08119856995062626  Training Accuracy:0.8921734234234234\n",
            "3552/4708 - The training loss at 28th epoch : 0.08084539569417659  Training Accuracy:0.8926569506726457\n",
            "3568/4708 - The training loss at 28th epoch : 0.08067226037313767  Training Accuracy:0.8928571428571429\n",
            "3584/4708 - The training loss at 28th epoch : 0.08068926587151053  Training Accuracy:0.8927777777777778\n",
            "3600/4708 - The training loss at 28th epoch : 0.08056439104251407  Training Accuracy:0.8929756637168141\n",
            "3616/4708 - The training loss at 28th epoch : 0.08107454171680165  Training Accuracy:0.8920704845814978\n",
            "3632/4708 - The training loss at 28th epoch : 0.0807254497638823  Training Accuracy:0.8925438596491229\n",
            "3648/4708 - The training loss at 28th epoch : 0.08067499167379114  Training Accuracy:0.892467248908297\n",
            "3664/4708 - The training loss at 28th epoch : 0.08067120257708431  Training Accuracy:0.8923913043478261\n",
            "3680/4708 - The training loss at 28th epoch : 0.08082696873404573  Training Accuracy:0.8920454545454546\n",
            "3696/4708 - The training loss at 28th epoch : 0.08072813708172394  Training Accuracy:0.8922413793103449\n",
            "3712/4708 - The training loss at 28th epoch : 0.08061086265424132  Training Accuracy:0.8924356223175965\n",
            "3728/4708 - The training loss at 28th epoch : 0.08085188178863195  Training Accuracy:0.8920940170940171\n",
            "3744/4708 - The training loss at 28th epoch : 0.08107581234153821  Training Accuracy:0.8920212765957447\n",
            "3760/4708 - The training loss at 28th epoch : 0.08092462150859152  Training Accuracy:0.8922139830508474\n",
            "3776/4708 - The training loss at 28th epoch : 0.08085907844834751  Training Accuracy:0.8924050632911392\n",
            "3792/4708 - The training loss at 28th epoch : 0.08068479440251108  Training Accuracy:0.8925945378151261\n",
            "3808/4708 - The training loss at 28th epoch : 0.08103466505757385  Training Accuracy:0.8919979079497908\n",
            "3824/4708 - The training loss at 28th epoch : 0.0809189992668462  Training Accuracy:0.8919270833333334\n",
            "3840/4708 - The training loss at 28th epoch : 0.08088693841996158  Training Accuracy:0.8918568464730291\n",
            "3856/4708 - The training loss at 28th epoch : 0.08087443144836494  Training Accuracy:0.8917871900826446\n",
            "3872/4708 - The training loss at 28th epoch : 0.08090177721282776  Training Accuracy:0.8917181069958847\n",
            "3888/4708 - The training loss at 28th epoch : 0.08090997977355567  Training Accuracy:0.8916495901639344\n",
            "3904/4708 - The training loss at 28th epoch : 0.08077040448542905  Training Accuracy:0.8918367346938776\n",
            "3920/4708 - The training loss at 28th epoch : 0.0808319970033233  Training Accuracy:0.8917682926829268\n",
            "3936/4708 - The training loss at 28th epoch : 0.08060118047554905  Training Accuracy:0.8922064777327935\n",
            "3952/4708 - The training loss at 28th epoch : 0.08059507486317156  Training Accuracy:0.8921370967741935\n",
            "3968/4708 - The training loss at 28th epoch : 0.08093953068975843  Training Accuracy:0.891566265060241\n",
            "3984/4708 - The training loss at 28th epoch : 0.08102663259856566  Training Accuracy:0.89125\n",
            "4000/4708 - The training loss at 28th epoch : 0.08126148533469305  Training Accuracy:0.8911852589641435\n",
            "4016/4708 - The training loss at 28th epoch : 0.08134508153306474  Training Accuracy:0.8908730158730159\n",
            "4032/4708 - The training loss at 28th epoch : 0.0812182092621557  Training Accuracy:0.8910573122529645\n",
            "4048/4708 - The training loss at 28th epoch : 0.08118013726773528  Training Accuracy:0.890994094488189\n",
            "4064/4708 - The training loss at 28th epoch : 0.08160272113905737  Training Accuracy:0.8904411764705882\n",
            "4080/4708 - The training loss at 28th epoch : 0.081739642481904  Training Accuracy:0.89013671875\n",
            "4096/4708 - The training loss at 28th epoch : 0.08171822199689646  Training Accuracy:0.8903210116731517\n",
            "4112/4708 - The training loss at 28th epoch : 0.08161229211489522  Training Accuracy:0.8905038759689923\n",
            "4128/4708 - The training loss at 28th epoch : 0.08156957039480928  Training Accuracy:0.8906853281853282\n",
            "4144/4708 - The training loss at 28th epoch : 0.08148252064954135  Training Accuracy:0.890625\n",
            "4160/4708 - The training loss at 28th epoch : 0.08183149304707033  Training Accuracy:0.8900862068965517\n",
            "4176/4708 - The training loss at 28th epoch : 0.0816582286171292  Training Accuracy:0.8905057251908397\n",
            "4192/4708 - The training loss at 28th epoch : 0.08189790063602609  Training Accuracy:0.8899714828897338\n",
            "4208/4708 - The training loss at 28th epoch : 0.08190054709940245  Training Accuracy:0.8899147727272727\n",
            "4224/4708 - The training loss at 28th epoch : 0.08195236674818297  Training Accuracy:0.8898584905660377\n",
            "4240/4708 - The training loss at 28th epoch : 0.08186004491184198  Training Accuracy:0.8900375939849624\n",
            "4256/4708 - The training loss at 28th epoch : 0.08176248522806014  Training Accuracy:0.8899812734082397\n",
            "4272/4708 - The training loss at 28th epoch : 0.081818281128502  Training Accuracy:0.8899253731343284\n",
            "4288/4708 - The training loss at 28th epoch : 0.08161662978258626  Training Accuracy:0.8901022304832714\n",
            "4304/4708 - The training loss at 28th epoch : 0.0815373344877928  Training Accuracy:0.8902777777777777\n",
            "4320/4708 - The training loss at 28th epoch : 0.08147367790972407  Training Accuracy:0.8904520295202952\n",
            "4336/4708 - The training loss at 28th epoch : 0.0812098240923454  Training Accuracy:0.8908547794117647\n",
            "4352/4708 - The training loss at 28th epoch : 0.0810707612448323  Training Accuracy:0.8910256410256411\n",
            "4368/4708 - The training loss at 28th epoch : 0.08110851720519996  Training Accuracy:0.8909671532846716\n",
            "4384/4708 - The training loss at 28th epoch : 0.0809808955203842  Training Accuracy:0.8909090909090909\n",
            "4400/4708 - The training loss at 28th epoch : 0.0807782821278809  Training Accuracy:0.8910778985507246\n",
            "4416/4708 - The training loss at 28th epoch : 0.08069845666736035  Training Accuracy:0.891245487364621\n",
            "4432/4708 - The training loss at 28th epoch : 0.08091314136389961  Training Accuracy:0.8909622302158273\n",
            "4448/4708 - The training loss at 28th epoch : 0.08068072298772146  Training Accuracy:0.891353046594982\n",
            "4464/4708 - The training loss at 28th epoch : 0.08093666379742982  Training Accuracy:0.8910714285714286\n",
            "4480/4708 - The training loss at 28th epoch : 0.08083350293776068  Training Accuracy:0.8910142348754448\n",
            "4496/4708 - The training loss at 28th epoch : 0.08112923708583916  Training Accuracy:0.8905141843971631\n",
            "4512/4708 - The training loss at 28th epoch : 0.08091549103342369  Training Accuracy:0.8909010600706714\n",
            "4528/4708 - The training loss at 28th epoch : 0.08099341761936793  Training Accuracy:0.8908450704225352\n",
            "4544/4708 - The training loss at 28th epoch : 0.08117856346458645  Training Accuracy:0.8905701754385965\n",
            "4560/4708 - The training loss at 28th epoch : 0.0811231264963816  Training Accuracy:0.8907342657342657\n",
            "4576/4708 - The training loss at 28th epoch : 0.08104585990689327  Training Accuracy:0.890897212543554\n",
            "4592/4708 - The training loss at 28th epoch : 0.08085960625164257  Training Accuracy:0.8912760416666666\n",
            "4608/4708 - The training loss at 28th epoch : 0.081098000439734  Training Accuracy:0.8907871972318339\n",
            "4624/4708 - The training loss at 28th epoch : 0.08096198487179988  Training Accuracy:0.8909482758620689\n",
            "4640/4708 - The training loss at 28th epoch : 0.08139115245001  Training Accuracy:0.8902491408934707\n",
            "4656/4708 - The training loss at 28th epoch : 0.081438695129653  Training Accuracy:0.8904109589041096\n",
            "4672/4708 - The training loss at 28th epoch : 0.08161967863775642  Training Accuracy:0.8901450511945392\n",
            "4688/4708 - The training loss at 28th epoch : 0.08152843085796237  Training Accuracy:0.8903061224489796\n",
            "4704/4708 - The training loss at 28th epoch : 0.0816561733416997  Training Accuracy:0.8898305084745762\n",
            "4720/4708 - The training loss at 28th epoch : 0.08193481866550092  Training Accuracy:0.8893581081081081\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 29th epoch : 0.03834621345647794  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 29th epoch : 0.08378979632398847  Training Accuracy:0.875\n",
            "32/4708 - The training loss at 29th epoch : 0.08211895385739502  Training Accuracy:0.8958333333333334\n",
            "48/4708 - The training loss at 29th epoch : 0.06775168136373447  Training Accuracy:0.921875\n",
            "64/4708 - The training loss at 29th epoch : 0.05749294015830434  Training Accuracy:0.9375\n",
            "80/4708 - The training loss at 29th epoch : 0.06178178930869682  Training Accuracy:0.9375\n",
            "96/4708 - The training loss at 29th epoch : 0.06305421125013991  Training Accuracy:0.9285714285714286\n",
            "112/4708 - The training loss at 29th epoch : 0.06122834980045832  Training Accuracy:0.9296875\n",
            "128/4708 - The training loss at 29th epoch : 0.062479199755052006  Training Accuracy:0.9305555555555556\n",
            "144/4708 - The training loss at 29th epoch : 0.06204877064946827  Training Accuracy:0.93125\n",
            "160/4708 - The training loss at 29th epoch : 0.05777105316532278  Training Accuracy:0.9375\n",
            "176/4708 - The training loss at 29th epoch : 0.06424584243842539  Training Accuracy:0.9270833333333334\n",
            "192/4708 - The training loss at 29th epoch : 0.06671877862674233  Training Accuracy:0.9230769230769231\n",
            "208/4708 - The training loss at 29th epoch : 0.067506045167425  Training Accuracy:0.9241071428571429\n",
            "224/4708 - The training loss at 29th epoch : 0.07154546835896165  Training Accuracy:0.9208333333333333\n",
            "240/4708 - The training loss at 29th epoch : 0.06942015330586422  Training Accuracy:0.921875\n",
            "256/4708 - The training loss at 29th epoch : 0.06936948405935245  Training Accuracy:0.9227941176470589\n",
            "272/4708 - The training loss at 29th epoch : 0.07130558967019793  Training Accuracy:0.9201388888888888\n",
            "288/4708 - The training loss at 29th epoch : 0.0742728612092466  Training Accuracy:0.9111842105263158\n",
            "304/4708 - The training loss at 29th epoch : 0.07453930981472026  Training Accuracy:0.909375\n",
            "320/4708 - The training loss at 29th epoch : 0.07111632057398573  Training Accuracy:0.9136904761904762\n",
            "336/4708 - The training loss at 29th epoch : 0.06990522147881455  Training Accuracy:0.9147727272727273\n",
            "352/4708 - The training loss at 29th epoch : 0.07516296173855365  Training Accuracy:0.907608695652174\n",
            "368/4708 - The training loss at 29th epoch : 0.07632483235671601  Training Accuracy:0.90625\n",
            "384/4708 - The training loss at 29th epoch : 0.07418862812331063  Training Accuracy:0.91\n",
            "400/4708 - The training loss at 29th epoch : 0.07320324761493366  Training Accuracy:0.9110576923076923\n",
            "416/4708 - The training loss at 29th epoch : 0.0749373581776885  Training Accuracy:0.9097222222222222\n",
            "432/4708 - The training loss at 29th epoch : 0.07545196803111408  Training Accuracy:0.9084821428571429\n",
            "448/4708 - The training loss at 29th epoch : 0.07510031321949423  Training Accuracy:0.9094827586206896\n",
            "464/4708 - The training loss at 29th epoch : 0.07559255069793065  Training Accuracy:0.9083333333333333\n",
            "480/4708 - The training loss at 29th epoch : 0.07735145583980312  Training Accuracy:0.905241935483871\n",
            "496/4708 - The training loss at 29th epoch : 0.0760340832656713  Training Accuracy:0.908203125\n",
            "512/4708 - The training loss at 29th epoch : 0.07720656970139543  Training Accuracy:0.9071969696969697\n",
            "528/4708 - The training loss at 29th epoch : 0.07595051780704595  Training Accuracy:0.9080882352941176\n",
            "544/4708 - The training loss at 29th epoch : 0.0742461760360674  Training Accuracy:0.9107142857142857\n",
            "560/4708 - The training loss at 29th epoch : 0.073472957513525  Training Accuracy:0.9114583333333334\n",
            "576/4708 - The training loss at 29th epoch : 0.07367557208684539  Training Accuracy:0.910472972972973\n",
            "592/4708 - The training loss at 29th epoch : 0.07181038912377631  Training Accuracy:0.912828947368421\n",
            "608/4708 - The training loss at 29th epoch : 0.0718352260562943  Training Accuracy:0.9118589743589743\n",
            "624/4708 - The training loss at 29th epoch : 0.07340876406618888  Training Accuracy:0.9078125\n",
            "640/4708 - The training loss at 29th epoch : 0.0733647970448888  Training Accuracy:0.9070121951219512\n",
            "656/4708 - The training loss at 29th epoch : 0.07340928443716081  Training Accuracy:0.9077380952380952\n",
            "672/4708 - The training loss at 29th epoch : 0.07245424313294889  Training Accuracy:0.9084302325581395\n",
            "688/4708 - The training loss at 29th epoch : 0.07292661266985867  Training Accuracy:0.9076704545454546\n",
            "704/4708 - The training loss at 29th epoch : 0.07494633446592847  Training Accuracy:0.9055555555555556\n",
            "720/4708 - The training loss at 29th epoch : 0.07565907111329892  Training Accuracy:0.9035326086956522\n",
            "736/4708 - The training loss at 29th epoch : 0.07499007690824076  Training Accuracy:0.9029255319148937\n",
            "752/4708 - The training loss at 29th epoch : 0.07506091976351999  Training Accuracy:0.9010416666666666\n",
            "768/4708 - The training loss at 29th epoch : 0.07807932178093513  Training Accuracy:0.8966836734693877\n",
            "784/4708 - The training loss at 29th epoch : 0.07774268807940199  Training Accuracy:0.8975\n",
            "800/4708 - The training loss at 29th epoch : 0.0772303637264932  Training Accuracy:0.8982843137254902\n",
            "816/4708 - The training loss at 29th epoch : 0.07650873499132621  Training Accuracy:0.8990384615384616\n",
            "832/4708 - The training loss at 29th epoch : 0.07605893527923813  Training Accuracy:0.8997641509433962\n",
            "848/4708 - The training loss at 29th epoch : 0.07627099427856804  Training Accuracy:0.8993055555555556\n",
            "864/4708 - The training loss at 29th epoch : 0.07659505989913615  Training Accuracy:0.8988636363636363\n",
            "880/4708 - The training loss at 29th epoch : 0.07663955117335507  Training Accuracy:0.8995535714285714\n",
            "896/4708 - The training loss at 29th epoch : 0.07722332713194853  Training Accuracy:0.8991228070175439\n",
            "912/4708 - The training loss at 29th epoch : 0.07793583153457725  Training Accuracy:0.8976293103448276\n",
            "928/4708 - The training loss at 29th epoch : 0.07837710676850569  Training Accuracy:0.8972457627118644\n",
            "944/4708 - The training loss at 29th epoch : 0.0781321275223048  Training Accuracy:0.8979166666666667\n",
            "960/4708 - The training loss at 29th epoch : 0.07777357510974431  Training Accuracy:0.8975409836065574\n",
            "976/4708 - The training loss at 29th epoch : 0.07691847272359874  Training Accuracy:0.8981854838709677\n",
            "992/4708 - The training loss at 29th epoch : 0.07677233877510661  Training Accuracy:0.8988095238095238\n",
            "1008/4708 - The training loss at 29th epoch : 0.07775182590189536  Training Accuracy:0.8984375\n",
            "1024/4708 - The training loss at 29th epoch : 0.07845051895813068  Training Accuracy:0.8980769230769231\n",
            "1040/4708 - The training loss at 29th epoch : 0.07787699170696413  Training Accuracy:0.8986742424242424\n",
            "1056/4708 - The training loss at 29th epoch : 0.0777961074588358  Training Accuracy:0.898320895522388\n",
            "1072/4708 - The training loss at 29th epoch : 0.0768214169104526  Training Accuracy:0.8998161764705882\n",
            "1088/4708 - The training loss at 29th epoch : 0.07658096116373356  Training Accuracy:0.9003623188405797\n",
            "1104/4708 - The training loss at 29th epoch : 0.0768212731430686  Training Accuracy:0.9\n",
            "1120/4708 - The training loss at 29th epoch : 0.07581016592458048  Training Accuracy:0.9014084507042254\n",
            "1136/4708 - The training loss at 29th epoch : 0.07686826941995317  Training Accuracy:0.9001736111111112\n",
            "1152/4708 - The training loss at 29th epoch : 0.07609700150390906  Training Accuracy:0.901541095890411\n",
            "1168/4708 - The training loss at 29th epoch : 0.07545558035785796  Training Accuracy:0.9028716216216216\n",
            "1184/4708 - The training loss at 29th epoch : 0.07520412567492667  Training Accuracy:0.9033333333333333\n",
            "1200/4708 - The training loss at 29th epoch : 0.07534738668452834  Training Accuracy:0.9037828947368421\n",
            "1216/4708 - The training loss at 29th epoch : 0.07553833243879991  Training Accuracy:0.9034090909090909\n",
            "1232/4708 - The training loss at 29th epoch : 0.07563308634344058  Training Accuracy:0.9030448717948718\n",
            "1248/4708 - The training loss at 29th epoch : 0.0758202262577847  Training Accuracy:0.9026898734177216\n",
            "1264/4708 - The training loss at 29th epoch : 0.07574769140353063  Training Accuracy:0.90234375\n",
            "1280/4708 - The training loss at 29th epoch : 0.07613911417366638  Training Accuracy:0.9012345679012346\n",
            "1296/4708 - The training loss at 29th epoch : 0.0774752078754011  Training Accuracy:0.899390243902439\n",
            "1312/4708 - The training loss at 29th epoch : 0.07743198515700649  Training Accuracy:0.8998493975903614\n",
            "1328/4708 - The training loss at 29th epoch : 0.07788975763023116  Training Accuracy:0.8988095238095238\n",
            "1344/4708 - The training loss at 29th epoch : 0.07720465737114968  Training Accuracy:0.9\n",
            "1360/4708 - The training loss at 29th epoch : 0.07876001527997208  Training Accuracy:0.8982558139534884\n",
            "1376/4708 - The training loss at 29th epoch : 0.07895942919460472  Training Accuracy:0.8979885057471264\n",
            "1392/4708 - The training loss at 29th epoch : 0.07893971245277881  Training Accuracy:0.8970170454545454\n",
            "1408/4708 - The training loss at 29th epoch : 0.07842855269085494  Training Accuracy:0.8974719101123596\n",
            "1424/4708 - The training loss at 29th epoch : 0.07899406885782179  Training Accuracy:0.8958333333333334\n",
            "1440/4708 - The training loss at 29th epoch : 0.07873544684178298  Training Accuracy:0.8962912087912088\n",
            "1456/4708 - The training loss at 29th epoch : 0.07868110222360558  Training Accuracy:0.8960597826086957\n",
            "1472/4708 - The training loss at 29th epoch : 0.07924770349731075  Training Accuracy:0.8958333333333334\n",
            "1488/4708 - The training loss at 29th epoch : 0.0790839659167443  Training Accuracy:0.8956117021276596\n",
            "1504/4708 - The training loss at 29th epoch : 0.07879549978287496  Training Accuracy:0.8953947368421052\n",
            "1520/4708 - The training loss at 29th epoch : 0.07873591675934881  Training Accuracy:0.8951822916666666\n",
            "1536/4708 - The training loss at 29th epoch : 0.07860735005131157  Training Accuracy:0.895618556701031\n",
            "1552/4708 - The training loss at 29th epoch : 0.07866705732862131  Training Accuracy:0.8954081632653061\n",
            "1568/4708 - The training loss at 29th epoch : 0.07851363362672767  Training Accuracy:0.8958333333333334\n",
            "1584/4708 - The training loss at 29th epoch : 0.0783380588741526  Training Accuracy:0.895625\n",
            "1600/4708 - The training loss at 29th epoch : 0.07785338356903852  Training Accuracy:0.8960396039603961\n",
            "1616/4708 - The training loss at 29th epoch : 0.07762222185588037  Training Accuracy:0.8964460784313726\n",
            "1632/4708 - The training loss at 29th epoch : 0.07770435610514953  Training Accuracy:0.8956310679611651\n",
            "1648/4708 - The training loss at 29th epoch : 0.07732848328168879  Training Accuracy:0.8960336538461539\n",
            "1664/4708 - The training loss at 29th epoch : 0.07721911092071782  Training Accuracy:0.8958333333333334\n",
            "1680/4708 - The training loss at 29th epoch : 0.07773050799724461  Training Accuracy:0.8950471698113207\n",
            "1696/4708 - The training loss at 29th epoch : 0.07782536761637154  Training Accuracy:0.8942757009345794\n",
            "1712/4708 - The training loss at 29th epoch : 0.07801111037592838  Training Accuracy:0.8940972222222222\n",
            "1728/4708 - The training loss at 29th epoch : 0.07806729784875548  Training Accuracy:0.8939220183486238\n",
            "1744/4708 - The training loss at 29th epoch : 0.0774299260604389  Training Accuracy:0.8948863636363636\n",
            "1760/4708 - The training loss at 29th epoch : 0.07688370453233469  Training Accuracy:0.8958333333333334\n",
            "1776/4708 - The training loss at 29th epoch : 0.0771453351628096  Training Accuracy:0.8950892857142857\n",
            "1792/4708 - The training loss at 29th epoch : 0.07682483497821017  Training Accuracy:0.8954646017699115\n",
            "1808/4708 - The training loss at 29th epoch : 0.07658983361440233  Training Accuracy:0.8958333333333334\n",
            "1824/4708 - The training loss at 29th epoch : 0.07597598118677029  Training Accuracy:0.8967391304347826\n",
            "1840/4708 - The training loss at 29th epoch : 0.0760836709955503  Training Accuracy:0.896551724137931\n",
            "1856/4708 - The training loss at 29th epoch : 0.07611500773061272  Training Accuracy:0.8963675213675214\n",
            "1872/4708 - The training loss at 29th epoch : 0.0761896799885356  Training Accuracy:0.895656779661017\n",
            "1888/4708 - The training loss at 29th epoch : 0.07599946667351797  Training Accuracy:0.8960084033613446\n",
            "1904/4708 - The training loss at 29th epoch : 0.07626833300413653  Training Accuracy:0.8958333333333334\n",
            "1920/4708 - The training loss at 29th epoch : 0.07670002293123072  Training Accuracy:0.8956611570247934\n",
            "1936/4708 - The training loss at 29th epoch : 0.0764995741376415  Training Accuracy:0.8954918032786885\n",
            "1952/4708 - The training loss at 29th epoch : 0.0765305498531904  Training Accuracy:0.8953252032520326\n",
            "1968/4708 - The training loss at 29th epoch : 0.07641710442840532  Training Accuracy:0.8951612903225806\n",
            "1984/4708 - The training loss at 29th epoch : 0.07637702611099789  Training Accuracy:0.895\n",
            "2000/4708 - The training loss at 29th epoch : 0.07617491469339875  Training Accuracy:0.8948412698412699\n",
            "2016/4708 - The training loss at 29th epoch : 0.07576072323127526  Training Accuracy:0.8956692913385826\n",
            "2032/4708 - The training loss at 29th epoch : 0.075799582097065  Training Accuracy:0.8955078125\n",
            "2048/4708 - The training loss at 29th epoch : 0.0755779495379324  Training Accuracy:0.8958333333333334\n",
            "2064/4708 - The training loss at 29th epoch : 0.07608771617556362  Training Accuracy:0.8951923076923077\n",
            "2080/4708 - The training loss at 29th epoch : 0.07585695518233214  Training Accuracy:0.8955152671755725\n",
            "2096/4708 - The training loss at 29th epoch : 0.07559928108335784  Training Accuracy:0.8958333333333334\n",
            "2112/4708 - The training loss at 29th epoch : 0.07536273371369144  Training Accuracy:0.8961466165413534\n",
            "2128/4708 - The training loss at 29th epoch : 0.07483025567475617  Training Accuracy:0.8969216417910447\n",
            "2144/4708 - The training loss at 29th epoch : 0.07431979685694799  Training Accuracy:0.8976851851851851\n",
            "2160/4708 - The training loss at 29th epoch : 0.07455924393915143  Training Accuracy:0.8975183823529411\n",
            "2176/4708 - The training loss at 29th epoch : 0.07462018741916637  Training Accuracy:0.8978102189781022\n",
            "2192/4708 - The training loss at 29th epoch : 0.07447665123093285  Training Accuracy:0.8980978260869565\n",
            "2208/4708 - The training loss at 29th epoch : 0.07495436391294896  Training Accuracy:0.8974820143884892\n",
            "2224/4708 - The training loss at 29th epoch : 0.07475155108187512  Training Accuracy:0.8977678571428571\n",
            "2240/4708 - The training loss at 29th epoch : 0.07469936734921452  Training Accuracy:0.8980496453900709\n",
            "2256/4708 - The training loss at 29th epoch : 0.07498459152454501  Training Accuracy:0.897887323943662\n",
            "2272/4708 - The training loss at 29th epoch : 0.07511764450927902  Training Accuracy:0.8972902097902098\n",
            "2288/4708 - The training loss at 29th epoch : 0.07555194806974239  Training Accuracy:0.8967013888888888\n",
            "2304/4708 - The training loss at 29th epoch : 0.07547236469385926  Training Accuracy:0.896551724137931\n",
            "2320/4708 - The training loss at 29th epoch : 0.07534366088438081  Training Accuracy:0.896404109589041\n",
            "2336/4708 - The training loss at 29th epoch : 0.0755890044942808  Training Accuracy:0.8962585034013606\n",
            "2352/4708 - The training loss at 29th epoch : 0.07551263021150705  Training Accuracy:0.8965371621621622\n",
            "2368/4708 - The training loss at 29th epoch : 0.07649968413186373  Training Accuracy:0.8951342281879194\n",
            "2384/4708 - The training loss at 29th epoch : 0.0765364420123556  Training Accuracy:0.8954166666666666\n",
            "2400/4708 - The training loss at 29th epoch : 0.07697731273101421  Training Accuracy:0.8948675496688742\n",
            "2416/4708 - The training loss at 29th epoch : 0.07729891744109364  Training Accuracy:0.8947368421052632\n",
            "2432/4708 - The training loss at 29th epoch : 0.07775023013652295  Training Accuracy:0.8937908496732027\n",
            "2448/4708 - The training loss at 29th epoch : 0.07763593190405726  Training Accuracy:0.8940746753246753\n",
            "2464/4708 - The training loss at 29th epoch : 0.07744972641449357  Training Accuracy:0.8943548387096775\n",
            "2480/4708 - The training loss at 29th epoch : 0.07802881549910769  Training Accuracy:0.8938301282051282\n",
            "2496/4708 - The training loss at 29th epoch : 0.07827783014297708  Training Accuracy:0.8937101910828026\n",
            "2512/4708 - The training loss at 29th epoch : 0.07860437443392432  Training Accuracy:0.8935917721518988\n",
            "2528/4708 - The training loss at 29th epoch : 0.07887314871156885  Training Accuracy:0.8934748427672956\n",
            "2544/4708 - The training loss at 29th epoch : 0.0790171659744606  Training Accuracy:0.893359375\n",
            "2560/4708 - The training loss at 29th epoch : 0.07903918915522133  Training Accuracy:0.8928571428571429\n",
            "2576/4708 - The training loss at 29th epoch : 0.07940886442443594  Training Accuracy:0.8923611111111112\n",
            "2592/4708 - The training loss at 29th epoch : 0.07934492256737617  Training Accuracy:0.8922546012269938\n",
            "2608/4708 - The training loss at 29th epoch : 0.07910861838816878  Training Accuracy:0.8925304878048781\n",
            "2624/4708 - The training loss at 29th epoch : 0.07900569916731202  Training Accuracy:0.8928030303030303\n",
            "2640/4708 - The training loss at 29th epoch : 0.07879313193296228  Training Accuracy:0.8930722891566265\n",
            "2656/4708 - The training loss at 29th epoch : 0.07890920713029691  Training Accuracy:0.8929640718562875\n",
            "2672/4708 - The training loss at 29th epoch : 0.07925599734460992  Training Accuracy:0.8921130952380952\n",
            "2688/4708 - The training loss at 29th epoch : 0.07954618513094361  Training Accuracy:0.8916420118343196\n",
            "2704/4708 - The training loss at 29th epoch : 0.0793244530600045  Training Accuracy:0.8919117647058824\n",
            "2720/4708 - The training loss at 29th epoch : 0.07926490578581509  Training Accuracy:0.8918128654970761\n",
            "2736/4708 - The training loss at 29th epoch : 0.07900595924455948  Training Accuracy:0.892078488372093\n",
            "2752/4708 - The training loss at 29th epoch : 0.07949474317286584  Training Accuracy:0.8908959537572254\n",
            "2768/4708 - The training loss at 29th epoch : 0.07917750243766333  Training Accuracy:0.8915229885057471\n",
            "2784/4708 - The training loss at 29th epoch : 0.07920379337297823  Training Accuracy:0.8914285714285715\n",
            "2800/4708 - The training loss at 29th epoch : 0.07893691893981246  Training Accuracy:0.8920454545454546\n",
            "2816/4708 - The training loss at 29th epoch : 0.07906466007106237  Training Accuracy:0.8919491525423728\n",
            "2832/4708 - The training loss at 29th epoch : 0.0794303645387088  Training Accuracy:0.8911516853932584\n",
            "2848/4708 - The training loss at 29th epoch : 0.07943428044333538  Training Accuracy:0.8910614525139665\n",
            "2864/4708 - The training loss at 29th epoch : 0.07954099714361526  Training Accuracy:0.890625\n",
            "2880/4708 - The training loss at 29th epoch : 0.07977561498339869  Training Accuracy:0.8905386740331491\n",
            "2896/4708 - The training loss at 29th epoch : 0.07948480585300173  Training Accuracy:0.8907967032967034\n",
            "2912/4708 - The training loss at 29th epoch : 0.07921814970622978  Training Accuracy:0.8913934426229508\n",
            "2928/4708 - The training loss at 29th epoch : 0.07919518303497114  Training Accuracy:0.8913043478260869\n",
            "2944/4708 - The training loss at 29th epoch : 0.07907552877384884  Training Accuracy:0.8912162162162162\n",
            "2960/4708 - The training loss at 29th epoch : 0.07898163015804602  Training Accuracy:0.8914650537634409\n",
            "2976/4708 - The training loss at 29th epoch : 0.07865196810262555  Training Accuracy:0.8920454545454546\n",
            "2992/4708 - The training loss at 29th epoch : 0.07836961546075408  Training Accuracy:0.8926196808510638\n",
            "3008/4708 - The training loss at 29th epoch : 0.07804392972663515  Training Accuracy:0.8931878306878307\n",
            "3024/4708 - The training loss at 29th epoch : 0.07797394564891871  Training Accuracy:0.8934210526315789\n",
            "3040/4708 - The training loss at 29th epoch : 0.07805670878462502  Training Accuracy:0.893324607329843\n",
            "3056/4708 - The training loss at 29th epoch : 0.07835381438806639  Training Accuracy:0.8929036458333334\n",
            "3072/4708 - The training loss at 29th epoch : 0.07866503723211173  Training Accuracy:0.8924870466321243\n",
            "3088/4708 - The training loss at 29th epoch : 0.07848270775747901  Training Accuracy:0.8927190721649485\n",
            "3104/4708 - The training loss at 29th epoch : 0.0788940026338066  Training Accuracy:0.8919871794871795\n",
            "3120/4708 - The training loss at 29th epoch : 0.07883217701427588  Training Accuracy:0.892219387755102\n",
            "3136/4708 - The training loss at 29th epoch : 0.07873411457686358  Training Accuracy:0.8924492385786802\n",
            "3152/4708 - The training loss at 29th epoch : 0.07899285770134545  Training Accuracy:0.8923611111111112\n",
            "3168/4708 - The training loss at 29th epoch : 0.07914401918120999  Training Accuracy:0.8919597989949749\n",
            "3184/4708 - The training loss at 29th epoch : 0.07910934098492453  Training Accuracy:0.8921875\n",
            "3200/4708 - The training loss at 29th epoch : 0.07891908230489915  Training Accuracy:0.8924129353233831\n",
            "3216/4708 - The training loss at 29th epoch : 0.07898430486009524  Training Accuracy:0.8923267326732673\n",
            "3232/4708 - The training loss at 29th epoch : 0.07896446439353849  Training Accuracy:0.8922413793103449\n",
            "3248/4708 - The training loss at 29th epoch : 0.07940911949206313  Training Accuracy:0.8918504901960784\n",
            "3264/4708 - The training loss at 29th epoch : 0.07923581438313693  Training Accuracy:0.8920731707317073\n",
            "3280/4708 - The training loss at 29th epoch : 0.0792945903392676  Training Accuracy:0.8919902912621359\n",
            "3296/4708 - The training loss at 29th epoch : 0.07934942009019233  Training Accuracy:0.8919082125603864\n",
            "3312/4708 - The training loss at 29th epoch : 0.07923005680839597  Training Accuracy:0.8918269230769231\n",
            "3328/4708 - The training loss at 29th epoch : 0.07921261660820172  Training Accuracy:0.8920454545454546\n",
            "3344/4708 - The training loss at 29th epoch : 0.07975153202677879  Training Accuracy:0.8913690476190477\n",
            "3360/4708 - The training loss at 29th epoch : 0.08000413530904527  Training Accuracy:0.8909952606635071\n",
            "3376/4708 - The training loss at 29th epoch : 0.07999744084296274  Training Accuracy:0.8909198113207547\n",
            "3392/4708 - The training loss at 29th epoch : 0.0799876708011991  Training Accuracy:0.8908450704225352\n",
            "3408/4708 - The training loss at 29th epoch : 0.08018507859855098  Training Accuracy:0.8904789719626168\n",
            "3424/4708 - The training loss at 29th epoch : 0.08008051184225676  Training Accuracy:0.8906976744186047\n",
            "3440/4708 - The training loss at 29th epoch : 0.080221989825575  Training Accuracy:0.890625\n",
            "3456/4708 - The training loss at 29th epoch : 0.07999916915291762  Training Accuracy:0.8908410138248848\n",
            "3472/4708 - The training loss at 29th epoch : 0.08001704768294073  Training Accuracy:0.8907683486238532\n",
            "3488/4708 - The training loss at 29th epoch : 0.08013813390758709  Training Accuracy:0.8906963470319634\n",
            "3504/4708 - The training loss at 29th epoch : 0.08030372704386264  Training Accuracy:0.8903409090909091\n",
            "3520/4708 - The training loss at 29th epoch : 0.0803496410155466  Training Accuracy:0.8902714932126696\n",
            "3536/4708 - The training loss at 29th epoch : 0.08032598440134307  Training Accuracy:0.8907657657657657\n",
            "3552/4708 - The training loss at 29th epoch : 0.08006351983893174  Training Accuracy:0.8912556053811659\n",
            "3568/4708 - The training loss at 29th epoch : 0.07978384264423526  Training Accuracy:0.8917410714285714\n",
            "3584/4708 - The training loss at 29th epoch : 0.07943553117266745  Training Accuracy:0.8922222222222222\n",
            "3600/4708 - The training loss at 29th epoch : 0.079628245398269  Training Accuracy:0.8915929203539823\n",
            "3616/4708 - The training loss at 29th epoch : 0.07977097083487247  Training Accuracy:0.8915198237885462\n",
            "3632/4708 - The training loss at 29th epoch : 0.07979092736034155  Training Accuracy:0.8914473684210527\n",
            "3648/4708 - The training loss at 29th epoch : 0.08039371891282983  Training Accuracy:0.8908296943231441\n",
            "3664/4708 - The training loss at 29th epoch : 0.08085738410938641  Training Accuracy:0.8902173913043478\n",
            "3680/4708 - The training loss at 29th epoch : 0.0805892747579463  Training Accuracy:0.8906926406926406\n",
            "3696/4708 - The training loss at 29th epoch : 0.08057791831927631  Training Accuracy:0.890625\n",
            "3712/4708 - The training loss at 29th epoch : 0.0808177999930205  Training Accuracy:0.8900214592274678\n",
            "3728/4708 - The training loss at 29th epoch : 0.08049372863329787  Training Accuracy:0.8904914529914529\n",
            "3744/4708 - The training loss at 29th epoch : 0.08029409059451918  Training Accuracy:0.8906914893617022\n",
            "3760/4708 - The training loss at 29th epoch : 0.0803648861131163  Training Accuracy:0.890625\n",
            "3776/4708 - The training loss at 29th epoch : 0.0801908063501868  Training Accuracy:0.8908227848101266\n",
            "3792/4708 - The training loss at 29th epoch : 0.08040719881954016  Training Accuracy:0.8902310924369747\n",
            "3808/4708 - The training loss at 29th epoch : 0.08028790353320843  Training Accuracy:0.890428870292887\n",
            "3824/4708 - The training loss at 29th epoch : 0.0800680824020124  Training Accuracy:0.890625\n",
            "3840/4708 - The training loss at 29th epoch : 0.07978561455952167  Training Accuracy:0.8910788381742739\n",
            "3856/4708 - The training loss at 29th epoch : 0.07959981693625853  Training Accuracy:0.8912706611570248\n",
            "3872/4708 - The training loss at 29th epoch : 0.07972255546907285  Training Accuracy:0.8912037037037037\n",
            "3888/4708 - The training loss at 29th epoch : 0.07971365139330602  Training Accuracy:0.8911372950819673\n",
            "3904/4708 - The training loss at 29th epoch : 0.0797661224955868  Training Accuracy:0.8913265306122449\n",
            "3920/4708 - The training loss at 29th epoch : 0.07954117267791641  Training Accuracy:0.8917682926829268\n",
            "3936/4708 - The training loss at 29th epoch : 0.07960603283655782  Training Accuracy:0.8917004048582996\n",
            "3952/4708 - The training loss at 29th epoch : 0.07961782693857097  Training Accuracy:0.891633064516129\n",
            "3968/4708 - The training loss at 29th epoch : 0.07936403519179011  Training Accuracy:0.8920682730923695\n",
            "3984/4708 - The training loss at 29th epoch : 0.07980086749421747  Training Accuracy:0.8915\n",
            "4000/4708 - The training loss at 29th epoch : 0.07974267120556332  Training Accuracy:0.8914342629482072\n",
            "4016/4708 - The training loss at 29th epoch : 0.07955848421172874  Training Accuracy:0.8916170634920635\n",
            "4032/4708 - The training loss at 29th epoch : 0.0797194783904916  Training Accuracy:0.8913043478260869\n",
            "4048/4708 - The training loss at 29th epoch : 0.07946645303879357  Training Accuracy:0.8917322834645669\n",
            "4064/4708 - The training loss at 29th epoch : 0.07943470397123026  Training Accuracy:0.8919117647058824\n",
            "4080/4708 - The training loss at 29th epoch : 0.07961313163582817  Training Accuracy:0.891845703125\n",
            "4096/4708 - The training loss at 29th epoch : 0.07992008217473308  Training Accuracy:0.8912937743190662\n",
            "4112/4708 - The training loss at 29th epoch : 0.07967699175791332  Training Accuracy:0.8917151162790697\n",
            "4128/4708 - The training loss at 29th epoch : 0.07960331616425062  Training Accuracy:0.8918918918918919\n",
            "4144/4708 - The training loss at 29th epoch : 0.07980672064530436  Training Accuracy:0.8915865384615385\n",
            "4160/4708 - The training loss at 29th epoch : 0.07966942921095624  Training Accuracy:0.8920019157088123\n",
            "4176/4708 - The training loss at 29th epoch : 0.07949212561117178  Training Accuracy:0.892175572519084\n",
            "4192/4708 - The training loss at 29th epoch : 0.07928349651411686  Training Accuracy:0.8925855513307985\n",
            "4208/4708 - The training loss at 29th epoch : 0.07949301802624834  Training Accuracy:0.8925189393939394\n",
            "4224/4708 - The training loss at 29th epoch : 0.07950658774523955  Training Accuracy:0.8926886792452831\n",
            "4240/4708 - The training loss at 29th epoch : 0.0795762625589692  Training Accuracy:0.8926221804511278\n",
            "4256/4708 - The training loss at 29th epoch : 0.07970514726457767  Training Accuracy:0.8925561797752809\n",
            "4272/4708 - The training loss at 29th epoch : 0.07955909444683824  Training Accuracy:0.8927238805970149\n",
            "4288/4708 - The training loss at 29th epoch : 0.07946151404056791  Training Accuracy:0.8928903345724907\n",
            "4304/4708 - The training loss at 29th epoch : 0.0797800473111081  Training Accuracy:0.8923611111111112\n",
            "4320/4708 - The training loss at 29th epoch : 0.07966814457407705  Training Accuracy:0.8922970479704797\n",
            "4336/4708 - The training loss at 29th epoch : 0.07961425026706473  Training Accuracy:0.8924632352941176\n",
            "4352/4708 - The training loss at 29th epoch : 0.07956408968067841  Training Accuracy:0.8923992673992674\n",
            "4368/4708 - The training loss at 29th epoch : 0.07967953768636642  Training Accuracy:0.8921076642335767\n",
            "4384/4708 - The training loss at 29th epoch : 0.07948457749132216  Training Accuracy:0.8925\n",
            "4400/4708 - The training loss at 29th epoch : 0.0795408010733312  Training Accuracy:0.8924365942028986\n",
            "4416/4708 - The training loss at 29th epoch : 0.07971889175195927  Training Accuracy:0.8921480144404332\n",
            "4432/4708 - The training loss at 29th epoch : 0.07982712313673157  Training Accuracy:0.8920863309352518\n",
            "4448/4708 - The training loss at 29th epoch : 0.07986977997611372  Training Accuracy:0.8920250896057348\n",
            "4464/4708 - The training loss at 29th epoch : 0.0797469653846901  Training Accuracy:0.8921875\n",
            "4480/4708 - The training loss at 29th epoch : 0.07975254938189685  Training Accuracy:0.8921263345195729\n",
            "4496/4708 - The training loss at 29th epoch : 0.07985842786425981  Training Accuracy:0.8918439716312057\n",
            "4512/4708 - The training loss at 29th epoch : 0.07988872508271386  Training Accuracy:0.8920053003533569\n",
            "4528/4708 - The training loss at 29th epoch : 0.07980632338122516  Training Accuracy:0.8921654929577465\n",
            "4544/4708 - The training loss at 29th epoch : 0.07962749374039398  Training Accuracy:0.8923245614035088\n",
            "4560/4708 - The training loss at 29th epoch : 0.07988760431441465  Training Accuracy:0.8920454545454546\n",
            "4576/4708 - The training loss at 29th epoch : 0.08007185324087364  Training Accuracy:0.8917682926829268\n",
            "4592/4708 - The training loss at 29th epoch : 0.0800642130067567  Training Accuracy:0.8917100694444444\n",
            "4608/4708 - The training loss at 29th epoch : 0.080050610712758  Training Accuracy:0.8916522491349481\n",
            "4624/4708 - The training loss at 29th epoch : 0.0800046032271551  Training Accuracy:0.8915948275862069\n",
            "4640/4708 - The training loss at 29th epoch : 0.08040716832574782  Training Accuracy:0.8908934707903781\n",
            "4656/4708 - The training loss at 29th epoch : 0.08025450343303853  Training Accuracy:0.8910530821917808\n",
            "4672/4708 - The training loss at 29th epoch : 0.08005008158485738  Training Accuracy:0.8914249146757679\n",
            "4688/4708 - The training loss at 29th epoch : 0.07993338901901102  Training Accuracy:0.8915816326530612\n",
            "4704/4708 - The training loss at 29th epoch : 0.07999748496086584  Training Accuracy:0.8915254237288136\n",
            "4720/4708 - The training loss at 29th epoch : 0.08002127481037133  Training Accuracy:0.8914695945945946\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 30th epoch : 0.04870561875841743  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 30th epoch : 0.04453634608380319  Training Accuracy:0.96875\n",
            "32/4708 - The training loss at 30th epoch : 0.05076688660975356  Training Accuracy:0.9583333333333334\n",
            "48/4708 - The training loss at 30th epoch : 0.05256005850272234  Training Accuracy:0.953125\n",
            "64/4708 - The training loss at 30th epoch : 0.06876413626123026  Training Accuracy:0.9375\n",
            "80/4708 - The training loss at 30th epoch : 0.06282177025151973  Training Accuracy:0.9479166666666666\n",
            "96/4708 - The training loss at 30th epoch : 0.07167938833280073  Training Accuracy:0.9196428571428571\n",
            "112/4708 - The training loss at 30th epoch : 0.08298132213282797  Training Accuracy:0.8984375\n",
            "128/4708 - The training loss at 30th epoch : 0.07517537563808838  Training Accuracy:0.9097222222222222\n",
            "144/4708 - The training loss at 30th epoch : 0.07039532501372707  Training Accuracy:0.9125\n",
            "160/4708 - The training loss at 30th epoch : 0.07423614973791343  Training Accuracy:0.9090909090909091\n",
            "176/4708 - The training loss at 30th epoch : 0.07225471519093378  Training Accuracy:0.9114583333333334\n",
            "192/4708 - The training loss at 30th epoch : 0.0779171230315612  Training Accuracy:0.8990384615384616\n",
            "208/4708 - The training loss at 30th epoch : 0.07541139149498403  Training Accuracy:0.9017857142857143\n",
            "224/4708 - The training loss at 30th epoch : 0.07236440017749009  Training Accuracy:0.9083333333333333\n",
            "240/4708 - The training loss at 30th epoch : 0.06910453795770874  Training Accuracy:0.9140625\n",
            "256/4708 - The training loss at 30th epoch : 0.07181661503928638  Training Accuracy:0.9117647058823529\n",
            "272/4708 - The training loss at 30th epoch : 0.07077102087378814  Training Accuracy:0.9131944444444444\n",
            "288/4708 - The training loss at 30th epoch : 0.06899632750458436  Training Accuracy:0.9144736842105263\n",
            "304/4708 - The training loss at 30th epoch : 0.06901262605837946  Training Accuracy:0.9125\n",
            "320/4708 - The training loss at 30th epoch : 0.07806823210886557  Training Accuracy:0.8988095238095238\n",
            "336/4708 - The training loss at 30th epoch : 0.07752085575526402  Training Accuracy:0.8977272727272727\n",
            "352/4708 - The training loss at 30th epoch : 0.07619711432934576  Training Accuracy:0.8994565217391305\n",
            "368/4708 - The training loss at 30th epoch : 0.07736591910730824  Training Accuracy:0.8984375\n",
            "384/4708 - The training loss at 30th epoch : 0.0778250414983482  Training Accuracy:0.8975\n",
            "400/4708 - The training loss at 30th epoch : 0.08061560562182947  Training Accuracy:0.8942307692307693\n",
            "416/4708 - The training loss at 30th epoch : 0.08038482643016792  Training Accuracy:0.8912037037037037\n",
            "432/4708 - The training loss at 30th epoch : 0.08141163936217564  Training Accuracy:0.890625\n",
            "448/4708 - The training loss at 30th epoch : 0.07874633249401831  Training Accuracy:0.8943965517241379\n",
            "464/4708 - The training loss at 30th epoch : 0.07812673216924268  Training Accuracy:0.8958333333333334\n",
            "480/4708 - The training loss at 30th epoch : 0.07718723942622852  Training Accuracy:0.8971774193548387\n",
            "496/4708 - The training loss at 30th epoch : 0.07668784300704974  Training Accuracy:0.8984375\n",
            "512/4708 - The training loss at 30th epoch : 0.07607152085591863  Training Accuracy:0.8977272727272727\n",
            "528/4708 - The training loss at 30th epoch : 0.07743593636291658  Training Accuracy:0.8970588235294118\n",
            "544/4708 - The training loss at 30th epoch : 0.07826149335381785  Training Accuracy:0.8982142857142857\n",
            "560/4708 - The training loss at 30th epoch : 0.07881204304736009  Training Accuracy:0.8975694444444444\n",
            "576/4708 - The training loss at 30th epoch : 0.08165285128810021  Training Accuracy:0.893581081081081\n",
            "592/4708 - The training loss at 30th epoch : 0.07994712333512169  Training Accuracy:0.8963815789473685\n",
            "608/4708 - The training loss at 30th epoch : 0.07861639199691006  Training Accuracy:0.8974358974358975\n",
            "624/4708 - The training loss at 30th epoch : 0.07745973895631314  Training Accuracy:0.8984375\n",
            "640/4708 - The training loss at 30th epoch : 0.07800788559530653  Training Accuracy:0.8978658536585366\n",
            "656/4708 - The training loss at 30th epoch : 0.07746135227365739  Training Accuracy:0.8988095238095238\n",
            "672/4708 - The training loss at 30th epoch : 0.07730317340859763  Training Accuracy:0.8968023255813954\n",
            "688/4708 - The training loss at 30th epoch : 0.07587150993394819  Training Accuracy:0.8991477272727273\n",
            "704/4708 - The training loss at 30th epoch : 0.07446732945953186  Training Accuracy:0.9013888888888889\n",
            "720/4708 - The training loss at 30th epoch : 0.07347825720245967  Training Accuracy:0.9035326086956522\n",
            "736/4708 - The training loss at 30th epoch : 0.07265702193340985  Training Accuracy:0.9055851063829787\n",
            "752/4708 - The training loss at 30th epoch : 0.07279244547127282  Training Accuracy:0.90625\n",
            "768/4708 - The training loss at 30th epoch : 0.07271094180588528  Training Accuracy:0.9068877551020408\n",
            "784/4708 - The training loss at 30th epoch : 0.07446116212770278  Training Accuracy:0.9025\n",
            "800/4708 - The training loss at 30th epoch : 0.07535674242926739  Training Accuracy:0.9019607843137255\n",
            "816/4708 - The training loss at 30th epoch : 0.07501840821909399  Training Accuracy:0.9026442307692307\n",
            "832/4708 - The training loss at 30th epoch : 0.07701838534489211  Training Accuracy:0.8997641509433962\n",
            "848/4708 - The training loss at 30th epoch : 0.07676326738183852  Training Accuracy:0.9004629629629629\n",
            "864/4708 - The training loss at 30th epoch : 0.076006024071495  Training Accuracy:0.9011363636363636\n",
            "880/4708 - The training loss at 30th epoch : 0.0754879746962451  Training Accuracy:0.9006696428571429\n",
            "896/4708 - The training loss at 30th epoch : 0.07428980214555961  Training Accuracy:0.9024122807017544\n",
            "912/4708 - The training loss at 30th epoch : 0.07533649369268536  Training Accuracy:0.9008620689655172\n",
            "928/4708 - The training loss at 30th epoch : 0.07584078021214663  Training Accuracy:0.899364406779661\n",
            "944/4708 - The training loss at 30th epoch : 0.07509774854832425  Training Accuracy:0.9\n",
            "960/4708 - The training loss at 30th epoch : 0.07520573895451797  Training Accuracy:0.8995901639344263\n",
            "976/4708 - The training loss at 30th epoch : 0.0760227617595295  Training Accuracy:0.8981854838709677\n",
            "992/4708 - The training loss at 30th epoch : 0.07574162634462991  Training Accuracy:0.8988095238095238\n",
            "1008/4708 - The training loss at 30th epoch : 0.07559456601319772  Training Accuracy:0.8994140625\n",
            "1024/4708 - The training loss at 30th epoch : 0.07508480354239296  Training Accuracy:0.9\n",
            "1040/4708 - The training loss at 30th epoch : 0.07541743497044544  Training Accuracy:0.8996212121212122\n",
            "1056/4708 - The training loss at 30th epoch : 0.0748127483100715  Training Accuracy:0.9001865671641791\n",
            "1072/4708 - The training loss at 30th epoch : 0.07563974736729498  Training Accuracy:0.8998161764705882\n",
            "1088/4708 - The training loss at 30th epoch : 0.07609876767631524  Training Accuracy:0.8985507246376812\n",
            "1104/4708 - The training loss at 30th epoch : 0.0756994955074305  Training Accuracy:0.8991071428571429\n",
            "1120/4708 - The training loss at 30th epoch : 0.07656109335475458  Training Accuracy:0.897887323943662\n",
            "1136/4708 - The training loss at 30th epoch : 0.07618846324248392  Training Accuracy:0.8984375\n",
            "1152/4708 - The training loss at 30th epoch : 0.07663193162433968  Training Accuracy:0.8981164383561644\n",
            "1168/4708 - The training loss at 30th epoch : 0.07625350836029218  Training Accuracy:0.8986486486486487\n",
            "1184/4708 - The training loss at 30th epoch : 0.07673323342055045  Training Accuracy:0.8983333333333333\n",
            "1200/4708 - The training loss at 30th epoch : 0.07589255478944049  Training Accuracy:0.899671052631579\n",
            "1216/4708 - The training loss at 30th epoch : 0.07773109799921402  Training Accuracy:0.8961038961038961\n",
            "1232/4708 - The training loss at 30th epoch : 0.07794563452339953  Training Accuracy:0.8958333333333334\n",
            "1248/4708 - The training loss at 30th epoch : 0.07849961888011293  Training Accuracy:0.8947784810126582\n",
            "1264/4708 - The training loss at 30th epoch : 0.07822336455946576  Training Accuracy:0.8953125\n",
            "1280/4708 - The training loss at 30th epoch : 0.07786329889781607  Training Accuracy:0.8958333333333334\n",
            "1296/4708 - The training loss at 30th epoch : 0.07721132694179361  Training Accuracy:0.8971036585365854\n",
            "1312/4708 - The training loss at 30th epoch : 0.07647986408639153  Training Accuracy:0.8983433734939759\n",
            "1328/4708 - The training loss at 30th epoch : 0.07625694879017914  Training Accuracy:0.8988095238095238\n",
            "1344/4708 - The training loss at 30th epoch : 0.07730082948778234  Training Accuracy:0.8970588235294118\n",
            "1360/4708 - The training loss at 30th epoch : 0.076571510719313  Training Accuracy:0.8982558139534884\n",
            "1376/4708 - The training loss at 30th epoch : 0.07588787179251824  Training Accuracy:0.8994252873563219\n",
            "1392/4708 - The training loss at 30th epoch : 0.07536689021172875  Training Accuracy:0.9005681818181818\n",
            "1408/4708 - The training loss at 30th epoch : 0.0756667959387209  Training Accuracy:0.9002808988764045\n",
            "1424/4708 - The training loss at 30th epoch : 0.07584592873207084  Training Accuracy:0.8993055555555556\n",
            "1440/4708 - The training loss at 30th epoch : 0.07555580858527634  Training Accuracy:0.8997252747252747\n",
            "1456/4708 - The training loss at 30th epoch : 0.07627812123743409  Training Accuracy:0.8980978260869565\n",
            "1472/4708 - The training loss at 30th epoch : 0.07633946609891928  Training Accuracy:0.8978494623655914\n",
            "1488/4708 - The training loss at 30th epoch : 0.07585024726881141  Training Accuracy:0.8982712765957447\n",
            "1504/4708 - The training loss at 30th epoch : 0.07572583970380005  Training Accuracy:0.8980263157894737\n",
            "1520/4708 - The training loss at 30th epoch : 0.07573265508816286  Training Accuracy:0.8984375\n",
            "1536/4708 - The training loss at 30th epoch : 0.07620617627910736  Training Accuracy:0.8975515463917526\n",
            "1552/4708 - The training loss at 30th epoch : 0.07600214152645984  Training Accuracy:0.8979591836734694\n",
            "1568/4708 - The training loss at 30th epoch : 0.07559535585931962  Training Accuracy:0.898989898989899\n",
            "1584/4708 - The training loss at 30th epoch : 0.07621254569094539  Training Accuracy:0.898125\n",
            "1600/4708 - The training loss at 30th epoch : 0.07678659901895821  Training Accuracy:0.8972772277227723\n",
            "1616/4708 - The training loss at 30th epoch : 0.07653116537758653  Training Accuracy:0.897671568627451\n",
            "1632/4708 - The training loss at 30th epoch : 0.07672799928993022  Training Accuracy:0.8974514563106796\n",
            "1648/4708 - The training loss at 30th epoch : 0.07681541462308691  Training Accuracy:0.8978365384615384\n",
            "1664/4708 - The training loss at 30th epoch : 0.07687247258989757  Training Accuracy:0.8976190476190476\n",
            "1680/4708 - The training loss at 30th epoch : 0.07712476279778893  Training Accuracy:0.8968160377358491\n",
            "1696/4708 - The training loss at 30th epoch : 0.07792205574979869  Training Accuracy:0.8954439252336449\n",
            "1712/4708 - The training loss at 30th epoch : 0.07866205043900243  Training Accuracy:0.8940972222222222\n",
            "1728/4708 - The training loss at 30th epoch : 0.07853743849342237  Training Accuracy:0.8939220183486238\n",
            "1744/4708 - The training loss at 30th epoch : 0.07870442405210738  Training Accuracy:0.89375\n",
            "1760/4708 - The training loss at 30th epoch : 0.0789888783559236  Training Accuracy:0.8941441441441441\n",
            "1776/4708 - The training loss at 30th epoch : 0.07933869639674243  Training Accuracy:0.8939732142857143\n",
            "1792/4708 - The training loss at 30th epoch : 0.07913774927397292  Training Accuracy:0.894358407079646\n",
            "1808/4708 - The training loss at 30th epoch : 0.07952452874017645  Training Accuracy:0.893640350877193\n",
            "1824/4708 - The training loss at 30th epoch : 0.07934755068284917  Training Accuracy:0.8934782608695652\n",
            "1840/4708 - The training loss at 30th epoch : 0.0789935640495846  Training Accuracy:0.8938577586206896\n",
            "1856/4708 - The training loss at 30th epoch : 0.079207759512831  Training Accuracy:0.8926282051282052\n",
            "1872/4708 - The training loss at 30th epoch : 0.08039680619788306  Training Accuracy:0.8914194915254238\n",
            "1888/4708 - The training loss at 30th epoch : 0.07990953580398326  Training Accuracy:0.8918067226890757\n",
            "1904/4708 - The training loss at 30th epoch : 0.07932521415055839  Training Accuracy:0.8927083333333333\n",
            "1920/4708 - The training loss at 30th epoch : 0.07919511649908316  Training Accuracy:0.8930785123966942\n",
            "1936/4708 - The training loss at 30th epoch : 0.0785641596348784  Training Accuracy:0.8939549180327869\n",
            "1952/4708 - The training loss at 30th epoch : 0.0786150870506026  Training Accuracy:0.8938008130081301\n",
            "1968/4708 - The training loss at 30th epoch : 0.07870740511183476  Training Accuracy:0.8936491935483871\n",
            "1984/4708 - The training loss at 30th epoch : 0.0789455915461818  Training Accuracy:0.8925\n",
            "2000/4708 - The training loss at 30th epoch : 0.07878124963928308  Training Accuracy:0.8928571428571429\n",
            "2016/4708 - The training loss at 30th epoch : 0.07822536528153794  Training Accuracy:0.8937007874015748\n",
            "2032/4708 - The training loss at 30th epoch : 0.07863721792339558  Training Accuracy:0.89306640625\n",
            "2048/4708 - The training loss at 30th epoch : 0.07839474145397213  Training Accuracy:0.8929263565891473\n",
            "2064/4708 - The training loss at 30th epoch : 0.07832903411334163  Training Accuracy:0.8932692307692308\n",
            "2080/4708 - The training loss at 30th epoch : 0.07835739174342289  Training Accuracy:0.8931297709923665\n",
            "2096/4708 - The training loss at 30th epoch : 0.07885317207066779  Training Accuracy:0.8929924242424242\n",
            "2112/4708 - The training loss at 30th epoch : 0.07847543498424968  Training Accuracy:0.893796992481203\n",
            "2128/4708 - The training loss at 30th epoch : 0.07930812555705277  Training Accuracy:0.8922574626865671\n",
            "2144/4708 - The training loss at 30th epoch : 0.0800185074441425  Training Accuracy:0.8916666666666667\n",
            "2160/4708 - The training loss at 30th epoch : 0.08008584938766304  Training Accuracy:0.8910845588235294\n",
            "2176/4708 - The training loss at 30th epoch : 0.07983305506617831  Training Accuracy:0.8914233576642335\n",
            "2192/4708 - The training loss at 30th epoch : 0.07937263899129898  Training Accuracy:0.8922101449275363\n",
            "2208/4708 - The training loss at 30th epoch : 0.07965479263780742  Training Accuracy:0.8920863309352518\n",
            "2224/4708 - The training loss at 30th epoch : 0.07984755856269221  Training Accuracy:0.8919642857142858\n",
            "2240/4708 - The training loss at 30th epoch : 0.08059485099463763  Training Accuracy:0.8905141843971631\n",
            "2256/4708 - The training loss at 30th epoch : 0.0812227991953629  Training Accuracy:0.889524647887324\n",
            "2272/4708 - The training loss at 30th epoch : 0.08133195586562711  Training Accuracy:0.8898601398601399\n",
            "2288/4708 - The training loss at 30th epoch : 0.08087135734225094  Training Accuracy:0.890625\n",
            "2304/4708 - The training loss at 30th epoch : 0.08104405348294838  Training Accuracy:0.8905172413793103\n",
            "2320/4708 - The training loss at 30th epoch : 0.08174176570272317  Training Accuracy:0.8899828767123288\n",
            "2336/4708 - The training loss at 30th epoch : 0.08232341995737681  Training Accuracy:0.889030612244898\n",
            "2352/4708 - The training loss at 30th epoch : 0.08231141647586702  Training Accuracy:0.8893581081081081\n",
            "2368/4708 - The training loss at 30th epoch : 0.08206434790148708  Training Accuracy:0.8896812080536913\n",
            "2384/4708 - The training loss at 30th epoch : 0.08286491421261469  Training Accuracy:0.88875\n",
            "2400/4708 - The training loss at 30th epoch : 0.08262362885721937  Training Accuracy:0.8886589403973509\n",
            "2416/4708 - The training loss at 30th epoch : 0.08301279794919696  Training Accuracy:0.8885690789473685\n",
            "2432/4708 - The training loss at 30th epoch : 0.08342401478888994  Training Accuracy:0.8876633986928104\n",
            "2448/4708 - The training loss at 30th epoch : 0.0841970367174163  Training Accuracy:0.8867694805194806\n",
            "2464/4708 - The training loss at 30th epoch : 0.08388747615482134  Training Accuracy:0.8870967741935484\n",
            "2480/4708 - The training loss at 30th epoch : 0.0834448704124004  Training Accuracy:0.8878205128205128\n",
            "2496/4708 - The training loss at 30th epoch : 0.0837535381791029  Training Accuracy:0.8873407643312102\n",
            "2512/4708 - The training loss at 30th epoch : 0.08445191403563636  Training Accuracy:0.8864715189873418\n",
            "2528/4708 - The training loss at 30th epoch : 0.08434826966007865  Training Accuracy:0.8867924528301887\n",
            "2544/4708 - The training loss at 30th epoch : 0.08447435656717613  Training Accuracy:0.88671875\n",
            "2560/4708 - The training loss at 30th epoch : 0.08481390987482937  Training Accuracy:0.8858695652173914\n",
            "2576/4708 - The training loss at 30th epoch : 0.08466060049529271  Training Accuracy:0.8861882716049383\n",
            "2592/4708 - The training loss at 30th epoch : 0.0844097584151477  Training Accuracy:0.8865030674846626\n",
            "2608/4708 - The training loss at 30th epoch : 0.08442067407973018  Training Accuracy:0.8864329268292683\n",
            "2624/4708 - The training loss at 30th epoch : 0.08425319797244463  Training Accuracy:0.8867424242424242\n",
            "2640/4708 - The training loss at 30th epoch : 0.0839383606678527  Training Accuracy:0.8870481927710844\n",
            "2656/4708 - The training loss at 30th epoch : 0.08385093211533749  Training Accuracy:0.8866017964071856\n",
            "2672/4708 - The training loss at 30th epoch : 0.08346762861700828  Training Accuracy:0.8872767857142857\n",
            "2688/4708 - The training loss at 30th epoch : 0.08320759541535973  Training Accuracy:0.8875739644970414\n",
            "2704/4708 - The training loss at 30th epoch : 0.08286039034790864  Training Accuracy:0.888235294117647\n",
            "2720/4708 - The training loss at 30th epoch : 0.08277471448155974  Training Accuracy:0.8885233918128655\n",
            "2736/4708 - The training loss at 30th epoch : 0.08310667051829028  Training Accuracy:0.8873546511627907\n",
            "2752/4708 - The training loss at 30th epoch : 0.08299777996429535  Training Accuracy:0.8876445086705202\n",
            "2768/4708 - The training loss at 30th epoch : 0.0834518188714445  Training Accuracy:0.8868534482758621\n",
            "2784/4708 - The training loss at 30th epoch : 0.08344031475745559  Training Accuracy:0.8867857142857143\n",
            "2800/4708 - The training loss at 30th epoch : 0.08321503283392984  Training Accuracy:0.8874289772727273\n",
            "2816/4708 - The training loss at 30th epoch : 0.08302252504244824  Training Accuracy:0.8877118644067796\n",
            "2832/4708 - The training loss at 30th epoch : 0.08276587721828671  Training Accuracy:0.8879915730337079\n",
            "2848/4708 - The training loss at 30th epoch : 0.08254058562973261  Training Accuracy:0.888268156424581\n",
            "2864/4708 - The training loss at 30th epoch : 0.08250976222136017  Training Accuracy:0.8885416666666667\n",
            "2880/4708 - The training loss at 30th epoch : 0.0828404477258039  Training Accuracy:0.888121546961326\n",
            "2896/4708 - The training loss at 30th epoch : 0.08281902674226248  Training Accuracy:0.8880494505494505\n",
            "2912/4708 - The training loss at 30th epoch : 0.08274882114886696  Training Accuracy:0.8879781420765027\n",
            "2928/4708 - The training loss at 30th epoch : 0.08268228022095982  Training Accuracy:0.8879076086956522\n",
            "2944/4708 - The training loss at 30th epoch : 0.08241635456020531  Training Accuracy:0.8881756756756757\n",
            "2960/4708 - The training loss at 30th epoch : 0.0822940201928621  Training Accuracy:0.8884408602150538\n",
            "2976/4708 - The training loss at 30th epoch : 0.08250850509964147  Training Accuracy:0.8883689839572193\n",
            "2992/4708 - The training loss at 30th epoch : 0.08216438410036389  Training Accuracy:0.8886303191489362\n",
            "3008/4708 - The training loss at 30th epoch : 0.08203322618831613  Training Accuracy:0.888558201058201\n",
            "3024/4708 - The training loss at 30th epoch : 0.0824510867415036  Training Accuracy:0.8881578947368421\n",
            "3040/4708 - The training loss at 30th epoch : 0.08236717165695938  Training Accuracy:0.8877617801047121\n",
            "3056/4708 - The training loss at 30th epoch : 0.08290378152402537  Training Accuracy:0.8870442708333334\n",
            "3072/4708 - The training loss at 30th epoch : 0.0826446035251044  Training Accuracy:0.8873056994818653\n",
            "3088/4708 - The training loss at 30th epoch : 0.08235807693789003  Training Accuracy:0.8878865979381443\n",
            "3104/4708 - The training loss at 30th epoch : 0.08229459341732459  Training Accuracy:0.8878205128205128\n",
            "3120/4708 - The training loss at 30th epoch : 0.08208079105987683  Training Accuracy:0.8880739795918368\n",
            "3136/4708 - The training loss at 30th epoch : 0.08184443997789598  Training Accuracy:0.8886421319796954\n",
            "3152/4708 - The training loss at 30th epoch : 0.08154659769730781  Training Accuracy:0.8892045454545454\n",
            "3168/4708 - The training loss at 30th epoch : 0.0814773032431024  Training Accuracy:0.8894472361809045\n",
            "3184/4708 - The training loss at 30th epoch : 0.0815863984505784  Training Accuracy:0.8890625\n",
            "3200/4708 - The training loss at 30th epoch : 0.08120169067771672  Training Accuracy:0.8896144278606966\n",
            "3216/4708 - The training loss at 30th epoch : 0.08117911964673127  Training Accuracy:0.8892326732673267\n",
            "3232/4708 - The training loss at 30th epoch : 0.08100685856386929  Training Accuracy:0.8894704433497537\n",
            "3248/4708 - The training loss at 30th epoch : 0.08079228595084992  Training Accuracy:0.8897058823529411\n",
            "3264/4708 - The training loss at 30th epoch : 0.08100636896673494  Training Accuracy:0.8893292682926829\n",
            "3280/4708 - The training loss at 30th epoch : 0.08077810879259995  Training Accuracy:0.8895631067961165\n",
            "3296/4708 - The training loss at 30th epoch : 0.08079457955008526  Training Accuracy:0.8894927536231884\n",
            "3312/4708 - The training loss at 30th epoch : 0.08071068355970178  Training Accuracy:0.8897235576923077\n",
            "3328/4708 - The training loss at 30th epoch : 0.08038250750279709  Training Accuracy:0.8902511961722488\n",
            "3344/4708 - The training loss at 30th epoch : 0.08016533389259502  Training Accuracy:0.8904761904761904\n",
            "3360/4708 - The training loss at 30th epoch : 0.07983071675145374  Training Accuracy:0.8909952606635071\n",
            "3376/4708 - The training loss at 30th epoch : 0.07969605130331947  Training Accuracy:0.8912146226415094\n",
            "3392/4708 - The training loss at 30th epoch : 0.07956723715590017  Training Accuracy:0.8911384976525821\n",
            "3408/4708 - The training loss at 30th epoch : 0.07956794541668091  Training Accuracy:0.8913551401869159\n",
            "3424/4708 - The training loss at 30th epoch : 0.07959519791607692  Training Accuracy:0.8909883720930233\n",
            "3440/4708 - The training loss at 30th epoch : 0.08005267647004617  Training Accuracy:0.8900462962962963\n",
            "3456/4708 - The training loss at 30th epoch : 0.08022749536480522  Training Accuracy:0.8902649769585254\n",
            "3472/4708 - The training loss at 30th epoch : 0.07993468342098772  Training Accuracy:0.8907683486238532\n",
            "3488/4708 - The training loss at 30th epoch : 0.07986913860548667  Training Accuracy:0.8906963470319634\n",
            "3504/4708 - The training loss at 30th epoch : 0.08042526199809688  Training Accuracy:0.8900568181818181\n",
            "3520/4708 - The training loss at 30th epoch : 0.08073108611189302  Training Accuracy:0.8894230769230769\n",
            "3536/4708 - The training loss at 30th epoch : 0.08049123754873404  Training Accuracy:0.8896396396396397\n",
            "3552/4708 - The training loss at 30th epoch : 0.08057584471200589  Training Accuracy:0.8892937219730942\n",
            "3568/4708 - The training loss at 30th epoch : 0.08044735689961294  Training Accuracy:0.8895089285714286\n",
            "3584/4708 - The training loss at 30th epoch : 0.08042876765703325  Training Accuracy:0.8894444444444445\n",
            "3600/4708 - The training loss at 30th epoch : 0.08028864092361941  Training Accuracy:0.8896570796460177\n",
            "3616/4708 - The training loss at 30th epoch : 0.08014803353470881  Training Accuracy:0.8898678414096917\n",
            "3632/4708 - The training loss at 30th epoch : 0.07997788387650906  Training Accuracy:0.8900767543859649\n",
            "3648/4708 - The training loss at 30th epoch : 0.07984403920464646  Training Accuracy:0.8902838427947598\n",
            "3664/4708 - The training loss at 30th epoch : 0.0795213120032561  Training Accuracy:0.8907608695652174\n",
            "3680/4708 - The training loss at 30th epoch : 0.07985901660908089  Training Accuracy:0.890422077922078\n",
            "3696/4708 - The training loss at 30th epoch : 0.07996677658661229  Training Accuracy:0.8903556034482759\n",
            "3712/4708 - The training loss at 30th epoch : 0.07982460821022803  Training Accuracy:0.8905579399141631\n",
            "3728/4708 - The training loss at 30th epoch : 0.07993041600271043  Training Accuracy:0.8902243589743589\n",
            "3744/4708 - The training loss at 30th epoch : 0.07984174360580538  Training Accuracy:0.8904255319148936\n",
            "3760/4708 - The training loss at 30th epoch : 0.0798068963029682  Training Accuracy:0.8903601694915254\n",
            "3776/4708 - The training loss at 30th epoch : 0.0797312986733706  Training Accuracy:0.8905590717299579\n",
            "3792/4708 - The training loss at 30th epoch : 0.07971711476081254  Training Accuracy:0.8907563025210085\n",
            "3808/4708 - The training loss at 30th epoch : 0.07941121994949288  Training Accuracy:0.891213389121339\n",
            "3824/4708 - The training loss at 30th epoch : 0.07976338554507728  Training Accuracy:0.890625\n",
            "3840/4708 - The training loss at 30th epoch : 0.07970982997107291  Training Accuracy:0.8908195020746889\n",
            "3856/4708 - The training loss at 30th epoch : 0.07986543366078958  Training Accuracy:0.890754132231405\n",
            "3872/4708 - The training loss at 30th epoch : 0.08001908292273244  Training Accuracy:0.8906893004115226\n",
            "3888/4708 - The training loss at 30th epoch : 0.08007784158782767  Training Accuracy:0.890625\n",
            "3904/4708 - The training loss at 30th epoch : 0.07992897112650117  Training Accuracy:0.8910714285714286\n",
            "3920/4708 - The training loss at 30th epoch : 0.07971164165241652  Training Accuracy:0.8915142276422764\n",
            "3936/4708 - The training loss at 30th epoch : 0.07958053131579537  Training Accuracy:0.8914473684210527\n",
            "3952/4708 - The training loss at 30th epoch : 0.07932227083211305  Training Accuracy:0.8918850806451613\n",
            "3968/4708 - The training loss at 30th epoch : 0.0797205592106291  Training Accuracy:0.891566265060241\n",
            "3984/4708 - The training loss at 30th epoch : 0.07973818111322098  Training Accuracy:0.89125\n",
            "4000/4708 - The training loss at 30th epoch : 0.0798353541207935  Training Accuracy:0.8911852589641435\n",
            "4016/4708 - The training loss at 30th epoch : 0.0798221784645449  Training Accuracy:0.8913690476190477\n",
            "4032/4708 - The training loss at 30th epoch : 0.07968310652009616  Training Accuracy:0.8915513833992095\n",
            "4048/4708 - The training loss at 30th epoch : 0.07977970251704669  Training Accuracy:0.891486220472441\n",
            "4064/4708 - The training loss at 30th epoch : 0.07969915593218542  Training Accuracy:0.891421568627451\n",
            "4080/4708 - The training loss at 30th epoch : 0.0794312909769262  Training Accuracy:0.891845703125\n",
            "4096/4708 - The training loss at 30th epoch : 0.07941364228170451  Training Accuracy:0.8917801556420234\n",
            "4112/4708 - The training loss at 30th epoch : 0.079878038189471  Training Accuracy:0.8909883720930233\n",
            "4128/4708 - The training loss at 30th epoch : 0.07985860838154095  Training Accuracy:0.890926640926641\n",
            "4144/4708 - The training loss at 30th epoch : 0.07976792919798238  Training Accuracy:0.8911057692307692\n",
            "4160/4708 - The training loss at 30th epoch : 0.08002845201745358  Training Accuracy:0.8908045977011494\n",
            "4176/4708 - The training loss at 30th epoch : 0.07992823113510156  Training Accuracy:0.8907442748091603\n",
            "4192/4708 - The training loss at 30th epoch : 0.07995365016368075  Training Accuracy:0.8904467680608364\n",
            "4208/4708 - The training loss at 30th epoch : 0.07967658884840685  Training Accuracy:0.8908617424242424\n",
            "4224/4708 - The training loss at 30th epoch : 0.07953198253029321  Training Accuracy:0.8910377358490567\n",
            "4240/4708 - The training loss at 30th epoch : 0.07944818696272843  Training Accuracy:0.8912124060150376\n",
            "4256/4708 - The training loss at 30th epoch : 0.07939959988184163  Training Accuracy:0.8911516853932584\n",
            "4272/4708 - The training loss at 30th epoch : 0.07923184997903365  Training Accuracy:0.8913246268656716\n",
            "4288/4708 - The training loss at 30th epoch : 0.07930194514823347  Training Accuracy:0.8912639405204461\n",
            "4304/4708 - The training loss at 30th epoch : 0.07929044900100288  Training Accuracy:0.8912037037037037\n",
            "4320/4708 - The training loss at 30th epoch : 0.07904469455567405  Training Accuracy:0.8916051660516605\n",
            "4336/4708 - The training loss at 30th epoch : 0.07922037244712371  Training Accuracy:0.8913143382352942\n",
            "4352/4708 - The training loss at 30th epoch : 0.07911101316554464  Training Accuracy:0.8914835164835165\n",
            "4368/4708 - The training loss at 30th epoch : 0.07911026774369787  Training Accuracy:0.8914233576642335\n",
            "4384/4708 - The training loss at 30th epoch : 0.07912701414700855  Training Accuracy:0.8913636363636364\n",
            "4400/4708 - The training loss at 30th epoch : 0.07923617843955277  Training Accuracy:0.8913043478260869\n",
            "4416/4708 - The training loss at 30th epoch : 0.07902722296566049  Training Accuracy:0.8916967509025271\n",
            "4432/4708 - The training loss at 30th epoch : 0.07892111939953997  Training Accuracy:0.8918615107913669\n",
            "4448/4708 - The training loss at 30th epoch : 0.07878525975250657  Training Accuracy:0.8920250896057348\n",
            "4464/4708 - The training loss at 30th epoch : 0.07871397764549709  Training Accuracy:0.8919642857142858\n",
            "4480/4708 - The training loss at 30th epoch : 0.07874818590608262  Training Accuracy:0.8919039145907474\n",
            "4496/4708 - The training loss at 30th epoch : 0.07891387157154581  Training Accuracy:0.8914007092198581\n",
            "4512/4708 - The training loss at 30th epoch : 0.07908496496590338  Training Accuracy:0.8913427561837456\n",
            "4528/4708 - The training loss at 30th epoch : 0.07912524401396824  Training Accuracy:0.8912852112676056\n",
            "4544/4708 - The training loss at 30th epoch : 0.07907827474503179  Training Accuracy:0.8914473684210527\n",
            "4560/4708 - The training loss at 30th epoch : 0.07931358690962666  Training Accuracy:0.8909527972027972\n",
            "4576/4708 - The training loss at 30th epoch : 0.07930128655521934  Training Accuracy:0.8911149825783972\n",
            "4592/4708 - The training loss at 30th epoch : 0.07935759260239815  Training Accuracy:0.8910590277777778\n",
            "4608/4708 - The training loss at 30th epoch : 0.07915916056002666  Training Accuracy:0.8914359861591695\n",
            "4624/4708 - The training loss at 30th epoch : 0.07916784568521786  Training Accuracy:0.8913793103448275\n",
            "4640/4708 - The training loss at 30th epoch : 0.07903375241605197  Training Accuracy:0.8915378006872853\n",
            "4656/4708 - The training loss at 30th epoch : 0.07907838969542257  Training Accuracy:0.8912671232876712\n",
            "4672/4708 - The training loss at 30th epoch : 0.07913387191936856  Training Accuracy:0.8914249146757679\n",
            "4688/4708 - The training loss at 30th epoch : 0.07894286124299503  Training Accuracy:0.8917942176870748\n",
            "4704/4708 - The training loss at 30th epoch : 0.07897110140446419  Training Accuracy:0.8917372881355933\n",
            "4720/4708 - The training loss at 30th epoch : 0.07902870631338457  Training Accuracy:0.8914695945945946\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 31th epoch : 0.06021841108414036  Training Accuracy:0.9375\n",
            "16/4708 - The training loss at 31th epoch : 0.07062553551618427  Training Accuracy:0.875\n",
            "32/4708 - The training loss at 31th epoch : 0.06385946315900963  Training Accuracy:0.8958333333333334\n",
            "48/4708 - The training loss at 31th epoch : 0.07554613052671044  Training Accuracy:0.890625\n",
            "64/4708 - The training loss at 31th epoch : 0.07975827616267173  Training Accuracy:0.9\n",
            "80/4708 - The training loss at 31th epoch : 0.07102623278897131  Training Accuracy:0.90625\n",
            "96/4708 - The training loss at 31th epoch : 0.0659848719289234  Training Accuracy:0.9107142857142857\n",
            "112/4708 - The training loss at 31th epoch : 0.06587248186156766  Training Accuracy:0.90625\n",
            "128/4708 - The training loss at 31th epoch : 0.06887967720928473  Training Accuracy:0.9027777777777778\n",
            "144/4708 - The training loss at 31th epoch : 0.06752458066365619  Training Accuracy:0.9\n",
            "160/4708 - The training loss at 31th epoch : 0.06380822070973202  Training Accuracy:0.9034090909090909\n",
            "176/4708 - The training loss at 31th epoch : 0.06743609010557225  Training Accuracy:0.9010416666666666\n",
            "192/4708 - The training loss at 31th epoch : 0.06524238112187905  Training Accuracy:0.9038461538461539\n",
            "208/4708 - The training loss at 31th epoch : 0.06242635049180577  Training Accuracy:0.90625\n",
            "224/4708 - The training loss at 31th epoch : 0.061763501045460044  Training Accuracy:0.9083333333333333\n",
            "240/4708 - The training loss at 31th epoch : 0.06362805032745783  Training Accuracy:0.90234375\n",
            "256/4708 - The training loss at 31th epoch : 0.060582848787735004  Training Accuracy:0.9080882352941176\n",
            "272/4708 - The training loss at 31th epoch : 0.06563152575312256  Training Accuracy:0.9027777777777778\n",
            "288/4708 - The training loss at 31th epoch : 0.06459306161058474  Training Accuracy:0.9046052631578947\n",
            "304/4708 - The training loss at 31th epoch : 0.06951005333207352  Training Accuracy:0.896875\n",
            "320/4708 - The training loss at 31th epoch : 0.07188686978305088  Training Accuracy:0.8928571428571429\n",
            "336/4708 - The training loss at 31th epoch : 0.07461024189240954  Training Accuracy:0.8892045454545454\n",
            "352/4708 - The training loss at 31th epoch : 0.07921660243178398  Training Accuracy:0.8831521739130435\n",
            "368/4708 - The training loss at 31th epoch : 0.07860890794702269  Training Accuracy:0.8828125\n",
            "384/4708 - The training loss at 31th epoch : 0.07732159289108541  Training Accuracy:0.885\n",
            "400/4708 - The training loss at 31th epoch : 0.07759669797629654  Training Accuracy:0.8846153846153846\n",
            "416/4708 - The training loss at 31th epoch : 0.07962611931307402  Training Accuracy:0.8842592592592593\n",
            "432/4708 - The training loss at 31th epoch : 0.07796106382654729  Training Accuracy:0.8883928571428571\n",
            "448/4708 - The training loss at 31th epoch : 0.07921290231867249  Training Accuracy:0.8857758620689655\n",
            "464/4708 - The training loss at 31th epoch : 0.078163088941218  Training Accuracy:0.8875\n",
            "480/4708 - The training loss at 31th epoch : 0.07816205977788192  Training Accuracy:0.8891129032258065\n",
            "496/4708 - The training loss at 31th epoch : 0.076107359605026  Training Accuracy:0.892578125\n",
            "512/4708 - The training loss at 31th epoch : 0.07506022190469291  Training Accuracy:0.8939393939393939\n",
            "528/4708 - The training loss at 31th epoch : 0.07806102447812757  Training Accuracy:0.8915441176470589\n",
            "544/4708 - The training loss at 31th epoch : 0.07963240926119536  Training Accuracy:0.8892857142857142\n",
            "560/4708 - The training loss at 31th epoch : 0.07917554090095785  Training Accuracy:0.890625\n",
            "576/4708 - The training loss at 31th epoch : 0.07812277119316234  Training Accuracy:0.8918918918918919\n",
            "592/4708 - The training loss at 31th epoch : 0.0771181915374684  Training Accuracy:0.8930921052631579\n",
            "608/4708 - The training loss at 31th epoch : 0.07993323732629667  Training Accuracy:0.8910256410256411\n",
            "624/4708 - The training loss at 31th epoch : 0.08067817381346594  Training Accuracy:0.890625\n",
            "640/4708 - The training loss at 31th epoch : 0.07889855697093522  Training Accuracy:0.8932926829268293\n",
            "656/4708 - The training loss at 31th epoch : 0.07734597864116963  Training Accuracy:0.8958333333333334\n",
            "672/4708 - The training loss at 31th epoch : 0.07855765254897693  Training Accuracy:0.8938953488372093\n",
            "688/4708 - The training loss at 31th epoch : 0.07709819677180868  Training Accuracy:0.8963068181818182\n",
            "704/4708 - The training loss at 31th epoch : 0.07666865261870895  Training Accuracy:0.8972222222222223\n",
            "720/4708 - The training loss at 31th epoch : 0.07730652784207778  Training Accuracy:0.8953804347826086\n",
            "736/4708 - The training loss at 31th epoch : 0.07767370713962397  Training Accuracy:0.8949468085106383\n",
            "752/4708 - The training loss at 31th epoch : 0.0772960857695744  Training Accuracy:0.8958333333333334\n",
            "768/4708 - The training loss at 31th epoch : 0.07878384825228615  Training Accuracy:0.8941326530612245\n",
            "784/4708 - The training loss at 31th epoch : 0.07980156965189701  Training Accuracy:0.89125\n",
            "800/4708 - The training loss at 31th epoch : 0.0797489911933247  Training Accuracy:0.8909313725490197\n",
            "816/4708 - The training loss at 31th epoch : 0.07920528639264236  Training Accuracy:0.8918269230769231\n",
            "832/4708 - The training loss at 31th epoch : 0.07927206196620475  Training Accuracy:0.8926886792452831\n",
            "848/4708 - The training loss at 31th epoch : 0.08035091740279532  Training Accuracy:0.8912037037037037\n",
            "864/4708 - The training loss at 31th epoch : 0.07998001473775447  Training Accuracy:0.8909090909090909\n",
            "880/4708 - The training loss at 31th epoch : 0.0814029881678006  Training Accuracy:0.8895089285714286\n",
            "896/4708 - The training loss at 31th epoch : 0.08269702107577462  Training Accuracy:0.8881578947368421\n",
            "912/4708 - The training loss at 31th epoch : 0.08218791749335845  Training Accuracy:0.8890086206896551\n",
            "928/4708 - The training loss at 31th epoch : 0.0814436370387181  Training Accuracy:0.8908898305084746\n",
            "944/4708 - The training loss at 31th epoch : 0.0819917597427706  Training Accuracy:0.8895833333333333\n",
            "960/4708 - The training loss at 31th epoch : 0.08093786766960914  Training Accuracy:0.8913934426229508\n",
            "976/4708 - The training loss at 31th epoch : 0.08107088385043461  Training Accuracy:0.8911290322580645\n",
            "992/4708 - The training loss at 31th epoch : 0.08043854776131142  Training Accuracy:0.8918650793650794\n",
            "1008/4708 - The training loss at 31th epoch : 0.08115245514685104  Training Accuracy:0.8916015625\n",
            "1024/4708 - The training loss at 31th epoch : 0.08001686963011942  Training Accuracy:0.8932692307692308\n",
            "1040/4708 - The training loss at 31th epoch : 0.08033252384388966  Training Accuracy:0.8929924242424242\n",
            "1056/4708 - The training loss at 31th epoch : 0.08016677135053843  Training Accuracy:0.8936567164179104\n",
            "1072/4708 - The training loss at 31th epoch : 0.07973745086891001  Training Accuracy:0.8933823529411765\n",
            "1088/4708 - The training loss at 31th epoch : 0.08007322723375035  Training Accuracy:0.8931159420289855\n",
            "1104/4708 - The training loss at 31th epoch : 0.08021933112957218  Training Accuracy:0.8928571428571429\n",
            "1120/4708 - The training loss at 31th epoch : 0.08036146466461981  Training Accuracy:0.8934859154929577\n",
            "1136/4708 - The training loss at 31th epoch : 0.0798507660231474  Training Accuracy:0.8940972222222222\n",
            "1152/4708 - The training loss at 31th epoch : 0.07926662637304768  Training Accuracy:0.8946917808219178\n",
            "1168/4708 - The training loss at 31th epoch : 0.07842030983919833  Training Accuracy:0.8961148648648649\n",
            "1184/4708 - The training loss at 31th epoch : 0.0793720426939398  Training Accuracy:0.8941666666666667\n",
            "1200/4708 - The training loss at 31th epoch : 0.08014071189899831  Training Accuracy:0.8930921052631579\n",
            "1216/4708 - The training loss at 31th epoch : 0.08005642517246778  Training Accuracy:0.8928571428571429\n",
            "1232/4708 - The training loss at 31th epoch : 0.0809318330196962  Training Accuracy:0.8918269230769231\n",
            "1248/4708 - The training loss at 31th epoch : 0.08128304464993762  Training Accuracy:0.8916139240506329\n",
            "1264/4708 - The training loss at 31th epoch : 0.0816812449861267  Training Accuracy:0.890625\n",
            "1280/4708 - The training loss at 31th epoch : 0.0813207088908809  Training Accuracy:0.8912037037037037\n",
            "1296/4708 - The training loss at 31th epoch : 0.08098083244559265  Training Accuracy:0.8917682926829268\n",
            "1312/4708 - The training loss at 31th epoch : 0.08040969551551809  Training Accuracy:0.8923192771084337\n",
            "1328/4708 - The training loss at 31th epoch : 0.08123703905766005  Training Accuracy:0.8913690476190477\n",
            "1344/4708 - The training loss at 31th epoch : 0.0808058948059139  Training Accuracy:0.8911764705882353\n",
            "1360/4708 - The training loss at 31th epoch : 0.08006156694762664  Training Accuracy:0.8924418604651163\n",
            "1376/4708 - The training loss at 31th epoch : 0.07928729951447254  Training Accuracy:0.8936781609195402\n",
            "1392/4708 - The training loss at 31th epoch : 0.07942426449260123  Training Accuracy:0.8941761363636364\n",
            "1408/4708 - The training loss at 31th epoch : 0.07968769244413265  Training Accuracy:0.8932584269662921\n",
            "1424/4708 - The training loss at 31th epoch : 0.07951459493108835  Training Accuracy:0.89375\n",
            "1440/4708 - The training loss at 31th epoch : 0.07911665975719914  Training Accuracy:0.8942307692307693\n",
            "1456/4708 - The training loss at 31th epoch : 0.07918950955933753  Training Accuracy:0.8940217391304348\n",
            "1472/4708 - The training loss at 31th epoch : 0.08012497252907201  Training Accuracy:0.8924731182795699\n",
            "1488/4708 - The training loss at 31th epoch : 0.0801769076488637  Training Accuracy:0.8922872340425532\n",
            "1504/4708 - The training loss at 31th epoch : 0.07966086828597047  Training Accuracy:0.8927631578947368\n",
            "1520/4708 - The training loss at 31th epoch : 0.08065473138353046  Training Accuracy:0.890625\n",
            "1536/4708 - The training loss at 31th epoch : 0.08147722753199253  Training Accuracy:0.8898195876288659\n",
            "1552/4708 - The training loss at 31th epoch : 0.08079555039266413  Training Accuracy:0.8909438775510204\n",
            "1568/4708 - The training loss at 31th epoch : 0.08058686463312746  Training Accuracy:0.8914141414141414\n",
            "1584/4708 - The training loss at 31th epoch : 0.08085596871517377  Training Accuracy:0.890625\n",
            "1600/4708 - The training loss at 31th epoch : 0.08089880601374333  Training Accuracy:0.8898514851485149\n",
            "1616/4708 - The training loss at 31th epoch : 0.0805993012078091  Training Accuracy:0.8903186274509803\n",
            "1632/4708 - The training loss at 31th epoch : 0.0806588245814501  Training Accuracy:0.8901699029126213\n",
            "1648/4708 - The training loss at 31th epoch : 0.08076871167337277  Training Accuracy:0.8894230769230769\n",
            "1664/4708 - The training loss at 31th epoch : 0.0810212427519333  Training Accuracy:0.8892857142857142\n",
            "1680/4708 - The training loss at 31th epoch : 0.08125793365342718  Training Accuracy:0.8891509433962265\n",
            "1696/4708 - The training loss at 31th epoch : 0.08206845768714761  Training Accuracy:0.8884345794392523\n",
            "1712/4708 - The training loss at 31th epoch : 0.08191629204689678  Training Accuracy:0.8888888888888888\n",
            "1728/4708 - The training loss at 31th epoch : 0.08207839723963789  Training Accuracy:0.8881880733944955\n",
            "1744/4708 - The training loss at 31th epoch : 0.08251556838403674  Training Accuracy:0.8875\n",
            "1760/4708 - The training loss at 31th epoch : 0.08212265039691347  Training Accuracy:0.8879504504504504\n",
            "1776/4708 - The training loss at 31th epoch : 0.08178432991988674  Training Accuracy:0.8883928571428571\n",
            "1792/4708 - The training loss at 31th epoch : 0.08111839073335514  Training Accuracy:0.8893805309734514\n",
            "1808/4708 - The training loss at 31th epoch : 0.08068105023163481  Training Accuracy:0.8898026315789473\n",
            "1824/4708 - The training loss at 31th epoch : 0.0808052889442039  Training Accuracy:0.8902173913043478\n",
            "1840/4708 - The training loss at 31th epoch : 0.08117801922634128  Training Accuracy:0.8900862068965517\n",
            "1856/4708 - The training loss at 31th epoch : 0.08087055527452999  Training Accuracy:0.8904914529914529\n",
            "1872/4708 - The training loss at 31th epoch : 0.08063873046548907  Training Accuracy:0.8908898305084746\n",
            "1888/4708 - The training loss at 31th epoch : 0.08065618464743671  Training Accuracy:0.8907563025210085\n",
            "1904/4708 - The training loss at 31th epoch : 0.08003330945228737  Training Accuracy:0.8916666666666667\n",
            "1920/4708 - The training loss at 31th epoch : 0.07963746053927473  Training Accuracy:0.8920454545454546\n",
            "1936/4708 - The training loss at 31th epoch : 0.07939392832395681  Training Accuracy:0.8924180327868853\n",
            "1952/4708 - The training loss at 31th epoch : 0.07917887861202653  Training Accuracy:0.8927845528455285\n",
            "1968/4708 - The training loss at 31th epoch : 0.08040786520599931  Training Accuracy:0.890625\n",
            "1984/4708 - The training loss at 31th epoch : 0.08035394153502141  Training Accuracy:0.891\n",
            "2000/4708 - The training loss at 31th epoch : 0.08001654772042899  Training Accuracy:0.8918650793650794\n",
            "2016/4708 - The training loss at 31th epoch : 0.08056270867558663  Training Accuracy:0.8912401574803149\n",
            "2032/4708 - The training loss at 31th epoch : 0.08072153670081558  Training Accuracy:0.89111328125\n",
            "2048/4708 - The training loss at 31th epoch : 0.08097095581562593  Training Accuracy:0.8909883720930233\n",
            "2064/4708 - The training loss at 31th epoch : 0.08072374497072458  Training Accuracy:0.8908653846153847\n",
            "2080/4708 - The training loss at 31th epoch : 0.08111314861649833  Training Accuracy:0.8902671755725191\n",
            "2096/4708 - The training loss at 31th epoch : 0.08144213282261102  Training Accuracy:0.8896780303030303\n",
            "2112/4708 - The training loss at 31th epoch : 0.08165612105380772  Training Accuracy:0.8895676691729323\n",
            "2128/4708 - The training loss at 31th epoch : 0.08151209740145224  Training Accuracy:0.8894589552238806\n",
            "2144/4708 - The training loss at 31th epoch : 0.08143320937071379  Training Accuracy:0.8898148148148148\n",
            "2160/4708 - The training loss at 31th epoch : 0.08158088681959708  Training Accuracy:0.8897058823529411\n",
            "2176/4708 - The training loss at 31th epoch : 0.08142707458937697  Training Accuracy:0.8900547445255474\n",
            "2192/4708 - The training loss at 31th epoch : 0.08119087115306825  Training Accuracy:0.8899456521739131\n",
            "2208/4708 - The training loss at 31th epoch : 0.08125568108443361  Training Accuracy:0.8893884892086331\n",
            "2224/4708 - The training loss at 31th epoch : 0.08144722962156149  Training Accuracy:0.8892857142857142\n",
            "2240/4708 - The training loss at 31th epoch : 0.08107447576219808  Training Accuracy:0.8900709219858156\n",
            "2256/4708 - The training loss at 31th epoch : 0.08094042836840515  Training Accuracy:0.8904049295774648\n",
            "2272/4708 - The training loss at 31th epoch : 0.08040319575050914  Training Accuracy:0.8911713286713286\n",
            "2288/4708 - The training loss at 31th epoch : 0.08063087642341463  Training Accuracy:0.8910590277777778\n",
            "2304/4708 - The training loss at 31th epoch : 0.08019549101428021  Training Accuracy:0.8918103448275863\n",
            "2320/4708 - The training loss at 31th epoch : 0.07971481814419615  Training Accuracy:0.8925513698630136\n",
            "2336/4708 - The training loss at 31th epoch : 0.08046277802992391  Training Accuracy:0.891156462585034\n",
            "2352/4708 - The training loss at 31th epoch : 0.08065373807660954  Training Accuracy:0.8902027027027027\n",
            "2368/4708 - The training loss at 31th epoch : 0.08057805090332068  Training Accuracy:0.8901006711409396\n",
            "2384/4708 - The training loss at 31th epoch : 0.08120156268302836  Training Accuracy:0.8895833333333333\n",
            "2400/4708 - The training loss at 31th epoch : 0.08116213322833844  Training Accuracy:0.8894867549668874\n",
            "2416/4708 - The training loss at 31th epoch : 0.0810576156682599  Training Accuracy:0.8898026315789473\n",
            "2432/4708 - The training loss at 31th epoch : 0.08117509832184792  Training Accuracy:0.8897058823529411\n",
            "2448/4708 - The training loss at 31th epoch : 0.08124608142004872  Training Accuracy:0.8892045454545454\n",
            "2464/4708 - The training loss at 31th epoch : 0.08147365041429014  Training Accuracy:0.8891129032258065\n",
            "2480/4708 - The training loss at 31th epoch : 0.0810694740746337  Training Accuracy:0.889823717948718\n",
            "2496/4708 - The training loss at 31th epoch : 0.08064844756412522  Training Accuracy:0.8905254777070064\n",
            "2512/4708 - The training loss at 31th epoch : 0.08020343622327196  Training Accuracy:0.8912183544303798\n",
            "2528/4708 - The training loss at 31th epoch : 0.08055138605363316  Training Accuracy:0.8911163522012578\n",
            "2544/4708 - The training loss at 31th epoch : 0.08015338733425566  Training Accuracy:0.891796875\n",
            "2560/4708 - The training loss at 31th epoch : 0.08029834377875855  Training Accuracy:0.8916925465838509\n",
            "2576/4708 - The training loss at 31th epoch : 0.08001960465210999  Training Accuracy:0.8919753086419753\n",
            "2592/4708 - The training loss at 31th epoch : 0.08074324862396859  Training Accuracy:0.8911042944785276\n",
            "2608/4708 - The training loss at 31th epoch : 0.08059514153804939  Training Accuracy:0.8913871951219512\n",
            "2624/4708 - The training loss at 31th epoch : 0.08088335533827788  Training Accuracy:0.890530303030303\n",
            "2640/4708 - The training loss at 31th epoch : 0.08049879870258711  Training Accuracy:0.8911897590361446\n",
            "2656/4708 - The training loss at 31th epoch : 0.08096308264899182  Training Accuracy:0.8907185628742516\n",
            "2672/4708 - The training loss at 31th epoch : 0.08108247468961746  Training Accuracy:0.890625\n",
            "2688/4708 - The training loss at 31th epoch : 0.08154004684953613  Training Accuracy:0.889792899408284\n",
            "2704/4708 - The training loss at 31th epoch : 0.08164994461892992  Training Accuracy:0.8897058823529411\n",
            "2720/4708 - The training loss at 31th epoch : 0.08160404174388886  Training Accuracy:0.889985380116959\n",
            "2736/4708 - The training loss at 31th epoch : 0.08158551494815791  Training Accuracy:0.8902616279069767\n",
            "2752/4708 - The training loss at 31th epoch : 0.08155122660797393  Training Accuracy:0.8905346820809249\n",
            "2768/4708 - The training loss at 31th epoch : 0.08173745861850315  Training Accuracy:0.8900862068965517\n",
            "2784/4708 - The training loss at 31th epoch : 0.08175702977254826  Training Accuracy:0.89\n",
            "2800/4708 - The training loss at 31th epoch : 0.0815274695481247  Training Accuracy:0.8902698863636364\n",
            "2816/4708 - The training loss at 31th epoch : 0.08194734639777257  Training Accuracy:0.8898305084745762\n",
            "2832/4708 - The training loss at 31th epoch : 0.0819275323568797  Training Accuracy:0.8893960674157303\n",
            "2848/4708 - The training loss at 31th epoch : 0.08221193296345915  Training Accuracy:0.8889664804469274\n",
            "2864/4708 - The training loss at 31th epoch : 0.08215408705272126  Training Accuracy:0.8892361111111111\n",
            "2880/4708 - The training loss at 31th epoch : 0.08205743308740654  Training Accuracy:0.8895027624309392\n",
            "2896/4708 - The training loss at 31th epoch : 0.08208725245522563  Training Accuracy:0.8894230769230769\n",
            "2912/4708 - The training loss at 31th epoch : 0.08261487000311203  Training Accuracy:0.8890027322404371\n",
            "2928/4708 - The training loss at 31th epoch : 0.08247039231106615  Training Accuracy:0.889266304347826\n",
            "2944/4708 - The training loss at 31th epoch : 0.08265468354847384  Training Accuracy:0.8891891891891892\n",
            "2960/4708 - The training loss at 31th epoch : 0.0825843311931001  Training Accuracy:0.8894489247311828\n",
            "2976/4708 - The training loss at 31th epoch : 0.08259234905552149  Training Accuracy:0.8893716577540107\n",
            "2992/4708 - The training loss at 31th epoch : 0.08233714516135306  Training Accuracy:0.8896276595744681\n",
            "3008/4708 - The training loss at 31th epoch : 0.0824360744194286  Training Accuracy:0.8895502645502645\n",
            "3024/4708 - The training loss at 31th epoch : 0.0822455251225145  Training Accuracy:0.8894736842105263\n",
            "3040/4708 - The training loss at 31th epoch : 0.08193344439909897  Training Accuracy:0.8900523560209425\n",
            "3056/4708 - The training loss at 31th epoch : 0.08189747538028526  Training Accuracy:0.8899739583333334\n",
            "3072/4708 - The training loss at 31th epoch : 0.0815796276272434  Training Accuracy:0.8905440414507773\n",
            "3088/4708 - The training loss at 31th epoch : 0.08141149706542743  Training Accuracy:0.8907860824742269\n",
            "3104/4708 - The training loss at 31th epoch : 0.08110480651731329  Training Accuracy:0.8910256410256411\n",
            "3120/4708 - The training loss at 31th epoch : 0.08086262918804725  Training Accuracy:0.8915816326530612\n",
            "3136/4708 - The training loss at 31th epoch : 0.08054270088130776  Training Accuracy:0.8921319796954315\n",
            "3152/4708 - The training loss at 31th epoch : 0.08062064333815615  Training Accuracy:0.891729797979798\n",
            "3168/4708 - The training loss at 31th epoch : 0.08028458318004696  Training Accuracy:0.8922738693467337\n",
            "3184/4708 - The training loss at 31th epoch : 0.07995315733710716  Training Accuracy:0.8928125\n",
            "3200/4708 - The training loss at 31th epoch : 0.07963418999425162  Training Accuracy:0.8933457711442786\n",
            "3216/4708 - The training loss at 31th epoch : 0.07932994742153919  Training Accuracy:0.8938737623762376\n",
            "3232/4708 - The training loss at 31th epoch : 0.08001949982156463  Training Accuracy:0.8928571428571429\n",
            "3248/4708 - The training loss at 31th epoch : 0.07979793999978546  Training Accuracy:0.8930759803921569\n",
            "3264/4708 - The training loss at 31th epoch : 0.07966169530632315  Training Accuracy:0.8929878048780487\n",
            "3280/4708 - The training loss at 31th epoch : 0.07960424945350991  Training Accuracy:0.8932038834951457\n",
            "3296/4708 - The training loss at 31th epoch : 0.07956924968977465  Training Accuracy:0.8931159420289855\n",
            "3312/4708 - The training loss at 31th epoch : 0.0799545594483804  Training Accuracy:0.8927283653846154\n",
            "3328/4708 - The training loss at 31th epoch : 0.08012345612159097  Training Accuracy:0.8926435406698564\n",
            "3344/4708 - The training loss at 31th epoch : 0.08024706872217166  Training Accuracy:0.8925595238095239\n",
            "3360/4708 - The training loss at 31th epoch : 0.08046622940821713  Training Accuracy:0.8921800947867299\n",
            "3376/4708 - The training loss at 31th epoch : 0.08019493673026377  Training Accuracy:0.8926886792452831\n",
            "3392/4708 - The training loss at 31th epoch : 0.07991076998048731  Training Accuracy:0.8931924882629108\n",
            "3408/4708 - The training loss at 31th epoch : 0.07964535515767028  Training Accuracy:0.8936915887850467\n",
            "3424/4708 - The training loss at 31th epoch : 0.07999273267336582  Training Accuracy:0.8930232558139535\n",
            "3440/4708 - The training loss at 31th epoch : 0.07969173519703203  Training Accuracy:0.8935185185185185\n",
            "3456/4708 - The training loss at 31th epoch : 0.07993159335111155  Training Accuracy:0.8931451612903226\n",
            "3472/4708 - The training loss at 31th epoch : 0.08001966499396845  Training Accuracy:0.8930619266055045\n",
            "3488/4708 - The training loss at 31th epoch : 0.08020087946041025  Training Accuracy:0.8929794520547946\n",
            "3504/4708 - The training loss at 31th epoch : 0.07991212678012569  Training Accuracy:0.8934659090909091\n",
            "3520/4708 - The training loss at 31th epoch : 0.0799435486906343  Training Accuracy:0.8933823529411765\n",
            "3536/4708 - The training loss at 31th epoch : 0.08031616496055612  Training Accuracy:0.8930180180180181\n",
            "3552/4708 - The training loss at 31th epoch : 0.0800083136840674  Training Accuracy:0.8934977578475336\n",
            "3568/4708 - The training loss at 31th epoch : 0.08018530584724425  Training Accuracy:0.8931361607142857\n",
            "3584/4708 - The training loss at 31th epoch : 0.08001290165642565  Training Accuracy:0.8933333333333333\n",
            "3600/4708 - The training loss at 31th epoch : 0.07993799792872654  Training Accuracy:0.8932522123893806\n",
            "3616/4708 - The training loss at 31th epoch : 0.08055973887600006  Training Accuracy:0.8926211453744494\n",
            "3632/4708 - The training loss at 31th epoch : 0.0803320062333176  Training Accuracy:0.8930921052631579\n",
            "3648/4708 - The training loss at 31th epoch : 0.08023531435285093  Training Accuracy:0.8932860262008734\n",
            "3664/4708 - The training loss at 31th epoch : 0.0799529138080469  Training Accuracy:0.89375\n",
            "3680/4708 - The training loss at 31th epoch : 0.07975118182350396  Training Accuracy:0.8939393939393939\n",
            "3696/4708 - The training loss at 31th epoch : 0.08001868877807145  Training Accuracy:0.8935883620689655\n",
            "3712/4708 - The training loss at 31th epoch : 0.08007977567884302  Training Accuracy:0.8935085836909872\n",
            "3728/4708 - The training loss at 31th epoch : 0.08019744445820197  Training Accuracy:0.8934294871794872\n",
            "3744/4708 - The training loss at 31th epoch : 0.07995721592058062  Training Accuracy:0.8938829787234043\n",
            "3760/4708 - The training loss at 31th epoch : 0.08006911242193669  Training Accuracy:0.893802966101695\n",
            "3776/4708 - The training loss at 31th epoch : 0.07979935195672037  Training Accuracy:0.8942510548523207\n",
            "3792/4708 - The training loss at 31th epoch : 0.0798903460885485  Training Accuracy:0.8939075630252101\n",
            "3808/4708 - The training loss at 31th epoch : 0.07996033847069886  Training Accuracy:0.8935669456066946\n",
            "3824/4708 - The training loss at 31th epoch : 0.0799025256780717  Training Accuracy:0.89375\n",
            "3840/4708 - The training loss at 31th epoch : 0.08039582089489984  Training Accuracy:0.8931535269709544\n",
            "3856/4708 - The training loss at 31th epoch : 0.08072961415915426  Training Accuracy:0.8923037190082644\n",
            "3872/4708 - The training loss at 31th epoch : 0.08066431780057058  Training Accuracy:0.8924897119341564\n",
            "3888/4708 - The training loss at 31th epoch : 0.08075929083169607  Training Accuracy:0.8921618852459017\n",
            "3904/4708 - The training loss at 31th epoch : 0.08074508960760386  Training Accuracy:0.8923469387755102\n",
            "3920/4708 - The training loss at 31th epoch : 0.08049109407146465  Training Accuracy:0.8927845528455285\n",
            "3936/4708 - The training loss at 31th epoch : 0.08036075831788109  Training Accuracy:0.8929655870445344\n",
            "3952/4708 - The training loss at 31th epoch : 0.08020333659476472  Training Accuracy:0.8931451612903226\n",
            "3968/4708 - The training loss at 31th epoch : 0.08006977588223331  Training Accuracy:0.8933232931726908\n",
            "3984/4708 - The training loss at 31th epoch : 0.08002137021644308  Training Accuracy:0.8935\n",
            "4000/4708 - The training loss at 31th epoch : 0.07984874925992361  Training Accuracy:0.8939243027888446\n",
            "4016/4708 - The training loss at 31th epoch : 0.07987914722699602  Training Accuracy:0.8940972222222222\n",
            "4032/4708 - The training loss at 31th epoch : 0.07980622321394638  Training Accuracy:0.8942687747035574\n",
            "4048/4708 - The training loss at 31th epoch : 0.07994889733783314  Training Accuracy:0.8939468503937008\n",
            "4064/4708 - The training loss at 31th epoch : 0.07995852974916777  Training Accuracy:0.8938725490196079\n",
            "4080/4708 - The training loss at 31th epoch : 0.0799036793004259  Training Accuracy:0.893798828125\n",
            "4096/4708 - The training loss at 31th epoch : 0.08013618959753878  Training Accuracy:0.8934824902723736\n",
            "4112/4708 - The training loss at 31th epoch : 0.08013120830189792  Training Accuracy:0.8931686046511628\n",
            "4128/4708 - The training loss at 31th epoch : 0.07991089133368702  Training Accuracy:0.893581081081081\n",
            "4144/4708 - The training loss at 31th epoch : 0.07990402274164068  Training Accuracy:0.8935096153846154\n",
            "4160/4708 - The training loss at 31th epoch : 0.07990885049185709  Training Accuracy:0.8936781609195402\n",
            "4176/4708 - The training loss at 31th epoch : 0.07976357545218471  Training Accuracy:0.8940839694656488\n",
            "4192/4708 - The training loss at 31th epoch : 0.07957972733483365  Training Accuracy:0.8942490494296578\n",
            "4208/4708 - The training loss at 31th epoch : 0.07962398006984395  Training Accuracy:0.8939393939393939\n",
            "4224/4708 - The training loss at 31th epoch : 0.07935978158008772  Training Accuracy:0.8943396226415095\n",
            "4240/4708 - The training loss at 31th epoch : 0.07931276882003695  Training Accuracy:0.894266917293233\n",
            "4256/4708 - The training loss at 31th epoch : 0.07912930412420222  Training Accuracy:0.8944288389513109\n",
            "4272/4708 - The training loss at 31th epoch : 0.07894632946760355  Training Accuracy:0.8948227611940298\n",
            "4288/4708 - The training loss at 31th epoch : 0.07877678806380468  Training Accuracy:0.8949814126394052\n",
            "4304/4708 - The training loss at 31th epoch : 0.07860083594522294  Training Accuracy:0.8951388888888889\n",
            "4320/4708 - The training loss at 31th epoch : 0.07858340465191074  Training Accuracy:0.8950645756457565\n",
            "4336/4708 - The training loss at 31th epoch : 0.07888157593155938  Training Accuracy:0.8947610294117647\n",
            "4352/4708 - The training loss at 31th epoch : 0.07904299256899772  Training Accuracy:0.8942307692307693\n",
            "4368/4708 - The training loss at 31th epoch : 0.07917156520010468  Training Accuracy:0.8939324817518248\n",
            "4384/4708 - The training loss at 31th epoch : 0.07927324351429607  Training Accuracy:0.8938636363636364\n",
            "4400/4708 - The training loss at 31th epoch : 0.07947744385477665  Training Accuracy:0.8937952898550725\n",
            "4416/4708 - The training loss at 31th epoch : 0.0793624545582981  Training Accuracy:0.8939530685920578\n",
            "4432/4708 - The training loss at 31th epoch : 0.07911172465132563  Training Accuracy:0.8943345323741008\n",
            "4448/4708 - The training loss at 31th epoch : 0.0793502091770821  Training Accuracy:0.8938172043010753\n",
            "4464/4708 - The training loss at 31th epoch : 0.07948476260006677  Training Accuracy:0.8933035714285714\n",
            "4480/4708 - The training loss at 31th epoch : 0.07933235015523532  Training Accuracy:0.8934608540925267\n",
            "4496/4708 - The training loss at 31th epoch : 0.0791329093753146  Training Accuracy:0.8936170212765957\n",
            "4512/4708 - The training loss at 31th epoch : 0.07893400934481126  Training Accuracy:0.8939929328621908\n",
            "4528/4708 - The training loss at 31th epoch : 0.07889181094983727  Training Accuracy:0.8939260563380281\n",
            "4544/4708 - The training loss at 31th epoch : 0.07870507869587737  Training Accuracy:0.894298245614035\n",
            "4560/4708 - The training loss at 31th epoch : 0.07865473795958258  Training Accuracy:0.8942307692307693\n",
            "4576/4708 - The training loss at 31th epoch : 0.0785644473994754  Training Accuracy:0.894163763066202\n",
            "4592/4708 - The training loss at 31th epoch : 0.07853385322532604  Training Accuracy:0.8943142361111112\n",
            "4608/4708 - The training loss at 31th epoch : 0.07858468315047669  Training Accuracy:0.8942474048442907\n",
            "4624/4708 - The training loss at 31th epoch : 0.07839742270040348  Training Accuracy:0.8943965517241379\n",
            "4640/4708 - The training loss at 31th epoch : 0.07828104734363772  Training Accuracy:0.8945446735395189\n",
            "4656/4708 - The training loss at 31th epoch : 0.07847009703795853  Training Accuracy:0.894263698630137\n",
            "4672/4708 - The training loss at 31th epoch : 0.07853556836403319  Training Accuracy:0.89419795221843\n",
            "4688/4708 - The training loss at 31th epoch : 0.07863033838796019  Training Accuracy:0.8941326530612245\n",
            "4704/4708 - The training loss at 31th epoch : 0.07868674479789678  Training Accuracy:0.8938559322033899\n",
            "4720/4708 - The training loss at 31th epoch : 0.07856937470282337  Training Accuracy:0.8940033783783784\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 32th epoch : 0.1624083190155918  Training Accuracy:0.8125\n",
            "16/4708 - The training loss at 32th epoch : 0.1185789274132676  Training Accuracy:0.875\n",
            "32/4708 - The training loss at 32th epoch : 0.09361738024555272  Training Accuracy:0.8958333333333334\n",
            "48/4708 - The training loss at 32th epoch : 0.0931746773172003  Training Accuracy:0.890625\n",
            "64/4708 - The training loss at 32th epoch : 0.0906710906388005  Training Accuracy:0.9\n",
            "80/4708 - The training loss at 32th epoch : 0.0936492634860961  Training Accuracy:0.8854166666666666\n",
            "96/4708 - The training loss at 32th epoch : 0.10240141390899349  Training Accuracy:0.8660714285714286\n",
            "112/4708 - The training loss at 32th epoch : 0.11224741823531315  Training Accuracy:0.8515625\n",
            "128/4708 - The training loss at 32th epoch : 0.10656133415670806  Training Accuracy:0.8541666666666666\n",
            "144/4708 - The training loss at 32th epoch : 0.10412802143078599  Training Accuracy:0.85625\n",
            "160/4708 - The training loss at 32th epoch : 0.1059805942965591  Training Accuracy:0.8522727272727273\n",
            "176/4708 - The training loss at 32th epoch : 0.10791843489200025  Training Accuracy:0.8489583333333334\n",
            "192/4708 - The training loss at 32th epoch : 0.10307499280957556  Training Accuracy:0.8605769230769231\n",
            "208/4708 - The training loss at 32th epoch : 0.10241875335263916  Training Accuracy:0.8571428571428571\n",
            "224/4708 - The training loss at 32th epoch : 0.10532167176515171  Training Accuracy:0.8541666666666666\n",
            "240/4708 - The training loss at 32th epoch : 0.10955986828986981  Training Accuracy:0.84765625\n",
            "256/4708 - The training loss at 32th epoch : 0.10399815467452125  Training Accuracy:0.8566176470588235\n",
            "272/4708 - The training loss at 32th epoch : 0.10234627753604747  Training Accuracy:0.8576388888888888\n",
            "288/4708 - The training loss at 32th epoch : 0.10084787615414767  Training Accuracy:0.8585526315789473\n",
            "304/4708 - The training loss at 32th epoch : 0.09686501538733303  Training Accuracy:0.865625\n",
            "320/4708 - The training loss at 32th epoch : 0.10010390969066917  Training Accuracy:0.8630952380952381\n",
            "336/4708 - The training loss at 32th epoch : 0.10547987870963262  Training Accuracy:0.8551136363636364\n",
            "352/4708 - The training loss at 32th epoch : 0.10407768705778929  Training Accuracy:0.8586956521739131\n",
            "368/4708 - The training loss at 32th epoch : 0.10074503312981785  Training Accuracy:0.8645833333333334\n",
            "384/4708 - The training loss at 32th epoch : 0.0993689998470378  Training Accuracy:0.865\n",
            "400/4708 - The training loss at 32th epoch : 0.09674926290775863  Training Accuracy:0.8677884615384616\n",
            "416/4708 - The training loss at 32th epoch : 0.10145181254943363  Training Accuracy:0.8634259259259259\n",
            "432/4708 - The training loss at 32th epoch : 0.098978118465311  Training Accuracy:0.8683035714285714\n",
            "448/4708 - The training loss at 32th epoch : 0.09888178217170442  Training Accuracy:0.8663793103448276\n",
            "464/4708 - The training loss at 32th epoch : 0.09679478585186406  Training Accuracy:0.86875\n",
            "480/4708 - The training loss at 32th epoch : 0.09465187964068644  Training Accuracy:0.8709677419354839\n",
            "496/4708 - The training loss at 32th epoch : 0.09496614295579395  Training Accuracy:0.87109375\n",
            "512/4708 - The training loss at 32th epoch : 0.09791670381439027  Training Accuracy:0.865530303030303\n",
            "528/4708 - The training loss at 32th epoch : 0.09827864659930798  Training Accuracy:0.8639705882352942\n",
            "544/4708 - The training loss at 32th epoch : 0.09735460190715094  Training Accuracy:0.8642857142857143\n",
            "560/4708 - The training loss at 32th epoch : 0.09742744236562391  Training Accuracy:0.8645833333333334\n",
            "576/4708 - The training loss at 32th epoch : 0.09627051712131071  Training Accuracy:0.8665540540540541\n",
            "592/4708 - The training loss at 32th epoch : 0.09534327275652171  Training Accuracy:0.8667763157894737\n",
            "608/4708 - The training loss at 32th epoch : 0.09501972278738638  Training Accuracy:0.8669871794871795\n",
            "624/4708 - The training loss at 32th epoch : 0.09442584197487466  Training Accuracy:0.86875\n",
            "640/4708 - The training loss at 32th epoch : 0.09240785609806187  Training Accuracy:0.8719512195121951\n",
            "656/4708 - The training loss at 32th epoch : 0.09199688311084138  Training Accuracy:0.8735119047619048\n",
            "672/4708 - The training loss at 32th epoch : 0.08986667750583366  Training Accuracy:0.876453488372093\n",
            "688/4708 - The training loss at 32th epoch : 0.09008900113372881  Training Accuracy:0.8764204545454546\n",
            "704/4708 - The training loss at 32th epoch : 0.0895829005058802  Training Accuracy:0.8777777777777778\n",
            "720/4708 - The training loss at 32th epoch : 0.08985570352316119  Training Accuracy:0.876358695652174\n",
            "736/4708 - The training loss at 32th epoch : 0.08872348498173831  Training Accuracy:0.8776595744680851\n",
            "752/4708 - The training loss at 32th epoch : 0.08718173187916843  Training Accuracy:0.8802083333333334\n",
            "768/4708 - The training loss at 32th epoch : 0.08673083720646874  Training Accuracy:0.8813775510204082\n",
            "784/4708 - The training loss at 32th epoch : 0.08617972658293431  Training Accuracy:0.88125\n",
            "800/4708 - The training loss at 32th epoch : 0.08906333196843039  Training Accuracy:0.8774509803921569\n",
            "816/4708 - The training loss at 32th epoch : 0.0893454251073586  Training Accuracy:0.8774038461538461\n",
            "832/4708 - The training loss at 32th epoch : 0.0891461384497096  Training Accuracy:0.8785377358490566\n",
            "848/4708 - The training loss at 32th epoch : 0.08934199604407883  Training Accuracy:0.8784722222222222\n",
            "864/4708 - The training loss at 32th epoch : 0.08912200028365765  Training Accuracy:0.8795454545454545\n",
            "880/4708 - The training loss at 32th epoch : 0.08898014163567468  Training Accuracy:0.8794642857142857\n",
            "896/4708 - The training loss at 32th epoch : 0.08948061107427198  Training Accuracy:0.8782894736842105\n",
            "912/4708 - The training loss at 32th epoch : 0.09024920096458244  Training Accuracy:0.8782327586206896\n",
            "928/4708 - The training loss at 32th epoch : 0.09072298332466856  Training Accuracy:0.878177966101695\n",
            "944/4708 - The training loss at 32th epoch : 0.08968678244481561  Training Accuracy:0.8791666666666667\n",
            "960/4708 - The training loss at 32th epoch : 0.08879942819046571  Training Accuracy:0.8801229508196722\n",
            "976/4708 - The training loss at 32th epoch : 0.08968095795187814  Training Accuracy:0.8800403225806451\n",
            "992/4708 - The training loss at 32th epoch : 0.09031965268155062  Training Accuracy:0.8799603174603174\n",
            "1008/4708 - The training loss at 32th epoch : 0.08907965415649964  Training Accuracy:0.8818359375\n",
            "1024/4708 - The training loss at 32th epoch : 0.08904209992003777  Training Accuracy:0.8817307692307692\n",
            "1040/4708 - The training loss at 32th epoch : 0.08891460456265725  Training Accuracy:0.8816287878787878\n",
            "1056/4708 - The training loss at 32th epoch : 0.08845869821726872  Training Accuracy:0.8824626865671642\n",
            "1072/4708 - The training loss at 32th epoch : 0.0873610720852647  Training Accuracy:0.8841911764705882\n",
            "1088/4708 - The training loss at 32th epoch : 0.08720910587262806  Training Accuracy:0.884963768115942\n",
            "1104/4708 - The training loss at 32th epoch : 0.08764682522734583  Training Accuracy:0.8848214285714285\n",
            "1120/4708 - The training loss at 32th epoch : 0.08747232558642988  Training Accuracy:0.8855633802816901\n",
            "1136/4708 - The training loss at 32th epoch : 0.0876297204161302  Training Accuracy:0.8854166666666666\n",
            "1152/4708 - The training loss at 32th epoch : 0.08734959071118946  Training Accuracy:0.8861301369863014\n",
            "1168/4708 - The training loss at 32th epoch : 0.0864888865221283  Training Accuracy:0.8868243243243243\n",
            "1184/4708 - The training loss at 32th epoch : 0.08619426711915286  Training Accuracy:0.8875\n",
            "1200/4708 - The training loss at 32th epoch : 0.08531395727384977  Training Accuracy:0.8889802631578947\n",
            "1216/4708 - The training loss at 32th epoch : 0.08454345482552003  Training Accuracy:0.890422077922078\n",
            "1232/4708 - The training loss at 32th epoch : 0.08599348679698038  Training Accuracy:0.8878205128205128\n",
            "1248/4708 - The training loss at 32th epoch : 0.08572193653358538  Training Accuracy:0.8884493670886076\n",
            "1264/4708 - The training loss at 32th epoch : 0.08622235339152876  Training Accuracy:0.8875\n",
            "1280/4708 - The training loss at 32th epoch : 0.08562943012930332  Training Accuracy:0.8881172839506173\n",
            "1296/4708 - The training loss at 32th epoch : 0.08603901279093444  Training Accuracy:0.8879573170731707\n",
            "1312/4708 - The training loss at 32th epoch : 0.08561493578276808  Training Accuracy:0.8885542168674698\n",
            "1328/4708 - The training loss at 32th epoch : 0.08562263618919509  Training Accuracy:0.8883928571428571\n",
            "1344/4708 - The training loss at 32th epoch : 0.0853785265248758  Training Accuracy:0.8889705882352941\n",
            "1360/4708 - The training loss at 32th epoch : 0.08526386928172336  Training Accuracy:0.8895348837209303\n",
            "1376/4708 - The training loss at 32th epoch : 0.08543452632408134  Training Accuracy:0.889367816091954\n",
            "1392/4708 - The training loss at 32th epoch : 0.08572954714766781  Training Accuracy:0.8884943181818182\n",
            "1408/4708 - The training loss at 32th epoch : 0.0855671388050161  Training Accuracy:0.8883426966292135\n",
            "1424/4708 - The training loss at 32th epoch : 0.08486745036846714  Training Accuracy:0.8895833333333333\n",
            "1440/4708 - The training loss at 32th epoch : 0.08493654244429275  Training Accuracy:0.8901098901098901\n",
            "1456/4708 - The training loss at 32th epoch : 0.08446366798071757  Training Accuracy:0.890625\n",
            "1472/4708 - The training loss at 32th epoch : 0.08506243887925409  Training Accuracy:0.8897849462365591\n",
            "1488/4708 - The training loss at 32th epoch : 0.08499023837420143  Training Accuracy:0.8902925531914894\n",
            "1504/4708 - The training loss at 32th epoch : 0.08591430604340622  Training Accuracy:0.8894736842105263\n",
            "1520/4708 - The training loss at 32th epoch : 0.08514890870518733  Training Accuracy:0.890625\n",
            "1536/4708 - The training loss at 32th epoch : 0.08466294157484096  Training Accuracy:0.8911082474226805\n",
            "1552/4708 - The training loss at 32th epoch : 0.08494196979309329  Training Accuracy:0.8909438775510204\n",
            "1568/4708 - The training loss at 32th epoch : 0.08538321059190081  Training Accuracy:0.8901515151515151\n",
            "1584/4708 - The training loss at 32th epoch : 0.08532334998997529  Training Accuracy:0.89\n",
            "1600/4708 - The training loss at 32th epoch : 0.08535611954857641  Training Accuracy:0.8892326732673267\n",
            "1616/4708 - The training loss at 32th epoch : 0.08549611029521109  Training Accuracy:0.8884803921568627\n",
            "1632/4708 - The training loss at 32th epoch : 0.08542392745247232  Training Accuracy:0.8889563106796117\n",
            "1648/4708 - The training loss at 32th epoch : 0.08535898878695149  Training Accuracy:0.8888221153846154\n",
            "1664/4708 - The training loss at 32th epoch : 0.08607701160344373  Training Accuracy:0.8875\n",
            "1680/4708 - The training loss at 32th epoch : 0.08596411486616712  Training Accuracy:0.8879716981132075\n",
            "1696/4708 - The training loss at 32th epoch : 0.08588555042187086  Training Accuracy:0.8878504672897196\n",
            "1712/4708 - The training loss at 32th epoch : 0.08524948931404355  Training Accuracy:0.8888888888888888\n",
            "1728/4708 - The training loss at 32th epoch : 0.08479089887056647  Training Accuracy:0.8899082568807339\n",
            "1744/4708 - The training loss at 32th epoch : 0.08455501302088064  Training Accuracy:0.8903409090909091\n",
            "1760/4708 - The training loss at 32th epoch : 0.08391870823356307  Training Accuracy:0.8913288288288288\n",
            "1776/4708 - The training loss at 32th epoch : 0.08337837775852489  Training Accuracy:0.8922991071428571\n",
            "1792/4708 - The training loss at 32th epoch : 0.08320296932820452  Training Accuracy:0.8926991150442478\n",
            "1808/4708 - The training loss at 32th epoch : 0.0825729548131672  Training Accuracy:0.893640350877193\n",
            "1824/4708 - The training loss at 32th epoch : 0.08195511503600504  Training Accuracy:0.8945652173913043\n",
            "1840/4708 - The training loss at 32th epoch : 0.0814534265782299  Training Accuracy:0.8954741379310345\n",
            "1856/4708 - The training loss at 32th epoch : 0.08135239279892534  Training Accuracy:0.8958333333333334\n",
            "1872/4708 - The training loss at 32th epoch : 0.08146395100926142  Training Accuracy:0.895656779661017\n",
            "1888/4708 - The training loss at 32th epoch : 0.08141644074482102  Training Accuracy:0.8949579831932774\n",
            "1904/4708 - The training loss at 32th epoch : 0.08086723315714354  Training Accuracy:0.8958333333333334\n",
            "1920/4708 - The training loss at 32th epoch : 0.08128462261277063  Training Accuracy:0.8951446280991735\n",
            "1936/4708 - The training loss at 32th epoch : 0.08153004204544637  Training Accuracy:0.8949795081967213\n",
            "1952/4708 - The training loss at 32th epoch : 0.08194642356581741  Training Accuracy:0.8948170731707317\n",
            "1968/4708 - The training loss at 32th epoch : 0.08184746393554149  Training Accuracy:0.8946572580645161\n",
            "1984/4708 - The training loss at 32th epoch : 0.08145151510145501  Training Accuracy:0.895\n",
            "2000/4708 - The training loss at 32th epoch : 0.08165623962107586  Training Accuracy:0.8948412698412699\n",
            "2016/4708 - The training loss at 32th epoch : 0.08112318444636805  Training Accuracy:0.8956692913385826\n",
            "2032/4708 - The training loss at 32th epoch : 0.0807396541314837  Training Accuracy:0.89599609375\n",
            "2048/4708 - The training loss at 32th epoch : 0.08042906795414904  Training Accuracy:0.8963178294573644\n",
            "2064/4708 - The training loss at 32th epoch : 0.08053506359000841  Training Accuracy:0.8961538461538462\n",
            "2080/4708 - The training loss at 32th epoch : 0.08062520597757554  Training Accuracy:0.8959923664122137\n",
            "2096/4708 - The training loss at 32th epoch : 0.0800769369828887  Training Accuracy:0.896780303030303\n",
            "2112/4708 - The training loss at 32th epoch : 0.08056750658758695  Training Accuracy:0.8961466165413534\n",
            "2128/4708 - The training loss at 32th epoch : 0.08139171548644551  Training Accuracy:0.8950559701492538\n",
            "2144/4708 - The training loss at 32th epoch : 0.08099819826091256  Training Accuracy:0.8953703703703704\n",
            "2160/4708 - The training loss at 32th epoch : 0.08052059598472411  Training Accuracy:0.8961397058823529\n",
            "2176/4708 - The training loss at 32th epoch : 0.080347645090057  Training Accuracy:0.896441605839416\n",
            "2192/4708 - The training loss at 32th epoch : 0.0805900505012691  Training Accuracy:0.896286231884058\n",
            "2208/4708 - The training loss at 32th epoch : 0.08091965595250725  Training Accuracy:0.8961330935251799\n",
            "2224/4708 - The training loss at 32th epoch : 0.08104873779340668  Training Accuracy:0.8959821428571428\n",
            "2240/4708 - The training loss at 32th epoch : 0.08081451937510557  Training Accuracy:0.8962765957446809\n",
            "2256/4708 - The training loss at 32th epoch : 0.08128857225077553  Training Accuracy:0.8952464788732394\n",
            "2272/4708 - The training loss at 32th epoch : 0.0808018944133207  Training Accuracy:0.8959790209790209\n",
            "2288/4708 - The training loss at 32th epoch : 0.08051745186338492  Training Accuracy:0.8962673611111112\n",
            "2304/4708 - The training loss at 32th epoch : 0.08025367576487594  Training Accuracy:0.896551724137931\n",
            "2320/4708 - The training loss at 32th epoch : 0.08063089176959727  Training Accuracy:0.8955479452054794\n",
            "2336/4708 - The training loss at 32th epoch : 0.08049727016968031  Training Accuracy:0.8958333333333334\n",
            "2352/4708 - The training loss at 32th epoch : 0.08034176794584895  Training Accuracy:0.8961148648648649\n",
            "2368/4708 - The training loss at 32th epoch : 0.08048037503052276  Training Accuracy:0.8959731543624161\n",
            "2384/4708 - The training loss at 32th epoch : 0.08033169143778407  Training Accuracy:0.8958333333333334\n",
            "2400/4708 - The training loss at 32th epoch : 0.07990182208150413  Training Accuracy:0.8965231788079471\n",
            "2416/4708 - The training loss at 32th epoch : 0.07952597205531313  Training Accuracy:0.8967927631578947\n",
            "2432/4708 - The training loss at 32th epoch : 0.07915459894788487  Training Accuracy:0.8970588235294118\n",
            "2448/4708 - The training loss at 32th epoch : 0.07877701669583602  Training Accuracy:0.8977272727272727\n",
            "2464/4708 - The training loss at 32th epoch : 0.0791837920890516  Training Accuracy:0.896774193548387\n",
            "2480/4708 - The training loss at 32th epoch : 0.07914331200884846  Training Accuracy:0.8970352564102564\n",
            "2496/4708 - The training loss at 32th epoch : 0.07888077337063924  Training Accuracy:0.8972929936305732\n",
            "2512/4708 - The training loss at 32th epoch : 0.07926239186800724  Training Accuracy:0.8971518987341772\n",
            "2528/4708 - The training loss at 32th epoch : 0.07894433714620518  Training Accuracy:0.8977987421383647\n",
            "2544/4708 - The training loss at 32th epoch : 0.07968626291133726  Training Accuracy:0.896875\n",
            "2560/4708 - The training loss at 32th epoch : 0.0803512153972848  Training Accuracy:0.8955745341614907\n",
            "2576/4708 - The training loss at 32th epoch : 0.08026599884802606  Training Accuracy:0.8958333333333334\n",
            "2592/4708 - The training loss at 32th epoch : 0.08054661036785508  Training Accuracy:0.8957055214723927\n",
            "2608/4708 - The training loss at 32th epoch : 0.08027443450336529  Training Accuracy:0.8959603658536586\n",
            "2624/4708 - The training loss at 32th epoch : 0.08019759411045982  Training Accuracy:0.8958333333333334\n",
            "2640/4708 - The training loss at 32th epoch : 0.08035267594545696  Training Accuracy:0.8957078313253012\n",
            "2656/4708 - The training loss at 32th epoch : 0.08091961255853594  Training Accuracy:0.8952095808383234\n",
            "2672/4708 - The training loss at 32th epoch : 0.08049625686861331  Training Accuracy:0.8958333333333334\n",
            "2688/4708 - The training loss at 32th epoch : 0.08063613915531721  Training Accuracy:0.8953402366863905\n",
            "2704/4708 - The training loss at 32th epoch : 0.08081103487957161  Training Accuracy:0.8952205882352942\n",
            "2720/4708 - The training loss at 32th epoch : 0.08035896032277788  Training Accuracy:0.8958333333333334\n",
            "2736/4708 - The training loss at 32th epoch : 0.08069136888085825  Training Accuracy:0.8957122093023255\n",
            "2752/4708 - The training loss at 32th epoch : 0.08059129799026965  Training Accuracy:0.895592485549133\n",
            "2768/4708 - The training loss at 32th epoch : 0.08042616979568404  Training Accuracy:0.8958333333333334\n",
            "2784/4708 - The training loss at 32th epoch : 0.0808221611193526  Training Accuracy:0.8957142857142857\n",
            "2800/4708 - The training loss at 32th epoch : 0.08102642623637658  Training Accuracy:0.8955965909090909\n",
            "2816/4708 - The training loss at 32th epoch : 0.08108298657678527  Training Accuracy:0.8958333333333334\n",
            "2832/4708 - The training loss at 32th epoch : 0.08094072307208611  Training Accuracy:0.8957162921348315\n",
            "2848/4708 - The training loss at 32th epoch : 0.08093332367627086  Training Accuracy:0.8956005586592178\n",
            "2864/4708 - The training loss at 32th epoch : 0.08100380260648274  Training Accuracy:0.8954861111111111\n",
            "2880/4708 - The training loss at 32th epoch : 0.08091981431467786  Training Accuracy:0.8957182320441989\n",
            "2896/4708 - The training loss at 32th epoch : 0.08065453337389598  Training Accuracy:0.8959478021978022\n",
            "2912/4708 - The training loss at 32th epoch : 0.08054327387245981  Training Accuracy:0.8958333333333334\n",
            "2928/4708 - The training loss at 32th epoch : 0.0805694712546858  Training Accuracy:0.8957201086956522\n",
            "2944/4708 - The training loss at 32th epoch : 0.0804980834120661  Training Accuracy:0.8952702702702703\n",
            "2960/4708 - The training loss at 32th epoch : 0.08044344132072476  Training Accuracy:0.895497311827957\n",
            "2976/4708 - The training loss at 32th epoch : 0.08045637357132016  Training Accuracy:0.8957219251336899\n",
            "2992/4708 - The training loss at 32th epoch : 0.08024043928522716  Training Accuracy:0.8959441489361702\n",
            "3008/4708 - The training loss at 32th epoch : 0.08005975138395674  Training Accuracy:0.8961640211640212\n",
            "3024/4708 - The training loss at 32th epoch : 0.07966483850619613  Training Accuracy:0.8967105263157895\n",
            "3040/4708 - The training loss at 32th epoch : 0.07956315487992137  Training Accuracy:0.8969240837696335\n",
            "3056/4708 - The training loss at 32th epoch : 0.07994696764933577  Training Accuracy:0.8958333333333334\n",
            "3072/4708 - The training loss at 32th epoch : 0.07982337334223115  Training Accuracy:0.8960492227979274\n",
            "3088/4708 - The training loss at 32th epoch : 0.07982204228350744  Training Accuracy:0.8962628865979382\n",
            "3104/4708 - The training loss at 32th epoch : 0.07972053387609943  Training Accuracy:0.8961538461538462\n",
            "3120/4708 - The training loss at 32th epoch : 0.07962706363545168  Training Accuracy:0.8963647959183674\n",
            "3136/4708 - The training loss at 32th epoch : 0.07954725829132966  Training Accuracy:0.8965736040609137\n",
            "3152/4708 - The training loss at 32th epoch : 0.07938133517088759  Training Accuracy:0.896780303030303\n",
            "3168/4708 - The training loss at 32th epoch : 0.07984812424609233  Training Accuracy:0.8963567839195979\n",
            "3184/4708 - The training loss at 32th epoch : 0.07960752137032094  Training Accuracy:0.8965625\n",
            "3200/4708 - The training loss at 32th epoch : 0.07931050723577736  Training Accuracy:0.8970771144278606\n",
            "3216/4708 - The training loss at 32th epoch : 0.07951167283887435  Training Accuracy:0.8966584158415841\n",
            "3232/4708 - The training loss at 32th epoch : 0.07975729378373661  Training Accuracy:0.895935960591133\n",
            "3248/4708 - The training loss at 32th epoch : 0.07985188304637851  Training Accuracy:0.8961397058823529\n",
            "3264/4708 - The training loss at 32th epoch : 0.07998420022964506  Training Accuracy:0.8954268292682926\n",
            "3280/4708 - The training loss at 32th epoch : 0.08024223244527261  Training Accuracy:0.8947208737864077\n",
            "3296/4708 - The training loss at 32th epoch : 0.08042826736798275  Training Accuracy:0.8943236714975845\n",
            "3312/4708 - The training loss at 32th epoch : 0.0804486216230362  Training Accuracy:0.8939302884615384\n",
            "3328/4708 - The training loss at 32th epoch : 0.08027468164354999  Training Accuracy:0.8941387559808612\n",
            "3344/4708 - The training loss at 32th epoch : 0.08025898729694611  Training Accuracy:0.8943452380952381\n",
            "3360/4708 - The training loss at 32th epoch : 0.08022771238617944  Training Accuracy:0.8945497630331753\n",
            "3376/4708 - The training loss at 32th epoch : 0.0802940759163599  Training Accuracy:0.8944575471698113\n",
            "3392/4708 - The training loss at 32th epoch : 0.08003176537339493  Training Accuracy:0.8946596244131455\n",
            "3408/4708 - The training loss at 32th epoch : 0.0801334841780167  Training Accuracy:0.8942757009345794\n",
            "3424/4708 - The training loss at 32th epoch : 0.0806317057393617  Training Accuracy:0.8938953488372093\n",
            "3440/4708 - The training loss at 32th epoch : 0.08050186081381339  Training Accuracy:0.8938078703703703\n",
            "3456/4708 - The training loss at 32th epoch : 0.0803332917516035  Training Accuracy:0.8942972350230415\n",
            "3472/4708 - The training loss at 32th epoch : 0.08008730775717406  Training Accuracy:0.8944954128440367\n",
            "3488/4708 - The training loss at 32th epoch : 0.08029157751706584  Training Accuracy:0.894406392694064\n",
            "3504/4708 - The training loss at 32th epoch : 0.08002848944471473  Training Accuracy:0.8946022727272728\n",
            "3520/4708 - The training loss at 32th epoch : 0.0800013812531572  Training Accuracy:0.8945135746606335\n",
            "3536/4708 - The training loss at 32th epoch : 0.08013189921251283  Training Accuracy:0.8941441441441441\n",
            "3552/4708 - The training loss at 32th epoch : 0.07993792728089036  Training Accuracy:0.8943385650224215\n",
            "3568/4708 - The training loss at 32th epoch : 0.07976402810722001  Training Accuracy:0.8942522321428571\n",
            "3584/4708 - The training loss at 32th epoch : 0.07986503058695932  Training Accuracy:0.8938888888888888\n",
            "3600/4708 - The training loss at 32th epoch : 0.07976797412615651  Training Accuracy:0.8938053097345132\n",
            "3616/4708 - The training loss at 32th epoch : 0.07983542656729016  Training Accuracy:0.8937224669603524\n",
            "3632/4708 - The training loss at 32th epoch : 0.07976592999779351  Training Accuracy:0.893640350877193\n",
            "3648/4708 - The training loss at 32th epoch : 0.07964706298683796  Training Accuracy:0.8935589519650655\n",
            "3664/4708 - The training loss at 32th epoch : 0.07985275626100119  Training Accuracy:0.8932065217391304\n",
            "3680/4708 - The training loss at 32th epoch : 0.07989611128306663  Training Accuracy:0.8931277056277056\n",
            "3696/4708 - The training loss at 32th epoch : 0.07980517263177213  Training Accuracy:0.8933189655172413\n",
            "3712/4708 - The training loss at 32th epoch : 0.07988165785154733  Training Accuracy:0.8932403433476395\n",
            "3728/4708 - The training loss at 32th epoch : 0.07992926624231582  Training Accuracy:0.8934294871794872\n",
            "3744/4708 - The training loss at 32th epoch : 0.08002210224344793  Training Accuracy:0.8930851063829788\n",
            "3760/4708 - The training loss at 32th epoch : 0.08013726299199161  Training Accuracy:0.8927436440677966\n",
            "3776/4708 - The training loss at 32th epoch : 0.07984518085235648  Training Accuracy:0.8931962025316456\n",
            "3792/4708 - The training loss at 32th epoch : 0.07969714052722982  Training Accuracy:0.8933823529411765\n",
            "3808/4708 - The training loss at 32th epoch : 0.07951306669249483  Training Accuracy:0.8938284518828452\n",
            "3824/4708 - The training loss at 32th epoch : 0.07952854025157596  Training Accuracy:0.89375\n",
            "3840/4708 - The training loss at 32th epoch : 0.079374679850113  Training Accuracy:0.8939315352697096\n",
            "3856/4708 - The training loss at 32th epoch : 0.07922639775915115  Training Accuracy:0.8941115702479339\n",
            "3872/4708 - The training loss at 32th epoch : 0.07905828696504162  Training Accuracy:0.8942901234567902\n",
            "3888/4708 - The training loss at 32th epoch : 0.07899257956695266  Training Accuracy:0.8944672131147541\n",
            "3904/4708 - The training loss at 32th epoch : 0.07887525448593814  Training Accuracy:0.8948979591836734\n",
            "3920/4708 - The training loss at 32th epoch : 0.07888292286047488  Training Accuracy:0.8950711382113821\n",
            "3936/4708 - The training loss at 32th epoch : 0.07879981097672992  Training Accuracy:0.895242914979757\n",
            "3952/4708 - The training loss at 32th epoch : 0.07868320627936948  Training Accuracy:0.8956653225806451\n",
            "3968/4708 - The training loss at 32th epoch : 0.07845269840365587  Training Accuracy:0.8960843373493976\n",
            "3984/4708 - The training loss at 32th epoch : 0.07854413149349157  Training Accuracy:0.896\n",
            "4000/4708 - The training loss at 32th epoch : 0.07869278884569544  Training Accuracy:0.8956673306772909\n",
            "4016/4708 - The training loss at 32th epoch : 0.07852212868301142  Training Accuracy:0.8958333333333334\n",
            "4032/4708 - The training loss at 32th epoch : 0.07871639918017317  Training Accuracy:0.8955039525691699\n",
            "4048/4708 - The training loss at 32th epoch : 0.07853579338584304  Training Accuracy:0.8956692913385826\n",
            "4064/4708 - The training loss at 32th epoch : 0.07847341331566995  Training Accuracy:0.8958333333333334\n",
            "4080/4708 - The training loss at 32th epoch : 0.0784872804567675  Training Accuracy:0.895751953125\n",
            "4096/4708 - The training loss at 32th epoch : 0.07835945050221921  Training Accuracy:0.8959143968871596\n",
            "4112/4708 - The training loss at 32th epoch : 0.07830580544473008  Training Accuracy:0.8960755813953488\n",
            "4128/4708 - The training loss at 32th epoch : 0.07862828542668966  Training Accuracy:0.895511583011583\n",
            "4144/4708 - The training loss at 32th epoch : 0.07844430738299579  Training Accuracy:0.895673076923077\n",
            "4160/4708 - The training loss at 32th epoch : 0.07852448456898366  Training Accuracy:0.8955938697318008\n",
            "4176/4708 - The training loss at 32th epoch : 0.07847436901794363  Training Accuracy:0.8957538167938931\n",
            "4192/4708 - The training loss at 32th epoch : 0.07836042573659315  Training Accuracy:0.8956749049429658\n",
            "4208/4708 - The training loss at 32th epoch : 0.07869920902555154  Training Accuracy:0.8951231060606061\n",
            "4224/4708 - The training loss at 32th epoch : 0.07863032285910969  Training Accuracy:0.8950471698113207\n",
            "4240/4708 - The training loss at 32th epoch : 0.07838177766158307  Training Accuracy:0.8954417293233082\n",
            "4256/4708 - The training loss at 32th epoch : 0.07818434629677178  Training Accuracy:0.8955992509363296\n",
            "4272/4708 - The training loss at 32th epoch : 0.07821870333078257  Training Accuracy:0.8955223880597015\n",
            "4288/4708 - The training loss at 32th epoch : 0.07805327208065599  Training Accuracy:0.89567843866171\n",
            "4304/4708 - The training loss at 32th epoch : 0.07800148617118607  Training Accuracy:0.8958333333333334\n",
            "4320/4708 - The training loss at 32th epoch : 0.07801748031179835  Training Accuracy:0.8959870848708487\n",
            "4336/4708 - The training loss at 32th epoch : 0.07782177141725485  Training Accuracy:0.8963694852941176\n",
            "4352/4708 - The training loss at 32th epoch : 0.07795970374567468  Training Accuracy:0.8958333333333334\n",
            "4368/4708 - The training loss at 32th epoch : 0.07816784494825452  Training Accuracy:0.895529197080292\n",
            "4384/4708 - The training loss at 32th epoch : 0.07808293219745105  Training Accuracy:0.8956818181818181\n",
            "4400/4708 - The training loss at 32th epoch : 0.07838230004614041  Training Accuracy:0.8951539855072463\n",
            "4416/4708 - The training loss at 32th epoch : 0.07819670283939209  Training Accuracy:0.8955324909747292\n",
            "4432/4708 - The training loss at 32th epoch : 0.07821934236748439  Training Accuracy:0.8954586330935251\n",
            "4448/4708 - The training loss at 32th epoch : 0.07850694470186619  Training Accuracy:0.8951612903225806\n",
            "4464/4708 - The training loss at 32th epoch : 0.07855767523734974  Training Accuracy:0.8948660714285714\n",
            "4480/4708 - The training loss at 32th epoch : 0.07878486925141927  Training Accuracy:0.8947953736654805\n",
            "4496/4708 - The training loss at 32th epoch : 0.07888644308020279  Training Accuracy:0.8945035460992907\n",
            "4512/4708 - The training loss at 32th epoch : 0.07867243760336848  Training Accuracy:0.8948763250883393\n",
            "4528/4708 - The training loss at 32th epoch : 0.0788222219033261  Training Accuracy:0.8945862676056338\n",
            "4544/4708 - The training loss at 32th epoch : 0.07887553616441485  Training Accuracy:0.8947368421052632\n",
            "4560/4708 - The training loss at 32th epoch : 0.07922061583175748  Training Accuracy:0.8940122377622378\n",
            "4576/4708 - The training loss at 32th epoch : 0.07911388390318197  Training Accuracy:0.894163763066202\n",
            "4592/4708 - The training loss at 32th epoch : 0.07916146218434258  Training Accuracy:0.8940972222222222\n",
            "4608/4708 - The training loss at 32th epoch : 0.07925903921286337  Training Accuracy:0.8940311418685121\n",
            "4624/4708 - The training loss at 32th epoch : 0.07902422792996894  Training Accuracy:0.8943965517241379\n",
            "4640/4708 - The training loss at 32th epoch : 0.07907416708633949  Training Accuracy:0.8943298969072165\n",
            "4656/4708 - The training loss at 32th epoch : 0.07937781754196752  Training Accuracy:0.8938356164383562\n",
            "4672/4708 - The training loss at 32th epoch : 0.07938979175433278  Training Accuracy:0.8937713310580204\n",
            "4688/4708 - The training loss at 32th epoch : 0.07926619251609306  Training Accuracy:0.8939200680272109\n",
            "4704/4708 - The training loss at 32th epoch : 0.07951237092678753  Training Accuracy:0.8936440677966102\n",
            "4720/4708 - The training loss at 32th epoch : 0.07942454992850045  Training Accuracy:0.8937922297297297\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 33th epoch : 0.008693049164371348  Training Accuracy:1.0\n",
            "16/4708 - The training loss at 33th epoch : 0.007963752493531349  Training Accuracy:1.0\n",
            "32/4708 - The training loss at 33th epoch : 0.05966671720490583  Training Accuracy:0.8958333333333334\n",
            "48/4708 - The training loss at 33th epoch : 0.05044202732028564  Training Accuracy:0.90625\n",
            "64/4708 - The training loss at 33th epoch : 0.04410228540653412  Training Accuracy:0.925\n",
            "80/4708 - The training loss at 33th epoch : 0.0553238982303216  Training Accuracy:0.9166666666666666\n",
            "96/4708 - The training loss at 33th epoch : 0.050963133273004786  Training Accuracy:0.9196428571428571\n",
            "112/4708 - The training loss at 33th epoch : 0.04859935971426975  Training Accuracy:0.9296875\n",
            "128/4708 - The training loss at 33th epoch : 0.047305308597877155  Training Accuracy:0.9305555555555556\n",
            "144/4708 - The training loss at 33th epoch : 0.0511027998694016  Training Accuracy:0.93125\n",
            "160/4708 - The training loss at 33th epoch : 0.04703396926544388  Training Accuracy:0.9375\n",
            "176/4708 - The training loss at 33th epoch : 0.05019721576388078  Training Accuracy:0.9375\n",
            "192/4708 - The training loss at 33th epoch : 0.047388194338391205  Training Accuracy:0.9423076923076923\n",
            "208/4708 - The training loss at 33th epoch : 0.05144617190641543  Training Accuracy:0.9375\n",
            "224/4708 - The training loss at 33th epoch : 0.05470512168555473  Training Accuracy:0.9333333333333333\n",
            "240/4708 - The training loss at 33th epoch : 0.05672918942973095  Training Accuracy:0.9296875\n",
            "256/4708 - The training loss at 33th epoch : 0.06302143823100155  Training Accuracy:0.9227941176470589\n",
            "272/4708 - The training loss at 33th epoch : 0.06223701196244712  Training Accuracy:0.9236111111111112\n",
            "288/4708 - The training loss at 33th epoch : 0.06254570571901076  Training Accuracy:0.9243421052631579\n",
            "304/4708 - The training loss at 33th epoch : 0.06195369918349464  Training Accuracy:0.925\n",
            "320/4708 - The training loss at 33th epoch : 0.06021696403519775  Training Accuracy:0.9255952380952381\n",
            "336/4708 - The training loss at 33th epoch : 0.06036346016208718  Training Accuracy:0.9261363636363636\n",
            "352/4708 - The training loss at 33th epoch : 0.06529324972663834  Training Accuracy:0.9157608695652174\n",
            "368/4708 - The training loss at 33th epoch : 0.06362882226510014  Training Accuracy:0.9192708333333334\n",
            "384/4708 - The training loss at 33th epoch : 0.06287722840498493  Training Accuracy:0.92\n",
            "400/4708 - The training loss at 33th epoch : 0.060813527211055304  Training Accuracy:0.9230769230769231\n",
            "416/4708 - The training loss at 33th epoch : 0.0615505057865454  Training Accuracy:0.9212962962962963\n",
            "432/4708 - The training loss at 33th epoch : 0.06494923005024761  Training Accuracy:0.9151785714285714\n",
            "448/4708 - The training loss at 33th epoch : 0.06429954243614436  Training Accuracy:0.915948275862069\n",
            "464/4708 - The training loss at 33th epoch : 0.06765974894740549  Training Accuracy:0.9083333333333333\n",
            "480/4708 - The training loss at 33th epoch : 0.06719957609009769  Training Accuracy:0.9092741935483871\n",
            "496/4708 - The training loss at 33th epoch : 0.06731048636266063  Training Accuracy:0.908203125\n",
            "512/4708 - The training loss at 33th epoch : 0.06670924871504468  Training Accuracy:0.9090909090909091\n",
            "528/4708 - The training loss at 33th epoch : 0.06540286436975812  Training Accuracy:0.9117647058823529\n",
            "544/4708 - The training loss at 33th epoch : 0.06577388488807386  Training Accuracy:0.9125\n",
            "560/4708 - The training loss at 33th epoch : 0.06461103227490621  Training Accuracy:0.9131944444444444\n",
            "576/4708 - The training loss at 33th epoch : 0.06373945231941507  Training Accuracy:0.9155405405405406\n",
            "592/4708 - The training loss at 33th epoch : 0.06454058406334175  Training Accuracy:0.9144736842105263\n",
            "608/4708 - The training loss at 33th epoch : 0.06693670288591969  Training Accuracy:0.9102564102564102\n",
            "624/4708 - The training loss at 33th epoch : 0.06727913703775826  Training Accuracy:0.909375\n",
            "640/4708 - The training loss at 33th epoch : 0.06623645146384134  Training Accuracy:0.9115853658536586\n",
            "656/4708 - The training loss at 33th epoch : 0.06727479655374324  Training Accuracy:0.9092261904761905\n",
            "672/4708 - The training loss at 33th epoch : 0.06688963469807732  Training Accuracy:0.9098837209302325\n",
            "688/4708 - The training loss at 33th epoch : 0.06817257815037385  Training Accuracy:0.9076704545454546\n",
            "704/4708 - The training loss at 33th epoch : 0.06782977952303619  Training Accuracy:0.9069444444444444\n",
            "720/4708 - The training loss at 33th epoch : 0.06713541362399057  Training Accuracy:0.907608695652174\n",
            "736/4708 - The training loss at 33th epoch : 0.06811318304724764  Training Accuracy:0.9055851063829787\n",
            "752/4708 - The training loss at 33th epoch : 0.06708123843457987  Training Accuracy:0.9075520833333334\n",
            "768/4708 - The training loss at 33th epoch : 0.06702774909010852  Training Accuracy:0.9068877551020408\n",
            "784/4708 - The training loss at 33th epoch : 0.06776203312282492  Training Accuracy:0.90625\n",
            "800/4708 - The training loss at 33th epoch : 0.0679552735751534  Training Accuracy:0.9068627450980392\n",
            "816/4708 - The training loss at 33th epoch : 0.0677967802794523  Training Accuracy:0.9074519230769231\n",
            "832/4708 - The training loss at 33th epoch : 0.06933987717268379  Training Accuracy:0.9044811320754716\n",
            "848/4708 - The training loss at 33th epoch : 0.06972166315154112  Training Accuracy:0.9050925925925926\n",
            "864/4708 - The training loss at 33th epoch : 0.06959422446524892  Training Accuracy:0.9045454545454545\n",
            "880/4708 - The training loss at 33th epoch : 0.07041443686523596  Training Accuracy:0.9029017857142857\n",
            "896/4708 - The training loss at 33th epoch : 0.06938741667465517  Training Accuracy:0.9046052631578947\n",
            "912/4708 - The training loss at 33th epoch : 0.06915717345816275  Training Accuracy:0.9051724137931034\n",
            "928/4708 - The training loss at 33th epoch : 0.07026490557831473  Training Accuracy:0.9036016949152542\n",
            "944/4708 - The training loss at 33th epoch : 0.06992012676931424  Training Accuracy:0.9041666666666667\n",
            "960/4708 - The training loss at 33th epoch : 0.07089140730595961  Training Accuracy:0.9026639344262295\n",
            "976/4708 - The training loss at 33th epoch : 0.07123058581454611  Training Accuracy:0.9022177419354839\n",
            "992/4708 - The training loss at 33th epoch : 0.07099871378132568  Training Accuracy:0.9027777777777778\n",
            "1008/4708 - The training loss at 33th epoch : 0.07046078676879516  Training Accuracy:0.9033203125\n",
            "1024/4708 - The training loss at 33th epoch : 0.07021249338350885  Training Accuracy:0.9038461538461539\n",
            "1040/4708 - The training loss at 33th epoch : 0.06970163946414337  Training Accuracy:0.9043560606060606\n",
            "1056/4708 - The training loss at 33th epoch : 0.07080223977783758  Training Accuracy:0.9029850746268657\n",
            "1072/4708 - The training loss at 33th epoch : 0.0706072375751561  Training Accuracy:0.9034926470588235\n",
            "1088/4708 - The training loss at 33th epoch : 0.06965559615609776  Training Accuracy:0.904891304347826\n",
            "1104/4708 - The training loss at 33th epoch : 0.06932740006194012  Training Accuracy:0.9053571428571429\n",
            "1120/4708 - The training loss at 33th epoch : 0.06896371921535223  Training Accuracy:0.9066901408450704\n",
            "1136/4708 - The training loss at 33th epoch : 0.06885258962665586  Training Accuracy:0.90625\n",
            "1152/4708 - The training loss at 33th epoch : 0.06924221502238484  Training Accuracy:0.9058219178082192\n",
            "1168/4708 - The training loss at 33th epoch : 0.06905109047092087  Training Accuracy:0.90625\n",
            "1184/4708 - The training loss at 33th epoch : 0.06924142456874866  Training Accuracy:0.9058333333333334\n",
            "1200/4708 - The training loss at 33th epoch : 0.06955478766101093  Training Accuracy:0.9054276315789473\n",
            "1216/4708 - The training loss at 33th epoch : 0.07066929286668225  Training Accuracy:0.9042207792207793\n",
            "1232/4708 - The training loss at 33th epoch : 0.07072523333202298  Training Accuracy:0.9038461538461539\n",
            "1248/4708 - The training loss at 33th epoch : 0.0704444239539795  Training Accuracy:0.9042721518987342\n",
            "1264/4708 - The training loss at 33th epoch : 0.06978651970072444  Training Accuracy:0.90546875\n",
            "1280/4708 - The training loss at 33th epoch : 0.0712238505314928  Training Accuracy:0.9027777777777778\n",
            "1296/4708 - The training loss at 33th epoch : 0.07136192239515593  Training Accuracy:0.9024390243902439\n",
            "1312/4708 - The training loss at 33th epoch : 0.07074050748338158  Training Accuracy:0.9036144578313253\n",
            "1328/4708 - The training loss at 33th epoch : 0.07061247861936601  Training Accuracy:0.9040178571428571\n",
            "1344/4708 - The training loss at 33th epoch : 0.07131460895752106  Training Accuracy:0.9036764705882353\n",
            "1360/4708 - The training loss at 33th epoch : 0.07322526477691212  Training Accuracy:0.9018895348837209\n",
            "1376/4708 - The training loss at 33th epoch : 0.07282401980731092  Training Accuracy:0.9022988505747126\n",
            "1392/4708 - The training loss at 33th epoch : 0.07340954394857807  Training Accuracy:0.9012784090909091\n",
            "1408/4708 - The training loss at 33th epoch : 0.0733038571812214  Training Accuracy:0.901685393258427\n",
            "1424/4708 - The training loss at 33th epoch : 0.07276371184984828  Training Accuracy:0.9027777777777778\n",
            "1440/4708 - The training loss at 33th epoch : 0.07201613124777506  Training Accuracy:0.9038461538461539\n",
            "1456/4708 - The training loss at 33th epoch : 0.0713407890923309  Training Accuracy:0.904891304347826\n",
            "1472/4708 - The training loss at 33th epoch : 0.07135291442327735  Training Accuracy:0.905241935483871\n",
            "1488/4708 - The training loss at 33th epoch : 0.07140773491932563  Training Accuracy:0.9049202127659575\n",
            "1504/4708 - The training loss at 33th epoch : 0.07112539577712058  Training Accuracy:0.9052631578947369\n",
            "1520/4708 - The training loss at 33th epoch : 0.07105568728756954  Training Accuracy:0.9055989583333334\n",
            "1536/4708 - The training loss at 33th epoch : 0.07057344783494988  Training Accuracy:0.9065721649484536\n",
            "1552/4708 - The training loss at 33th epoch : 0.07000710627500353  Training Accuracy:0.9075255102040817\n",
            "1568/4708 - The training loss at 33th epoch : 0.06955519228202678  Training Accuracy:0.9078282828282829\n",
            "1584/4708 - The training loss at 33th epoch : 0.06977013246008805  Training Accuracy:0.9075\n",
            "1600/4708 - The training loss at 33th epoch : 0.06919388653405047  Training Accuracy:0.9084158415841584\n",
            "1616/4708 - The training loss at 33th epoch : 0.06857291242412586  Training Accuracy:0.9093137254901961\n",
            "1632/4708 - The training loss at 33th epoch : 0.06853604961668266  Training Accuracy:0.9095873786407767\n",
            "1648/4708 - The training loss at 33th epoch : 0.06844456421983672  Training Accuracy:0.9098557692307693\n",
            "1664/4708 - The training loss at 33th epoch : 0.07011343410671785  Training Accuracy:0.9071428571428571\n",
            "1680/4708 - The training loss at 33th epoch : 0.06979710098643323  Training Accuracy:0.9074292452830188\n",
            "1696/4708 - The training loss at 33th epoch : 0.0696875607324594  Training Accuracy:0.9077102803738317\n",
            "1712/4708 - The training loss at 33th epoch : 0.07047806139966141  Training Accuracy:0.9068287037037037\n",
            "1728/4708 - The training loss at 33th epoch : 0.07098858534120885  Training Accuracy:0.9065366972477065\n",
            "1744/4708 - The training loss at 33th epoch : 0.0712488897265073  Training Accuracy:0.9056818181818181\n",
            "1760/4708 - The training loss at 33th epoch : 0.07157029076082867  Training Accuracy:0.9054054054054054\n",
            "1776/4708 - The training loss at 33th epoch : 0.0712145719986393  Training Accuracy:0.90625\n",
            "1792/4708 - The training loss at 33th epoch : 0.07100655091405982  Training Accuracy:0.9065265486725663\n",
            "1808/4708 - The training loss at 33th epoch : 0.07155625026235284  Training Accuracy:0.9051535087719298\n",
            "1824/4708 - The training loss at 33th epoch : 0.07127866621940389  Training Accuracy:0.904891304347826\n",
            "1840/4708 - The training loss at 33th epoch : 0.07141096414504088  Training Accuracy:0.9046336206896551\n",
            "1856/4708 - The training loss at 33th epoch : 0.07183979735703457  Training Accuracy:0.9038461538461539\n",
            "1872/4708 - The training loss at 33th epoch : 0.07201422599775724  Training Accuracy:0.9036016949152542\n",
            "1888/4708 - The training loss at 33th epoch : 0.0721875464597185  Training Accuracy:0.9033613445378151\n",
            "1904/4708 - The training loss at 33th epoch : 0.07164833982921201  Training Accuracy:0.9041666666666667\n",
            "1920/4708 - The training loss at 33th epoch : 0.07241860813561778  Training Accuracy:0.9028925619834711\n",
            "1936/4708 - The training loss at 33th epoch : 0.07200017339806003  Training Accuracy:0.9036885245901639\n",
            "1952/4708 - The training loss at 33th epoch : 0.07147768613688148  Training Accuracy:0.9044715447154471\n",
            "1968/4708 - The training loss at 33th epoch : 0.07168021806367898  Training Accuracy:0.9042338709677419\n",
            "1984/4708 - The training loss at 33th epoch : 0.07153835641721164  Training Accuracy:0.9045\n",
            "2000/4708 - The training loss at 33th epoch : 0.07150302347061188  Training Accuracy:0.904265873015873\n",
            "2016/4708 - The training loss at 33th epoch : 0.07163946883191437  Training Accuracy:0.9040354330708661\n",
            "2032/4708 - The training loss at 33th epoch : 0.07266623005497556  Training Accuracy:0.90234375\n",
            "2048/4708 - The training loss at 33th epoch : 0.07249765991090396  Training Accuracy:0.9026162790697675\n",
            "2064/4708 - The training loss at 33th epoch : 0.07266348826453489  Training Accuracy:0.9019230769230769\n",
            "2080/4708 - The training loss at 33th epoch : 0.07240629810130954  Training Accuracy:0.9021946564885496\n",
            "2096/4708 - The training loss at 33th epoch : 0.07227713218718394  Training Accuracy:0.9024621212121212\n",
            "2112/4708 - The training loss at 33th epoch : 0.07229758155619607  Training Accuracy:0.9027255639097744\n",
            "2128/4708 - The training loss at 33th epoch : 0.07196153654266105  Training Accuracy:0.9029850746268657\n",
            "2144/4708 - The training loss at 33th epoch : 0.07145260543300577  Training Accuracy:0.9037037037037037\n",
            "2160/4708 - The training loss at 33th epoch : 0.07144741747584232  Training Accuracy:0.9039522058823529\n",
            "2176/4708 - The training loss at 33th epoch : 0.07099524148862218  Training Accuracy:0.9046532846715328\n",
            "2192/4708 - The training loss at 33th epoch : 0.0710118226948932  Training Accuracy:0.904891304347826\n",
            "2208/4708 - The training loss at 33th epoch : 0.07140419806070747  Training Accuracy:0.904226618705036\n",
            "2224/4708 - The training loss at 33th epoch : 0.07236329923145693  Training Accuracy:0.9026785714285714\n",
            "2240/4708 - The training loss at 33th epoch : 0.07225334474673575  Training Accuracy:0.9029255319148937\n",
            "2256/4708 - The training loss at 33th epoch : 0.07199237819370237  Training Accuracy:0.903169014084507\n",
            "2272/4708 - The training loss at 33th epoch : 0.07216707573198193  Training Accuracy:0.902972027972028\n",
            "2288/4708 - The training loss at 33th epoch : 0.07231999006014478  Training Accuracy:0.9027777777777778\n",
            "2304/4708 - The training loss at 33th epoch : 0.07270455780794174  Training Accuracy:0.9025862068965518\n",
            "2320/4708 - The training loss at 33th epoch : 0.07327349231172965  Training Accuracy:0.901541095890411\n",
            "2336/4708 - The training loss at 33th epoch : 0.07386879667119932  Training Accuracy:0.9005102040816326\n",
            "2352/4708 - The training loss at 33th epoch : 0.07348479396307371  Training Accuracy:0.9011824324324325\n",
            "2368/4708 - The training loss at 33th epoch : 0.07380246330505108  Training Accuracy:0.9001677852348994\n",
            "2384/4708 - The training loss at 33th epoch : 0.07379557744471622  Training Accuracy:0.9004166666666666\n",
            "2400/4708 - The training loss at 33th epoch : 0.07433503279444445  Training Accuracy:0.8994205298013245\n",
            "2416/4708 - The training loss at 33th epoch : 0.07424098618610611  Training Accuracy:0.899671052631579\n",
            "2432/4708 - The training loss at 33th epoch : 0.0740901347640755  Training Accuracy:0.8999183006535948\n",
            "2448/4708 - The training loss at 33th epoch : 0.07392763863500464  Training Accuracy:0.9001623376623377\n",
            "2464/4708 - The training loss at 33th epoch : 0.07368473828929786  Training Accuracy:0.9004032258064516\n",
            "2480/4708 - The training loss at 33th epoch : 0.07365559906296112  Training Accuracy:0.9006410256410257\n",
            "2496/4708 - The training loss at 33th epoch : 0.07338616647556681  Training Accuracy:0.9012738853503185\n",
            "2512/4708 - The training loss at 33th epoch : 0.07340468316176749  Training Accuracy:0.9011075949367089\n",
            "2528/4708 - The training loss at 33th epoch : 0.07361261260835837  Training Accuracy:0.9009433962264151\n",
            "2544/4708 - The training loss at 33th epoch : 0.07386090838720696  Training Accuracy:0.90078125\n",
            "2560/4708 - The training loss at 33th epoch : 0.07354575349012399  Training Accuracy:0.9010093167701864\n",
            "2576/4708 - The training loss at 33th epoch : 0.07400765735459366  Training Accuracy:0.9004629629629629\n",
            "2592/4708 - The training loss at 33th epoch : 0.07423293671719641  Training Accuracy:0.8999233128834356\n",
            "2608/4708 - The training loss at 33th epoch : 0.07406605431796713  Training Accuracy:0.9001524390243902\n",
            "2624/4708 - The training loss at 33th epoch : 0.0739284880317705  Training Accuracy:0.9\n",
            "2640/4708 - The training loss at 33th epoch : 0.07374752426504315  Training Accuracy:0.9006024096385542\n",
            "2656/4708 - The training loss at 33th epoch : 0.07404872334890412  Training Accuracy:0.9000748502994012\n",
            "2672/4708 - The training loss at 33th epoch : 0.07459808635147558  Training Accuracy:0.8995535714285714\n",
            "2688/4708 - The training loss at 33th epoch : 0.07488106729188597  Training Accuracy:0.8994082840236687\n",
            "2704/4708 - The training loss at 33th epoch : 0.07480088903178807  Training Accuracy:0.8996323529411765\n",
            "2720/4708 - The training loss at 33th epoch : 0.07502533036517516  Training Accuracy:0.8994883040935673\n",
            "2736/4708 - The training loss at 33th epoch : 0.07477250972806591  Training Accuracy:0.8997093023255814\n",
            "2752/4708 - The training loss at 33th epoch : 0.07465087162697347  Training Accuracy:0.8999277456647399\n",
            "2768/4708 - The training loss at 33th epoch : 0.0747288756747609  Training Accuracy:0.8997844827586207\n",
            "2784/4708 - The training loss at 33th epoch : 0.07461479621559094  Training Accuracy:0.9\n",
            "2800/4708 - The training loss at 33th epoch : 0.07473162461234194  Training Accuracy:0.8998579545454546\n",
            "2816/4708 - The training loss at 33th epoch : 0.07481946242510656  Training Accuracy:0.8997175141242938\n",
            "2832/4708 - The training loss at 33th epoch : 0.07490457110200188  Training Accuracy:0.8992275280898876\n",
            "2848/4708 - The training loss at 33th epoch : 0.07499470025569786  Training Accuracy:0.8994413407821229\n",
            "2864/4708 - The training loss at 33th epoch : 0.0749450191249535  Training Accuracy:0.8993055555555556\n",
            "2880/4708 - The training loss at 33th epoch : 0.07500485381891608  Training Accuracy:0.899171270718232\n",
            "2896/4708 - The training loss at 33th epoch : 0.07536727518184871  Training Accuracy:0.898695054945055\n",
            "2912/4708 - The training loss at 33th epoch : 0.07517289434759114  Training Accuracy:0.8989071038251366\n",
            "2928/4708 - The training loss at 33th epoch : 0.07494860517705702  Training Accuracy:0.8994565217391305\n",
            "2944/4708 - The training loss at 33th epoch : 0.07475348353800061  Training Accuracy:0.9\n",
            "2960/4708 - The training loss at 33th epoch : 0.07495777686207249  Training Accuracy:0.8995295698924731\n",
            "2976/4708 - The training loss at 33th epoch : 0.07473998788591879  Training Accuracy:0.9000668449197861\n",
            "2992/4708 - The training loss at 33th epoch : 0.07485632305191  Training Accuracy:0.8999335106382979\n",
            "3008/4708 - The training loss at 33th epoch : 0.0750002628493812  Training Accuracy:0.8998015873015873\n",
            "3024/4708 - The training loss at 33th epoch : 0.0746982197449973  Training Accuracy:0.9\n",
            "3040/4708 - The training loss at 33th epoch : 0.07488502450739923  Training Accuracy:0.899869109947644\n",
            "3056/4708 - The training loss at 33th epoch : 0.07451885813370335  Training Accuracy:0.900390625\n",
            "3072/4708 - The training loss at 33th epoch : 0.07455952728392859  Training Accuracy:0.9002590673575129\n",
            "3088/4708 - The training loss at 33th epoch : 0.07462974140678141  Training Accuracy:0.8998067010309279\n",
            "3104/4708 - The training loss at 33th epoch : 0.0748210919005746  Training Accuracy:0.8996794871794872\n",
            "3120/4708 - The training loss at 33th epoch : 0.07469308955938572  Training Accuracy:0.8995535714285714\n",
            "3136/4708 - The training loss at 33th epoch : 0.0747784148068449  Training Accuracy:0.8994289340101523\n",
            "3152/4708 - The training loss at 33th epoch : 0.07485029108379106  Training Accuracy:0.8993055555555556\n",
            "3168/4708 - The training loss at 33th epoch : 0.07474982343265238  Training Accuracy:0.8994974874371859\n",
            "3184/4708 - The training loss at 33th epoch : 0.07506580019135091  Training Accuracy:0.899375\n",
            "3200/4708 - The training loss at 33th epoch : 0.07525208489639798  Training Accuracy:0.8992537313432836\n",
            "3216/4708 - The training loss at 33th epoch : 0.07557963523129582  Training Accuracy:0.8988242574257426\n",
            "3232/4708 - The training loss at 33th epoch : 0.07545105810813928  Training Accuracy:0.8990147783251231\n",
            "3248/4708 - The training loss at 33th epoch : 0.07532685961451627  Training Accuracy:0.899203431372549\n",
            "3264/4708 - The training loss at 33th epoch : 0.07541715113373666  Training Accuracy:0.8990853658536585\n",
            "3280/4708 - The training loss at 33th epoch : 0.07539262949529901  Training Accuracy:0.8986650485436893\n",
            "3296/4708 - The training loss at 33th epoch : 0.07574758970907158  Training Accuracy:0.8982487922705314\n",
            "3312/4708 - The training loss at 33th epoch : 0.0756167473371081  Training Accuracy:0.8984375\n",
            "3328/4708 - The training loss at 33th epoch : 0.07548571957650183  Training Accuracy:0.8986244019138756\n",
            "3344/4708 - The training loss at 33th epoch : 0.07529581108798565  Training Accuracy:0.8991071428571429\n",
            "3360/4708 - The training loss at 33th epoch : 0.0753731172607924  Training Accuracy:0.8989928909952607\n",
            "3376/4708 - The training loss at 33th epoch : 0.07574685841319354  Training Accuracy:0.8985849056603774\n",
            "3392/4708 - The training loss at 33th epoch : 0.07616190667779857  Training Accuracy:0.897887323943662\n",
            "3408/4708 - The training loss at 33th epoch : 0.07654389910974961  Training Accuracy:0.8974883177570093\n",
            "3424/4708 - The training loss at 33th epoch : 0.0766267353292858  Training Accuracy:0.897093023255814\n",
            "3440/4708 - The training loss at 33th epoch : 0.07684433214467716  Training Accuracy:0.8967013888888888\n",
            "3456/4708 - The training loss at 33th epoch : 0.07694801410440055  Training Accuracy:0.8963133640552995\n",
            "3472/4708 - The training loss at 33th epoch : 0.07728334908365264  Training Accuracy:0.8959288990825688\n",
            "3488/4708 - The training loss at 33th epoch : 0.07739554011472255  Training Accuracy:0.8958333333333334\n",
            "3504/4708 - The training loss at 33th epoch : 0.0773940873528582  Training Accuracy:0.8957386363636364\n",
            "3520/4708 - The training loss at 33th epoch : 0.07735768049449049  Training Accuracy:0.8956447963800905\n",
            "3536/4708 - The training loss at 33th epoch : 0.07728427710441495  Training Accuracy:0.8958333333333334\n",
            "3552/4708 - The training loss at 33th epoch : 0.07759253691874711  Training Accuracy:0.8954596412556054\n",
            "3568/4708 - The training loss at 33th epoch : 0.07775735702884064  Training Accuracy:0.8950892857142857\n",
            "3584/4708 - The training loss at 33th epoch : 0.07768976010479965  Training Accuracy:0.8952777777777777\n",
            "3600/4708 - The training loss at 33th epoch : 0.07760883352755457  Training Accuracy:0.8954646017699115\n",
            "3616/4708 - The training loss at 33th epoch : 0.07775767122167936  Training Accuracy:0.8950991189427313\n",
            "3632/4708 - The training loss at 33th epoch : 0.07765287832024081  Training Accuracy:0.8950109649122807\n",
            "3648/4708 - The training loss at 33th epoch : 0.07747284218926712  Training Accuracy:0.8951965065502183\n",
            "3664/4708 - The training loss at 33th epoch : 0.07737073125734664  Training Accuracy:0.8953804347826086\n",
            "3680/4708 - The training loss at 33th epoch : 0.07738853954985796  Training Accuracy:0.8952922077922078\n",
            "3696/4708 - The training loss at 33th epoch : 0.0773536103454896  Training Accuracy:0.8954741379310345\n",
            "3712/4708 - The training loss at 33th epoch : 0.07716426674664233  Training Accuracy:0.8956545064377682\n",
            "3728/4708 - The training loss at 33th epoch : 0.07694859239455566  Training Accuracy:0.8961004273504274\n",
            "3744/4708 - The training loss at 33th epoch : 0.07694317093996975  Training Accuracy:0.8957446808510638\n",
            "3760/4708 - The training loss at 33th epoch : 0.07716093907153507  Training Accuracy:0.8953919491525424\n",
            "3776/4708 - The training loss at 33th epoch : 0.07744482556445999  Training Accuracy:0.8953059071729957\n",
            "3792/4708 - The training loss at 33th epoch : 0.07757145614308228  Training Accuracy:0.8949579831932774\n",
            "3808/4708 - The training loss at 33th epoch : 0.07756985893373623  Training Accuracy:0.8951359832635983\n",
            "3824/4708 - The training loss at 33th epoch : 0.07751633505585438  Training Accuracy:0.8953125\n",
            "3840/4708 - The training loss at 33th epoch : 0.07763920429723535  Training Accuracy:0.8949688796680498\n",
            "3856/4708 - The training loss at 33th epoch : 0.07740707120728553  Training Accuracy:0.8954028925619835\n",
            "3872/4708 - The training loss at 33th epoch : 0.07742560363276108  Training Accuracy:0.8953189300411523\n",
            "3888/4708 - The training loss at 33th epoch : 0.07743399911574586  Training Accuracy:0.8949795081967213\n",
            "3904/4708 - The training loss at 33th epoch : 0.07788729755096518  Training Accuracy:0.8943877551020408\n",
            "3920/4708 - The training loss at 33th epoch : 0.07776516317241969  Training Accuracy:0.8945630081300813\n",
            "3936/4708 - The training loss at 33th epoch : 0.07778550392609672  Training Accuracy:0.8942307692307693\n",
            "3952/4708 - The training loss at 33th epoch : 0.07772707868213001  Training Accuracy:0.8944052419354839\n",
            "3968/4708 - The training loss at 33th epoch : 0.07764871174874974  Training Accuracy:0.8945783132530121\n",
            "3984/4708 - The training loss at 33th epoch : 0.0776500708919269  Training Accuracy:0.89475\n",
            "4000/4708 - The training loss at 33th epoch : 0.07750093480513535  Training Accuracy:0.8949203187250996\n",
            "4016/4708 - The training loss at 33th epoch : 0.07727441052167128  Training Accuracy:0.8953373015873016\n",
            "4032/4708 - The training loss at 33th epoch : 0.07748066802681852  Training Accuracy:0.8952569169960475\n",
            "4048/4708 - The training loss at 33th epoch : 0.07752465482380942  Training Accuracy:0.8951771653543307\n",
            "4064/4708 - The training loss at 33th epoch : 0.07741425100074238  Training Accuracy:0.895343137254902\n",
            "4080/4708 - The training loss at 33th epoch : 0.0772604451337831  Training Accuracy:0.8955078125\n",
            "4096/4708 - The training loss at 33th epoch : 0.07729033486381447  Training Accuracy:0.8954280155642024\n",
            "4112/4708 - The training loss at 33th epoch : 0.07758479339996432  Training Accuracy:0.8951065891472868\n",
            "4128/4708 - The training loss at 33th epoch : 0.07748852335156127  Training Accuracy:0.8952702702702703\n",
            "4144/4708 - The training loss at 33th epoch : 0.07722895294779056  Training Accuracy:0.895673076923077\n",
            "4160/4708 - The training loss at 33th epoch : 0.07734164326149642  Training Accuracy:0.8955938697318008\n",
            "4176/4708 - The training loss at 33th epoch : 0.07736441959646473  Training Accuracy:0.8955152671755725\n",
            "4192/4708 - The training loss at 33th epoch : 0.07791606305391566  Training Accuracy:0.8947243346007605\n",
            "4208/4708 - The training loss at 33th epoch : 0.07767028941569618  Training Accuracy:0.8951231060606061\n",
            "4224/4708 - The training loss at 33th epoch : 0.07755083214606615  Training Accuracy:0.8952830188679245\n",
            "4240/4708 - The training loss at 33th epoch : 0.07753289692804687  Training Accuracy:0.8952067669172933\n",
            "4256/4708 - The training loss at 33th epoch : 0.07754105454348627  Training Accuracy:0.8953651685393258\n",
            "4272/4708 - The training loss at 33th epoch : 0.07755371251075284  Training Accuracy:0.8955223880597015\n",
            "4288/4708 - The training loss at 33th epoch : 0.07763137745763384  Training Accuracy:0.8954460966542751\n",
            "4304/4708 - The training loss at 33th epoch : 0.0776609844940391  Training Accuracy:0.8951388888888889\n",
            "4320/4708 - The training loss at 33th epoch : 0.07765135047267921  Training Accuracy:0.8952952029520295\n",
            "4336/4708 - The training loss at 33th epoch : 0.07757130878123758  Training Accuracy:0.8954503676470589\n",
            "4352/4708 - The training loss at 33th epoch : 0.07770110979980595  Training Accuracy:0.8953754578754579\n",
            "4368/4708 - The training loss at 33th epoch : 0.07773406739895933  Training Accuracy:0.8953010948905109\n",
            "4384/4708 - The training loss at 33th epoch : 0.07790202367318769  Training Accuracy:0.8952272727272728\n",
            "4400/4708 - The training loss at 33th epoch : 0.07785848662483157  Training Accuracy:0.8951539855072463\n",
            "4416/4708 - The training loss at 33th epoch : 0.07763016102062024  Training Accuracy:0.8955324909747292\n",
            "4432/4708 - The training loss at 33th epoch : 0.07759677753684437  Training Accuracy:0.8952338129496403\n",
            "4448/4708 - The training loss at 33th epoch : 0.07751576243385663  Training Accuracy:0.8951612903225806\n",
            "4464/4708 - The training loss at 33th epoch : 0.07753591016024707  Training Accuracy:0.8950892857142857\n",
            "4480/4708 - The training loss at 33th epoch : 0.07739872598009426  Training Accuracy:0.8952402135231317\n",
            "4496/4708 - The training loss at 33th epoch : 0.07715843802464198  Training Accuracy:0.8956117021276596\n",
            "4512/4708 - The training loss at 33th epoch : 0.07713702839116054  Training Accuracy:0.8957597173144877\n",
            "4528/4708 - The training loss at 33th epoch : 0.07699213951444918  Training Accuracy:0.8961267605633803\n",
            "4544/4708 - The training loss at 33th epoch : 0.07684806369384152  Training Accuracy:0.8964912280701754\n",
            "4560/4708 - The training loss at 33th epoch : 0.07679540721275004  Training Accuracy:0.8966346153846154\n",
            "4576/4708 - The training loss at 33th epoch : 0.0768035866783176  Training Accuracy:0.8965592334494773\n",
            "4592/4708 - The training loss at 33th epoch : 0.07666715225935065  Training Accuracy:0.8967013888888888\n",
            "4608/4708 - The training loss at 33th epoch : 0.07647539399102557  Training Accuracy:0.8970588235294118\n",
            "4624/4708 - The training loss at 33th epoch : 0.07636488301261653  Training Accuracy:0.897198275862069\n",
            "4640/4708 - The training loss at 33th epoch : 0.07645092641391465  Training Accuracy:0.8969072164948454\n",
            "4656/4708 - The training loss at 33th epoch : 0.07639900020561932  Training Accuracy:0.8970462328767124\n",
            "4672/4708 - The training loss at 33th epoch : 0.07617459337574584  Training Accuracy:0.8973976109215017\n",
            "4688/4708 - The training loss at 33th epoch : 0.07622373848954507  Training Accuracy:0.8973214285714286\n",
            "4704/4708 - The training loss at 33th epoch : 0.07632909090350248  Training Accuracy:0.8968220338983051\n",
            "4720/4708 - The training loss at 33th epoch : 0.07645910716180353  Training Accuracy:0.8965371621621622\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 34th epoch : 0.11631313168783572  Training Accuracy:0.875\n",
            "16/4708 - The training loss at 34th epoch : 0.1011523271605167  Training Accuracy:0.875\n",
            "32/4708 - The training loss at 34th epoch : 0.1134620835886543  Training Accuracy:0.8541666666666666\n",
            "48/4708 - The training loss at 34th epoch : 0.0959146693140987  Training Accuracy:0.875\n",
            "64/4708 - The training loss at 34th epoch : 0.0922879590940929  Training Accuracy:0.875\n",
            "80/4708 - The training loss at 34th epoch : 0.08765516698288807  Training Accuracy:0.8854166666666666\n",
            "96/4708 - The training loss at 34th epoch : 0.08638352551561053  Training Accuracy:0.8928571428571429\n",
            "112/4708 - The training loss at 34th epoch : 0.08326312795474258  Training Accuracy:0.8984375\n",
            "128/4708 - The training loss at 34th epoch : 0.08816525003350525  Training Accuracy:0.8958333333333334\n",
            "144/4708 - The training loss at 34th epoch : 0.0826323410609521  Training Accuracy:0.9\n",
            "160/4708 - The training loss at 34th epoch : 0.07774176479268574  Training Accuracy:0.9034090909090909\n",
            "176/4708 - The training loss at 34th epoch : 0.0738569216114421  Training Accuracy:0.9114583333333334\n",
            "192/4708 - The training loss at 34th epoch : 0.0767663970444252  Training Accuracy:0.8990384615384616\n",
            "208/4708 - The training loss at 34th epoch : 0.08275839329542935  Training Accuracy:0.8839285714285714\n",
            "224/4708 - The training loss at 34th epoch : 0.08499598601416572  Training Accuracy:0.8833333333333333\n",
            "240/4708 - The training loss at 34th epoch : 0.08113448267078624  Training Accuracy:0.890625\n",
            "256/4708 - The training loss at 34th epoch : 0.0817022612391406  Training Accuracy:0.8933823529411765\n",
            "272/4708 - The training loss at 34th epoch : 0.07803415112958821  Training Accuracy:0.8993055555555556\n",
            "288/4708 - The training loss at 34th epoch : 0.07954618222104896  Training Accuracy:0.8980263157894737\n",
            "304/4708 - The training loss at 34th epoch : 0.07828035534318391  Training Accuracy:0.9\n",
            "320/4708 - The training loss at 34th epoch : 0.08274251791955696  Training Accuracy:0.8898809523809523\n",
            "336/4708 - The training loss at 34th epoch : 0.08021909854708797  Training Accuracy:0.8920454545454546\n",
            "352/4708 - The training loss at 34th epoch : 0.07694302328694634  Training Accuracy:0.8967391304347826\n",
            "368/4708 - The training loss at 34th epoch : 0.0798643436047166  Training Accuracy:0.8932291666666666\n",
            "384/4708 - The training loss at 34th epoch : 0.07893679097648372  Training Accuracy:0.895\n",
            "400/4708 - The training loss at 34th epoch : 0.080726351985395  Training Accuracy:0.8942307692307693\n",
            "416/4708 - The training loss at 34th epoch : 0.07869655717212228  Training Accuracy:0.8958333333333334\n",
            "432/4708 - The training loss at 34th epoch : 0.07784517654282819  Training Accuracy:0.8950892857142857\n",
            "448/4708 - The training loss at 34th epoch : 0.07819757504079722  Training Accuracy:0.8943965517241379\n",
            "464/4708 - The training loss at 34th epoch : 0.07706424501372312  Training Accuracy:0.8958333333333334\n",
            "480/4708 - The training loss at 34th epoch : 0.07762362202946096  Training Accuracy:0.8951612903225806\n",
            "496/4708 - The training loss at 34th epoch : 0.07568123752652307  Training Accuracy:0.8984375\n",
            "512/4708 - The training loss at 34th epoch : 0.07513896984245794  Training Accuracy:0.8977272727272727\n",
            "528/4708 - The training loss at 34th epoch : 0.07464703165530404  Training Accuracy:0.8988970588235294\n",
            "544/4708 - The training loss at 34th epoch : 0.07342385191485855  Training Accuracy:0.9\n",
            "560/4708 - The training loss at 34th epoch : 0.0749369382712267  Training Accuracy:0.8975694444444444\n",
            "576/4708 - The training loss at 34th epoch : 0.07456965416533098  Training Accuracy:0.8986486486486487\n",
            "592/4708 - The training loss at 34th epoch : 0.07374637485526933  Training Accuracy:0.899671052631579\n",
            "608/4708 - The training loss at 34th epoch : 0.07482765812152044  Training Accuracy:0.8990384615384616\n",
            "624/4708 - The training loss at 34th epoch : 0.07476435901347109  Training Accuracy:0.9\n",
            "640/4708 - The training loss at 34th epoch : 0.07431577165187926  Training Accuracy:0.899390243902439\n",
            "656/4708 - The training loss at 34th epoch : 0.07464495050162148  Training Accuracy:0.8988095238095238\n",
            "672/4708 - The training loss at 34th epoch : 0.07398729497554334  Training Accuracy:0.8997093023255814\n",
            "688/4708 - The training loss at 34th epoch : 0.07558882876858539  Training Accuracy:0.8963068181818182\n",
            "704/4708 - The training loss at 34th epoch : 0.07541967037523259  Training Accuracy:0.8972222222222223\n",
            "720/4708 - The training loss at 34th epoch : 0.07511955962844072  Training Accuracy:0.8980978260869565\n",
            "736/4708 - The training loss at 34th epoch : 0.07624698587496274  Training Accuracy:0.8976063829787234\n",
            "752/4708 - The training loss at 34th epoch : 0.07750130485070648  Training Accuracy:0.8971354166666666\n",
            "768/4708 - The training loss at 34th epoch : 0.0776204562754511  Training Accuracy:0.8979591836734694\n",
            "784/4708 - The training loss at 34th epoch : 0.0803733698961496  Training Accuracy:0.8925\n",
            "800/4708 - The training loss at 34th epoch : 0.08028954348651887  Training Accuracy:0.8933823529411765\n",
            "816/4708 - The training loss at 34th epoch : 0.08063537013635101  Training Accuracy:0.8918269230769231\n",
            "832/4708 - The training loss at 34th epoch : 0.08142424573754206  Training Accuracy:0.8903301886792453\n",
            "848/4708 - The training loss at 34th epoch : 0.08030129991978724  Training Accuracy:0.8923611111111112\n",
            "864/4708 - The training loss at 34th epoch : 0.0824544941731827  Training Accuracy:0.8897727272727273\n",
            "880/4708 - The training loss at 34th epoch : 0.08328280762044808  Training Accuracy:0.8883928571428571\n",
            "896/4708 - The training loss at 34th epoch : 0.08351480314984978  Training Accuracy:0.8881578947368421\n",
            "912/4708 - The training loss at 34th epoch : 0.08286937516483434  Training Accuracy:0.8900862068965517\n",
            "928/4708 - The training loss at 34th epoch : 0.08224728389651742  Training Accuracy:0.8898305084745762\n",
            "944/4708 - The training loss at 34th epoch : 0.08254433115894125  Training Accuracy:0.8895833333333333\n",
            "960/4708 - The training loss at 34th epoch : 0.08360291988959687  Training Accuracy:0.8883196721311475\n",
            "976/4708 - The training loss at 34th epoch : 0.08455362117144152  Training Accuracy:0.8870967741935484\n",
            "992/4708 - The training loss at 34th epoch : 0.08366573875538745  Training Accuracy:0.8888888888888888\n",
            "1008/4708 - The training loss at 34th epoch : 0.08332445615221425  Training Accuracy:0.8896484375\n",
            "1024/4708 - The training loss at 34th epoch : 0.08427217140462577  Training Accuracy:0.8875\n",
            "1040/4708 - The training loss at 34th epoch : 0.08395096467542032  Training Accuracy:0.8873106060606061\n",
            "1056/4708 - The training loss at 34th epoch : 0.0832545746332456  Training Accuracy:0.8880597014925373\n",
            "1072/4708 - The training loss at 34th epoch : 0.0836081684963493  Training Accuracy:0.8878676470588235\n",
            "1088/4708 - The training loss at 34th epoch : 0.08371118099449203  Training Accuracy:0.8867753623188406\n",
            "1104/4708 - The training loss at 34th epoch : 0.08556343871284211  Training Accuracy:0.8830357142857143\n",
            "1120/4708 - The training loss at 34th epoch : 0.08538893479048726  Training Accuracy:0.8838028169014085\n",
            "1136/4708 - The training loss at 34th epoch : 0.08545521303289944  Training Accuracy:0.8836805555555556\n",
            "1152/4708 - The training loss at 34th epoch : 0.08482418771846324  Training Accuracy:0.884417808219178\n",
            "1168/4708 - The training loss at 34th epoch : 0.08558383698440343  Training Accuracy:0.8834459459459459\n",
            "1184/4708 - The training loss at 34th epoch : 0.0857874477498237  Training Accuracy:0.8841666666666667\n",
            "1200/4708 - The training loss at 34th epoch : 0.08549610001994476  Training Accuracy:0.884046052631579\n",
            "1216/4708 - The training loss at 34th epoch : 0.08570341052858177  Training Accuracy:0.8839285714285714\n",
            "1232/4708 - The training loss at 34th epoch : 0.0852655357807696  Training Accuracy:0.8854166666666666\n",
            "1248/4708 - The training loss at 34th epoch : 0.08519464090187011  Training Accuracy:0.8860759493670886\n",
            "1264/4708 - The training loss at 34th epoch : 0.08471019673042875  Training Accuracy:0.88671875\n",
            "1280/4708 - The training loss at 34th epoch : 0.08645528775403118  Training Accuracy:0.8842592592592593\n",
            "1296/4708 - The training loss at 34th epoch : 0.08766190681599514  Training Accuracy:0.8826219512195121\n",
            "1312/4708 - The training loss at 34th epoch : 0.08734176493769465  Training Accuracy:0.8832831325301205\n",
            "1328/4708 - The training loss at 34th epoch : 0.0869163269982099  Training Accuracy:0.8839285714285714\n",
            "1344/4708 - The training loss at 34th epoch : 0.08611704345305676  Training Accuracy:0.8852941176470588\n",
            "1360/4708 - The training loss at 34th epoch : 0.08587994760698278  Training Accuracy:0.8859011627906976\n",
            "1376/4708 - The training loss at 34th epoch : 0.08660361425667933  Training Accuracy:0.8850574712643678\n",
            "1392/4708 - The training loss at 34th epoch : 0.08708842178956998  Training Accuracy:0.8849431818181818\n",
            "1408/4708 - The training loss at 34th epoch : 0.08697122982039573  Training Accuracy:0.8855337078651685\n",
            "1424/4708 - The training loss at 34th epoch : 0.08625356806181661  Training Accuracy:0.8868055555555555\n",
            "1440/4708 - The training loss at 34th epoch : 0.08539125449559497  Training Accuracy:0.8880494505494505\n",
            "1456/4708 - The training loss at 34th epoch : 0.08544949467366873  Training Accuracy:0.8885869565217391\n",
            "1472/4708 - The training loss at 34th epoch : 0.08546477699877336  Training Accuracy:0.8884408602150538\n",
            "1488/4708 - The training loss at 34th epoch : 0.0848102101291354  Training Accuracy:0.8896276595744681\n",
            "1504/4708 - The training loss at 34th epoch : 0.0851750806609159  Training Accuracy:0.8894736842105263\n",
            "1520/4708 - The training loss at 34th epoch : 0.08549585544645553  Training Accuracy:0.8893229166666666\n",
            "1536/4708 - The training loss at 34th epoch : 0.08619145056006597  Training Accuracy:0.8878865979381443\n",
            "1552/4708 - The training loss at 34th epoch : 0.08572523565283373  Training Accuracy:0.8883928571428571\n",
            "1568/4708 - The training loss at 34th epoch : 0.08627686114694937  Training Accuracy:0.8876262626262627\n",
            "1584/4708 - The training loss at 34th epoch : 0.08648417664075306  Training Accuracy:0.8875\n",
            "1600/4708 - The training loss at 34th epoch : 0.08708142134003996  Training Accuracy:0.8861386138613861\n",
            "1616/4708 - The training loss at 34th epoch : 0.08679873070943334  Training Accuracy:0.8860294117647058\n",
            "1632/4708 - The training loss at 34th epoch : 0.08666680550138395  Training Accuracy:0.8865291262135923\n",
            "1648/4708 - The training loss at 34th epoch : 0.08594939818102475  Training Accuracy:0.8876201923076923\n",
            "1664/4708 - The training loss at 34th epoch : 0.08562000274933412  Training Accuracy:0.8886904761904761\n",
            "1680/4708 - The training loss at 34th epoch : 0.08684302060054533  Training Accuracy:0.8867924528301887\n",
            "1696/4708 - The training loss at 34th epoch : 0.08611572576886378  Training Accuracy:0.8878504672897196\n",
            "1712/4708 - The training loss at 34th epoch : 0.08590903783278404  Training Accuracy:0.8877314814814815\n",
            "1728/4708 - The training loss at 34th epoch : 0.08582035173542954  Training Accuracy:0.8876146788990825\n",
            "1744/4708 - The training loss at 34th epoch : 0.08511325496151408  Training Accuracy:0.8886363636363637\n",
            "1760/4708 - The training loss at 34th epoch : 0.08499361003238964  Training Accuracy:0.8885135135135135\n",
            "1776/4708 - The training loss at 34th epoch : 0.08487284067106497  Training Accuracy:0.8889508928571429\n",
            "1792/4708 - The training loss at 34th epoch : 0.0852647853537961  Training Accuracy:0.8882743362831859\n",
            "1808/4708 - The training loss at 34th epoch : 0.08487914386367694  Training Accuracy:0.8887061403508771\n",
            "1824/4708 - The training loss at 34th epoch : 0.08507082624767616  Training Accuracy:0.8885869565217391\n",
            "1840/4708 - The training loss at 34th epoch : 0.08589848626968255  Training Accuracy:0.8873922413793104\n",
            "1856/4708 - The training loss at 34th epoch : 0.0853210094924704  Training Accuracy:0.8883547008547008\n",
            "1872/4708 - The training loss at 34th epoch : 0.08501245380963147  Training Accuracy:0.888771186440678\n",
            "1888/4708 - The training loss at 34th epoch : 0.08463127930627545  Training Accuracy:0.8891806722689075\n",
            "1904/4708 - The training loss at 34th epoch : 0.08444033131045625  Training Accuracy:0.8895833333333333\n",
            "1920/4708 - The training loss at 34th epoch : 0.08425198547468146  Training Accuracy:0.8894628099173554\n",
            "1936/4708 - The training loss at 34th epoch : 0.08368156692375618  Training Accuracy:0.8903688524590164\n",
            "1952/4708 - The training loss at 34th epoch : 0.08406564060087066  Training Accuracy:0.8892276422764228\n",
            "1968/4708 - The training loss at 34th epoch : 0.08433362936124515  Training Accuracy:0.8886088709677419\n",
            "1984/4708 - The training loss at 34th epoch : 0.08384716192406576  Training Accuracy:0.889\n",
            "2000/4708 - The training loss at 34th epoch : 0.0840259359255352  Training Accuracy:0.8883928571428571\n",
            "2016/4708 - The training loss at 34th epoch : 0.08343458321667054  Training Accuracy:0.8892716535433071\n",
            "2032/4708 - The training loss at 34th epoch : 0.08368712835643571  Training Accuracy:0.88916015625\n",
            "2048/4708 - The training loss at 34th epoch : 0.08326833290051855  Training Accuracy:0.8900193798449613\n",
            "2064/4708 - The training loss at 34th epoch : 0.08330078400257902  Training Accuracy:0.8899038461538461\n",
            "2080/4708 - The training loss at 34th epoch : 0.0838876842926501  Training Accuracy:0.8883587786259542\n",
            "2096/4708 - The training loss at 34th epoch : 0.08381766873658791  Training Accuracy:0.8887310606060606\n",
            "2112/4708 - The training loss at 34th epoch : 0.08325639270028855  Training Accuracy:0.8895676691729323\n",
            "2128/4708 - The training loss at 34th epoch : 0.08282351736347995  Training Accuracy:0.8903917910447762\n",
            "2144/4708 - The training loss at 34th epoch : 0.08246235082098648  Training Accuracy:0.8907407407407407\n",
            "2160/4708 - The training loss at 34th epoch : 0.08237084234225389  Training Accuracy:0.890625\n",
            "2176/4708 - The training loss at 34th epoch : 0.08188479523495529  Training Accuracy:0.8914233576642335\n",
            "2192/4708 - The training loss at 34th epoch : 0.08136334200438594  Training Accuracy:0.8922101449275363\n",
            "2208/4708 - The training loss at 34th epoch : 0.08130201464019705  Training Accuracy:0.8925359712230215\n",
            "2224/4708 - The training loss at 34th epoch : 0.08075989431520071  Training Accuracy:0.8933035714285714\n",
            "2240/4708 - The training loss at 34th epoch : 0.08068630364113094  Training Accuracy:0.8936170212765957\n",
            "2256/4708 - The training loss at 34th epoch : 0.08034542481164221  Training Accuracy:0.8943661971830986\n",
            "2272/4708 - The training loss at 34th epoch : 0.08024299459549175  Training Accuracy:0.8942307692307693\n",
            "2288/4708 - The training loss at 34th epoch : 0.07988344905051495  Training Accuracy:0.8949652777777778\n",
            "2304/4708 - The training loss at 34th epoch : 0.08021129937633587  Training Accuracy:0.8943965517241379\n",
            "2320/4708 - The training loss at 34th epoch : 0.07994100821701933  Training Accuracy:0.8946917808219178\n",
            "2336/4708 - The training loss at 34th epoch : 0.07970390341666457  Training Accuracy:0.8949829931972789\n",
            "2352/4708 - The training loss at 34th epoch : 0.07938375368468054  Training Accuracy:0.8956925675675675\n",
            "2368/4708 - The training loss at 34th epoch : 0.07955312721362089  Training Accuracy:0.8955536912751678\n",
            "2384/4708 - The training loss at 34th epoch : 0.07912342107316  Training Accuracy:0.89625\n",
            "2400/4708 - The training loss at 34th epoch : 0.078790354088196  Training Accuracy:0.8965231788079471\n",
            "2416/4708 - The training loss at 34th epoch : 0.07889961070503759  Training Accuracy:0.8959703947368421\n",
            "2432/4708 - The training loss at 34th epoch : 0.07877838448240274  Training Accuracy:0.8962418300653595\n",
            "2448/4708 - The training loss at 34th epoch : 0.07905189816234408  Training Accuracy:0.895698051948052\n",
            "2464/4708 - The training loss at 34th epoch : 0.07889749818394909  Training Accuracy:0.8959677419354839\n",
            "2480/4708 - The training loss at 34th epoch : 0.07858293315610154  Training Accuracy:0.8962339743589743\n",
            "2496/4708 - The training loss at 34th epoch : 0.07815601220335237  Training Accuracy:0.8968949044585988\n",
            "2512/4708 - The training loss at 34th epoch : 0.07779699701798129  Training Accuracy:0.8975474683544303\n",
            "2528/4708 - The training loss at 34th epoch : 0.07810854959398329  Training Accuracy:0.8970125786163522\n",
            "2544/4708 - The training loss at 34th epoch : 0.07781887776902453  Training Accuracy:0.897265625\n",
            "2560/4708 - The training loss at 34th epoch : 0.07763675051261901  Training Accuracy:0.8971273291925466\n",
            "2576/4708 - The training loss at 34th epoch : 0.07757279793939978  Training Accuracy:0.8973765432098766\n",
            "2592/4708 - The training loss at 34th epoch : 0.07722923997964462  Training Accuracy:0.8980061349693251\n",
            "2608/4708 - The training loss at 34th epoch : 0.07721099888231939  Training Accuracy:0.8978658536585366\n",
            "2624/4708 - The training loss at 34th epoch : 0.07676520947458589  Training Accuracy:0.8984848484848484\n",
            "2640/4708 - The training loss at 34th epoch : 0.07675411015475488  Training Accuracy:0.8987198795180723\n",
            "2656/4708 - The training loss at 34th epoch : 0.07668332195836183  Training Accuracy:0.8985778443113772\n",
            "2672/4708 - The training loss at 34th epoch : 0.07645277457230802  Training Accuracy:0.8988095238095238\n",
            "2688/4708 - The training loss at 34th epoch : 0.0763368836711161  Training Accuracy:0.8990384615384616\n",
            "2704/4708 - The training loss at 34th epoch : 0.07665182061754112  Training Accuracy:0.8981617647058824\n",
            "2720/4708 - The training loss at 34th epoch : 0.07660027011346893  Training Accuracy:0.8980263157894737\n",
            "2736/4708 - The training loss at 34th epoch : 0.07702741906458545  Training Accuracy:0.8975290697674418\n",
            "2752/4708 - The training loss at 34th epoch : 0.07704102612885924  Training Accuracy:0.8977601156069365\n",
            "2768/4708 - The training loss at 34th epoch : 0.07713607143075372  Training Accuracy:0.8976293103448276\n",
            "2784/4708 - The training loss at 34th epoch : 0.07683439157215935  Training Accuracy:0.8982142857142857\n",
            "2800/4708 - The training loss at 34th epoch : 0.07705508476443675  Training Accuracy:0.8980823863636364\n",
            "2816/4708 - The training loss at 34th epoch : 0.0774038798195621  Training Accuracy:0.8975988700564972\n",
            "2832/4708 - The training loss at 34th epoch : 0.07759239516944798  Training Accuracy:0.8974719101123596\n",
            "2848/4708 - The training loss at 34th epoch : 0.07726764939722294  Training Accuracy:0.8980446927374302\n",
            "2864/4708 - The training loss at 34th epoch : 0.07739836010696373  Training Accuracy:0.8979166666666667\n",
            "2880/4708 - The training loss at 34th epoch : 0.07698408769696198  Training Accuracy:0.8984806629834254\n",
            "2896/4708 - The training loss at 34th epoch : 0.07688079179990032  Training Accuracy:0.898695054945055\n",
            "2912/4708 - The training loss at 34th epoch : 0.07757270290741976  Training Accuracy:0.8978825136612022\n",
            "2928/4708 - The training loss at 34th epoch : 0.07820928735007956  Training Accuracy:0.897078804347826\n",
            "2944/4708 - The training loss at 34th epoch : 0.0780797178769194  Training Accuracy:0.8972972972972973\n",
            "2960/4708 - The training loss at 34th epoch : 0.07793941400768827  Training Accuracy:0.897513440860215\n",
            "2976/4708 - The training loss at 34th epoch : 0.07857741352545412  Training Accuracy:0.8967245989304813\n",
            "2992/4708 - The training loss at 34th epoch : 0.07830540907004839  Training Accuracy:0.8972739361702128\n",
            "3008/4708 - The training loss at 34th epoch : 0.07847802582259095  Training Accuracy:0.896494708994709\n",
            "3024/4708 - The training loss at 34th epoch : 0.07857986201822312  Training Accuracy:0.8963815789473685\n",
            "3040/4708 - The training loss at 34th epoch : 0.07846958174664574  Training Accuracy:0.8965968586387435\n",
            "3056/4708 - The training loss at 34th epoch : 0.0790478868552746  Training Accuracy:0.8958333333333334\n",
            "3072/4708 - The training loss at 34th epoch : 0.07907521724326161  Training Accuracy:0.8957253886010362\n",
            "3088/4708 - The training loss at 34th epoch : 0.07914769937502622  Training Accuracy:0.895618556701031\n",
            "3104/4708 - The training loss at 34th epoch : 0.07882173180419402  Training Accuracy:0.8961538461538462\n",
            "3120/4708 - The training loss at 34th epoch : 0.07843320490054707  Training Accuracy:0.8966836734693877\n",
            "3136/4708 - The training loss at 34th epoch : 0.07823301281532666  Training Accuracy:0.8968908629441624\n",
            "3152/4708 - The training loss at 34th epoch : 0.07861917157428046  Training Accuracy:0.8964646464646465\n",
            "3168/4708 - The training loss at 34th epoch : 0.07861305633788791  Training Accuracy:0.8966708542713567\n",
            "3184/4708 - The training loss at 34th epoch : 0.07842946404877632  Training Accuracy:0.896875\n",
            "3200/4708 - The training loss at 34th epoch : 0.07857104529482173  Training Accuracy:0.8967661691542289\n",
            "3216/4708 - The training loss at 34th epoch : 0.07850268607449488  Training Accuracy:0.8966584158415841\n",
            "3232/4708 - The training loss at 34th epoch : 0.07837048244645821  Training Accuracy:0.8968596059113301\n",
            "3248/4708 - The training loss at 34th epoch : 0.07801543627775075  Training Accuracy:0.8973651960784313\n",
            "3264/4708 - The training loss at 34th epoch : 0.07768171203324362  Training Accuracy:0.8978658536585366\n",
            "3280/4708 - The training loss at 34th epoch : 0.07757458367064361  Training Accuracy:0.897754854368932\n",
            "3296/4708 - The training loss at 34th epoch : 0.0775117643189053  Training Accuracy:0.8979468599033816\n",
            "3312/4708 - The training loss at 34th epoch : 0.07768951876586848  Training Accuracy:0.8978365384615384\n",
            "3328/4708 - The training loss at 34th epoch : 0.07770008491763529  Training Accuracy:0.8977272727272727\n",
            "3344/4708 - The training loss at 34th epoch : 0.07807601329971155  Training Accuracy:0.8967261904761905\n",
            "3360/4708 - The training loss at 34th epoch : 0.0782182543207554  Training Accuracy:0.8963270142180095\n",
            "3376/4708 - The training loss at 34th epoch : 0.07815385635275958  Training Accuracy:0.8965212264150944\n",
            "3392/4708 - The training loss at 34th epoch : 0.07791152267371299  Training Accuracy:0.8967136150234741\n",
            "3408/4708 - The training loss at 34th epoch : 0.07810892505866097  Training Accuracy:0.8966121495327103\n",
            "3424/4708 - The training loss at 34th epoch : 0.07812151255792174  Training Accuracy:0.8965116279069767\n",
            "3440/4708 - The training loss at 34th epoch : 0.07818740298767592  Training Accuracy:0.8964120370370371\n",
            "3456/4708 - The training loss at 34th epoch : 0.07803538748773939  Training Accuracy:0.8966013824884793\n",
            "3472/4708 - The training loss at 34th epoch : 0.07792334223827638  Training Accuracy:0.8967889908256881\n",
            "3488/4708 - The training loss at 34th epoch : 0.07826316845908966  Training Accuracy:0.8961187214611872\n",
            "3504/4708 - The training loss at 34th epoch : 0.07829617690125175  Training Accuracy:0.8960227272727272\n",
            "3520/4708 - The training loss at 34th epoch : 0.07813871049539195  Training Accuracy:0.896210407239819\n",
            "3536/4708 - The training loss at 34th epoch : 0.07797109203924969  Training Accuracy:0.8963963963963963\n",
            "3552/4708 - The training loss at 34th epoch : 0.07783405099010378  Training Accuracy:0.8965807174887892\n",
            "3568/4708 - The training loss at 34th epoch : 0.07773047242606856  Training Accuracy:0.896484375\n",
            "3584/4708 - The training loss at 34th epoch : 0.0775234649471372  Training Accuracy:0.8966666666666666\n",
            "3600/4708 - The training loss at 34th epoch : 0.07732623027966648  Training Accuracy:0.8971238938053098\n",
            "3616/4708 - The training loss at 34th epoch : 0.07720072608720276  Training Accuracy:0.8973017621145375\n",
            "3632/4708 - The training loss at 34th epoch : 0.07702437710322647  Training Accuracy:0.8974780701754386\n",
            "3648/4708 - The training loss at 34th epoch : 0.07743252957816911  Training Accuracy:0.8971069868995634\n",
            "3664/4708 - The training loss at 34th epoch : 0.07776037933671233  Training Accuracy:0.8964673913043478\n",
            "3680/4708 - The training loss at 34th epoch : 0.0775918442116344  Training Accuracy:0.8966450216450217\n",
            "3696/4708 - The training loss at 34th epoch : 0.07756542864868936  Training Accuracy:0.896551724137931\n",
            "3712/4708 - The training loss at 34th epoch : 0.07759398372554802  Training Accuracy:0.8967274678111588\n",
            "3728/4708 - The training loss at 34th epoch : 0.07740732810789618  Training Accuracy:0.8971688034188035\n",
            "3744/4708 - The training loss at 34th epoch : 0.07780693275432343  Training Accuracy:0.8968085106382979\n",
            "3760/4708 - The training loss at 34th epoch : 0.07791184568562658  Training Accuracy:0.8964512711864406\n",
            "3776/4708 - The training loss at 34th epoch : 0.07816284052255804  Training Accuracy:0.8960970464135021\n",
            "3792/4708 - The training loss at 34th epoch : 0.07812805584266308  Training Accuracy:0.8960084033613446\n",
            "3808/4708 - The training loss at 34th epoch : 0.07806947940355359  Training Accuracy:0.8961820083682008\n",
            "3824/4708 - The training loss at 34th epoch : 0.07790157482135479  Training Accuracy:0.8966145833333333\n",
            "3840/4708 - The training loss at 34th epoch : 0.07802881525014387  Training Accuracy:0.8965248962655602\n",
            "3856/4708 - The training loss at 34th epoch : 0.07792379136623642  Training Accuracy:0.8966942148760331\n",
            "3872/4708 - The training loss at 34th epoch : 0.07797678590536535  Training Accuracy:0.8968621399176955\n",
            "3888/4708 - The training loss at 34th epoch : 0.07813416390798841  Training Accuracy:0.8967725409836066\n",
            "3904/4708 - The training loss at 34th epoch : 0.07809589779200006  Training Accuracy:0.8969387755102041\n",
            "3920/4708 - The training loss at 34th epoch : 0.07796208048699275  Training Accuracy:0.8971036585365854\n",
            "3936/4708 - The training loss at 34th epoch : 0.07804810297938053  Training Accuracy:0.8967611336032388\n",
            "3952/4708 - The training loss at 34th epoch : 0.07776611679061299  Training Accuracy:0.8971774193548387\n",
            "3968/4708 - The training loss at 34th epoch : 0.0779450341327188  Training Accuracy:0.8968373493975904\n",
            "3984/4708 - The training loss at 34th epoch : 0.07822782913014727  Training Accuracy:0.89625\n",
            "4000/4708 - The training loss at 34th epoch : 0.0782092850429795  Training Accuracy:0.8961653386454184\n",
            "4016/4708 - The training loss at 34th epoch : 0.07820695607460473  Training Accuracy:0.8963293650793651\n",
            "4032/4708 - The training loss at 34th epoch : 0.07797993322090477  Training Accuracy:0.8967391304347826\n",
            "4048/4708 - The training loss at 34th epoch : 0.07807341346690369  Training Accuracy:0.8966535433070866\n",
            "4064/4708 - The training loss at 34th epoch : 0.0780513205529598  Training Accuracy:0.8965686274509804\n",
            "4080/4708 - The training loss at 34th epoch : 0.07790290641646744  Training Accuracy:0.896728515625\n",
            "4096/4708 - The training loss at 34th epoch : 0.07779396885417712  Training Accuracy:0.896887159533074\n",
            "4112/4708 - The training loss at 34th epoch : 0.07785146460164977  Training Accuracy:0.8968023255813954\n",
            "4128/4708 - The training loss at 34th epoch : 0.07799694948459428  Training Accuracy:0.8967181467181468\n",
            "4144/4708 - The training loss at 34th epoch : 0.07787172911541959  Training Accuracy:0.8971153846153846\n",
            "4160/4708 - The training loss at 34th epoch : 0.07809156162652296  Training Accuracy:0.8967911877394636\n",
            "4176/4708 - The training loss at 34th epoch : 0.07826179136041966  Training Accuracy:0.896469465648855\n",
            "4192/4708 - The training loss at 34th epoch : 0.07854729103739538  Training Accuracy:0.8961501901140685\n",
            "4208/4708 - The training loss at 34th epoch : 0.07831110295808179  Training Accuracy:0.8965435606060606\n",
            "4224/4708 - The training loss at 34th epoch : 0.07826777726666208  Training Accuracy:0.8964622641509434\n",
            "4240/4708 - The training loss at 34th epoch : 0.07825135640530864  Training Accuracy:0.8963815789473685\n",
            "4256/4708 - The training loss at 34th epoch : 0.07806982980482688  Training Accuracy:0.8967696629213483\n",
            "4272/4708 - The training loss at 34th epoch : 0.07814959100177288  Training Accuracy:0.8966884328358209\n",
            "4288/4708 - The training loss at 34th epoch : 0.0780561009414551  Training Accuracy:0.8966078066914498\n",
            "4304/4708 - The training loss at 34th epoch : 0.07781345537479595  Training Accuracy:0.8969907407407407\n",
            "4320/4708 - The training loss at 34th epoch : 0.0779162268674763  Training Accuracy:0.896909594095941\n",
            "4336/4708 - The training loss at 34th epoch : 0.07787841672764795  Training Accuracy:0.8968290441176471\n",
            "4352/4708 - The training loss at 34th epoch : 0.0779836931315894  Training Accuracy:0.8967490842490843\n",
            "4368/4708 - The training loss at 34th epoch : 0.07790050632501473  Training Accuracy:0.8968978102189781\n",
            "4384/4708 - The training loss at 34th epoch : 0.07805536988638422  Training Accuracy:0.8968181818181818\n",
            "4400/4708 - The training loss at 34th epoch : 0.07792934293223128  Training Accuracy:0.8969655797101449\n",
            "4416/4708 - The training loss at 34th epoch : 0.07833907086317225  Training Accuracy:0.8962093862815884\n",
            "4432/4708 - The training loss at 34th epoch : 0.0782799140719238  Training Accuracy:0.8961330935251799\n",
            "4448/4708 - The training loss at 34th epoch : 0.07831083400083501  Training Accuracy:0.8960573476702509\n",
            "4464/4708 - The training loss at 34th epoch : 0.0781247963591463  Training Accuracy:0.8962053571428571\n",
            "4480/4708 - The training loss at 34th epoch : 0.07803196654849728  Training Accuracy:0.8963523131672598\n",
            "4496/4708 - The training loss at 34th epoch : 0.0779593214680759  Training Accuracy:0.8964982269503546\n",
            "4512/4708 - The training loss at 34th epoch : 0.07781601123914281  Training Accuracy:0.8968639575971732\n",
            "4528/4708 - The training loss at 34th epoch : 0.07779185958164896  Training Accuracy:0.8967869718309859\n",
            "4544/4708 - The training loss at 34th epoch : 0.07766180382304075  Training Accuracy:0.8969298245614035\n",
            "4560/4708 - The training loss at 34th epoch : 0.07778380680803627  Training Accuracy:0.8968531468531469\n",
            "4576/4708 - The training loss at 34th epoch : 0.07767455202118287  Training Accuracy:0.8967770034843205\n",
            "4592/4708 - The training loss at 34th epoch : 0.0777199899090133  Training Accuracy:0.8967013888888888\n",
            "4608/4708 - The training loss at 34th epoch : 0.07747053365302066  Training Accuracy:0.8970588235294118\n",
            "4624/4708 - The training loss at 34th epoch : 0.07729229854601154  Training Accuracy:0.8974137931034483\n",
            "4640/4708 - The training loss at 34th epoch : 0.07748475903220335  Training Accuracy:0.8971219931271478\n",
            "4656/4708 - The training loss at 34th epoch : 0.07747465972221164  Training Accuracy:0.8970462328767124\n",
            "4672/4708 - The training loss at 34th epoch : 0.07741988482900289  Training Accuracy:0.8971843003412969\n",
            "4688/4708 - The training loss at 34th epoch : 0.07741044412988224  Training Accuracy:0.8968962585034014\n",
            "4704/4708 - The training loss at 34th epoch : 0.07735406072882817  Training Accuracy:0.8970338983050847\n",
            "4720/4708 - The training loss at 34th epoch : 0.07737796296127047  Training Accuracy:0.8969594594594594\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 35th epoch : 0.24915600943786687  Training Accuracy:0.625\n",
            "16/4708 - The training loss at 35th epoch : 0.15635573316159046  Training Accuracy:0.78125\n",
            "32/4708 - The training loss at 35th epoch : 0.115096993981235  Training Accuracy:0.8333333333333334\n",
            "48/4708 - The training loss at 35th epoch : 0.1270421626485325  Training Accuracy:0.828125\n",
            "64/4708 - The training loss at 35th epoch : 0.11334791543841567  Training Accuracy:0.8375\n",
            "80/4708 - The training loss at 35th epoch : 0.10293689943371476  Training Accuracy:0.8541666666666666\n",
            "96/4708 - The training loss at 35th epoch : 0.0931799318584072  Training Accuracy:0.8660714285714286\n",
            "112/4708 - The training loss at 35th epoch : 0.10730156637707353  Training Accuracy:0.84375\n",
            "128/4708 - The training loss at 35th epoch : 0.09933069842461972  Training Accuracy:0.8541666666666666\n",
            "144/4708 - The training loss at 35th epoch : 0.09058834183325339  Training Accuracy:0.86875\n",
            "160/4708 - The training loss at 35th epoch : 0.08783463174523765  Training Accuracy:0.875\n",
            "176/4708 - The training loss at 35th epoch : 0.084600544114953  Training Accuracy:0.8802083333333334\n",
            "192/4708 - The training loss at 35th epoch : 0.08396618144334594  Training Accuracy:0.8846153846153846\n",
            "208/4708 - The training loss at 35th epoch : 0.08516204278231523  Training Accuracy:0.8839285714285714\n",
            "224/4708 - The training loss at 35th epoch : 0.0824565457291891  Training Accuracy:0.8875\n",
            "240/4708 - The training loss at 35th epoch : 0.08086606380275162  Training Accuracy:0.890625\n",
            "256/4708 - The training loss at 35th epoch : 0.08106353773606573  Training Accuracy:0.8897058823529411\n",
            "272/4708 - The training loss at 35th epoch : 0.07721311304191582  Training Accuracy:0.8958333333333334\n",
            "288/4708 - The training loss at 35th epoch : 0.07658710682493643  Training Accuracy:0.8947368421052632\n",
            "304/4708 - The training loss at 35th epoch : 0.07319623612414233  Training Accuracy:0.9\n",
            "320/4708 - The training loss at 35th epoch : 0.07069163104456225  Training Accuracy:0.9017857142857143\n",
            "336/4708 - The training loss at 35th epoch : 0.06923376998860725  Training Accuracy:0.9034090909090909\n",
            "352/4708 - The training loss at 35th epoch : 0.06834180938865894  Training Accuracy:0.904891304347826\n",
            "368/4708 - The training loss at 35th epoch : 0.06752851681740389  Training Accuracy:0.90625\n",
            "384/4708 - The training loss at 35th epoch : 0.0681881100796806  Training Accuracy:0.905\n",
            "400/4708 - The training loss at 35th epoch : 0.06822159693312896  Training Accuracy:0.90625\n",
            "416/4708 - The training loss at 35th epoch : 0.07215606514232566  Training Accuracy:0.9027777777777778\n",
            "432/4708 - The training loss at 35th epoch : 0.07256212894511808  Training Accuracy:0.9017857142857143\n",
            "448/4708 - The training loss at 35th epoch : 0.07260970212091335  Training Accuracy:0.9008620689655172\n",
            "464/4708 - The training loss at 35th epoch : 0.07284147331550761  Training Accuracy:0.9\n",
            "480/4708 - The training loss at 35th epoch : 0.07158905877757757  Training Accuracy:0.9012096774193549\n",
            "496/4708 - The training loss at 35th epoch : 0.07526826916252238  Training Accuracy:0.896484375\n",
            "512/4708 - The training loss at 35th epoch : 0.0799038455426846  Training Accuracy:0.8901515151515151\n",
            "528/4708 - The training loss at 35th epoch : 0.07842997047673163  Training Accuracy:0.8915441176470589\n",
            "544/4708 - The training loss at 35th epoch : 0.07728882015358583  Training Accuracy:0.8928571428571429\n",
            "560/4708 - The training loss at 35th epoch : 0.07695590457279926  Training Accuracy:0.8940972222222222\n",
            "576/4708 - The training loss at 35th epoch : 0.07667048419977247  Training Accuracy:0.8952702702702703\n",
            "592/4708 - The training loss at 35th epoch : 0.07706193372058129  Training Accuracy:0.8963815789473685\n",
            "608/4708 - The training loss at 35th epoch : 0.07626717118613464  Training Accuracy:0.8974358974358975\n",
            "624/4708 - The training loss at 35th epoch : 0.0750261781071172  Training Accuracy:0.9\n",
            "640/4708 - The training loss at 35th epoch : 0.0757079919033972  Training Accuracy:0.8978658536585366\n",
            "656/4708 - The training loss at 35th epoch : 0.07568416823730761  Training Accuracy:0.8988095238095238\n",
            "672/4708 - The training loss at 35th epoch : 0.07508617093514491  Training Accuracy:0.8997093023255814\n",
            "688/4708 - The training loss at 35th epoch : 0.07568287774434802  Training Accuracy:0.8991477272727273\n",
            "704/4708 - The training loss at 35th epoch : 0.0746990486320274  Training Accuracy:0.9013888888888889\n",
            "720/4708 - The training loss at 35th epoch : 0.07344171622303139  Training Accuracy:0.9035326086956522\n",
            "736/4708 - The training loss at 35th epoch : 0.07206732579052336  Training Accuracy:0.9055851063829787\n",
            "752/4708 - The training loss at 35th epoch : 0.07241244990119326  Training Accuracy:0.90625\n",
            "768/4708 - The training loss at 35th epoch : 0.07212571320962162  Training Accuracy:0.9068877551020408\n",
            "784/4708 - The training loss at 35th epoch : 0.0717644791486763  Training Accuracy:0.90625\n",
            "800/4708 - The training loss at 35th epoch : 0.07094344082102606  Training Accuracy:0.9068627450980392\n",
            "816/4708 - The training loss at 35th epoch : 0.07043331242027859  Training Accuracy:0.9074519230769231\n",
            "832/4708 - The training loss at 35th epoch : 0.07207554727703862  Training Accuracy:0.9056603773584906\n",
            "848/4708 - The training loss at 35th epoch : 0.0718876780182894  Training Accuracy:0.90625\n",
            "864/4708 - The training loss at 35th epoch : 0.07090882057379662  Training Accuracy:0.9079545454545455\n",
            "880/4708 - The training loss at 35th epoch : 0.07108213108374614  Training Accuracy:0.9073660714285714\n",
            "896/4708 - The training loss at 35th epoch : 0.07178969660150702  Training Accuracy:0.9057017543859649\n",
            "912/4708 - The training loss at 35th epoch : 0.07229702613426019  Training Accuracy:0.9051724137931034\n",
            "928/4708 - The training loss at 35th epoch : 0.07435183017536356  Training Accuracy:0.902542372881356\n",
            "944/4708 - The training loss at 35th epoch : 0.07409670422614326  Training Accuracy:0.903125\n",
            "960/4708 - The training loss at 35th epoch : 0.07542335900579394  Training Accuracy:0.9016393442622951\n",
            "976/4708 - The training loss at 35th epoch : 0.07674059542494154  Training Accuracy:0.8991935483870968\n",
            "992/4708 - The training loss at 35th epoch : 0.07565022623290649  Training Accuracy:0.9007936507936508\n",
            "1008/4708 - The training loss at 35th epoch : 0.07479151123390897  Training Accuracy:0.90234375\n",
            "1024/4708 - The training loss at 35th epoch : 0.07521664699243652  Training Accuracy:0.9019230769230769\n",
            "1040/4708 - The training loss at 35th epoch : 0.07659518260366255  Training Accuracy:0.9005681818181818\n",
            "1056/4708 - The training loss at 35th epoch : 0.0764844389697165  Training Accuracy:0.9001865671641791\n",
            "1072/4708 - The training loss at 35th epoch : 0.07565907392583526  Training Accuracy:0.9016544117647058\n",
            "1088/4708 - The training loss at 35th epoch : 0.07713293625459137  Training Accuracy:0.8985507246376812\n",
            "1104/4708 - The training loss at 35th epoch : 0.07654965910198927  Training Accuracy:0.8991071428571429\n",
            "1120/4708 - The training loss at 35th epoch : 0.07638611438624857  Training Accuracy:0.8996478873239436\n",
            "1136/4708 - The training loss at 35th epoch : 0.0762013111842616  Training Accuracy:0.9001736111111112\n",
            "1152/4708 - The training loss at 35th epoch : 0.07684644579711977  Training Accuracy:0.898972602739726\n",
            "1168/4708 - The training loss at 35th epoch : 0.07644255165118073  Training Accuracy:0.8994932432432432\n",
            "1184/4708 - The training loss at 35th epoch : 0.07660739190201506  Training Accuracy:0.8991666666666667\n",
            "1200/4708 - The training loss at 35th epoch : 0.07631774095007918  Training Accuracy:0.899671052631579\n",
            "1216/4708 - The training loss at 35th epoch : 0.07602048227001981  Training Accuracy:0.9001623376623377\n",
            "1232/4708 - The training loss at 35th epoch : 0.07551577863835862  Training Accuracy:0.9006410256410257\n",
            "1248/4708 - The training loss at 35th epoch : 0.07550130807326491  Training Accuracy:0.9003164556962026\n",
            "1264/4708 - The training loss at 35th epoch : 0.07558146634617105  Training Accuracy:0.9\n",
            "1280/4708 - The training loss at 35th epoch : 0.07625779323943975  Training Accuracy:0.8981481481481481\n",
            "1296/4708 - The training loss at 35th epoch : 0.07659342363459394  Training Accuracy:0.8978658536585366\n",
            "1312/4708 - The training loss at 35th epoch : 0.07651399802425606  Training Accuracy:0.8975903614457831\n",
            "1328/4708 - The training loss at 35th epoch : 0.07695807744835258  Training Accuracy:0.8965773809523809\n",
            "1344/4708 - The training loss at 35th epoch : 0.07670173524554669  Training Accuracy:0.8970588235294118\n",
            "1360/4708 - The training loss at 35th epoch : 0.07616361357416039  Training Accuracy:0.8975290697674418\n",
            "1376/4708 - The training loss at 35th epoch : 0.07604822694577514  Training Accuracy:0.8979885057471264\n",
            "1392/4708 - The training loss at 35th epoch : 0.07665369726874584  Training Accuracy:0.8970170454545454\n",
            "1408/4708 - The training loss at 35th epoch : 0.0759119535780756  Training Accuracy:0.8981741573033708\n",
            "1424/4708 - The training loss at 35th epoch : 0.07569806847806852  Training Accuracy:0.8986111111111111\n",
            "1440/4708 - The training loss at 35th epoch : 0.07587808238157483  Training Accuracy:0.8983516483516484\n",
            "1456/4708 - The training loss at 35th epoch : 0.07573968873629515  Training Accuracy:0.8987771739130435\n",
            "1472/4708 - The training loss at 35th epoch : 0.07595279663357359  Training Accuracy:0.8991935483870968\n",
            "1488/4708 - The training loss at 35th epoch : 0.07517645088795732  Training Accuracy:0.9002659574468085\n",
            "1504/4708 - The training loss at 35th epoch : 0.07571620899447622  Training Accuracy:0.8993421052631579\n",
            "1520/4708 - The training loss at 35th epoch : 0.07559563015177874  Training Accuracy:0.8990885416666666\n",
            "1536/4708 - The training loss at 35th epoch : 0.07630680793166186  Training Accuracy:0.8981958762886598\n",
            "1552/4708 - The training loss at 35th epoch : 0.07644371845170077  Training Accuracy:0.8979591836734694\n",
            "1568/4708 - The training loss at 35th epoch : 0.07721301224895269  Training Accuracy:0.8970959595959596\n",
            "1584/4708 - The training loss at 35th epoch : 0.07784870984481741  Training Accuracy:0.89625\n",
            "1600/4708 - The training loss at 35th epoch : 0.07747821008578587  Training Accuracy:0.8966584158415841\n",
            "1616/4708 - The training loss at 35th epoch : 0.07734512232872987  Training Accuracy:0.8970588235294118\n",
            "1632/4708 - The training loss at 35th epoch : 0.07688409875510885  Training Accuracy:0.8974514563106796\n",
            "1648/4708 - The training loss at 35th epoch : 0.07737630722676496  Training Accuracy:0.8972355769230769\n",
            "1664/4708 - The training loss at 35th epoch : 0.07718319230337244  Training Accuracy:0.8976190476190476\n",
            "1680/4708 - The training loss at 35th epoch : 0.07717911043174779  Training Accuracy:0.8979952830188679\n",
            "1696/4708 - The training loss at 35th epoch : 0.0769288765510972  Training Accuracy:0.8977803738317757\n",
            "1712/4708 - The training loss at 35th epoch : 0.07627600284000084  Training Accuracy:0.8987268518518519\n",
            "1728/4708 - The training loss at 35th epoch : 0.07604773544652711  Training Accuracy:0.8990825688073395\n",
            "1744/4708 - The training loss at 35th epoch : 0.07598030510876885  Training Accuracy:0.8994318181818182\n",
            "1760/4708 - The training loss at 35th epoch : 0.07579289366566176  Training Accuracy:0.8997747747747747\n",
            "1776/4708 - The training loss at 35th epoch : 0.07529807799877311  Training Accuracy:0.9006696428571429\n",
            "1792/4708 - The training loss at 35th epoch : 0.07477124706041391  Training Accuracy:0.9015486725663717\n",
            "1808/4708 - The training loss at 35th epoch : 0.07488333247161282  Training Accuracy:0.9013157894736842\n",
            "1824/4708 - The training loss at 35th epoch : 0.07438407958816294  Training Accuracy:0.9021739130434783\n",
            "1840/4708 - The training loss at 35th epoch : 0.07490559150562405  Training Accuracy:0.9008620689655172\n",
            "1856/4708 - The training loss at 35th epoch : 0.07539903719329677  Training Accuracy:0.9006410256410257\n",
            "1872/4708 - The training loss at 35th epoch : 0.07521925311879644  Training Accuracy:0.9009533898305084\n",
            "1888/4708 - The training loss at 35th epoch : 0.0754319511631221  Training Accuracy:0.9007352941176471\n",
            "1904/4708 - The training loss at 35th epoch : 0.07604380363034746  Training Accuracy:0.8994791666666667\n",
            "1920/4708 - The training loss at 35th epoch : 0.0770031860148153  Training Accuracy:0.8982438016528925\n",
            "1936/4708 - The training loss at 35th epoch : 0.07657850395151741  Training Accuracy:0.899077868852459\n",
            "1952/4708 - The training loss at 35th epoch : 0.07598289663671536  Training Accuracy:0.8998983739837398\n",
            "1968/4708 - The training loss at 35th epoch : 0.07638648637890072  Training Accuracy:0.8991935483870968\n",
            "1984/4708 - The training loss at 35th epoch : 0.07646042586268809  Training Accuracy:0.899\n",
            "2000/4708 - The training loss at 35th epoch : 0.07633538025307612  Training Accuracy:0.8993055555555556\n",
            "2016/4708 - The training loss at 35th epoch : 0.0759296923042909  Training Accuracy:0.8996062992125984\n",
            "2032/4708 - The training loss at 35th epoch : 0.07558732684966497  Training Accuracy:0.89990234375\n",
            "2048/4708 - The training loss at 35th epoch : 0.07537812043927469  Training Accuracy:0.9001937984496124\n",
            "2064/4708 - The training loss at 35th epoch : 0.07494731334716985  Training Accuracy:0.9009615384615385\n",
            "2080/4708 - The training loss at 35th epoch : 0.07445948863391709  Training Accuracy:0.9017175572519084\n",
            "2096/4708 - The training loss at 35th epoch : 0.07402788911477978  Training Accuracy:0.9024621212121212\n",
            "2112/4708 - The training loss at 35th epoch : 0.0738208363577853  Training Accuracy:0.9027255639097744\n",
            "2128/4708 - The training loss at 35th epoch : 0.07446662806879242  Training Accuracy:0.9020522388059702\n",
            "2144/4708 - The training loss at 35th epoch : 0.07480145087830231  Training Accuracy:0.9018518518518519\n",
            "2160/4708 - The training loss at 35th epoch : 0.07442200794324431  Training Accuracy:0.9021139705882353\n",
            "2176/4708 - The training loss at 35th epoch : 0.07424580487192274  Training Accuracy:0.9019160583941606\n",
            "2192/4708 - The training loss at 35th epoch : 0.07410521270693575  Training Accuracy:0.9021739130434783\n",
            "2208/4708 - The training loss at 35th epoch : 0.07394043083810065  Training Accuracy:0.9024280575539568\n",
            "2224/4708 - The training loss at 35th epoch : 0.0741258601660059  Training Accuracy:0.9017857142857143\n",
            "2240/4708 - The training loss at 35th epoch : 0.07455034308602215  Training Accuracy:0.9011524822695035\n",
            "2256/4708 - The training loss at 35th epoch : 0.0748850326280417  Training Accuracy:0.9005281690140845\n",
            "2272/4708 - The training loss at 35th epoch : 0.07474029345298329  Training Accuracy:0.9003496503496503\n",
            "2288/4708 - The training loss at 35th epoch : 0.07442556636389792  Training Accuracy:0.9006076388888888\n",
            "2304/4708 - The training loss at 35th epoch : 0.07466642793637865  Training Accuracy:0.9004310344827586\n",
            "2320/4708 - The training loss at 35th epoch : 0.0742033763746372  Training Accuracy:0.9011130136986302\n",
            "2336/4708 - The training loss at 35th epoch : 0.07418111616730308  Training Accuracy:0.9009353741496599\n",
            "2352/4708 - The training loss at 35th epoch : 0.07405322525170904  Training Accuracy:0.9011824324324325\n",
            "2368/4708 - The training loss at 35th epoch : 0.07410449964546788  Training Accuracy:0.9010067114093959\n",
            "2384/4708 - The training loss at 35th epoch : 0.07401337597502246  Training Accuracy:0.9008333333333334\n",
            "2400/4708 - The training loss at 35th epoch : 0.07356730708154136  Training Accuracy:0.9014900662251656\n",
            "2416/4708 - The training loss at 35th epoch : 0.07343429308310136  Training Accuracy:0.9013157894736842\n",
            "2432/4708 - The training loss at 35th epoch : 0.07355897410650193  Training Accuracy:0.9011437908496732\n",
            "2448/4708 - The training loss at 35th epoch : 0.07370134470318926  Training Accuracy:0.900974025974026\n",
            "2464/4708 - The training loss at 35th epoch : 0.07362401182105556  Training Accuracy:0.9012096774193549\n",
            "2480/4708 - The training loss at 35th epoch : 0.07394542941858295  Training Accuracy:0.9006410256410257\n",
            "2496/4708 - The training loss at 35th epoch : 0.074195622877187  Training Accuracy:0.9004777070063694\n",
            "2512/4708 - The training loss at 35th epoch : 0.07462091532500338  Training Accuracy:0.8999208860759493\n",
            "2528/4708 - The training loss at 35th epoch : 0.07499777966206676  Training Accuracy:0.8989779874213837\n",
            "2544/4708 - The training loss at 35th epoch : 0.07460635888490634  Training Accuracy:0.899609375\n",
            "2560/4708 - The training loss at 35th epoch : 0.0743390239195536  Training Accuracy:0.9002329192546584\n",
            "2576/4708 - The training loss at 35th epoch : 0.07477565111490543  Training Accuracy:0.8996913580246914\n",
            "2592/4708 - The training loss at 35th epoch : 0.07472465589289892  Training Accuracy:0.8999233128834356\n",
            "2608/4708 - The training loss at 35th epoch : 0.07503230698721877  Training Accuracy:0.8990091463414634\n",
            "2624/4708 - The training loss at 35th epoch : 0.07480992546257025  Training Accuracy:0.8992424242424243\n",
            "2640/4708 - The training loss at 35th epoch : 0.07475410189286284  Training Accuracy:0.8994728915662651\n",
            "2656/4708 - The training loss at 35th epoch : 0.0748833253703709  Training Accuracy:0.8993263473053892\n",
            "2672/4708 - The training loss at 35th epoch : 0.075154600540235  Training Accuracy:0.8991815476190477\n",
            "2688/4708 - The training loss at 35th epoch : 0.07487878127309189  Training Accuracy:0.8994082840236687\n",
            "2704/4708 - The training loss at 35th epoch : 0.07497589927329792  Training Accuracy:0.899264705882353\n",
            "2720/4708 - The training loss at 35th epoch : 0.07490912531385835  Training Accuracy:0.8991228070175439\n",
            "2736/4708 - The training loss at 35th epoch : 0.07503863829156406  Training Accuracy:0.8989825581395349\n",
            "2752/4708 - The training loss at 35th epoch : 0.07528579940975644  Training Accuracy:0.8988439306358381\n",
            "2768/4708 - The training loss at 35th epoch : 0.07526400566274294  Training Accuracy:0.899066091954023\n",
            "2784/4708 - The training loss at 35th epoch : 0.07528820648727441  Training Accuracy:0.8992857142857142\n",
            "2800/4708 - The training loss at 35th epoch : 0.07586809349986114  Training Accuracy:0.8987926136363636\n",
            "2816/4708 - The training loss at 35th epoch : 0.07684118536766227  Training Accuracy:0.8975988700564972\n",
            "2832/4708 - The training loss at 35th epoch : 0.07721037994403611  Training Accuracy:0.8971207865168539\n",
            "2848/4708 - The training loss at 35th epoch : 0.07715246446712419  Training Accuracy:0.8969972067039106\n",
            "2864/4708 - The training loss at 35th epoch : 0.07708948117673649  Training Accuracy:0.896875\n",
            "2880/4708 - The training loss at 35th epoch : 0.07688915545865271  Training Accuracy:0.8970994475138122\n",
            "2896/4708 - The training loss at 35th epoch : 0.07733830877334219  Training Accuracy:0.8966346153846154\n",
            "2912/4708 - The training loss at 35th epoch : 0.07740978205383037  Training Accuracy:0.8965163934426229\n",
            "2928/4708 - The training loss at 35th epoch : 0.077662462147268  Training Accuracy:0.8960597826086957\n",
            "2944/4708 - The training loss at 35th epoch : 0.07760651027290563  Training Accuracy:0.8962837837837838\n",
            "2960/4708 - The training loss at 35th epoch : 0.07757360384774624  Training Accuracy:0.8961693548387096\n",
            "2976/4708 - The training loss at 35th epoch : 0.07740119282927393  Training Accuracy:0.8963903743315508\n",
            "2992/4708 - The training loss at 35th epoch : 0.07751114275277377  Training Accuracy:0.8959441489361702\n",
            "3008/4708 - The training loss at 35th epoch : 0.07767032532380623  Training Accuracy:0.8958333333333334\n",
            "3024/4708 - The training loss at 35th epoch : 0.07761530261494158  Training Accuracy:0.8960526315789473\n",
            "3040/4708 - The training loss at 35th epoch : 0.07735934133401753  Training Accuracy:0.8965968586387435\n",
            "3056/4708 - The training loss at 35th epoch : 0.07776314060458493  Training Accuracy:0.8958333333333334\n",
            "3072/4708 - The training loss at 35th epoch : 0.07764256830238651  Training Accuracy:0.8960492227979274\n",
            "3088/4708 - The training loss at 35th epoch : 0.07735891347889988  Training Accuracy:0.8965850515463918\n",
            "3104/4708 - The training loss at 35th epoch : 0.07725945301675112  Training Accuracy:0.896474358974359\n",
            "3120/4708 - The training loss at 35th epoch : 0.07764191266352151  Training Accuracy:0.8960459183673469\n",
            "3136/4708 - The training loss at 35th epoch : 0.07738329505644373  Training Accuracy:0.8965736040609137\n",
            "3152/4708 - The training loss at 35th epoch : 0.07759320099524215  Training Accuracy:0.8964646464646465\n",
            "3168/4708 - The training loss at 35th epoch : 0.07727608080885319  Training Accuracy:0.8969849246231156\n",
            "3184/4708 - The training loss at 35th epoch : 0.07768535526736424  Training Accuracy:0.89625\n",
            "3200/4708 - The training loss at 35th epoch : 0.07748624084050297  Training Accuracy:0.8967661691542289\n",
            "3216/4708 - The training loss at 35th epoch : 0.07725842170581451  Training Accuracy:0.8972772277227723\n",
            "3232/4708 - The training loss at 35th epoch : 0.07698563999703124  Training Accuracy:0.8974753694581281\n",
            "3248/4708 - The training loss at 35th epoch : 0.07731893174188699  Training Accuracy:0.8970588235294118\n",
            "3264/4708 - The training loss at 35th epoch : 0.07740790321823768  Training Accuracy:0.8969512195121951\n",
            "3280/4708 - The training loss at 35th epoch : 0.07729736846021075  Training Accuracy:0.8971480582524272\n",
            "3296/4708 - The training loss at 35th epoch : 0.07746173854400834  Training Accuracy:0.8970410628019324\n",
            "3312/4708 - The training loss at 35th epoch : 0.07772796518521155  Training Accuracy:0.8966346153846154\n",
            "3328/4708 - The training loss at 35th epoch : 0.07788237206928081  Training Accuracy:0.8965311004784688\n",
            "3344/4708 - The training loss at 35th epoch : 0.07774333930412756  Training Accuracy:0.8964285714285715\n",
            "3360/4708 - The training loss at 35th epoch : 0.07788441816775099  Training Accuracy:0.8960308056872038\n",
            "3376/4708 - The training loss at 35th epoch : 0.077826102229888  Training Accuracy:0.8956367924528302\n",
            "3392/4708 - The training loss at 35th epoch : 0.07755226602086508  Training Accuracy:0.8961267605633803\n",
            "3408/4708 - The training loss at 35th epoch : 0.07754195328262618  Training Accuracy:0.8960280373831776\n",
            "3424/4708 - The training loss at 35th epoch : 0.07765283925409175  Training Accuracy:0.8959302325581395\n",
            "3440/4708 - The training loss at 35th epoch : 0.0775457099370829  Training Accuracy:0.8961226851851852\n",
            "3456/4708 - The training loss at 35th epoch : 0.07758302182768374  Training Accuracy:0.8957373271889401\n",
            "3472/4708 - The training loss at 35th epoch : 0.07741365110044152  Training Accuracy:0.8959288990825688\n",
            "3488/4708 - The training loss at 35th epoch : 0.0773666647287159  Training Accuracy:0.8961187214611872\n",
            "3504/4708 - The training loss at 35th epoch : 0.07720034518765928  Training Accuracy:0.8963068181818182\n",
            "3520/4708 - The training loss at 35th epoch : 0.07725171072786455  Training Accuracy:0.896210407239819\n",
            "3536/4708 - The training loss at 35th epoch : 0.07721820027963115  Training Accuracy:0.8963963963963963\n",
            "3552/4708 - The training loss at 35th epoch : 0.0770532643436309  Training Accuracy:0.8965807174887892\n",
            "3568/4708 - The training loss at 35th epoch : 0.07680701949024445  Training Accuracy:0.8970424107142857\n",
            "3584/4708 - The training loss at 35th epoch : 0.07655046400280491  Training Accuracy:0.8975\n",
            "3600/4708 - The training loss at 35th epoch : 0.07676944973651748  Training Accuracy:0.8971238938053098\n",
            "3616/4708 - The training loss at 35th epoch : 0.07668662427851927  Training Accuracy:0.8973017621145375\n",
            "3632/4708 - The training loss at 35th epoch : 0.07641638108064712  Training Accuracy:0.8977521929824561\n",
            "3648/4708 - The training loss at 35th epoch : 0.0762378656363043  Training Accuracy:0.8981986899563319\n",
            "3664/4708 - The training loss at 35th epoch : 0.07601664197107394  Training Accuracy:0.8983695652173913\n",
            "3680/4708 - The training loss at 35th epoch : 0.07573509700109372  Training Accuracy:0.8988095238095238\n",
            "3696/4708 - The training loss at 35th epoch : 0.07612533633199829  Training Accuracy:0.8981681034482759\n",
            "3712/4708 - The training loss at 35th epoch : 0.0758942666306505  Training Accuracy:0.8986051502145923\n",
            "3728/4708 - The training loss at 35th epoch : 0.07570853168744189  Training Accuracy:0.8990384615384616\n",
            "3744/4708 - The training loss at 35th epoch : 0.07592798075901105  Training Accuracy:0.8984042553191489\n",
            "3760/4708 - The training loss at 35th epoch : 0.07561271378306834  Training Accuracy:0.8988347457627118\n",
            "3776/4708 - The training loss at 35th epoch : 0.07559956063361603  Training Accuracy:0.8987341772151899\n",
            "3792/4708 - The training loss at 35th epoch : 0.07571366880524878  Training Accuracy:0.8983718487394958\n",
            "3808/4708 - The training loss at 35th epoch : 0.07585459303724261  Training Accuracy:0.8980125523012552\n",
            "3824/4708 - The training loss at 35th epoch : 0.07574832735255158  Training Accuracy:0.8981770833333333\n",
            "3840/4708 - The training loss at 35th epoch : 0.07607013950406434  Training Accuracy:0.8975622406639004\n",
            "3856/4708 - The training loss at 35th epoch : 0.07613848502806417  Training Accuracy:0.8974690082644629\n",
            "3872/4708 - The training loss at 35th epoch : 0.07614138084175648  Training Accuracy:0.8973765432098766\n",
            "3888/4708 - The training loss at 35th epoch : 0.07587425845848272  Training Accuracy:0.897797131147541\n",
            "3904/4708 - The training loss at 35th epoch : 0.07560477023485268  Training Accuracy:0.8982142857142857\n",
            "3920/4708 - The training loss at 35th epoch : 0.07538131165141197  Training Accuracy:0.8986280487804879\n",
            "3936/4708 - The training loss at 35th epoch : 0.07524183105282592  Training Accuracy:0.8990384615384616\n",
            "3952/4708 - The training loss at 35th epoch : 0.07554983765338882  Training Accuracy:0.8984375\n",
            "3968/4708 - The training loss at 35th epoch : 0.07536976089146441  Training Accuracy:0.8985943775100401\n",
            "3984/4708 - The training loss at 35th epoch : 0.07533662606249553  Training Accuracy:0.89875\n",
            "4000/4708 - The training loss at 35th epoch : 0.075066066996039  Training Accuracy:0.8991533864541833\n",
            "4016/4708 - The training loss at 35th epoch : 0.07486412480717589  Training Accuracy:0.8995535714285714\n",
            "4032/4708 - The training loss at 35th epoch : 0.07495117284484021  Training Accuracy:0.8994565217391305\n",
            "4048/4708 - The training loss at 35th epoch : 0.07485865745199925  Training Accuracy:0.8996062992125984\n",
            "4064/4708 - The training loss at 35th epoch : 0.07486230629215183  Training Accuracy:0.8995098039215687\n",
            "4080/4708 - The training loss at 35th epoch : 0.07488744356398225  Training Accuracy:0.899658203125\n",
            "4096/4708 - The training loss at 35th epoch : 0.07491640523810798  Training Accuracy:0.8995622568093385\n",
            "4112/4708 - The training loss at 35th epoch : 0.07496633316872343  Training Accuracy:0.8992248062015504\n",
            "4128/4708 - The training loss at 35th epoch : 0.07487061351296345  Training Accuracy:0.8993725868725869\n",
            "4144/4708 - The training loss at 35th epoch : 0.07473231751872621  Training Accuracy:0.8995192307692308\n",
            "4160/4708 - The training loss at 35th epoch : 0.07500429142709315  Training Accuracy:0.8991858237547893\n",
            "4176/4708 - The training loss at 35th epoch : 0.0751128382528294  Training Accuracy:0.8990935114503816\n",
            "4192/4708 - The training loss at 35th epoch : 0.07500256912952827  Training Accuracy:0.8990019011406845\n",
            "4208/4708 - The training loss at 35th epoch : 0.07496804364112891  Training Accuracy:0.8991477272727273\n",
            "4224/4708 - The training loss at 35th epoch : 0.07488899170227611  Training Accuracy:0.8992924528301887\n",
            "4240/4708 - The training loss at 35th epoch : 0.07491338212486269  Training Accuracy:0.8992011278195489\n",
            "4256/4708 - The training loss at 35th epoch : 0.07479278695536658  Training Accuracy:0.8993445692883895\n",
            "4272/4708 - The training loss at 35th epoch : 0.07517786935115517  Training Accuracy:0.8987873134328358\n",
            "4288/4708 - The training loss at 35th epoch : 0.07556312097365644  Training Accuracy:0.8982342007434945\n",
            "4304/4708 - The training loss at 35th epoch : 0.07541778039216877  Training Accuracy:0.8983796296296296\n",
            "4320/4708 - The training loss at 35th epoch : 0.0755617924177502  Training Accuracy:0.8978321033210332\n",
            "4336/4708 - The training loss at 35th epoch : 0.07589698208877659  Training Accuracy:0.8975183823529411\n",
            "4352/4708 - The training loss at 35th epoch : 0.07578828551048633  Training Accuracy:0.8976648351648352\n",
            "4368/4708 - The training loss at 35th epoch : 0.07558125153291487  Training Accuracy:0.8980383211678832\n",
            "4384/4708 - The training loss at 35th epoch : 0.07583168525372071  Training Accuracy:0.8977272727272727\n",
            "4400/4708 - The training loss at 35th epoch : 0.07617134259319756  Training Accuracy:0.8974184782608695\n",
            "4416/4708 - The training loss at 35th epoch : 0.07593083427890232  Training Accuracy:0.8977888086642599\n",
            "4432/4708 - The training loss at 35th epoch : 0.07566435073259886  Training Accuracy:0.8981564748201439\n",
            "4448/4708 - The training loss at 35th epoch : 0.0755666936206417  Training Accuracy:0.8982974910394266\n",
            "4464/4708 - The training loss at 35th epoch : 0.07583227721807488  Training Accuracy:0.8979910714285714\n",
            "4480/4708 - The training loss at 35th epoch : 0.07562183973531925  Training Accuracy:0.8983540925266904\n",
            "4496/4708 - The training loss at 35th epoch : 0.07563763135167254  Training Accuracy:0.8982712765957447\n",
            "4512/4708 - The training loss at 35th epoch : 0.0756444692885004  Training Accuracy:0.8981890459363958\n",
            "4528/4708 - The training loss at 35th epoch : 0.07559433753291771  Training Accuracy:0.8983274647887324\n",
            "4544/4708 - The training loss at 35th epoch : 0.07548526774309029  Training Accuracy:0.8984649122807018\n",
            "4560/4708 - The training loss at 35th epoch : 0.07586912724155785  Training Accuracy:0.8979458041958042\n",
            "4576/4708 - The training loss at 35th epoch : 0.07618293092941775  Training Accuracy:0.8974303135888502\n",
            "4592/4708 - The training loss at 35th epoch : 0.07617136884634726  Training Accuracy:0.8975694444444444\n",
            "4608/4708 - The training loss at 35th epoch : 0.07661979600492848  Training Accuracy:0.8968425605536332\n",
            "4624/4708 - The training loss at 35th epoch : 0.07654532393213345  Training Accuracy:0.8969827586206897\n",
            "4640/4708 - The training loss at 35th epoch : 0.07629930175504031  Training Accuracy:0.8973367697594502\n",
            "4656/4708 - The training loss at 35th epoch : 0.07618456335355142  Training Accuracy:0.8974743150684932\n",
            "4672/4708 - The training loss at 35th epoch : 0.07595889100387092  Training Accuracy:0.8978242320819113\n",
            "4688/4708 - The training loss at 35th epoch : 0.0759883744056604  Training Accuracy:0.8977465986394558\n",
            "4704/4708 - The training loss at 35th epoch : 0.07608502146151856  Training Accuracy:0.8974576271186441\n",
            "4720/4708 - The training loss at 35th epoch : 0.07602058556300517  Training Accuracy:0.8975929054054054\n",
            "-----------------------------------------------------------\n",
            "0/4708 - The training loss at 36th epoch : 0.02082139647847797  Training Accuracy:1.0\n",
            "16/4708 - The training loss at 36th epoch : 0.03804115946929651  Training Accuracy:0.96875\n",
            "32/4708 - The training loss at 36th epoch : 0.0323389658785987  Training Accuracy:0.9791666666666666\n",
            "48/4708 - The training loss at 36th epoch : 0.05783793455472855  Training Accuracy:0.953125\n",
            "64/4708 - The training loss at 36th epoch : 0.05792515239947178  Training Accuracy:0.95\n",
            "80/4708 - The training loss at 36th epoch : 0.06324925271879188  Training Accuracy:0.9479166666666666\n",
            "96/4708 - The training loss at 36th epoch : 0.06264401785993035  Training Accuracy:0.9464285714285714\n",
            "112/4708 - The training loss at 36th epoch : 0.06229260403665954  Training Accuracy:0.953125\n",
            "128/4708 - The training loss at 36th epoch : 0.06769333727972927  Training Accuracy:0.9375\n",
            "144/4708 - The training loss at 36th epoch : 0.06464907755053662  Training Accuracy:0.9375\n",
            "160/4708 - The training loss at 36th epoch : 0.06503977275684356  Training Accuracy:0.9375\n",
            "176/4708 - The training loss at 36th epoch : 0.06648278810186639  Training Accuracy:0.9322916666666666\n",
            "192/4708 - The training loss at 36th epoch : 0.06164538550734912  Training Accuracy:0.9375\n",
            "208/4708 - The training loss at 36th epoch : 0.06635686230738978  Training Accuracy:0.9285714285714286\n",
            "224/4708 - The training loss at 36th epoch : 0.06293711243201869  Training Accuracy:0.9333333333333333\n",
            "240/4708 - The training loss at 36th epoch : 0.06301988862181515  Training Accuracy:0.9296875\n",
            "256/4708 - The training loss at 36th epoch : 0.06492018109461606  Training Accuracy:0.9264705882352942\n",
            "272/4708 - The training loss at 36th epoch : 0.06921790594236406  Training Accuracy:0.9166666666666666\n",
            "288/4708 - The training loss at 36th epoch : 0.06732182432352389  Training Accuracy:0.9210526315789473\n",
            "304/4708 - The training loss at 36th epoch : 0.06780473478725654  Training Accuracy:0.91875\n",
            "320/4708 - The training loss at 36th epoch : 0.07002398653424838  Training Accuracy:0.9107142857142857\n",
            "336/4708 - The training loss at 36th epoch : 0.07091192100669709  Training Accuracy:0.9090909090909091\n",
            "352/4708 - The training loss at 36th epoch : 0.06964966223140681  Training Accuracy:0.9103260869565217\n",
            "368/4708 - The training loss at 36th epoch : 0.06711743981660008  Training Accuracy:0.9140625\n",
            "384/4708 - The training loss at 36th epoch : 0.0681240154803792  Training Accuracy:0.915\n",
            "400/4708 - The training loss at 36th epoch : 0.0697840155701537  Training Accuracy:0.9110576923076923\n",
            "416/4708 - The training loss at 36th epoch : 0.07209031552604049  Training Accuracy:0.9074074074074074\n",
            "432/4708 - The training loss at 36th epoch : 0.07038444408482823  Training Accuracy:0.9084821428571429\n",
            "448/4708 - The training loss at 36th epoch : 0.07373644456523781  Training Accuracy:0.9051724137931034\n",
            "464/4708 - The training loss at 36th epoch : 0.07658449505362894  Training Accuracy:0.9020833333333333\n",
            "480/4708 - The training loss at 36th epoch : 0.08083078411719109  Training Accuracy:0.8971774193548387\n",
            "496/4708 - The training loss at 36th epoch : 0.08148837815775462  Training Accuracy:0.896484375\n",
            "512/4708 - The training loss at 36th epoch : 0.08174436917867654  Training Accuracy:0.8939393939393939\n",
            "528/4708 - The training loss at 36th epoch : 0.08222694271818741  Training Accuracy:0.8915441176470589\n",
            "544/4708 - The training loss at 36th epoch : 0.08400822170710952  Training Accuracy:0.8892857142857142\n",
            "560/4708 - The training loss at 36th epoch : 0.0833214928973798  Training Accuracy:0.8888888888888888\n",
            "576/4708 - The training loss at 36th epoch : 0.08138713786350615  Training Accuracy:0.8918918918918919\n",
            "592/4708 - The training loss at 36th epoch : 0.08125508433485726  Training Accuracy:0.8930921052631579\n",
            "608/4708 - The training loss at 36th epoch : 0.08227729507508402  Training Accuracy:0.8926282051282052\n",
            "624/4708 - The training loss at 36th epoch : 0.08162523329629039  Training Accuracy:0.89375\n",
            "640/4708 - The training loss at 36th epoch : 0.08105195907552049  Training Accuracy:0.8948170731707317\n",
            "656/4708 - The training loss at 36th epoch : 0.08271957045161553  Training Accuracy:0.8928571428571429\n",
            "672/4708 - The training loss at 36th epoch : 0.08199946945732851  Training Accuracy:0.8938953488372093\n",
            "688/4708 - The training loss at 36th epoch : 0.08220237948763745  Training Accuracy:0.8934659090909091\n",
            "704/4708 - The training loss at 36th epoch : 0.08052628757280204  Training Accuracy:0.8958333333333334\n",
            "720/4708 - The training loss at 36th epoch : 0.08062596335599415  Training Accuracy:0.8953804347826086\n",
            "736/4708 - The training loss at 36th epoch : 0.07982085891224504  Training Accuracy:0.8962765957446809\n",
            "752/4708 - The training loss at 36th epoch : 0.07841331586321802  Training Accuracy:0.8984375\n",
            "768/4708 - The training loss at 36th epoch : 0.0781550072595248  Training Accuracy:0.8992346938775511\n",
            "784/4708 - The training loss at 36th epoch : 0.07826056169917134  Training Accuracy:0.8975\n",
            "800/4708 - The training loss at 36th epoch : 0.0788607952234916  Training Accuracy:0.8958333333333334\n",
            "816/4708 - The training loss at 36th epoch : 0.07793003576867076  Training Accuracy:0.8966346153846154\n",
            "832/4708 - The training loss at 36th epoch : 0.07802570330506675  Training Accuracy:0.8950471698113207\n",
            "848/4708 - The training loss at 36th epoch : 0.07841117186673766  Training Accuracy:0.8946759259259259\n",
            "864/4708 - The training loss at 36th epoch : 0.07869450797090241  Training Accuracy:0.8931818181818182\n",
            "880/4708 - The training loss at 36th epoch : 0.0774782044017992  Training Accuracy:0.8950892857142857\n",
            "896/4708 - The training loss at 36th epoch : 0.07818007897643628  Training Accuracy:0.893640350877193\n",
            "912/4708 - The training loss at 36th epoch : 0.07710144705037193  Training Accuracy:0.8954741379310345\n",
            "928/4708 - The training loss at 36th epoch : 0.0764447657800476  Training Accuracy:0.8961864406779662\n",
            "944/4708 - The training loss at 36th epoch : 0.07643191319765807  Training Accuracy:0.8958333333333334\n",
            "960/4708 - The training loss at 36th epoch : 0.07661851635379742  Training Accuracy:0.8965163934426229\n",
            "976/4708 - The training loss at 36th epoch : 0.07716206611163622  Training Accuracy:0.8961693548387096\n",
            "992/4708 - The training loss at 36th epoch : 0.07611952789406531  Training Accuracy:0.8978174603174603\n",
            "1008/4708 - The training loss at 36th epoch : 0.07672134242529788  Training Accuracy:0.8974609375\n",
            "1024/4708 - The training loss at 36th epoch : 0.07709084919103677  Training Accuracy:0.8961538461538462\n",
            "1040/4708 - The training loss at 36th epoch : 0.07619415647562347  Training Accuracy:0.8977272727272727\n",
            "1056/4708 - The training loss at 36th epoch : 0.07710644877631888  Training Accuracy:0.8964552238805971\n",
            "1072/4708 - The training loss at 36th epoch : 0.0766214910363986  Training Accuracy:0.8970588235294118\n",
            "1088/4708 - The training loss at 36th epoch : 0.07756693216175331  Training Accuracy:0.894927536231884\n",
            "1104/4708 - The training loss at 36th epoch : 0.07785005222113937  Training Accuracy:0.8946428571428572\n",
            "1120/4708 - The training loss at 36th epoch : 0.07738254582799053  Training Accuracy:0.8952464788732394\n",
            "1136/4708 - The training loss at 36th epoch : 0.07663902019305634  Training Accuracy:0.8967013888888888\n",
            "1152/4708 - The training loss at 36th epoch : 0.07586518424931461  Training Accuracy:0.8981164383561644\n",
            "1168/4708 - The training loss at 36th epoch : 0.07575322826676725  Training Accuracy:0.8986486486486487\n",
            "1184/4708 - The training loss at 36th epoch : 0.07668346497752265  Training Accuracy:0.8966666666666666\n",
            "1200/4708 - The training loss at 36th epoch : 0.07681082771363992  Training Accuracy:0.8963815789473685\n",
            "1216/4708 - The training loss at 36th epoch : 0.07654235747815705  Training Accuracy:0.8969155844155844\n",
            "1232/4708 - The training loss at 36th epoch : 0.07644760735022124  Training Accuracy:0.8966346153846154\n",
            "1248/4708 - The training loss at 36th epoch : 0.0765294650424568  Training Accuracy:0.8955696202531646\n",
            "1264/4708 - The training loss at 36th epoch : 0.07640400719071799  Training Accuracy:0.89609375\n",
            "1280/4708 - The training loss at 36th epoch : 0.0758026682024522  Training Accuracy:0.8973765432098766\n",
            "1296/4708 - The training loss at 36th epoch : 0.0753303394375476  Training Accuracy:0.8978658536585366\n",
            "1312/4708 - The training loss at 36th epoch : 0.0752058140061963  Training Accuracy:0.8983433734939759\n",
            "1328/4708 - The training loss at 36th epoch : 0.0768919727151596  Training Accuracy:0.8965773809523809\n",
            "1344/4708 - The training loss at 36th epoch : 0.0769044500566122  Training Accuracy:0.8963235294117647\n",
            "1360/4708 - The training loss at 36th epoch : 0.07698925372059816  Training Accuracy:0.8968023255813954\n",
            "1376/4708 - The training loss at 36th epoch : 0.07700391387919148  Training Accuracy:0.896551724137931\n",
            "1392/4708 - The training loss at 36th epoch : 0.07754900795480353  Training Accuracy:0.8963068181818182\n",
            "1408/4708 - The training loss at 36th epoch : 0.07731046489711822  Training Accuracy:0.8960674157303371\n",
            "1424/4708 - The training loss at 36th epoch : 0.07709332374980075  Training Accuracy:0.8958333333333334\n",
            "1440/4708 - The training loss at 36th epoch : 0.07697473544575117  Training Accuracy:0.8956043956043956\n",
            "1456/4708 - The training loss at 36th epoch : 0.07697633458983524  Training Accuracy:0.8960597826086957\n",
            "1472/4708 - The training loss at 36th epoch : 0.07682694203860062  Training Accuracy:0.896505376344086\n",
            "1488/4708 - The training loss at 36th epoch : 0.07716689476469543  Training Accuracy:0.8962765957446809\n",
            "1504/4708 - The training loss at 36th epoch : 0.07702050385180266  Training Accuracy:0.8967105263157895\n",
            "1520/4708 - The training loss at 36th epoch : 0.07671486930100942  Training Accuracy:0.896484375\n",
            "1536/4708 - The training loss at 36th epoch : 0.07668690782244182  Training Accuracy:0.8962628865979382\n",
            "1552/4708 - The training loss at 36th epoch : 0.07634162058056458  Training Accuracy:0.8973214285714286\n",
            "1568/4708 - The training loss at 36th epoch : 0.0764759442850671  Training Accuracy:0.8970959595959596\n",
            "1584/4708 - The training loss at 36th epoch : 0.07628132372560718  Training Accuracy:0.8975\n",
            "1600/4708 - The training loss at 36th epoch : 0.07578767803699625  Training Accuracy:0.8978960396039604\n",
            "1616/4708 - The training loss at 36th epoch : 0.0760567200731669  Training Accuracy:0.897671568627451\n",
            "1632/4708 - The training loss at 36th epoch : 0.07719414825506159  Training Accuracy:0.8962378640776699\n",
            "1648/4708 - The training loss at 36th epoch : 0.07707340201873586  Training Accuracy:0.8966346153846154\n",
            "1664/4708 - The training loss at 36th epoch : 0.07694513561367945  Training Accuracy:0.8970238095238096\n",
            "1680/4708 - The training loss at 36th epoch : 0.07668892001941881  Training Accuracy:0.8968160377358491\n",
            "1696/4708 - The training loss at 36th epoch : 0.07655759441512866  Training Accuracy:0.897196261682243\n",
            "1712/4708 - The training loss at 36th epoch : 0.07627794578326377  Training Accuracy:0.8969907407407407\n",
            "1728/4708 - The training loss at 36th epoch : 0.076579425428782  Training Accuracy:0.8967889908256881\n",
            "1744/4708 - The training loss at 36th epoch : 0.07672254197814456  Training Accuracy:0.8965909090909091\n",
            "1760/4708 - The training loss at 36th epoch : 0.07688956311006098  Training Accuracy:0.8963963963963963\n",
            "1776/4708 - The training loss at 36th epoch : 0.07663639654534714  Training Accuracy:0.8967633928571429\n",
            "1792/4708 - The training loss at 36th epoch : 0.07705952788290855  Training Accuracy:0.896570796460177\n",
            "1808/4708 - The training loss at 36th epoch : 0.07753086563833399  Training Accuracy:0.8963815789473685\n",
            "1824/4708 - The training loss at 36th epoch : 0.07838540726575263  Training Accuracy:0.8956521739130435\n",
            "1840/4708 - The training loss at 36th epoch : 0.07837333942313782  Training Accuracy:0.8960129310344828\n",
            "1856/4708 - The training loss at 36th epoch : 0.07827074792481027  Training Accuracy:0.8963675213675214\n",
            "1872/4708 - The training loss at 36th epoch : 0.07761750970852926  Training Accuracy:0.8972457627118644\n",
            "1888/4708 - The training loss at 36th epoch : 0.07798601290093073  Training Accuracy:0.8965336134453782\n",
            "1904/4708 - The training loss at 36th epoch : 0.07755178686584457  Training Accuracy:0.8973958333333333\n",
            "1920/4708 - The training loss at 36th epoch : 0.07736321731575009  Training Accuracy:0.8977272727272727\n",
            "1936/4708 - The training loss at 36th epoch : 0.07684116499227353  Training Accuracy:0.8985655737704918\n",
            "1952/4708 - The training loss at 36th epoch : 0.07693178066394733  Training Accuracy:0.8978658536585366\n",
            "1968/4708 - The training loss at 36th epoch : 0.07648193725217992  Training Accuracy:0.8986895161290323\n",
            "1984/4708 - The training loss at 36th epoch : 0.07743450797346225  Training Accuracy:0.8975\n",
            "2000/4708 - The training loss at 36th epoch : 0.07716943238380837  Training Accuracy:0.8978174603174603\n",
            "2016/4708 - The training loss at 36th epoch : 0.0769847397935488  Training Accuracy:0.8976377952755905\n",
            "2032/4708 - The training loss at 36th epoch : 0.07696663575147625  Training Accuracy:0.8974609375\n",
            "2048/4708 - The training loss at 36th epoch : 0.07702468973010468  Training Accuracy:0.8977713178294574\n",
            "2064/4708 - The training loss at 36th epoch : 0.07686561438856263  Training Accuracy:0.8975961538461539\n",
            "2080/4708 - The training loss at 36th epoch : 0.07653653359803018  Training Accuracy:0.8979007633587787\n",
            "2096/4708 - The training loss at 36th epoch : 0.07630772275038543  Training Accuracy:0.8982007575757576\n",
            "2112/4708 - The training loss at 36th epoch : 0.07581826694323213  Training Accuracy:0.8989661654135338\n",
            "2128/4708 - The training loss at 36th epoch : 0.07578037241111987  Training Accuracy:0.8987873134328358\n",
            "2144/4708 - The training loss at 36th epoch : 0.07543268433327836  Training Accuracy:0.899537037037037\n",
            "2160/4708 - The training loss at 36th epoch : 0.07615716739409006  Training Accuracy:0.8984375\n",
            "2176/4708 - The training loss at 36th epoch : 0.0759945871374792  Training Accuracy:0.8987226277372263\n",
            "2192/4708 - The training loss at 36th epoch : 0.07580230299583363  Training Accuracy:0.8990036231884058\n",
            "2208/4708 - The training loss at 36th epoch : 0.07582210152768346  Training Accuracy:0.8992805755395683\n",
            "2224/4708 - The training loss at 36th epoch : 0.07644458300010111  Training Accuracy:0.8986607142857143\n",
            "2240/4708 - The training loss at 36th epoch : 0.07660870540048643  Training Accuracy:0.8984929078014184\n",
            "2256/4708 - The training loss at 36th epoch : 0.07648102295823923  Training Accuracy:0.8987676056338029\n",
            "2272/4708 - The training loss at 36th epoch : 0.07703107045903507  Training Accuracy:0.8977272727272727\n",
            "2288/4708 - The training loss at 36th epoch : 0.07699800749388234  Training Accuracy:0.8980034722222222\n",
            "2304/4708 - The training loss at 36th epoch : 0.07783192031509342  Training Accuracy:0.8974137931034483\n",
            "2320/4708 - The training loss at 36th epoch : 0.07786428192110231  Training Accuracy:0.8972602739726028\n",
            "2336/4708 - The training loss at 36th epoch : 0.07778856557494716  Training Accuracy:0.8971088435374149\n",
            "2352/4708 - The training loss at 36th epoch : 0.07781417352087909  Training Accuracy:0.8969594594594594\n",
            "2368/4708 - The training loss at 36th epoch : 0.07765356641091431  Training Accuracy:0.897231543624161\n",
            "2384/4708 - The training loss at 36th epoch : 0.07750368414955316  Training Accuracy:0.8975\n",
            "2400/4708 - The training loss at 36th epoch : 0.07768052606729407  Training Accuracy:0.8969370860927153\n",
            "2416/4708 - The training loss at 36th epoch : 0.07790832996153911  Training Accuracy:0.8963815789473685\n",
            "2432/4708 - The training loss at 36th epoch : 0.07806114082020336  Training Accuracy:0.8962418300653595\n",
            "2448/4708 - The training loss at 36th epoch : 0.07797776932407913  Training Accuracy:0.8961038961038961\n",
            "2464/4708 - The training loss at 36th epoch : 0.07772608536370605  Training Accuracy:0.8963709677419355\n",
            "2480/4708 - The training loss at 36th epoch : 0.07773547388357836  Training Accuracy:0.8966346153846154\n",
            "2496/4708 - The training loss at 36th epoch : 0.07764098973871568  Training Accuracy:0.8968949044585988\n",
            "2512/4708 - The training loss at 36th epoch : 0.07715534171739231  Training Accuracy:0.8975474683544303\n",
            "2528/4708 - The training loss at 36th epoch : 0.07700008615196131  Training Accuracy:0.8974056603773585\n",
            "2544/4708 - The training loss at 36th epoch : 0.07717255350839661  Training Accuracy:0.896875\n",
            "2560/4708 - The training loss at 36th epoch : 0.07683584910348418  Training Accuracy:0.8975155279503105\n",
            "2576/4708 - The training loss at 36th epoch : 0.07711977332432031  Training Accuracy:0.8969907407407407\n",
            "2592/4708 - The training loss at 36th epoch : 0.07690613810700009  Training Accuracy:0.897239263803681\n",
            "2608/4708 - The training loss at 36th epoch : 0.07657155709070129  Training Accuracy:0.8978658536585366\n",
            "2624/4708 - The training loss at 36th epoch : 0.07644372571770153  Training Accuracy:0.8981060606060606\n",
            "2640/4708 - The training loss at 36th epoch : 0.07623971543928833  Training Accuracy:0.8983433734939759\n",
            "2656/4708 - The training loss at 36th epoch : 0.07622696018397099  Training Accuracy:0.8985778443113772\n",
            "2672/4708 - The training loss at 36th epoch : 0.07600768955790531  Training Accuracy:0.8988095238095238\n",
            "2688/4708 - The training loss at 36th epoch : 0.0760272729039673  Training Accuracy:0.8986686390532544\n",
            "2704/4708 - The training loss at 36th epoch : 0.0756440428205053  Training Accuracy:0.899264705882353\n",
            "2720/4708 - The training loss at 36th epoch : 0.07538922371938626  Training Accuracy:0.8994883040935673\n",
            "2736/4708 - The training loss at 36th epoch : 0.07538985300873442  Training Accuracy:0.8989825581395349\n",
            "2752/4708 - The training loss at 36th epoch : 0.07555632385747947  Training Accuracy:0.8984826589595376\n",
            "2768/4708 - The training loss at 36th epoch : 0.07588901617982519  Training Accuracy:0.8976293103448276\n",
            "2784/4708 - The training loss at 36th epoch : 0.07568977926877013  Training Accuracy:0.8978571428571429\n",
            "2800/4708 - The training loss at 36th epoch : 0.07556630369229725  Training Accuracy:0.8980823863636364\n",
            "2816/4708 - The training loss at 36th epoch : 0.07517871643211213  Training Accuracy:0.8986581920903954\n",
            "2832/4708 - The training loss at 36th epoch : 0.07528939415960686  Training Accuracy:0.8985252808988764\n",
            "2848/4708 - The training loss at 36th epoch : 0.0754296457789754  Training Accuracy:0.8980446927374302\n",
            "2864/4708 - The training loss at 36th epoch : 0.07522830080599606  Training Accuracy:0.8982638888888889\n",
            "2880/4708 - The training loss at 36th epoch : 0.07533136214051579  Training Accuracy:0.898135359116022\n",
            "2896/4708 - The training loss at 36th epoch : 0.07502529141368423  Training Accuracy:0.898695054945055\n",
            "2912/4708 - The training loss at 36th epoch : 0.07508792148037775  Training Accuracy:0.8985655737704918\n",
            "2928/4708 - The training loss at 36th epoch : 0.0756267092511379  Training Accuracy:0.8980978260869565\n",
            "2944/4708 - The training loss at 36th epoch : 0.07529040394482175  Training Accuracy:0.8986486486486487\n",
            "2960/4708 - The training loss at 36th epoch : 0.07524227793526943  Training Accuracy:0.8985215053763441\n",
            "2976/4708 - The training loss at 36th epoch : 0.07511369879058016  Training Accuracy:0.8983957219251337\n",
            "2992/4708 - The training loss at 36th epoch : 0.07513258576000094  Training Accuracy:0.8986037234042553\n",
            "3008/4708 - The training loss at 36th epoch : 0.0751449816965773  Training Accuracy:0.8988095238095238\n",
            "3024/4708 - The training loss at 36th epoch : 0.07504602989391819  Training Accuracy:0.8990131578947368\n",
            "3040/4708 - The training loss at 36th epoch : 0.07466596478937759  Training Accuracy:0.8995418848167539\n",
            "3056/4708 - The training loss at 36th epoch : 0.07472823051308024  Training Accuracy:0.8994140625\n",
            "3072/4708 - The training loss at 36th epoch : 0.0746014429646536  Training Accuracy:0.8996113989637305\n",
            "3088/4708 - The training loss at 36th epoch : 0.07457178282675052  Training Accuracy:0.8998067010309279\n",
            "3104/4708 - The training loss at 36th epoch : 0.07427740785871499  Training Accuracy:0.9003205128205128\n",
            "3120/4708 - The training loss at 36th epoch : 0.0739581246223029  Training Accuracy:0.9008290816326531\n",
            "3136/4708 - The training loss at 36th epoch : 0.07408816146389112  Training Accuracy:0.9006979695431472\n",
            "3152/4708 - The training loss at 36th epoch : 0.07402144819279247  Training Accuracy:0.9008838383838383\n",
            "3168/4708 - The training loss at 36th epoch : 0.07458158088282164  Training Accuracy:0.9004396984924623\n",
            "3184/4708 - The training loss at 36th epoch : 0.07530606228587912  Training Accuracy:0.899375\n",
            "3200/4708 - The training loss at 36th epoch : 0.07501037955247203  Training Accuracy:0.8998756218905473\n",
            "3216/4708 - The training loss at 36th epoch : 0.07465673522044725  Training Accuracy:0.9003712871287128\n",
            "3232/4708 - The training loss at 36th epoch : 0.07477782394557478  Training Accuracy:0.9002463054187192\n",
            "3248/4708 - The training loss at 36th epoch : 0.07443691221099234  Training Accuracy:0.9007352941176471\n",
            "3264/4708 - The training loss at 36th epoch : 0.07451869443053437  Training Accuracy:0.900609756097561\n",
            "3280/4708 - The training loss at 36th epoch : 0.07432136384770913  Training Accuracy:0.9007888349514563\n",
            "3296/4708 - The training loss at 36th epoch : 0.07455036271865854  Training Accuracy:0.9006642512077294\n",
            "3312/4708 - The training loss at 36th epoch : 0.07468061796915147  Training Accuracy:0.9002403846153846\n",
            "3328/4708 - The training loss at 36th epoch : 0.07476603939782006  Training Accuracy:0.9001196172248804\n",
            "3344/4708 - The training loss at 36th epoch : 0.07447825517575549  Training Accuracy:0.9005952380952381\n",
            "3360/4708 - The training loss at 36th epoch : 0.07488801242054854  Training Accuracy:0.9001777251184834\n",
            "3376/4708 - The training loss at 36th epoch : 0.07483988525878604  Training Accuracy:0.9000589622641509\n",
            "3392/4708 - The training loss at 36th epoch : 0.07553972727167285  Training Accuracy:0.8993544600938967\n",
            "3408/4708 - The training loss at 36th epoch : 0.07530745666363359  Training Accuracy:0.8998247663551402\n",
            "3424/4708 - The training loss at 36th epoch : 0.07519064056172066  Training Accuracy:0.9\n",
            "3440/4708 - The training loss at 36th epoch : 0.07512322849445674  Training Accuracy:0.9001736111111112\n",
            "3456/4708 - The training loss at 36th epoch : 0.07506418420263693  Training Accuracy:0.9003456221198156\n",
            "3472/4708 - The training loss at 36th epoch : 0.07491088953181681  Training Accuracy:0.9005160550458715\n",
            "3488/4708 - The training loss at 36th epoch : 0.07472057307406117  Training Accuracy:0.9006849315068494\n",
            "3504/4708 - The training loss at 36th epoch : 0.07468591222138984  Training Accuracy:0.9008522727272728\n",
            "3520/4708 - The training loss at 36th epoch : 0.07481093912083125  Training Accuracy:0.9007352941176471\n",
            "3536/4708 - The training loss at 36th epoch : 0.07455251573420862  Training Accuracy:0.9011824324324325\n",
            "3552/4708 - The training loss at 36th epoch : 0.07454571043257868  Training Accuracy:0.9013452914798207\n",
            "3568/4708 - The training loss at 36th epoch : 0.07449459308825847  Training Accuracy:0.9015066964285714\n",
            "3584/4708 - The training loss at 36th epoch : 0.07433280915441165  Training Accuracy:0.9019444444444444\n",
            "3600/4708 - The training loss at 36th epoch : 0.07466851154706437  Training Accuracy:0.9015486725663717\n",
            "3616/4708 - The training loss at 36th epoch : 0.0752401938480597  Training Accuracy:0.9008810572687225\n",
            "3632/4708 - The training loss at 36th epoch : 0.07503971269057085  Training Accuracy:0.9010416666666666\n",
            "3648/4708 - The training loss at 36th epoch : 0.07484099925173616  Training Accuracy:0.9012008733624454\n",
            "3664/4708 - The training loss at 36th epoch : 0.07489086821430202  Training Accuracy:0.9010869565217391\n",
            "3680/4708 - The training loss at 36th epoch : 0.075035061271013  Training Accuracy:0.900974025974026\n",
            "3696/4708 - The training loss at 36th epoch : 0.07482785024250198  Training Accuracy:0.9011314655172413\n",
            "3712/4708 - The training loss at 36th epoch : 0.07458179327377876  Training Accuracy:0.9015557939914163\n",
            "3728/4708 - The training loss at 36th epoch : 0.07486041033857552  Training Accuracy:0.9009081196581197\n",
            "3744/4708 - The training loss at 36th epoch : 0.07484303820976211  Training Accuracy:0.9010638297872341\n",
            "3760/4708 - The training loss at 36th epoch : 0.07477126903305649  Training Accuracy:0.901218220338983\n",
            "3776/4708 - The training loss at 36th epoch : 0.07477692150754264  Training Accuracy:0.9011075949367089\n",
            "3792/4708 - The training loss at 36th epoch : 0.07457411710795628  Training Accuracy:0.9015231092436975\n",
            "3808/4708 - The training loss at 36th epoch : 0.07430896319299632  Training Accuracy:0.9019351464435147\n",
            "3824/4708 - The training loss at 36th epoch : 0.07416198168801941  Training Accuracy:0.9020833333333333\n",
            "3840/4708 - The training loss at 36th epoch : 0.07400307498127215  Training Accuracy:0.9022302904564315\n",
            "3856/4708 - The training loss at 36th epoch : 0.07379203377226846  Training Accuracy:0.9026342975206612\n",
            "3872/4708 - The training loss at 36th epoch : 0.073905346450214  Training Accuracy:0.9022633744855967\n",
            "3888/4708 - The training loss at 36th epoch : 0.07416544980017749  Training Accuracy:0.9018954918032787\n",
            "3904/4708 - The training loss at 36th epoch : 0.07413953707996034  Training Accuracy:0.9017857142857143\n",
            "3920/4708 - The training loss at 36th epoch : 0.07400456965748595  Training Accuracy:0.9019308943089431\n",
            "3936/4708 - The training loss at 36th epoch : 0.07401622818396195  Training Accuracy:0.9020748987854251\n",
            "3952/4708 - The training loss at 36th epoch : 0.07381164699182768  Training Accuracy:0.9024697580645161\n",
            "3968/4708 - The training loss at 36th epoch : 0.07399428975948731  Training Accuracy:0.902359437751004\n",
            "3984/4708 - The training loss at 36th epoch : 0.07373723969435834  Training Accuracy:0.90275\n",
            "4000/4708 - The training loss at 36th epoch : 0.07363871239724569  Training Accuracy:0.9028884462151394\n",
            "4016/4708 - The training loss at 36th epoch : 0.07361411447299732  Training Accuracy:0.9030257936507936\n",
            "4032/4708 - The training loss at 36th epoch : 0.07362025734495856  Training Accuracy:0.9029150197628458\n",
            "4048/4708 - The training loss at 36th epoch : 0.0736986422678503  Training Accuracy:0.9028051181102362\n",
            "4064/4708 - The training loss at 36th epoch : 0.07356467188668331  Training Accuracy:0.9029411764705882\n",
            "4080/4708 - The training loss at 36th epoch : 0.07362005806460739  Training Accuracy:0.90283203125\n",
            "4096/4708 - The training loss at 36th epoch : 0.0737466018236069  Training Accuracy:0.9027237354085603\n",
            "4112/4708 - The training loss at 36th epoch : 0.07382132387894737  Training Accuracy:0.9026162790697675\n",
            "4128/4708 - The training loss at 36th epoch : 0.07373719874090537  Training Accuracy:0.9027509652509652\n",
            "4144/4708 - The training loss at 36th epoch : 0.07349381064578256  Training Accuracy:0.903125\n",
            "4160/4708 - The training loss at 36th epoch : 0.0736173443473801  Training Accuracy:0.9030172413793104\n",
            "4176/4708 - The training loss at 36th epoch : 0.07369240142378265  Training Accuracy:0.9029103053435115\n",
            "4192/4708 - The training loss at 36th epoch : 0.07387073374124142  Training Accuracy:0.9025665399239544\n",
            "4208/4708 - The training loss at 36th epoch : 0.07418338879820753  Training Accuracy:0.9022253787878788\n",
            "4224/4708 - The training loss at 36th epoch : 0.07392138326765893  Training Accuracy:0.9025943396226415\n",
            "4240/4708 - The training loss at 36th epoch : 0.07400298577448232  Training Accuracy:0.9024906015037594\n",
            "4256/4708 - The training loss at 36th epoch : 0.07413501690703224  Training Accuracy:0.9023876404494382\n",
            "4272/4708 - The training loss at 36th epoch : 0.07400392097829803  Training Accuracy:0.902518656716418\n",
            "4288/4708 - The training loss at 36th epoch : 0.07389442255694528  Training Accuracy:0.9026486988847584\n",
            "4304/4708 - The training loss at 36th epoch : 0.07392014376322088  Training Accuracy:0.9025462962962963\n",
            "4320/4708 - The training loss at 36th epoch : 0.07399818162251022  Training Accuracy:0.9024446494464945\n",
            "4336/4708 - The training loss at 36th epoch : 0.07400555458941918  Training Accuracy:0.90234375\n",
            "4352/4708 - The training loss at 36th epoch : 0.07398582159785905  Training Accuracy:0.9022435897435898\n",
            "4368/4708 - The training loss at 36th epoch : 0.0739573050565984  Training Accuracy:0.9023722627737226\n",
            "4384/4708 - The training loss at 36th epoch : 0.07393766781848184  Training Accuracy:0.9022727272727272\n",
            "4400/4708 - The training loss at 36th epoch : 0.07411263754569622  Training Accuracy:0.9021739130434783\n",
            "4416/4708 - The training loss at 36th epoch : 0.07404590960371918  Training Accuracy:0.9023014440433214\n",
            "4432/4708 - The training loss at 36th epoch : 0.07414135360089834  Training Accuracy:0.9019784172661871\n",
            "4448/4708 - The training loss at 36th epoch : 0.07446505592795806  Training Accuracy:0.9014336917562724\n",
            "4464/4708 - The training loss at 36th epoch : 0.07430807826389357  Training Accuracy:0.9015625\n",
            "4480/4708 - The training loss at 36th epoch : 0.07415514243090088  Training Accuracy:0.9016903914590747\n",
            "4496/4708 - The training loss at 36th epoch : 0.07409413648306264  Training Accuracy:0.9018173758865248\n",
            "4512/4708 - The training loss at 36th epoch : 0.07405443364411711  Training Accuracy:0.9019434628975265\n",
            "4528/4708 - The training loss at 36th epoch : 0.07411632814347988  Training Accuracy:0.9018485915492958\n",
            "4544/4708 - The training loss at 36th epoch : 0.07400420702959869  Training Accuracy:0.9021929824561403\n",
            "4560/4708 - The training loss at 36th epoch : 0.07431511083448988  Training Accuracy:0.9016608391608392\n",
            "4576/4708 - The training loss at 36th epoch : 0.07447404983214212  Training Accuracy:0.9015679442508711\n",
            "4592/4708 - The training loss at 36th epoch : 0.07445703285417518  Training Accuracy:0.9016927083333334\n",
            "4608/4708 - The training loss at 36th epoch : 0.07429337486310024  Training Accuracy:0.9020328719723183\n",
            "4624/4708 - The training loss at 36th epoch : 0.07427613691457897  Training Accuracy:0.9021551724137931\n",
            "4640/4708 - The training loss at 36th epoch : 0.07428656103703546  Training Accuracy:0.9020618556701031\n",
            "4656/4708 - The training loss at 36th epoch : 0.07423745506737792  Training Accuracy:0.9021832191780822\n",
            "4672/4708 - The training loss at 36th epoch : 0.07401310411868461  Training Accuracy:0.9025170648464164\n",
            "4688/4708 - The training loss at 36th epoch : 0.07409930497048393  Training Accuracy:0.9024234693877551\n",
            "4704/4708 - The training loss at 36th epoch : 0.07393172856635995  Training Accuracy:0.9027542372881356\n",
            "4720/4708 - The training loss at 36th epoch : 0.07416318304989761  Training Accuracy:0.9024493243243243\n",
            "Training finished in 36 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**"
      ],
      "metadata": {
        "id": "FZ4aOlK2BK4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from IPython.display import display\n",
        "\n",
        "index = random.randint(0, len(test_dataset))\n",
        "\n",
        "x, y = test_dataset[index]\n",
        "display(x.resize((140, 140)))\n",
        "x = np.array(x)\n",
        "L = x.shape[0] * x.shape[1]\n",
        "x = x.reshape(1, L)/255.\n",
        "pred = model(x)\n",
        "\n",
        "pred = pred.squeeze(0)\n",
        "pred[pred>=0.5] = 1\n",
        "pred[pred<0.5] = 0\n",
        "print(\"Prediction: Pneumonia\" if pred[0] else \"Prediction: Healthy\")\n",
        "print(\"Ground Truth: Pneumonia\" if y[0] else \"Ground Truth: Healthy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "bkwd3i4_BKxB",
        "outputId": "a06552b6-4780-45fc-b419-57478c93f13b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=140x140 at 0x7F5F5872BE90>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Healthy\n",
            "Ground Truth: Healthy\n"
          ]
        }
      ]
    }
  ]
}
